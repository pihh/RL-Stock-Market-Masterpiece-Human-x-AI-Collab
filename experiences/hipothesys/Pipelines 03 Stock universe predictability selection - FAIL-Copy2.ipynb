{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33beca1f",
   "metadata": {},
   "source": [
    "# 03 - Predictability & Universe Filtering\n",
    "\n",
    "### Previously on Stock universe p. s. ...\n",
    "\n",
    "In our previous efforts to improve generalization and downstream RL performance, we attempted to:\n",
    "- Apply statistical heuristics to identify \"easier\" stocks\n",
    "- Train predictive models to uncover latent structure\n",
    "\n",
    "While these offered some insight, they lacked **robustness** and **transferability** across time.\n",
    "\n",
    "\n",
    "### What's next:\n",
    "We now shift focus toward **meta-characterizing forecastability**, moving beyond surface-level accuracy and toward deeper indicators of *learnability* and *environmental stability*.\n",
    "\n",
    "#### Meta-Features of Forecasts\n",
    "I\n",
    "Instead of evaluating only R¬≤ from one-step regressors, we now extract richer *diagnostics from forecast behavior*:\n",
    "\n",
    "- **Residual Autocorrelation**: Persistence signals underfit\n",
    "- **ARCH Effects**: Volatility clustering may hint at instability\n",
    "- **Skew/Kurtosis of Residuals**: Shape mismatches between model and environment\n",
    "- **Entropy of Forecast Distribution**: High entropy = more chaotic returns\n",
    "\n",
    "These become meta-features to train models that classify or rank *predictable environments*.\n",
    "\n",
    "\n",
    "#### Meta-RL Labeling\n",
    "\n",
    "\n",
    "To ground our theory in agent behavior, we‚Äôll:\n",
    "\n",
    "1. Train a small RL agent (shallow horizon, simplified environment) on each stock-month\n",
    "2. Track early performance: Sharpe, alpha, drawdown, or advantage over random\n",
    "3. Use this as a **proxy label** for \"learnability\"\n",
    "4. Aggregate results over time, sectors, and macro states\n",
    "\n",
    "This creates a **meta-learning dataset** where the labels come from actual agent-environment interactions.\n",
    "\n",
    "\n",
    "### Pipeline\n",
    "1. Compute rolling predictability metrics for each ticker\n",
    "2. Visualize and compare scores across universe and time\n",
    "3. Select top-N most ‚Äúlearnable‚Äù tickers for RL agent\n",
    "4. Document all decisions, assumptions, and open questions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Outcome Goal\n",
    "\n",
    "Identify **which stocks are more ‚Äúlearnable‚Äù** in the near future ‚Äî not just based on past returns, but through the lens of *how models perform on them*.\n",
    "\n",
    "---\n",
    "\n",
    "###  Why This Matters\n",
    "\n",
    "RL agents don‚Äôt just need high alpha ‚Äî they need *structure they can exploit*. This study explores:\n",
    "- How to measure that structure\n",
    "- How to learn from past environments\n",
    "- How to build a filter that works across regimes\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ec606e",
   "metadata": {},
   "source": [
    "| Stage                 | Description                                                                                             |\n",
    "| --------------------- | ------------------------------------------------------------------------------------------------------- |\n",
    "| üßπ Preprocessing      | Clean stock OHLCV data, compute lagged returns                                                          |\n",
    "| üìà Forecast Models    | Run simple regressors on next-month returns                                                             |\n",
    "| üîç Diagnostics        | Extract residual meta-features, R¬≤, forecast entropy, etc.                                              |\n",
    "| üß† Labeling           | - Regression: R¬≤ as target<br>- Ranking: (A > B)<br>- RL Reward: agent learnability                     |\n",
    "| üìä Feature Extraction | Use summary stats + diagnostic/meta features                                                            |\n",
    "| üß¨ Modeling           | - Regression: Predict R¬≤<br>- Classification: Predict \"learnable\"<br>- Contrastive: Rank predictability |\n",
    "| üèÜ Output             | Sorted top-k stock-months or environments where RL thrives                                              |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df56772c",
   "metadata": {},
   "source": [
    "| Section                             | Purpose                                                                                                                                                                                                          |\n",
    "| ----------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| üîß **Setup & Pipeline Description** | High-level explanation of your RL pipeline, feature engineering, and data sources                                                                                                                                |\n",
    "| üß™ **Completed Studies**            | Summary table or list of ablation studies, e.g.:<br>`01 - Reward Function Impact`<br>`02 - Predictability Filters via R¬≤`<br>`03 - Meta-Learnability Scores`                                                     |\n",
    "| ‚úÖ **Conclusions So Far**            | Bullet points of key findings from each experiment, e.g.:<br>‚Äì Simple R¬≤ doesn't generalize across time<br>‚Äì Residual-based features offer better stability<br>‚Äì Meta-RL proxy labels correlate with test Sharpe |\n",
    "| üî¨ **Ongoing Work**                 | One-liner of what‚Äôs running or planned, so future you remembers                                                                                                                                                  |\n",
    "| üìé **Notebook Index**               | List of notebooks and what each one covers                                                                                                                                                                       |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525a9f5b",
   "metadata": {},
   "source": [
    "We start with both:\n",
    "\n",
    "First, build the regression pipeline ‚Üí quick wins, visualization, baseline.\n",
    "\n",
    "Then, shift to contrastive ranking ‚Üí build a PairwiseMetaDataset, use XGBoostRanker or SiameseNet.\n",
    "\n",
    "Ready to begin with the regression version using:\n",
    "\n",
    "LinearReg + RF residuals\n",
    "\n",
    "Autocorr / Ljung-Box / ARCH tests\n",
    "\n",
    "Predict next-month R¬≤?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cab993d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP: Imports & Paths ===========================\n",
    "import jupyter\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "from src.utils.system import boot, Notify\n",
    "from src.data.feature_pipeline import basic_chart_features,load_base_dataframe\n",
    "from src.predictability.easiness import rolling_sharpe, rolling_r2, rolling_info_ratio, rolling_autocorr\n",
    "from src.predictability.pipeline import generate_universe_easiness_report\n",
    "from IPython import display\n",
    "from src.utils.system import boot,notify\n",
    "from src.experiments.experiment_tracker import ExperimentTracker\n",
    "from src.config import TOP2_STOCK_BY_SECTOR\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy.stats import skew, kurtosis, entropy\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from statsmodels.tsa.stattools import acf, acovf\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "955d6b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_name = \"stock_universe_predictability_selection__MetaFeatures__MetaRlLabeling\"\n",
    "\n",
    "excluded_tickers=['CEG', 'GEHC', 'GEV', 'KVUE', 'SOLV']\n",
    "excluded_tickers.sort()\n",
    "config={\n",
    "    \"regressor\":\"RandomForestRegressor\",\n",
    "    \"n_estimators\": 100,\n",
    "    \"random_state\":42\n",
    "}\n",
    "run_settings={\n",
    "    \"excluded_tickers\": excluded_tickers,\n",
    "    \"min_samples\": 10,\n",
    "    \"cv_folds\": 3,\n",
    "    \"lags\": 5,\n",
    "    \"start_date\":\"2022-01-01\",\n",
    "    \"end_date\":\"2023-01-01\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bd2209",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b684e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD OHLCV ==========================================\n",
    "ohlcv_df = load_base_dataframe()\n",
    "ohlcv_df.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc22aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASIC PREPROCESSING ===================================\n",
    "excluded_tickers = run_settings[\"excluded_tickers\"]\n",
    "min_samples = run_settings[\"min_samples\"]\n",
    "cv_folds = run_settings[\"cv_folds\"]\n",
    "lags = run_settings[\"lags\"]\n",
    "start_date = run_settings[\"start_date\"]\n",
    "end_date = run_settings[\"end_date\"]\n",
    "\n",
    "# CROP THE SAMPLE =======================================\n",
    "tickers = ohlcv_df['symbol'].unique()[:100]\n",
    "tickers = tickers[~np.isin(tickers, excluded_tickers)]\n",
    "tickers = TOP2_BY_SECTOR\n",
    "\n",
    "# FOR POC ONLY\n",
    "\n",
    "\n",
    "ohlcv_df = ohlcv_df.copy()\n",
    "ohlcv_df['date'] = pd.to_datetime(ohlcv_df['date'])\n",
    "ohlcv_df = ohlcv_df[(ohlcv_df['date'] >= start_date) & (ohlcv_df['date'] < end_date)]\n",
    "ohlcv_df['month'] = ohlcv_df['date'].dt.to_period('M')\n",
    "ohlcv_df['return_1d'] = ohlcv_df['return_1d'].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8159060c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohlcv_df['sector_id'] = ohlcv_df['sector_id'].fillna('unknown')\n",
    "ohlcv_df['industry_id'] = ohlcv_df['industry_id'].fillna('unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66ce8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ohlcv_df.sort_values(by=\"date\").head().to_csv('ohlcv_to_upload.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99190a32",
   "metadata": {},
   "source": [
    "## Quick Recap\n",
    "We want to estimate how \"predictable\" each stock is in a given month, using meta-features of its behavior.\n",
    "\n",
    "#### Pipeline: \n",
    "**Loop: For each (stock, month)**\n",
    "From Previous Month (t) we will extract features. From the returns in month t, we compute:\n",
    "* Mean\n",
    "* Std \n",
    "* Skew \n",
    "* Kurtosis\n",
    "* Entropy of returns\n",
    "* Mean of volumne\n",
    "* Std of volume\n",
    "\n",
    "These become the meta-features for that stock-month.\n",
    "\n",
    "**From Following Month (t+1) we will compute \"predictability\"**\n",
    "\n",
    "* With 5 lags of daily returns from month t+1 will try to predict daily returns using a RandomForestRegressor\n",
    "* Evaluate performance with cross-validated R¬≤ (cv_r2)\n",
    "* Analyze residuals from this model with the Ljung‚ÄìBox test for autocorrelation ‚áí gives ljung_pval\n",
    "\n",
    "These become the target labels or diagnostic scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879ad8ac",
   "metadata": {},
   "source": [
    "| Feature                 | Description                                        |\n",
    "| ----------------------- | -------------------------------------------------- |\n",
    "| `resid_acf1`            | Autocorrelation of residuals (lag 1)               |\n",
    "| `resid_std`             | Std of residuals                                   |\n",
    "| `resid_skew`            | Skewness of residuals                              |\n",
    "| `resid_kurtosis`        | Kurtosis of residuals                              |\n",
    "| `resid_ljung_pval`      | p-value of Ljung-Box test for residual autocorr    |\n",
    "| `return_autocorr_1d`    | Lag-1 autocorrelation of raw 1D returns            |\n",
    "| `volatility_clustering` | Rolling std autocorrelation (vol clustering proxy) |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7ba8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE + LABEL EXTRACTION ============================\n",
    "features, targets, metadata = [], [], []\n",
    "def mean_policy(arr):\n",
    "    #return np.median(arr)\n",
    "    return pd.Series(arr).ewm(span=5).mean().iloc[-1]\n",
    "    \n",
    "for symbol in tqdm(tickers):\n",
    "\n",
    "    df = ohlcv_df[ohlcv_df['symbol'] == symbol].sort_values('date').copy()\n",
    "    df['month'] = df['date'].dt.to_period('M')\n",
    "    months = df['month'].unique()\n",
    "  \n",
    "    for i in range(1, len(months)):\n",
    "        m_t = months[i-1]\n",
    "        m_t1 = months[i]\n",
    "\n",
    "        df_t = df[df['month'] == m_t]\n",
    "        df_t1 = df[df['month'] == m_t1]\n",
    "        \n",
    "        if len(df_t1) < min_samples:\n",
    "            continue\n",
    "        \n",
    "        # Feature engineering from month t ---\n",
    "        r1d = df_t['return_1d'].astype(float).values\n",
    "        v = df_t['volume'].astype(float).values\n",
    "\n",
    "        feat = {\n",
    "            'symbol': symbol,\n",
    "            'month_str': str(m_t),\n",
    "            'mean_return': mean_policy(r1d),#r1d.mean(),\n",
    "            'std_return': r1d.std(),\n",
    "            'skew': skew(r1d),\n",
    "            'kurtosis': kurtosis(r1d),\n",
    "            'entropy': entropy(np.histogram(r1d, bins=10, density=True)[0] + 1e-8),\n",
    "            'vol_mean': mean_policy(v),#v.mean(),\n",
    "            'vol_std': v.std()\n",
    "        }\n",
    "\n",
    "        # Residual diagnostics from simple RF on t+1\n",
    "        df_lag = df_t1.copy()\n",
    "        \n",
    "        for lag in range(1,  run_settings['lags'] + 1):\n",
    "            df_lag[f'return_lag_{lag}'] = df_lag['return_1d'].shift(lag)\n",
    "            \n",
    "       \n",
    "        df_lag = df_lag.dropna()\n",
    "        if len(df_lag) < min_samples:\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        \n",
    "        X = df_lag[[f'return_lag_{i}' for i in range(1, run_settings['lags'] + 1)]].values\n",
    "        y = df_lag['return_1d'].values\n",
    "\n",
    "        model = RandomForestRegressor(n_estimators=config['n_estimators'], random_state=config['random_state'])\n",
    "        model.fit(X, y)\n",
    "        \n",
    "        residuals = y - model.predict(X)\n",
    "                \n",
    "        # Meta-diagnostics ---\n",
    "        ljung_pval = acorr_ljungbox(residuals, lags=[run_settings['lags']], return_df=True).iloc[0]['lb_pvalue']\n",
    "        feat['ljung_pval'] = ljung_pval\n",
    "\n",
    "        # Predictability label (cross-val R¬≤) ---\n",
    "        cv_r2 = mean_policy(cross_val_score(model, X, y, cv=cv_folds, scoring='r2'))#.mean()\n",
    "        #print({\"cv_r2\":cv_r2,\"ljung_pval\":ljung_pval})\n",
    "        features.append(feat)\n",
    "        targets.append(cv_r2)\n",
    "        metadata.append((symbol, str(m_t)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67543c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILD DTASETS ============================================\n",
    "X_df = pd.DataFrame(features)\n",
    "y_df = pd.Series(targets, name='cv_r2')\n",
    "meta_df = pd.DataFrame(metadata, columns=['symbol', 'month'])\n",
    "\n",
    "\n",
    "X = X_df.drop(columns=['symbol', 'month_str', 'month_dt'])\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96cf128",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714e8c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TIME-BASED TRAIN/TEST SPLIT ===============================\n",
    "\n",
    "\n",
    "X_df['month_dt'] = pd.to_datetime(X_df['month_str'])\n",
    "\n",
    "split_date = unique_months[int(0.8 * len(unique_months))]\n",
    "\n",
    "train_mask = X_df['month_dt'] < split_date\n",
    "test_mask = X_df['month_dt'] >= split_date\n",
    "\n",
    "X_train, X_test = X_scaled[train_mask], X_scaled[test_mask]\n",
    "y_train, y_test = y_df[train_mask], y_df[test_mask]\n",
    "meta_test = meta_df[test_mask.values].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7030d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REGRESSOR TRAINING ========================================\n",
    "import xgboost as xgb\n",
    "#final_model = RandomForestRegressor(n_estimators=config['n_estimators'], random_state=config['random_state'])\n",
    "final_model = RandomForestRegressor(n_estimators=500, random_state=config['random_state'])\n",
    "\n",
    "final_model.fit(X_train, y_train)\n",
    "y_pred = final_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83df0817",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# REGRESSION RESULTS ========================================\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_policy((y_test - y_pred)**2))\n",
    "\n",
    "print(f\"Test RMSE: {rmse:.4f}, R¬≤: {r2:.4f}\")\n",
    "\n",
    "meta_test['true_r2'] = y_test.values\n",
    "meta_test['predicted_r2'] = y_pred\n",
    "\n",
    "top = meta_test.sort_values('predicted_r2', ascending=False).head(10)\n",
    "print(\"Top predictable stock-months:\")\n",
    "print(top)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.scatterplot(x=y_test, y=y_pred)\n",
    "plt.xlabel(\"True R¬≤\")\n",
    "plt.ylabel(\"Predicted R¬≤\")\n",
    "plt.title(\"Meta-Predictability Regression\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ONLY ON FINAL MODEL\n",
    "# 100 - Test RMSE: 1.2389, R¬≤: -0.1142\n",
    "# 300 - Test RMSE: 1.2394, R¬≤: -0.1150 \n",
    "# 500 - Test RMSE: 1.2317, R¬≤: -0.1013\n",
    "\n",
    "# WITH MEDIAN AND ROBUST\n",
    "# 500 - Test RMSE: 0.4345, R¬≤: -0.1013\n",
    "\n",
    "# WITH EWM\n",
    "# 500 - Test RMSE: 1.5385, R¬≤: -0.0056"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2631d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "xxxxxxxxxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6714319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictability Meta-Feature Pipeline with Structural Diagnostics\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis, entropy\n",
    "from statsmodels.tsa.stattools import acf\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# === CONFIG ===\n",
    "min_samples = 10\n",
    "cv_folds = 3\n",
    "lag_window = 5\n",
    "\n",
    "# === DATA ===\n",
    "df = ohlcv_df[(ohlcv_df['date'] >= \"2022-01-01\") & (ohlcv_df['date'] < \"2023-01-01\")].copy()\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['month'] = df['date'].dt.to_period('M')\n",
    "df['return_1d'] = df['return_1d'].fillna(0)\n",
    "df.drop(columns=[\"sector_id\", \"industry_id\"], inplace=True)\n",
    "\n",
    "# === TICKERS ===\n",
    "tickers = [\"AAPL\", \"MSFT\", \"JPM\", \"V\", 'LLY', 'UNH', 'AMZN', 'TSLA', 'META', 'GOOGL',\n",
    "           'GE', 'UBER', 'COST', 'WMT', 'XOM', 'CVX', 'NEE', 'SO', 'AMT', 'PLD', 'LIN', 'SHW']\n",
    "\n",
    "\n",
    "\n",
    "features, targets, metadata = [], [], []\n",
    "\n",
    "def mean_policy(arr):\n",
    "    #return np.median(arr)\n",
    "    return pd.Series(arr).ewm(span=5).mean().iloc[-1]\n",
    "\n",
    "# === FEATURE + LABEL EXTRACTION ===\n",
    "for symbol in tqdm(tickers):\n",
    "    symbol_df = df[df['symbol'] == symbol].sort_values('date').copy()\n",
    "    months = symbol_df['month'].unique()\n",
    "\n",
    "    for i in range(1, len(months)):\n",
    "        m_t = months[i - 1]\n",
    "        m_t1 = months[i]\n",
    "\n",
    "        df_t = symbol_df[symbol_df['month'] == m_t].copy()\n",
    "        df_t1 = symbol_df[symbol_df['month'] == m_t1].copy()\n",
    "\n",
    "        if len(df_t1) < min_samples:\n",
    "            continue\n",
    "\n",
    "        r1d = df_t['return_1d'].astype(float).values\n",
    "        v = df_t['volume'].astype(float).values\n",
    "\n",
    "        hist = np.histogram(r1d, bins=10, density=True)[0] + 1e-8\n",
    "        acf_vals = acf(r1d, nlags=5, fft=True)[1:6]  # exclude lag 0\n",
    "        acf_names = {f'acf_lag_{i+1}': val for i, val in enumerate(acf_vals)}\n",
    "\n",
    "        time_idx = np.arange(len(r1d)).reshape(-1, 1)\n",
    "        try:\n",
    "            trend_r2 = RandomForestRegressor().fit(time_idx, r1d).score(time_idx, r1d)\n",
    "        except:\n",
    "            trend_r2 = 0\n",
    "\n",
    "        feat = {\n",
    "            'symbol': symbol,\n",
    "            'month_str': str(m_t),\n",
    "            'mean_return': mean_policy(r1d),\n",
    "            'std_return': np.std(r1d),\n",
    "            'skew': skew(r1d),\n",
    "            'kurtosis': kurtosis(r1d),\n",
    "            'entropy': entropy(hist),\n",
    "            'vol_median': mean_policy(v),\n",
    "            'vol_std': np.std(v),\n",
    "            'trend_r2': trend_r2,\n",
    "            **acf_names\n",
    "        }\n",
    "\n",
    "        # Residual diagnostics on t+1\n",
    "        df_lag = df_t1.copy()\n",
    "        for lag in range(1, lag_window + 1):\n",
    "            df_lag[f'return_lag_{lag}'] = df_lag['return_1d'].shift(lag)\n",
    "        df_lag = df_lag.dropna()\n",
    "\n",
    "        if len(df_lag) < min_samples:\n",
    "            continue\n",
    "\n",
    "        X = df_lag[[f'return_lag_{i}' for i in range(1, lag_window + 1)]].values\n",
    "        y = df_lag['return_1d'].values\n",
    "\n",
    "        model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "        model.fit(X, y)\n",
    "        residuals = y - model.predict(X)\n",
    "\n",
    "        ljung_pval = acorr_ljungbox(residuals, lags=[lag_window], return_df=True).iloc[0]['lb_pvalue']\n",
    "        feat['ljung_pval'] = ljung_pval\n",
    "\n",
    "        cv_r2 = np.mean(cross_val_score(model, X, y, cv=cv_folds, scoring='r2'))\n",
    "        features.append(feat)\n",
    "        targets.append(cv_r2)\n",
    "        metadata.append((symbol, str(m_t)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec731fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === DATAFRAME PREP ===\n",
    "X_df = pd.DataFrame(features)\n",
    "y_df = pd.Series(targets, name=\"cv_r2\")\n",
    "X_df['month_dt'] = pd.to_datetime(X_df['month_str'])\n",
    "meta_df = pd.DataFrame(metadata, columns=[\"symbol\", \"month\"])\n",
    "X = X_df.drop(columns=['symbol', 'month_str', 'month_dt'])\n",
    "\n",
    "# === SCALING ===\n",
    "scaler = RobustScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# === SPLIT ===\n",
    "split_idx = int(0.8 * len(X_scaled))\n",
    "X_train, X_test = X_scaled[:split_idx], X_scaled[split_idx:]\n",
    "y_train, y_test = y_df[:split_idx], y_df[split_idx:]\n",
    "meta_test = meta_df.iloc[split_idx:].copy()\n",
    "\n",
    "# === REGRESSOR TRAINING ===\n",
    "final_model = RandomForestRegressor(n_estimators=500, random_state=42)\n",
    "final_model.fit(X_train, y_train)\n",
    "y_pred = final_model.predict(X_test)\n",
    "\n",
    "# === METRICS ===\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"Test RMSE: {rmse:.4f}, R¬≤: {r2:.4f}\")\n",
    "\n",
    "meta_test['true_r2'] = y_test.values\n",
    "meta_test['predicted_r2'] = y_pred\n",
    "print(\"Top predictable stock-months:\")\n",
    "print(meta_test.sort_values('predicted_r2', ascending=False).head(10))\n",
    "\n",
    "# === VISUALIZATION ===\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.scatterplot(x=y_test, y=y_pred)\n",
    "plt.xlabel(\"True R¬≤\")\n",
    "plt.ylabel(\"Predicted R¬≤\")\n",
    "plt.title(\"Meta-Predictability Regression\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a573f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Contrastive Dataset Builder ===\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "def build_contrastive_dataset(X, y, meta, n_pairs=20000, margin=0.02):\n",
    "    X_pairs = []\n",
    "    y_pairs = []\n",
    "    meta_pairs = []\n",
    "\n",
    "    num_samples = len(y)\n",
    "    attempts = 0\n",
    "    max_attempts = n_pairs * 10\n",
    "\n",
    "    while len(X_pairs) < n_pairs and attempts < max_attempts:\n",
    "        i, j = np.random.choice(num_samples, size=2, replace=False)\n",
    "        r2_i, r2_j = y[i], y[j]\n",
    "\n",
    "        diff = r2_i - r2_j\n",
    "        if abs(diff) < margin:\n",
    "            attempts += 1\n",
    "            continue\n",
    "\n",
    "        if diff > 0:\n",
    "            X_diff = X[i] - X[j]\n",
    "            y_label = 1\n",
    "        else:\n",
    "            X_diff = X[j] - X[i]\n",
    "            y_label = 0\n",
    "\n",
    "        X_pairs.append(X_diff)\n",
    "        y_pairs.append(y_label)\n",
    "        meta_pairs.append((meta.iloc[i].to_dict(), meta.iloc[j].to_dict()))\n",
    "        attempts += 1\n",
    "\n",
    "    return np.array(X_pairs), np.array(y_pairs), meta_pairs\n",
    "\n",
    "# === Contrastive Model ===\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def train_contrastive_model(X_pairs, y_pairs):\n",
    "    clf = LogisticRegression(max_iter=1000)\n",
    "    clf.fit(X_pairs, y_pairs)\n",
    "    return clf\n",
    "\n",
    "\n",
    "# === Scoring Function from Single Sample ===\n",
    "class ScoringWrapper:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def score(self, x):\n",
    "        # Compare x to 0-vector (neutral baseline)\n",
    "        x = x.reshape(1, -1)\n",
    "        return self.model.decision_function(x)[0]\n",
    "\n",
    "\n",
    "# === Example Usage ===\n",
    "# X_scaled, y_df, meta_df assumed to exist\n",
    "\n",
    "X_pairs, y_pairs, meta_pairs = build_contrastive_dataset(X_scaled, y_df.values, meta_df, n_pairs=20000, margin=0.02)\n",
    "print(\"Class distribution:\", np.bincount(y_pairs))\n",
    "\n",
    "contrastive_model = train_contrastive_model(X_pairs, y_pairs)\n",
    "scorer = ScoringWrapper(contrastive_model)\n",
    "scores = [scorer.score(x) for x in X_scaled]\n",
    "meta_df['score'] = scores\n",
    "\n",
    "# Score individual months:\n",
    "scores = [scorer.score(x) for x in X_scaled]\n",
    "meta_df['score'] = scores\n",
    "meta_df['true_r2'] = y_df.values\n",
    "# Top predictable stock-months by contrastive model:\n",
    "top_ranked = meta_df.sort_values('score', ascending=False).head(10)\n",
    "print(top_ranked)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca48f55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "top = meta_df.sort_values(\"score\", ascending=False).head(10)\n",
    "bottom = meta_df.sort_values(\"score\", ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b33a368",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.histplot(meta_df['score'], bins=40, kde=True)\n",
    "plt.title(\"Contrastive Predictability Scores\")\n",
    "plt.xlabel(\"Score\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fcb9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=meta_df, x='true_r2', y='score')\n",
    "plt.xlabel(\"True R¬≤\")\n",
    "plt.ylabel(\"Contrastive Score\")\n",
    "plt.title(\"Score vs Ground Truth R¬≤\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc5170c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xxxxxxxxxxxxxxxxxxxxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83152788",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2b0a14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e97b19e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5c2f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent-Based Meta-Labeling (Advantage Estimation)\n",
    "from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "import gymnasium as gym\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
    "\n",
    "class WrappedStockTradingEnv(StockTradingEnv):\n",
    "    def step(self, actions):\n",
    "        # Call the original step method\n",
    "        state, reward, done, info = super().step(actions)\n",
    "\n",
    "        # Wrap the reward in a NumPy array so DummyVecEnv works properly\n",
    "        if not isinstance(reward, (list, np.ndarray)):\n",
    "            reward = np.array([reward])\n",
    "        \n",
    "        return state, reward, done, info\n",
    "# === ADVANTAGE FUNCTION ===\n",
    "def compute_agent_advantage(df, symbol, month_str):\n",
    "    df_symbol = df[df['symbol'] == symbol].copy()\n",
    "    df_symbol['month'] = df_symbol['date'].dt.to_period(\"M\")\n",
    "    df_month = df_symbol[df_symbol['month'] == pd.Period(month_str)]\n",
    "    df_next = df_symbol[df_symbol['month'] == pd.Period(month_str) + 1]\n",
    "\n",
    "    if len(df_next) < min_samples:\n",
    "        return np.nan\n",
    "\n",
    "    try:\n",
    "        # Define environment\n",
    "        env_df = df_next[['date', 'open', 'high', 'low', 'close', 'volume', 'return_1d','symbol']].copy()\n",
    "        env_df.rename(columns={'symbol':\"tic\"},inplace=True)\n",
    "        env_df = env_df.reset_index(drop=True)\n",
    "        stock_dim = 1\n",
    "        env_kwargs = {\n",
    "            \"hmax\": 100,\n",
    "            \"initial_amount\": 100000,\n",
    "            \"buy_cost_pct\": 0.001,\n",
    "            \"sell_cost_pct\": 0.001,\n",
    "            \"state_space\": 6 * stock_dim + 1,\n",
    "            \"stock_dim\": stock_dim,\n",
    "            \"tech_indicator_list\": [\"return_1d\"],\n",
    "            \"action_space\": stock_dim,\n",
    "            \"reward_scaling\": 1e-4,\n",
    "          \"num_stock_shares\":1\n",
    "        }\n",
    "        #env = DummyVecEnv([lambda: StockTradingEnv(df=env_df, **env_kwargs)])\n",
    "        env = DummyVecEnv([lambda: WrappedStockTradingEnv(df=env_df, **env_kwargs)])\n",
    "        # Train PPO Agent\n",
    "        model = PPO(\"MlpPolicy\", env, verbose=0)\n",
    "        model.learn(total_timesteps=5000)\n",
    "\n",
    "        # Evaluate\n",
    "        obs = env.reset()\n",
    "        total_reward_agent = 0\n",
    "        total_reward_random = 0\n",
    "\n",
    "        for _ in range(len(env_df)):\n",
    "            action, _states = model.predict(obs)\n",
    "            obs, rewards, dones, info = env.step(action)\n",
    "            total_reward_agent += float(rewards)\n",
    "\n",
    "        # Evaluate random policy\n",
    "        obs = env.reset()\n",
    "        for _ in range(len(env_df)):\n",
    "            action = env.action_space.sample()\n",
    "            obs, rewards, dones, info = env.step(action)\n",
    "            total_reward_random += float(rewards)\n",
    "\n",
    "        advantage = total_reward_agent - total_reward_random\n",
    "        return advantage\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Advantage error for {symbol}-{month_str}: {e}\")\n",
    "        return np.nan\n",
    "\n",
    "# === COMPUTE ADVANTAGE FOR META-DF ===\n",
    "meta_df['advantage'] = meta_df.apply(lambda row: compute_agent_advantage(df, row['symbol'], row['month']), axis=1)\n",
    "\n",
    "# === ADVANTAGE RESULTS ===\n",
    "print(\"Top agent-advantaged stock-months:\")\n",
    "print(meta_df.sort_values('advantage', ascending=False).head(10))\n",
    "\n",
    "# === Save Results (Optional) ===\n",
    "# meta_df.to_csv(\"predictability_meta_results.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ecefd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89730563",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab841c34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# === Agent-Based Meta-Labeling: Advantage Estimation ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gym\n",
    "import warnings\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# === PPO Utility Functions ===\n",
    "\n",
    "class WrappedStockTradingEnv(StockTradingEnv):\n",
    "    def step(self, actions):\n",
    "        # Call the original step method\n",
    "        state, reward, _,done, info = super().step(actions)\n",
    "\n",
    "        # Wrap the reward in a NumPy array so DummyVecEnv works properly\n",
    "        if not isinstance(reward, (list, np.ndarray)):\n",
    "            reward = np.array([reward])\n",
    "        \n",
    "        return state, reward, done, info\n",
    "    \n",
    "class PatchedStockTradingEnv(StockTradingEnv):\n",
    "    def step(self, actions):\n",
    "        #print('pst', actions)\n",
    "        obs, reward, done,truncated, info = super().step(actions)\n",
    "        #print('pst2')\n",
    "        reward = np.array([reward], dtype=np.float32)\n",
    "        done = np.array([done])\n",
    "        info = [info]\n",
    "        \n",
    "        # SB3 expects 5 items: obs, reward, terminated, truncated, info\n",
    "        info = {\"dummy\": True}\n",
    "        return obs, reward, done, done, info\n",
    "    \n",
    "def train_ppo_agent(env, timesteps=5000):\n",
    "\n",
    "    model = PPO(\"MlpPolicy\", env, verbose=0)\n",
    "  \n",
    "    model.learn(total_timesteps=timesteps)\n",
    "\n",
    "    return model\n",
    "def evaluate_policy(env, model, steps):\n",
    "    obs = env.reset()\n",
    "    total_reward = 0\n",
    "\n",
    "    for _ in range(steps):\n",
    "       \n",
    "        action, _ = model.predict(obs)\n",
    "     \n",
    "        truncated = False\n",
    "        obs, rewards, terminated, info = env.step(action)\n",
    "\n",
    "        done = terminated or truncated\n",
    "     \n",
    "        total_reward += float(np.squeeze(rewards))\n",
    "        if done:\n",
    "            break\n",
    "    #print('xxx 5',total_reward)\n",
    "    return total_reward\n",
    "\n",
    "def evaluate_random(env, steps):\n",
    "    #print('x')\n",
    "    obs = env.reset()\n",
    "    #print('x1',steps)\n",
    "    total_reward = 0\n",
    "    for _ in range(steps):\n",
    "        #print('x2',env.action_space.sample())\n",
    "        action = env.action_space.sample()\n",
    "        #print('x3',action)\n",
    "        truncated = False\n",
    "        #print('x4',env.step(np.array([action]).astype(np.float32)))\n",
    "        obs, rewards, terminated, info = env.step(np.array([action]).astype(np.float32))\n",
    "        #print('x5',rewards)\n",
    "        done = terminated or truncated\n",
    "        #print(f\"Type of rewards: {type(rewards)}, value: {rewards}\")\n",
    "        total_reward += float(np.squeeze(rewards))\n",
    "        if done:\n",
    "            break\n",
    "    return total_reward\n",
    "\n",
    "\n",
    "# === ADVANTAGE FUNCTION ===\n",
    "\n",
    "def compute_agent_advantage(df, symbol, month_str, min_samples=10):\n",
    "    try:\n",
    "        #print(month_str)\n",
    "        df_symbol = df[df['symbol'] == symbol].copy()\n",
    "        df_symbol['month'] = df_symbol['date'].dt.to_period(\"M\")\n",
    "        df_next = df_symbol[df_symbol['month'] == pd.Period(month_str) + 1].copy()\n",
    "        #print(1)\n",
    "        if len(df_next) < min_samples:\n",
    "            return np.nan\n",
    "\n",
    "        # Prepare DataFrame for env\n",
    "        df_next.rename(columns={\"symbol\": \"tic\"}, inplace=True)\n",
    "        env_df = df_next[['date', 'open', 'high', 'low', 'close', 'volume', 'return_1d', 'tic']].reset_index(drop=True)\n",
    "        #print(2)\n",
    "        env_kwargs = {\n",
    "            \"hmax\": 100,\n",
    "            \"initial_amount\": 100000,\n",
    "            \"buy_cost_pct\": np.array([0.001]),   # <-- FIXED\n",
    "            \"sell_cost_pct\": np.array([0.001]),  # <-- FIXED\n",
    "            \"state_space\": 4,\n",
    "            \"stock_dim\": 1,\n",
    "            \"tech_indicator_list\": [\"return_1d\"],\n",
    "            \"action_space\": 1,\n",
    "            \"reward_scaling\": 1e-4,\n",
    "            \"num_stock_shares\": 1\n",
    "        }\n",
    "\n",
    "        #env = DummyVecEnv([lambda: StockTradingEnv(df=env_df, **env_kwargs)])\n",
    "        env = DummyVecEnv([lambda: PatchedStockTradingEnv(df=env_df, **env_kwargs)])\n",
    "        #print(3)\n",
    "        #print(env.reset())\n",
    "        #print(env.action_space.sample())\n",
    "        #np.array([env.action_space.sample()]\n",
    "        #print(env.step([action]))\n",
    "        print('x')\n",
    "        # Train PPO and compute reward\n",
    "        model = train_ppo_agent(env)\n",
    "        #print(4)\n",
    "        steps = len(env_df)\n",
    "        print(4)\n",
    "        reward_agent = evaluate_policy(env, model, steps)\n",
    "        print(\"reward_agent\",reward_agent)\n",
    "        reward_random = evaluate_random(env, steps)\n",
    "        print(\"reward_random\",reward_agent)\n",
    "        advantage = reward_agent - reward_random\n",
    "        print(\"advantage\",advantage)\n",
    "        #print('y')\n",
    "        return advantage\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[Advantage error] {symbol}-{month_str}: {e}\")\n",
    "        return np.nan\n",
    "\n",
    "# === APPLY TO META_DF ===\n",
    "\n",
    "print(\"Computing RL agent advantages... (this may take a while)\")\n",
    "start = time.time()\n",
    "meta_df['advantage'] = meta_df.apply(\n",
    "    lambda row: compute_agent_advantage(df, row['symbol'], row['month']),\n",
    "    axis=1\n",
    ")\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Finished in {end - start:.1f} seconds.\")\n",
    "print(\"\\nTop stock-months by RL agent advantage:\")\n",
    "print(meta_df.sort_values('advantage', ascending=False).head(10))\n",
    "\n",
    "# Optional: Save\n",
    "# meta_df.to_csv(\"predictability_meta_with_advantage.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d250f753",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df.to_csv(\"predictability_meta_with_advantage.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cf14b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df['advantage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae89987f",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df['target'] = (meta_df['advantage'] > 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb058b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d43c75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf = pd.DataFrame(features)\n",
    "fdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ec55b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# === Construct target variable ===\n",
    "meta_df = meta_df.copy()\n",
    "meta_df['target'] = (meta_df['advantage'] > 0).astype(int)\n",
    "\n",
    "# === Select features (drop metadata) ===\n",
    "feature_cols = [col for col in meta_df.columns if col not in ['symbol', 'month', 'advantage', 'target']]\n",
    "X = meta_df[feature_cols]\n",
    "y = meta_df['target']\n",
    "\n",
    "# === Optional: scale features ===\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# === Train/test split ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# === Train classifier ===\n",
    "clf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# === Evaluate ===\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "importances = clf.feature_importances_\n",
    "sorted_idx = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(importances)), importances[sorted_idx])\n",
    "plt.xticks(range(len(importances)), [feature_cols[i] for i in sorted_idx], rotation=90)\n",
    "plt.title(\"Feature Importances\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6656041f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge on symbol and month (use consistent naming)\n",
    "fdf['month'] = fdf['month_str']  # Align column name for merge\n",
    "merged = pd.merge(fdf.drop(columns='month_str'), meta_df, on=['symbol', 'month'], how='inner')\n",
    "\n",
    "# Define target and features\n",
    "y = merged['target']\n",
    "X = merged.drop(columns=['symbol', 'month', 'advantage', 'target'])  # Keep 'score' and 'true_r2'\n",
    "\n",
    "# Scale features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Train classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855cbc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "importances = clf.feature_importances_\n",
    "sorted_idx = np.argsort(importances)[::-1]\n",
    "feature_names = X.columns if hasattr(X, 'columns') else merged.drop(columns=['symbol', 'month', 'advantage', 'target']).columns\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(range(len(importances)), importances[sorted_idx])\n",
    "plt.xticks(range(len(importances)), [feature_names[i] for i in sorted_idx], rotation=90)\n",
    "plt.title(\"Feature Importances for Predicting Agent Advantage\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6930f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#sm = SMOTE(random_state=42)\n",
    "#X_resampled, y_resampled = sm.fit_resample(X_train, y_train)\n",
    "#clf.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Train classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=200, random_state=42,class_weight='balanced')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507efa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Ensure both are NumPy arrays\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "class_0_idx = np.where(y_train == 0)[0]\n",
    "class_1_idx = np.where(y_train == 1)[0]\n",
    "\n",
    "n_to_add = len(class_1_idx) - len(class_0_idx)\n",
    "oversampled_idx = np.random.choice(class_0_idx, size=n_to_add, replace=True)\n",
    "\n",
    "X_oversampled = np.concatenate([X_train, X_train[oversampled_idx]], axis=0)\n",
    "y_oversampled = np.concatenate([y_train, y_train[oversampled_idx]], axis=0)\n",
    "\n",
    "shuffle_idx = np.random.permutation(len(y_oversampled))\n",
    "X_balanced = X_oversampled[shuffle_idx]\n",
    "y_balanced = y_oversampled[shuffle_idx]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a85552c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train your classifier\n",
    "clf = RandomForestClassifier( n_estimators=200, random_state=42,class_weight='balanced')\n",
    "clf.fit(X_balanced, y_balanced)\n",
    "\n",
    "# Evaluate\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696bbfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# 1. Create the classifier\n",
    "xgb_clf = xgb.XGBClassifier(\n",
    "    objective=\"binary:logistic\",   # binary classification\n",
    "    eval_metric=\"logloss\",         # evaluation metric\n",
    "    use_label_encoder=False,       # suppress warning\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 2. Fit on the oversampled data\n",
    "xgb_clf.fit(X_balanced, y_balanced)\n",
    "\n",
    "# 3. Predict on the test set\n",
    "y_pred = xgb_clf.predict(X_test)\n",
    "\n",
    "# 4. Evaluate\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1199e843",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 300, 500],\n",
    "    'max_depth': [3, 6, 10],\n",
    "    'learning_rate': [0.005,0.01, 0.05, 0.1],\n",
    "    'subsample': [0.5, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.5, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Create the classifier\n",
    "xgb_clf = xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_clf,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='f1_weighted',  # or 'roc_auc', 'accuracy', etc.\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best Params:\", grid_search.best_params_)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02873c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "calibrated_xgb = CalibratedClassifierCV(grid_search.best_estimator_, method='isotonic', cv=3)\n",
    "calibrated_xgb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = calibrated_xgb.predict(X_test)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249b3046",
   "metadata": {},
   "outputs": [],
   "source": [
    "2. Feature engineering:\n",
    "Add features that measure uncertainty, volatility clustering, or market randomness like:\n",
    "\n",
    "Hurst exponent\n",
    "\n",
    "GARCH volatility\n",
    "\n",
    "Rolling ADF p-values\n",
    "\n",
    "Change-point detection count"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
