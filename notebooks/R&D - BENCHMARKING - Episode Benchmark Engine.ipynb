{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d6cf50f",
   "metadata": {},
   "source": [
    "This is gold, Pi ‚Äî thank you for laying it out so clearly. What you built is already stronger than many academic meta-RL setups. Now let‚Äôs **merge the best of your past success with this current Battleground framework** and push it to the next level.\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Current Goal\n",
    "\n",
    "**Predict, with ‚â•75% confidence, whether a given RL training episode is transferable.**\n",
    "\n",
    "To do that, we need a **rich and expressive feature space** that captures **structure, uncertainty, dynamics, and regime information** ‚Äî just like your Stock-Month Predictability Study.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ What We Already Have\n",
    "\n",
    "From your current `result_df`, we already extract:\n",
    "\n",
    "| Group                 | Features                                                                 |\n",
    "| --------------------- | ------------------------------------------------------------------------ |\n",
    "| Statistical Moments   | `mean_return`, `std_return`, `skew_return`, `kurtosis_return`, `entropy` |\n",
    "| Price Trend           | `return_trend`, `ewm_mean_return`                                        |\n",
    "| Chaos / Regime        | `hurst`, `adf_stat`, `adf_pval`                                          |\n",
    "| Risk & Reward Metrics | `volatility`, `max_drawdown`, `sharpe`, `sortino`, `calmar`              |\n",
    "| Agent Diagnostics     | `success_trades`, `action_hold_ratio`, `action_long_ratio`               |\n",
    "| Outcome Labels        | `score_train`, `score_test`, `advantage_test`, `transfer_delta`          |\n",
    "\n",
    "---\n",
    "\n",
    "## üîÅ Let‚Äôs Extend: Feature Suggestions\n",
    "\n",
    "Below are **10 additional meta-features** we can compute **either now or as next step**, all in PyTorch/Numpy-friendly form:\n",
    "\n",
    "| Feature Name               | Why Add It?                                                                |\n",
    "| -------------------------- | -------------------------------------------------------------------------- |\n",
    "| `resid_std`                | From RF prediction of t+1 returns ‚Üí measures noise                         |\n",
    "| `resid_skew`, `resid_kurt` | Shape of the error ‚Üí asymmetry or tails                                    |\n",
    "| `resid_acf1`               | Temporal memory in prediction error                                        |\n",
    "| `ljung_pval`               | Statistical confirmation of noise/randomness                               |\n",
    "| `cv_r2`                    | Proxy for model learnability/predictability                                |\n",
    "| `garch_volatility`         | Conditional volatility ‚áí market stress estimation                          |\n",
    "| `change_point_count`       | Regime switch count (e.g. via ruptures or cusum)                           |\n",
    "| `rolling_adf_pval`         | Stationarity evolution over time                                           |\n",
    "| `forecast_entropy`         | Entropy of predictions from RF or AE                                       |\n",
    "| `price_entropy_peak`       | Local entropy spike detection before regime breaks (good for online usage) |\n",
    "\n",
    "These build on your previous success and aim at:\n",
    "\n",
    "* **Residual structure**\n",
    "* **Volatility structure**\n",
    "* **Forecast structure**\n",
    "* **Regime changes**\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Architecture Suggestion (Final Plan)\n",
    "\n",
    "```bash\n",
    "[Episode -> Raw OHLCV]\n",
    "         |\n",
    "         v\n",
    "[Feature Extractor (Meta + Residual + Chaos)]\n",
    "         |\n",
    "         v\n",
    "[Representation Learner (AE, Transformer Encoder, etc)]\n",
    "         |\n",
    "         v\n",
    "[Predictor (Classifier or Ranker)]\n",
    "         |\n",
    "         v\n",
    "[Score: Learnability + Transferability + Difficulty]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Action Plan (Ordered)\n",
    "\n",
    "**Phase 1 ‚Äì Today**\n",
    "\n",
    "1. ‚úÖ Implement `EpisodeMetaFeatureExtractor` (done or in progress)\n",
    "2. ‚úÖ Implement `TradingEnvironmentBattleground` (done!)\n",
    "3. üîÅ Add new diagnostics: `resid_std`, `resid_acf1`, `cv_r2`, `ljung_pval`\n",
    "4. üß† Train `EpisodeTransferabilityPredictor` with new features\n",
    "\n",
    "**Phase 2 ‚Äì Next**\n",
    "5\\. üß¨ Add `AutoencoderRepresentation` wrapper\n",
    "6\\. üîÑ Train contrastive ranking model: \"Is A > B?\"\n",
    "7\\. ‚è± Evaluate with out-of-time validation (e.g., train on 2023 Q1, test on Q2)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dbdf015",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e1d6324",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francisco S√°\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\arrays\\masked.py:61: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from src.utils.system import boot\n",
    "from src.defaults import RANDOM_SEEDS\n",
    "from src.data.feature_pipeline import load_base_dataframe\n",
    "from experiments import check_if_experiment_exists, register_experiment ,experiment_hash\n",
    "from environments import PositionTradingEnv,PositionTradingEnvV1\n",
    "\n",
    "# ========== SYSTEM BOOT ==========\n",
    "DEVICE = boot()\n",
    "EXPERIMENT_NAME = \"trading_environment_development\"\n",
    "DEFAULT_PATH = \"data/experiments/\" + EXPERIMENT_NAME\n",
    "\n",
    "# ========== CONFIG ==========\n",
    "TICKER = \"AAPL\"\n",
    "TIMESTEPS = 10_000\n",
    "EVAL_EPISODES = 5\n",
    "N_TIMESTEPS = 60\n",
    "LOOKBACK = 0\n",
    "SEEDS = [42, 52, 62]\n",
    "MARKET_FEATURES = ['close']\n",
    "BENCHMARK_PATH = DEFAULT_PATH+\"/benchmark_episodes.json\"\n",
    "CHECKPOINT_DIR = DEFAULT_PATH+\"/checkpoints\"\n",
    "SCORES_DIR = DEFAULT_PATH+\"/scores\"\n",
    "META_PATH = DEFAULT_PATH+\"/meta_df_transfer.csv\"\n",
    "\n",
    "MODEL_PATH = CHECKPOINT_DIR+\"/episode_quality_model.pkl\"\n",
    "MARKET_FEATURES.sort()\n",
    "SEEDS.sort()\n",
    "\n",
    "DEVICE = boot()\n",
    "OHLCV_DF = load_base_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad0502cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIENCE_NAME = \"stock_universe_predictability_selection__MetaFeatures__MetaRlLabeling\"\n",
    "FEATURES_PATH = f\"../data/cache/features_{EXPERIENCE_NAME}.pkl\"\n",
    "TARGETS_PATH = f\"../data/cache/targets_{EXPERIENCE_NAME}.pkl\"\n",
    "META_PATH = f\"../data/cache/meta_{EXPERIENCE_NAME}.pkl\"\n",
    "RL_LABELS_PATH = \"../data/cache/meta_rl_labels_stock_universe_predictability_selection__MetaFeatures__MetaRlLabeling__6293649262173480064.pkl\"\n",
    "\n",
    "excluded_tickers=['CEG', 'GEHC', 'GEV', 'KVUE', 'SOLV']\n",
    "excluded_tickers.sort()\n",
    "#tickers = TOP2_STOCK_BY_SECTOR\n",
    "\n",
    "config={\n",
    "    \"regressor\":\"RandomForestRegressor\",\n",
    "    \"n_estimators\": 200,\n",
    "    \"random_state\":314,\n",
    "    \"transaction_cost\":0\n",
    "}\n",
    "run_settings={\n",
    "    \"excluded_tickers\": excluded_tickers,\n",
    "    \"min_samples\": 10,\n",
    "    \"cv_folds\": 3,\n",
    "    \"lags\": 5,\n",
    "    \"start_date\":\"2022-01-01\",\n",
    "    \"end_date\":\"2025-01-01\",\n",
    "    \"seed\":314,\n",
    "    \"episode_length\":18,\n",
    "    \"noise_feature_cols\": [\"return_1d\", \"volume\"]  ,\n",
    "\n",
    "    \"train_steps\": 300,\n",
    "    \"min_ep_len\" : 18\n",
    "}\n",
    "\n",
    "# Config section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6077bcbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b1918f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# episode_benchmarking_engine.py\n",
    "\n",
    "import os\n",
    "import json\n",
    "import hashlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import Optional, Dict, List\n",
    "from stable_baselines3 import PPO, A2C\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.stats import skew, kurtosis, entropy\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "\n",
    "from environments import PositionTradingEnv,PositionTradingEnvV1,PositionTradingEnvV2\n",
    "\n",
    "# Updated utility functions\n",
    "\n",
    "def generate_lagged_features(df, config):\n",
    "    df = df.copy()\n",
    "    if config.get('return'):\n",
    "        df['return_1d'] = df['close'].pct_change()\n",
    "    if config.get('volume'):\n",
    "        df['volume_1d'] = df['volume'].pct_change()\n",
    "    for lag in range(1, config.get('lags', 0) + 1):\n",
    "        df[f'return_lag_{lag}'] = df['return_1d'].shift(lag)\n",
    "        df[f'volume_lag_{lag}'] = df['volume_1d'].shift(lag)\n",
    "    return df.dropna()\n",
    "\n",
    "def compute_sharpe_ratio(returns):\n",
    "    mean = np.mean(returns)\n",
    "    std = np.std(returns)\n",
    "    return mean / std if std > 0 else np.nan\n",
    "\n",
    "def compute_sortino_ratio(returns):\n",
    "    mean = np.mean(returns)\n",
    "    downside_std = np.std(returns[returns < 0])\n",
    "    return mean / downside_std if downside_std > 0 else np.nan\n",
    "\n",
    "def compute_calmar_ratio(returns):\n",
    "    cum_returns = np.cumprod(1 + returns)\n",
    "    drawdown = np.max(cum_returns) - np.min(cum_returns)\n",
    "    mean_return = np.mean(returns)\n",
    "    return mean_return / drawdown if drawdown > 0 else np.nan\n",
    "\n",
    "\n",
    "\n",
    "# Utility functions with real logic for agent and oracle evaluation\n",
    "def compute_agent_metrics(model, env, random=False):\n",
    "    obs, _ = env.reset()\n",
    "    done, actions, values = False, [], []\n",
    "    while not done:\n",
    "        action = env.action_space.sample() if random else model.predict(obs, deterministic=True)[0]\n",
    "        obs, reward, done, _, info = env.step(action)\n",
    "        actions.append(action)\n",
    "\n",
    "    values = np.array(env.env.wallet_progress)\n",
    "    if len(values) < 2:\n",
    "        return {}\n",
    "   \n",
    "    returns = values-1 #np.diff(values) #/ (values[:-1] + 1e-9)\n",
    "    negative_returns = returns[returns < 0] if len(returns[returns < 0]) > 0 else np.array([1e-9])\n",
    "    action_probs = np.bincount(actions, minlength=2) / (len(actions) + 1e-9)\n",
    "    drawdowns = values / np.maximum.accumulate(values)\n",
    "    max_drawdown = drawdowns.min() - 1 if len(drawdowns) > 0 else -1\n",
    "    success_trades = env.env.success_trades = 0\n",
    "    failed_trades = env.env.failed_trades = 0\n",
    "    total_trades = env.env.total_trades = 0\n",
    "  \n",
    "    sharpe = 0\n",
    "    sortino = 0\n",
    "    calmar = 0\n",
    "    if returns.std() !=0:\n",
    "        sharpe = returns.mean() / (returns.std() + 1e-9) * np.sqrt(252)\n",
    "        sortino = returns.mean() / (negative_returns.std() + 1e-9) * np.sqrt(252)\n",
    "   \n",
    "    return {\n",
    "        \"reward\": env.env.total_reward,\n",
    "        \"volatility\": returns.std(),\n",
    "        \"entropy\": -np.sum(action_probs * np.log2(action_probs + 1e-9)),\n",
    "        \"max_drawdown\": max_drawdown,\n",
    "        \"sharpe\": sharpe, #returns.mean() / (returns.std() + 1e-9) * np.sqrt(252),\n",
    "        \"sortino\": sortino, #returns.mean() / (negative_returns.std() + 1e-9) * np.sqrt(252),\n",
    "        \"calmar\": returns.mean() / abs(max_drawdown + 1e-9),\n",
    "        \"success_trades\": success_trades,\n",
    "        \"action_hold_ratio\": np.mean(np.array(actions) == 0),\n",
    "        \"action_long_ratio\": np.mean(np.array(actions) == 1),\n",
    "        \"cumulative_return\": values[-1] / values[0] - 1 if values[0] != 0 else 0\n",
    "    }\n",
    "\n",
    "def compute_oracle_metrics(env):\n",
    "    obs, _ = env.reset()\n",
    "    done, actions, values = False, [], []\n",
    "    \n",
    "\n",
    "    while not done:\n",
    "        curr_idx = env.env.step_idx\n",
    "        next_idx = min(curr_idx + 1, len(env.env.prices) - 1)\n",
    "        curr_price = env.env.prices[curr_idx]\n",
    "        next_price = env.env.prices[next_idx]\n",
    "        price_diff = next_price - curr_price\n",
    "        action = 1 if price_diff > 0 else 0\n",
    "        #action = episode_df.iloc[env.current]  # oracle always assumes uptrend (long)\n",
    "        obs, reward, done, _, info = env.step(action)\n",
    "        actions.append(action)\n",
    "\n",
    "    values = np.array(env.env.wallet_progress)\n",
    "    if len(values) < 2:\n",
    "        return {}\n",
    "    #print(values,actions)\n",
    "    returns = values #np.diff(values) / (values[:-1] + 1e-9)\n",
    "    negative_returns = returns[returns < 1] if len(returns[returns < 1]) > 0 else np.array([1e-9])\n",
    "    action_probs = np.bincount(actions, minlength=2) / (len(actions) + 1e-9)\n",
    "    drawdowns = values / np.maximum.accumulate(values)\n",
    "    max_drawdown = drawdowns.min() - 1 if len(drawdowns) > 0 else -1\n",
    "\n",
    "    success_trades = 0\n",
    "    fail_trades = 0\n",
    "    total_trades = 0\n",
    "  \n",
    "\n",
    "    return {\n",
    "        \"oracle_volatility\": returns.std(),\n",
    "        \"oracle_entropy\": -np.sum(action_probs * np.log2(action_probs + 1e-9)),\n",
    "        \"oracle_max_drawdown\": max_drawdown,\n",
    "        \"oracle_sharpe\": returns.mean() / (returns.std() + 1e-9) * np.sqrt(252),\n",
    "        \"oracle_sortino\": returns.mean() / (negative_returns.std() + 1e-9) * np.sqrt(252),\n",
    "        \"oracle_calmar\": returns.mean() / abs(max_drawdown + 1e-9),\n",
    "        \"oracle_success_trades\": success_trades,\n",
    "        \"oracle_action_hold_ratio\": np.mean(np.array(actions) == 0),\n",
    "        \"oracle_action_long_ratio\": np.mean(np.array(actions) == 1),\n",
    "        \"oracle_cumulative_return\": values[-1] / values[0] - 1 if values[0] != 0 else 0\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "def compute_additional_diagnostics(env):\n",
    "    df = env.env.episode_df\n",
    "    df = generate_lagged_features(df.copy(), {'return': True, 'volume':True,'lags': 5})\n",
    "    df = df.dropna()\n",
    "    X = df[[f'return_lag_{i}' for i in range(1, 6)]].values\n",
    "    y = df['return_1d'].values\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X, y)\n",
    "    residuals = y - model.predict(X)\n",
    "    ljung_pval = acorr_ljungbox(residuals, lags=[5], return_df=True).iloc[0]['lb_pvalue']\n",
    "    return {\n",
    "        'resid_std': residuals.std(),\n",
    "        'resid_skew': skew(residuals),\n",
    "        'resid_kurtosis': kurtosis(residuals),\n",
    "        'ljung_pval': ljung_pval\n",
    "    }\n",
    "\n",
    "class EpisodeBenchmarkingEngine:\n",
    "    def __init__(self, \n",
    "                 df: pd.DataFrame,\n",
    "                 experiment_name: str= \"episode_benchmark_engine\",\n",
    "                 agent_classes: List = [PPO, A2C],\n",
    "                 seeds: List[int] = RANDOM_SEEDS,\n",
    "                 train_steps: List[int] = [200_000], #, 50_000, 100_000, 200_000],\n",
    "                 n_timesteps: int = 120,\n",
    "                 lookback: int = 0,\n",
    "                 min_valid_length: int = 100,\n",
    "                 market_features=['close','volume'],\n",
    "                 feature_config: Dict = None,\n",
    "                ):\n",
    "\n",
    "        self.df = df.copy()\n",
    "        self.experiment_name = experiment_name\n",
    "        self.agent_classes = agent_classes\n",
    "        self.seeds = seeds\n",
    "        self.train_steps = train_steps\n",
    "        self.n_timesteps = n_timesteps\n",
    "        self.lookback = lookback\n",
    "        self.min_valid_length = min_valid_length\n",
    "        self.market_features = market_features\n",
    "        self.feature_config = feature_config or {'return': True, 'volume': True, 'lags': 5}\n",
    "        self.envs = [PositionTradingEnv,PositionTradingEnvV1,PositionTradingEnvV2]\n",
    "        self.base_path = f\"data/experiments/{experiment_name}\"\n",
    "        self.checkpoint_path = os.path.join(self.base_path, \"checkpoints\")\n",
    "        self.result_path = os.path.join(self.base_path, \"meta_df_transfer.csv\")\n",
    "        os.makedirs(self.checkpoint_path, exist_ok=True)\n",
    "\n",
    "    def _get_config_hash(self, config: Dict) -> str:\n",
    "        raw = json.dumps(config, sort_keys=True)\n",
    "        return hashlib.sha256(raw.encode()).hexdigest()\n",
    "\n",
    "    def _save_model(self, model, config_hash, agent_name, seed):\n",
    "        model_path = os.path.join(self.checkpoint_path, f\"{agent_name}_{config_hash}_{seed}.zip\")\n",
    "        model.save(model_path)\n",
    "\n",
    "    def _load_seen_hashes(self) -> set:\n",
    "        if os.path.exists(self.result_path):\n",
    "            df = pd.read_csv(self.result_path)\n",
    "            return set(zip(df['config_hash'], df['agent_name'], df['seed']))\n",
    "        return set()\n",
    "\n",
    "    def train(self, ticker: str):\n",
    "        df_ticker = self.df[self.df['symbol'] == ticker].sort_values(\"date\").reset_index(drop=True)\n",
    "        months = df_ticker['date'].dt.to_period(\"M\").unique()[24:]\n",
    "\n",
    "        records = []\n",
    "        seen_hashes = self._load_seen_hashes()\n",
    "        market_features = self.market_features\n",
    "        for m in tqdm(months[1:-1], desc=f\"Benchmarking {ticker}\"):\n",
    "            train_end_date = pd.Timestamp(m.start_time)\n",
    "            train_start_idx = df_ticker[df_ticker['date'] < train_end_date].index.max() - self.n_timesteps\n",
    "            test_start_idx = df_ticker[df_ticker['date'] < train_end_date].index.max() - self.lookback\n",
    "\n",
    "            if train_start_idx - self.lookback < 0 or test_start_idx + self.n_timesteps >= len(df_ticker):\n",
    "                continue\n",
    "            _df = df_ticker.copy() #.iloc[train_start_idx - self.lookback: train_start_idx + self.n_timesteps].copy()\n",
    "            #df_train = df_ticker.iloc[train_start_idx - self.lookback: train_start_idx + self.n_timesteps].copy()\n",
    "            #df_test = df_ticker.iloc[test_start_idx - self.lookback: test_start_idx + self.n_timesteps].copy()\n",
    "\n",
    "            #df_train = generate_lagged_features(df_train, self.feature_config)\n",
    "            #df_test = generate_lagged_features(df_test, self.feature_config)\n",
    "            _df = generate_lagged_features(_df, self.feature_config)\n",
    "            df_train = _df.iloc[: train_start_idx + self.n_timesteps].copy()\n",
    "            df_test = _df.iloc[: test_start_idx + self.n_timesteps].copy()\n",
    "            for agent_cls in self.agent_classes:\n",
    "                for seed in self.seeds:\n",
    "                    for steps in self.train_steps:\n",
    "                        for env_cls in self.envs:\n",
    "                            print(train_start_idx)\n",
    "                            env_version = 'v'+str(env_cls.__version__)\n",
    "                            config = {\n",
    "                                'ticker': ticker,\n",
    "                                'train_idx': int(train_start_idx),\n",
    "                                'test_idx': int(test_start_idx),\n",
    "                                'agent_policy':'MlpPolicy',\n",
    "                                'agent_name': agent_cls.__name__,\n",
    "                                'env_version':env_version,\n",
    "                                'agent_args':json.dumps({\"ent_coef\":0.1}),\n",
    "                                'timesteps': steps,\n",
    "                                'seed': seed,\n",
    "                                'feature_config': self.feature_config,\n",
    "                                'market_features':json.dumps(market_features)\n",
    "                            }\n",
    "                            config_hash = self._get_config_hash(config)\n",
    "\n",
    "                            if (config_hash, agent_cls.__name__, seed) in seen_hashes:\n",
    "                                continue\n",
    "\n",
    "                            env_train = Monitor(PositionTradingEnv(df_train, ticker , market_features=market_features, n_timesteps=self.n_timesteps, seed=seed, start_idx=train_start_idx))\n",
    "                            model = agent_cls(\"MlpPolicy\", env_train, verbose=0, seed=seed, ent_coef=0.1)\n",
    "                            model.learn(total_timesteps=steps)\n",
    "                            self._save_model(model, config_hash, agent_cls.__name__, seed)\n",
    "\n",
    "                            train_metrics = compute_agent_metrics(model, env_train)\n",
    "                            rand_metrics = compute_agent_metrics(None, env_train, random=True)\n",
    "\n",
    "                            env_test = Monitor(PositionTradingEnv(df_test, ticker,market_features=market_features, n_timesteps=self.n_timesteps, seed=seed, start_idx=test_start_idx))\n",
    "                            test_metrics = compute_agent_metrics(model, env_test)\n",
    "                            rand_test_metrics = compute_agent_metrics(None, env_test, random=True)\n",
    "\n",
    "                            oracle_train = compute_oracle_metrics(env_train)\n",
    "                            oracle_test = compute_oracle_metrics(env_test)\n",
    "\n",
    "                            record = {\n",
    "                                'ticker': ticker,\n",
    "                                'config_hash': config_hash,\n",
    "                                'agent_name': agent_cls.__name__,\n",
    "                                'env_version':env_version,\n",
    "                                'seed': seed,\n",
    "                                'month': m,\n",
    "                                #'train_reward': train_metrics['reward'],\n",
    "                                #'test_reward': test_metrics['reward'],\n",
    "                                #'train_random': rand_metrics['reward'],\n",
    "                                #'test_random': rand_test_metrics['reward'],\n",
    "                                'advantage_train': train_metrics['reward'] - rand_metrics['reward'],\n",
    "                                'advantage_test': test_metrics['reward'] - rand_test_metrics['reward'],\n",
    "                                'transfer_advantage': test_metrics['reward'] - rand_test_metrics['reward'],\n",
    "                                'generalization_score': (test_metrics['reward'] / (oracle_test.get(\"oracle_cumulative_return\", 1e-9))) -\n",
    "                                                        (rand_test_metrics['reward'] / (oracle_test.get(\"oracle_cumulative_return\", 1e-9))),\n",
    "                                'market_features':json.dumps(market_features),\n",
    "                                **{f\"train_{k}\": v for k, v in train_metrics.items()},\n",
    "                                **{f\"test_{k}\": v for k, v in test_metrics.items()},\n",
    "                                **{f\"train_random_{k}\": v for k, v in rand_metrics.items()},\n",
    "                                **{f\"test_random_{k}\": v for k, v in rand_test_metrics.items()},\n",
    "                                **{f\"train_{k}\": v for k, v in oracle_train.items()},\n",
    "                                **{f\"test_{k}\": v for k, v in oracle_test.items()},\n",
    "                                #**oracle_train,\n",
    "                                #**oracle_test,\n",
    "                                #**test_metrics,\n",
    "                                **compute_additional_diagnostics(env_test)\n",
    "                            }\n",
    "                            print(env_version,record['train_action_hold_ratio'],record['train_oracle_action_hold_ratio'])\n",
    "                            records.append(record)\n",
    "\n",
    "                if records:\n",
    "                    df_new = pd.DataFrame(records)\n",
    "                    if os.path.exists(self.result_path):\n",
    "                        df_existing = pd.read_csv(self.result_path)\n",
    "                        df_all = pd.concat([df_existing, df_new], ignore_index=True)\n",
    "                    else:\n",
    "                        df_all = df_new\n",
    "                    df_all.to_csv(self.result_path, index=False)\n",
    "                    print(f\"[‚úì] Results saved to {self.result_path}\")\n",
    "\n",
    "    def evaluate(self):\n",
    "        df = pd.read_csv(self.result_path)\n",
    "        print(\"[INFO] Transfer success rate:\", (df['transfer_delta'] > 0).mean())\n",
    "        plt.hist(df['transfer_delta'], bins=50)\n",
    "        plt.title(\"Transfer Delta Distribution\")\n",
    "        plt.show()\n",
    "        return df\n",
    "\n",
    "    def predict(self):\n",
    "        print(\"[TODO] Implement meta-feature-based predictor\")\n",
    "\n",
    "    def report(self):\n",
    "        print(\"[TODO] Implement full report generation with diagnostics\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff5da016",
   "metadata": {},
   "outputs": [],
   "source": [
    "ebm = EpisodeBenchmarkingEngine(OHLCV_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b472b2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Benchmarking AAPL:   0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      "v0 1.0 0.44537815126050423\n",
      "400\n",
      "v1 1.0 0.44537815126050423\n",
      "400\n"
     ]
    }
   ],
   "source": [
    "ebm.train('AAPL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f5474a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38199175",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5b50a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7740ecf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706b38dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af890458",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee326e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
