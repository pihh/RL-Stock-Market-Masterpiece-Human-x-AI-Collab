{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cab993d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP: Imports & Paths ===========================\n",
    "import jupyter\n",
    "from src.utils.system import boot, Notify\n",
    "\n",
    "boot()\n",
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.data.feature_pipeline import basic_chart_features,load_base_dataframe\n",
    "from src.predictability.easiness import rolling_sharpe, rolling_r2, rolling_info_ratio, rolling_autocorr\n",
    "from src.predictability.pipeline import generate_universe_easiness_report\n",
    "from IPython import display\n",
    "\n",
    "from src.experiments.experiment_tracker import ExperimentTracker\n",
    "from src.config import TOP2_STOCK_BY_SECTOR\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy.stats import skew, kurtosis, entropy\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from statsmodels.tsa.stattools import acf, acovf\n",
    "from src.defaults import TOP2_STOCK_BY_SECTOR\n",
    "from src.agent.base_model import TransformerPpo\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import  RobustScaler\n",
    "from IPython.display import display\n",
    "\n",
    "# FRAMEWORK STUFF =========================\n",
    "\n",
    "from src.data.feature_pipeline import load_base_dataframe\n",
    "from src.experiments.experiment_tracker import ExperimentTracker\n",
    "from src.env.base_trading_env import CumulativeTradingEnv,AlphaTradingEnv\n",
    "from src.env.base_timeseries_trading_env import SequenceAwareAlphaTradingEnv,SequenceAwareCumulativeTradingEnv\n",
    "from src.agent.base_model import TransformerPpo\n",
    "from src.defaults import RANDOM_SEEDS\n",
    "from src.utils.db import ConfigurableMixin\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "955d6b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "EXPERIENCE_NAME = \"episode_learning_transferability_v2\"\n",
    "FEATURE_COLS= [\"return_1d\", \"volume\", \"vix\"]\n",
    "# Prepare your dataframes for two consecutive episodes:\n",
    "SEEDS = RANDOM_SEEDS\n",
    "EPISODE_LENGTH = 21\n",
    "WINDOW_LENGTH = EPISODE_LENGTH*2\n",
    "N_UPDATES = 10\n",
    "\n",
    "excluded_tickers=['CEG', 'GEHC', 'GEV', 'KVUE', 'SOLV']\n",
    "excluded_tickers.sort()\n",
    "\n",
    "config={\n",
    "    \"excluded_tickers\": excluded_tickers,\n",
    "    \"episode_length\":EPISODE_LENGTH,\n",
    "    \"window_length\":WINDOW_LENGTH,\n",
    "    \"n_updates\":N_UPDATES,\n",
    "    \"agent\":\"TransformerPpoAgent\",\n",
    "    \"environment\":\"SequenceAwareCumulativeTradingEnv\"\n",
    "}\n",
    "run_settings={\n",
    "    \"excluded_tickers\": excluded_tickers,\n",
    "    \"start_date\": '2024-01-01',\n",
    "    \"end_date\":\"2026-01-01\",\n",
    "    \"episode_length\":EPISODE_LENGTH,\n",
    "    \"window_length\":WINDOW_LENGTH,\n",
    "    \"n_updates\":N_UPDATES\n",
    "}\n",
    "\n",
    "# Config section\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bd2209",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1b684e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD OHLCV ==========================================\n",
    "\n",
    "\n",
    "ohlcv_df = load_base_dataframe()\n",
    "ohlcv_df['date'] = pd.to_datetime(ohlcv_df['date'])\n",
    "ohlcv_df = ohlcv_df[(ohlcv_df['date'] >= run_settings[\"start_date\"]) & (ohlcv_df['date'] < run_settings[\"end_date\"])]\n",
    "ohlcv_df['month'] = ohlcv_df['date'].dt.to_period('M')\n",
    "ohlcv_df['return_1d'] = ohlcv_df['return_1d'].fillna(0)\n",
    "ohlcv_df['sector_id'] = ohlcv_df['sector_id'].fillna('unknown')\n",
    "ohlcv_df['industry_id'] = ohlcv_df['industry_id'].fillna('unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6643b935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP ===================================\n",
    "import jupyter\n",
    "import warnings\n",
    "\n",
    "from src.utils.system import boot, Notify\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b83a636e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohlcv_df = load_base_dataframe()\n",
    "notification = Notify(EXPERIENCE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "06bf8ae0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/22 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] AAPL 2023-01-01: Not enough lookback: start_idx=0 < window_length=42\n",
      "AAPL: Skipped 1/28 episodes due to insufficient lookback.\n",
      "[SKIP] AAPL 2023-02-01: Not enough lookback: start_idx=20 < window_length=42\n",
      "AAPL: Skipped 2/28 episodes due to insufficient lookback.\n",
      "[SKIP] AAPL 2023-03-01: Not enough lookback: start_idx=39 < window_length=42\n",
      "AAPL: Skipped 3/28 episodes due to insufficient lookback.\n",
      "{'ticker': 'AAPL', 'start': 62, 'id': 126, 'date': '2023-04-01'}\n",
      "{'ticker': 'AAPL', 'start': 81, 'id': 127, 'date': '2023-05-01'}\n",
      "will test\n",
      "<SequenceAwareCumulativeTradingEnv instance>\n",
      "<SequenceAwareCumulativeTradingEnv instance>\n",
      "<SequenceAwareCumulativeTradingEnv instance>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/22 [02:21<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Object of type Series is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 443\u001b[0m\n\u001b[0;32m    440\u001b[0m         notification\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain complete for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mticker\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Exec time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00melapsed\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 443\u001b[0m     main()\n\u001b[0;32m    445\u001b[0m \u001b[38;5;66;03m# --- Visualization Example: Transfer Matrix -----------------------------\u001b[39;00m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_transfer_matrix\u001b[39m(results_csv\u001b[38;5;241m=\u001b[39mRESULTS_CSV, ticker\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "Cell \u001b[1;32mIn[48], line 419\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    417\u001b[0m             train_sequence \u001b[38;5;241m=\u001b[39m [[ticker, train_ep[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m\"\u001b[39m]]]\n\u001b[0;32m    418\u001b[0m             test_sequence \u001b[38;5;241m=\u001b[39m [[ticker, test_ep[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m\"\u001b[39m]]]\n\u001b[1;32m--> 419\u001b[0m             agent_rewards, random_rewards, t_pval, mw_pval, results \u001b[38;5;241m=\u001b[39m test_transferability(\n\u001b[0;32m    420\u001b[0m                 env_maker,\n\u001b[0;32m    421\u001b[0m                 agent_maker,\n\u001b[0;32m    422\u001b[0m                 ohlcv_df,\n\u001b[0;32m    423\u001b[0m                 train_sequence,\n\u001b[0;32m    424\u001b[0m                 test_sequence,\n\u001b[0;32m    425\u001b[0m                 feature_cols\u001b[38;5;241m=\u001b[39mFEATURE_COLS,\n\u001b[0;32m    426\u001b[0m                 episode_length\u001b[38;5;241m=\u001b[39mEPISODE_LENGTH,\n\u001b[0;32m    427\u001b[0m                 random_seeds\u001b[38;5;241m=\u001b[39mRANDOM_SEEDS,\n\u001b[0;32m    428\u001b[0m                 n_updates\u001b[38;5;241m=\u001b[39mN_UPDATES,\n\u001b[0;32m    429\u001b[0m                 window_length\u001b[38;5;241m=\u001b[39mWINDOW_LENGTH,\n\u001b[0;32m    430\u001b[0m                 episode_id_train\u001b[38;5;241m=\u001b[39mtrain_ep[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    431\u001b[0m                 episode_id_test\u001b[38;5;241m=\u001b[39mtest_ep[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    432\u001b[0m                 policy_class\u001b[38;5;241m=\u001b[39mablation[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpolicy_class\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    433\u001b[0m                 agent_class\u001b[38;5;241m=\u001b[39mablation[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magent_class\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    434\u001b[0m                 ablation_tag\u001b[38;5;241m=\u001b[39mablation[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mablation_tag\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    435\u001b[0m                 meta_train\u001b[38;5;241m=\u001b[39mmeta_train,\n\u001b[0;32m    436\u001b[0m                 meta_test\u001b[38;5;241m=\u001b[39mmeta_test\n\u001b[0;32m    437\u001b[0m             )\n\u001b[0;32m    438\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mticker\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Valid train episodes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalid_train_episodes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Valid test episodes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalid_test_episodes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    439\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m run_start_time\n",
      "Cell \u001b[1;32mIn[48], line 293\u001b[0m, in \u001b[0;36mtest_transferability\u001b[1;34m(env_maker, agent_maker, ohlcv_df, episode_sequence_train, episode_sequence_test, feature_cols, episode_length, episode_id_train, episode_id_test, n_updates, window_length, random_seeds, policy_class, agent_class, ablation_tag, verbose, meta_train, meta_test)\u001b[0m\n\u001b[0;32m    285\u001b[0m mw_stat, mw_pval \u001b[38;5;241m=\u001b[39m mannwhitneyu(agent_rewards_B, random_rewards_B, alternative\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgreater\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# --- Save meta-features, report, and results\u001b[39;00m\n\u001b[0;32m    288\u001b[0m study_result \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexperience_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: EXPERIENCE_NAME,\n\u001b[0;32m    290\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpolicy_class\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(policy_class),\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magent_class\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(agent_class),\n\u001b[0;32m    292\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mablation\u001b[39m\u001b[38;5;124m\"\u001b[39m: ablation_tag,\n\u001b[1;32m--> 293\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_meta\u001b[39m\u001b[38;5;124m\"\u001b[39m: json\u001b[38;5;241m.\u001b[39mdumps(meta_train),\n\u001b[0;32m    294\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_meta\u001b[39m\u001b[38;5;124m\"\u001b[39m: json\u001b[38;5;241m.\u001b[39mdumps(meta_test),\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_episode_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: episode_id_train,\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_episode_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: episode_id_test,\n\u001b[0;32m    297\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhash\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_hash,\n\u001b[0;32m    298\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magent_rewards_mean\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mmedian(agent_rewards_B),\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magent_rewards_std\u001b[39m\u001b[38;5;124m\"\u001b[39m: agent_rewards_B\u001b[38;5;241m.\u001b[39mstd(),\n\u001b[0;32m    300\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandom_rewards_mean\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mmedian(random_rewards_B),\n\u001b[0;32m    301\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandom_rewards_std\u001b[39m\u001b[38;5;124m\"\u001b[39m: random_rewards_B\u001b[38;5;241m.\u001b[39mstd(),\n\u001b[0;32m    302\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt_pval\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(t_pval),\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmw_pval\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(mw_pval),\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madvantage\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mmedian(agent_rewards_B) \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mmedian(random_rewards_B),\n\u001b[0;32m    305\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magent_rewards\u001b[39m\u001b[38;5;124m\"\u001b[39m: json\u001b[38;5;241m.\u001b[39mdumps(agent_rewards_B\u001b[38;5;241m.\u001b[39mtolist()),\n\u001b[0;32m    306\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandom_rewards\u001b[39m\u001b[38;5;124m\"\u001b[39m: json\u001b[38;5;241m.\u001b[39mdumps(random_rewards_B\u001b[38;5;241m.\u001b[39mtolist()),\n\u001b[0;32m    307\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_date\u001b[39m\u001b[38;5;124m\"\u001b[39m: meta_train\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m meta_train \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    308\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_date\u001b[39m\u001b[38;5;124m\"\u001b[39m: meta_test\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m meta_test \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    309\u001b[0m }\n\u001b[0;32m    310\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df, pd\u001b[38;5;241m.\u001b[39mDataFrame([study_result])], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28mprint\u001b[39m(RESULTS_CSV)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\json\\__init__.py:231\u001b[0m, in \u001b[0;36mdumps\u001b[1;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;66;03m# cached encoder\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m skipkeys \u001b[38;5;129;01mand\u001b[39;00m ensure_ascii \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    228\u001b[0m     check_circular \u001b[38;5;129;01mand\u001b[39;00m allow_nan \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m separators \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    230\u001b[0m     default \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sort_keys \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _default_encoder\u001b[38;5;241m.\u001b[39mencode(obj)\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONEncoder\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\json\\encoder.py:200\u001b[0m, in \u001b[0;36mJSONEncoder.encode\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m encode_basestring(o)\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# This doesn't pass the iterator directly to ''.join() because the\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# exceptions aren't as detailed.  The list call should be roughly\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterencode(o, _one_shot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunks, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m    202\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(chunks)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\json\\encoder.py:258\u001b[0m, in \u001b[0;36mJSONEncoder.iterencode\u001b[1;34m(self, o, _one_shot)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    254\u001b[0m     _iterencode \u001b[38;5;241m=\u001b[39m _make_iterencode(\n\u001b[0;32m    255\u001b[0m         markers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault, _encoder, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindent, floatstr,\n\u001b[0;32m    256\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msort_keys,\n\u001b[0;32m    257\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskipkeys, _one_shot)\n\u001b[1;32m--> 258\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _iterencode(o, \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\json\\encoder.py:180\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[0;32m    162\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;124;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;124;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    178\u001b[0m \n\u001b[0;32m    179\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 180\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    181\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis not JSON serializable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Object of type Series is not JSON serializable"
     ]
    }
   ],
   "source": [
    "# --- Imports & Setup ----------------------------------------------------\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import hashlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import ttest_ind, mannwhitneyu, skew, kurtosis, entropy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Your custom imports:\n",
    "from src.utils.system import boot, Notify\n",
    "from src.data.feature_pipeline import load_base_dataframe, basic_chart_features\n",
    "from src.predictability.easiness import rolling_sharpe, rolling_r2, rolling_info_ratio, rolling_autocorr\n",
    "from src.experiments.experiment_tracker import ExperimentTracker\n",
    "from src.env.base_trading_env import CumulativeTradingEnv, AlphaTradingEnv\n",
    "from src.env.base_timeseries_trading_env import SequenceAwareAlphaTradingEnv, SequenceAwareCumulativeTradingEnv\n",
    "from src.agent.base_model import TransformerPpo\n",
    "from src.defaults import RANDOM_SEEDS, TOP2_STOCK_BY_SECTOR\n",
    "from src.utils.db import ConfigurableMixin\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from sb3_contrib import RecurrentPPO\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from stable_baselines3.common.policies import ActorCriticPolicy\n",
    "from stable_baselines3.common.callbacks import EvalCallback, CheckpointCallback\n",
    "from sb3_contrib.common.recurrent.policies import RecurrentActorCriticPolicy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "boot()\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from sb3_contrib import RecurrentPPO\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from stable_baselines3.common.policies import ActorCriticPolicy\n",
    "from stable_baselines3.common.callbacks import EvalCallback, CheckpointCallback\n",
    "from sb3_contrib.common.recurrent.policies import RecurrentActorCriticPolicy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "\n",
    "def generate_causal_mask(seq_len):\n",
    "    return torch.triu(torch.ones((seq_len, seq_len), dtype=torch.bool), diagonal=1)\n",
    "\n",
    "def sinusoidal_positional_encoding(seq_len, d_model, device):\n",
    "    \"\"\"Returns a (seq_len, d_model) matrix with classic Transformer sin-cos encoding.\"\"\"\n",
    "    pe = torch.zeros(seq_len, d_model, device=device)\n",
    "    position = torch.arange(0, seq_len, dtype=torch.float, device=device).unsqueeze(1)\n",
    "    div_term = torch.exp(torch.arange(0, d_model, 2, device=device).float() * (-torch.log(torch.tensor(10000.0)) / d_model))\n",
    "    pe[:, 0::2] = torch.sin(position * div_term)\n",
    "    pe[:, 1::2] = torch.cos(position * div_term)\n",
    "    return pe\n",
    "\n",
    "class TransformerFeatureExtractor(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space, d_model=64, n_heads=4, n_layers=2):\n",
    "        super().__init__(observation_space, features_dim=d_model)\n",
    "        self.d_model = d_model\n",
    "        input_dim = observation_space.shape[-1]\n",
    "        self.input_proj = nn.Linear(input_dim, d_model)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=n_heads, batch_first=True)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n",
    "\n",
    "    def forward(self, obs):\n",
    "        # obs: (batch, seq_len, input_dim)\n",
    "        x = self.input_proj(obs)\n",
    "        seq_len = x.size(1)\n",
    "        device = x.device\n",
    "        pe = sinusoidal_positional_encoding(seq_len, self.d_model, device)\n",
    "        x = x + pe.unsqueeze(0)  # (1, seq_len, d_model) for broadcasting\n",
    "        causal_mask = generate_causal_mask(seq_len).to(device)\n",
    "        x = self.transformer(x, mask=causal_mask)\n",
    "        pooled_output = x[:, -1]\n",
    "        return pooled_output\n",
    "\n",
    "# Transformer Policy ===================================\n",
    "class TransformerPolicy(RecurrentActorCriticPolicy):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs,\n",
    "                         features_extractor_class=TransformerFeatureExtractor,\n",
    "                         features_extractor_kwargs=dict(\n",
    "                             d_model=64, n_heads=4, n_layers=2\n",
    "                         ))\n",
    "        #self._build(self.lr_schedule)\n",
    "\n",
    "# Regime Augmentation Wrapper ===========================\n",
    "class RegimeAugmentingWrapper(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        self.regime_dim = 3  # One-hot: bull, bear, sideways\n",
    "        obs_shape = self.observation_space.shape\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            low=-np.inf, high=np.inf,\n",
    "            shape=(obs_shape[0], obs_shape[1] + self.regime_dim),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "\n",
    "    def observation(self, obs):\n",
    "        regime = self.env.get_current_regime()  # 0,1,2 -> bull,bear,sideways\n",
    "        one_hot = np.zeros(self.regime_dim)\n",
    "        one_hot[regime] = 1.0\n",
    "        one_hot = np.repeat(one_hot[None, :], obs.shape[0], axis=0)\n",
    "        return np.concatenate([obs, one_hot], axis=-1)\n",
    "# --- Config -------------------------------------------------------------\n",
    "\n",
    "EXPERIENCE_NAME = \"episode_learning_transferability_v2\"\n",
    "RESULTS_CSV = EXPERIENCE_NAME + \".csv\"\n",
    "FEATURE_COLS = [\"return_1d\", \"volume\", \"vix\"]\n",
    "\n",
    "EPISODE_LENGTH = 21\n",
    "WINDOW_LENGTH = EPISODE_LENGTH * 2\n",
    "N_UPDATES = 10\n",
    "MAX_LAG = 3   # How many months ahead to test (multi-lag transfer)\n",
    "RANDOM_SEEDS = [7, 314, 42]\n",
    "excluded_tickers = ['CEG', 'GEHC', 'GEV', 'KVUE', 'SOLV']\n",
    "excluded_tickers.sort()\n",
    "tickers = [t for t in TOP2_STOCK_BY_SECTOR if t not in excluded_tickers]\n",
    "\n",
    "run_settings = {\n",
    "    \"excluded_tickers\": excluded_tickers,\n",
    "    \"start_date\": '2023-01-01',\n",
    "    \"end_date\": \"2026-01-01\",\n",
    "    \"episode_length\": EPISODE_LENGTH,\n",
    "    \"window_length\": WINDOW_LENGTH,\n",
    "    \"n_updates\": N_UPDATES,\n",
    "    \"max_lag\": MAX_LAG,\n",
    "    \"random_seeds\": RANDOM_SEEDS\n",
    "}\n",
    "\n",
    "notification = Notify(EXPERIENCE_NAME)\n",
    "\n",
    "# --- Utilities ----------------------------------------------------------\n",
    "\n",
    "def encode_hash(run_config: dict) -> str:\n",
    "    xx = json.dumps(run_config, sort_keys=True)\n",
    "    return hashlib.sha256(xx.encode()).hexdigest()\n",
    "\n",
    "def month_ranges(start_date_str):\n",
    "    start = pd.Timestamp(start_date_str).replace(day=1)\n",
    "    today = pd.Timestamp.today().replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "    next_month = (today + pd.offsets.MonthBegin(1)).replace(day=1)\n",
    "    final_month = (next_month + pd.offsets.MonthBegin(1)).replace(day=1)\n",
    "    ranges = []\n",
    "    d = start\n",
    "    while d < final_month:\n",
    "        next_d = (d + pd.offsets.MonthBegin(1)).replace(day=1)\n",
    "        ranges.append([d.strftime('%Y-%m-%d'), next_d.strftime('%Y-%m-%d')])\n",
    "        d = next_d\n",
    "    return ranges\n",
    "\n",
    "def compute_meta_features(episode_df, returns_col='return_1d'):\n",
    "    \"\"\"Compute meta-features for a window/episode.\"\"\"\n",
    "    r = episode_df[returns_col].values\n",
    "\n",
    "    features = {\n",
    "        'volatility': np.std(r),\n",
    "        'mean_return': np.mean(r),\n",
    "        'skew': skew(r),\n",
    "        'kurtosis': kurtosis(r),\n",
    "        'entropy': entropy(np.histogram(r, bins=10, density=True)[0] + 1e-8),\n",
    "        'sharpe':rolling_sharpe(episode_df['return_1d'], window=EPISODE_LENGTH),\n",
    "        'autocorr':rolling_autocorr(episode_df['return_1d'], window=EPISODE_LENGTH),\n",
    "        'info_ratio': rolling_info_ratio(\n",
    "    episode_df['return_1d'],\n",
    "    episode_df['market_return_1d'],  # replace with actual column\n",
    "    window=EPISODE_LENGTH\n",
    ").iloc[-1],\n",
    "        'rolling_r2':rolling_r2(episode_df['return_1d'], window=EPISODE_LENGTH),\n",
    "        #'sharpe': rolling_sharpe(episode_df[['return_1d']], window=EPISODE_LENGTH).iloc[-1],\n",
    "        #' rolling_autocorr(episode_df[['return_1d']], window=EPISODE_LENGTH).iloc[-1],\n",
    "        #' rolling_info_ratio(episode_df[['return_1d']], window=EPISODE_LENGTH).iloc[-1],\n",
    "        #' rolling_r2(episode_df['return_1d'], window=EPISODE_LENGTH).iloc[-1],\n",
    "        'drawdown': episode_df['close'].cummax() - episode_df['return_1d'],\n",
    "    }\n",
    "    # Optionally: add regime label if available\n",
    "    if \"regime\" in episode_df.columns:\n",
    "        features[\"regime\"] = episode_df[\"regime\"].iloc[-1]\n",
    "    else:\n",
    "        features[\"regime\"] = 0  # Or compute via your regime classifier\n",
    "    return features\n",
    "\n",
    "# --- Environment & Agent Factory ----------------------------------------\n",
    "\n",
    "def env_maker(seed, ohlcv_df, feature_cols, episode_length, window_length):\n",
    "    return SequenceAwareCumulativeTradingEnv(\n",
    "        ohlcv_df,\n",
    "        feature_cols=feature_cols,\n",
    "        episode_length=episode_length,\n",
    "        transaction_cost=0,\n",
    "        seed=seed,\n",
    "        window_length=window_length\n",
    "    )\n",
    "\n",
    "def agent_maker(environment, seed, policy_class, agent_class=TransformerPpo, **kwargs):\n",
    "    agent = agent_class(\n",
    "        RecurrentPPO,\n",
    "        TransformerPolicy,\n",
    "        environment,\n",
    "        model_config={\n",
    "            \"n_steps\": EPISODE_LENGTH,\n",
    "            \"batch_size\": EPISODE_LENGTH,\n",
    "        },\n",
    "        run_config={\"seed\": seed, \"verbose\": 0},\n",
    "        **kwargs\n",
    "    )\n",
    "    return agent\n",
    "\n",
    "# --- Transferability Test Function --------------------------------------\n",
    "\n",
    "def test_transferability(\n",
    "    env_maker, agent_maker, ohlcv_df,\n",
    "    episode_sequence_train, episode_sequence_test, feature_cols, episode_length,\n",
    "    episode_id_train, episode_id_test, n_updates=8, window_length=10,\n",
    "    random_seeds=[7, 314], policy_class=None, agent_class=None,\n",
    "    ablation_tag=None, verbose=True, meta_train=None, meta_test=None\n",
    "):\n",
    "    agent_rewards_B, random_rewards_B = [], []\n",
    "    total_timesteps = episode_length * n_updates\n",
    "    run_results = []\n",
    "\n",
    "    run_hash = encode_hash({\n",
    "        \"policy_class\": str(policy_class),\n",
    "        \"agent_class\": str(agent_class),\n",
    "        \"n_updates\": n_updates,\n",
    "        \"train_episode_id\": episode_id_train,\n",
    "        \"test_episode_id\": episode_id_test,\n",
    "        \"ablation\": ablation_tag\n",
    "    })\n",
    "\n",
    "    # --- CSV result caching -----------\n",
    "    if os.path.exists(RESULTS_CSV):\n",
    "        df = pd.read_csv(RESULTS_CSV)\n",
    "        if not df.empty and (df['hash'] == run_hash).any():\n",
    "            return [], [], 0, 0, {}\n",
    "    else:\n",
    "        df = pd.DataFrame()\n",
    "\n",
    "    for run, seed in enumerate(random_seeds):\n",
    "        np.random.seed(seed)\n",
    "        # Train on Episode A\n",
    "        envA = env_maker(seed, ohlcv_df, feature_cols, episode_length, window_length)\n",
    "        envA.set_episode_sequence(episode_sequence_train)\n",
    "        print(envA)\n",
    "        model = agent_maker(envA, seed, policy_class, agent_class)\n",
    "        agent = model.agent\n",
    "        agent.learn(total_timesteps=total_timesteps)\n",
    "\n",
    "        # Test trained agent on Episode B\n",
    "        envB = env_maker(seed, ohlcv_df, feature_cols, episode_length, window_length)\n",
    "        envB.set_episode_sequence(episode_sequence_test)\n",
    "        obs, _ = envB.reset()\n",
    "        rewards = []\n",
    "        done = False\n",
    "        while not done:\n",
    "            action, _ = agent.predict(obs)\n",
    "            obs, reward, done, truncated, info = envB.step(action)\n",
    "            rewards.append(reward)\n",
    "        agent_rewards_B.append(np.sum(rewards))\n",
    "\n",
    "        # Random policy on Episode B\n",
    "        envB_rand = env_maker(seed, ohlcv_df, feature_cols, episode_length, window_length)\n",
    "        envB_rand.set_episode_sequence(episode_sequence_test)\n",
    "        obs, _ = envB_rand.reset()\n",
    "        rand_rewards = []\n",
    "        done = False\n",
    "        while not done:\n",
    "            action = envB_rand.action_space.sample()\n",
    "            obs, reward, done, truncated, info = envB_rand.step(action)\n",
    "            rand_rewards.append(reward)\n",
    "        random_rewards_B.append(np.sum(rand_rewards))\n",
    "\n",
    "    # --- Statistical testing on Episode B\n",
    "    agent_rewards_B = np.array(agent_rewards_B)\n",
    "    random_rewards_B = np.array(random_rewards_B)\n",
    "\n",
    "    t_stat, t_pval = ttest_ind(agent_rewards_B, random_rewards_B, equal_var=False)\n",
    "    mw_stat, mw_pval = mannwhitneyu(agent_rewards_B, random_rewards_B, alternative='greater')\n",
    "\n",
    "    # --- Save meta-features, report, and results\n",
    "    study_result = {\n",
    "        \"experience_name\": EXPERIENCE_NAME,\n",
    "        \"policy_class\": str(policy_class),\n",
    "        \"agent_class\": str(agent_class),\n",
    "        \"ablation\": ablation_tag,\n",
    "        \"train_meta\": json.dumps(meta_train),\n",
    "        \"test_meta\": json.dumps(meta_test),\n",
    "        \"train_episode_id\": episode_id_train,\n",
    "        \"test_episode_id\": episode_id_test,\n",
    "        \"hash\": run_hash,\n",
    "        \"agent_rewards_mean\": np.median(agent_rewards_B),\n",
    "        \"agent_rewards_std\": agent_rewards_B.std(),\n",
    "        \"random_rewards_mean\": np.median(random_rewards_B),\n",
    "        \"random_rewards_std\": random_rewards_B.std(),\n",
    "        \"t_pval\": float(t_pval),\n",
    "        \"mw_pval\": float(mw_pval),\n",
    "        \"advantage\": np.median(agent_rewards_B) - np.median(random_rewards_B),\n",
    "        \"agent_rewards\": json.dumps(agent_rewards_B.tolist()),\n",
    "        \"random_rewards\": json.dumps(random_rewards_B.tolist()),\n",
    "        \"train_date\": meta_train.get(\"date\") if meta_train else \"\",\n",
    "        \"test_date\": meta_test.get(\"date\") if meta_test else \"\",\n",
    "    }\n",
    "    df = pd.concat([df, pd.DataFrame([study_result])], ignore_index=True)\n",
    "    print(RESULTS_CSV)\n",
    "    df.to_csv(RESULTS_CSV, index=False)\n",
    "\n",
    "    # Optionally: Save a per-run markdown/HTML report here for later\n",
    "    with open(f\"report_{run_hash}.md\", \"w\") as f:\n",
    "        f.write(f\"# Transferability Run: {run_hash}\\n\")\n",
    "        f.write(f\"## Train Meta\\n{json.dumps(meta_train, indent=2)}\\n\")\n",
    "        f.write(f\"## Test Meta\\n{json.dumps(meta_test, indent=2)}\\n\")\n",
    "        f.write(f\"### Results\\n\")\n",
    "        f.write(json.dumps(study_result, indent=2))\n",
    "\n",
    "    return agent_rewards_B, random_rewards_B, t_pval, mw_pval, study_result\n",
    "\n",
    "# --- Multi-Lag Transfer, Meta-Features, NxN Matrix ----------------------\n",
    "def safe_get_episode(env, ticker, start):\n",
    "    try:\n",
    "        return env.get_episode_by_start_date(ticker, start)\n",
    "    except Exception as e:\n",
    "        print(f\"[SKIP] get_episode_by_start_date failed for {ticker} {start}: {e}\")\n",
    "        return None, None, None\n",
    "    \n",
    "def main():\n",
    "    ohlcv_df = load_base_dataframe()\n",
    "    ohlcv_df['date'] = pd.to_datetime(ohlcv_df['date'])\n",
    "    ohlcv_df = ohlcv_df[\n",
    "        (ohlcv_df['date'] >= run_settings[\"start_date\"]) &\n",
    "        (ohlcv_df['date'] < run_settings[\"end_date\"])\n",
    "    ]\n",
    "    ohlcv_df['month'] = ohlcv_df['date'].dt.to_period('M')\n",
    "    ohlcv_df['return_1d'] = ohlcv_df['return_1d'].fillna(0)\n",
    "    ohlcv_df['sector_id'] = ohlcv_df['sector_id'].fillna('unknown')\n",
    "    ohlcv_df['industry_id'] = ohlcv_df['industry_id'].fillna('unknown')\n",
    "\n",
    "    month_pairs = month_ranges(run_settings['start_date'])[:-3]\n",
    "    ablation_settings = [\n",
    "        {\"policy_class\": TransformerPolicy, \"agent_class\": TransformerPpo, \"ablation_tag\": \"full\"},\n",
    "        # Add ablation variants here, e.g., no regime, different policies, etc.\n",
    "        # {\"policy_class\": \"SimpleMLPPolicy\", \"agent_class\": MlpPpo, \"ablation_tag\": \"mlp\"},\n",
    "    ]\n",
    "\n",
    "    # For each ticker, perform NxN transfer, meta-feature logging, and multi-lag evaluation\n",
    "    for ticker in tqdm(tickers):\n",
    "        run_start_time = time.time()\n",
    "        notification.info(f\"Train start for {ticker} | {datetime.now().strftime('%Y-%m-%d %H:%M')}\")\n",
    "        # --- Precompute episodes for all months for this ticker\n",
    "        episodes = []\n",
    "        train_env = SequenceAwareCumulativeTradingEnv(\n",
    "            ohlcv_df,\n",
    "            feature_cols=FEATURE_COLS,\n",
    "            episode_length=EPISODE_LENGTH,\n",
    "            transaction_cost=0,\n",
    "            seed=RANDOM_SEEDS[0],\n",
    "            window_length=WINDOW_LENGTH\n",
    "        )\n",
    "        skipped = 0\n",
    "        for p in month_pairs:\n",
    "            try:\n",
    "                _, start_train, id_train = train_env.get_episode_by_start_date(ticker, p[0])\n",
    "                episodes.append({\"ticker\": ticker, \"start\": start_train, \"id\": id_train, \"date\": p[0]})\n",
    "            except ValueError as e:\n",
    "                # Optionally print or log this skip for traceability\n",
    "                print(f\"[SKIP] {ticker} {p[0]}: {e}\")\n",
    "                skipped += 1\n",
    "                print(f\"{ticker}: Skipped {skipped}/{len(month_pairs)} episodes due to insufficient lookback.\")\n",
    "\n",
    "                continue\n",
    "        # --- NxN transfer matrix loop\n",
    "        for ablation in ablation_settings:\n",
    "            valid_train_episodes = 0\n",
    "            valid_test_episodes = 0\n",
    "            for i, train_ep in enumerate(episodes):\n",
    "                try:\n",
    "                    print(train_ep)\n",
    "                    train_env.set_episode_sequence([[ticker, train_ep[\"start\"]]])\n",
    "               \n",
    "                    train_env.reset()\n",
    "                    train_df = train_env.episode_df.copy()\n",
    "                    #train_df, _, _ = train_env.get_episode_by_start_date(ticker, train_ep[\"start\"])\n",
    "                    #valid_train_episodes += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"[SKIP] Train episode failed for {ticker} {train_ep['start']}: {e}\")\n",
    "                    continue\n",
    "                for lag in range(1, MAX_LAG+1):\n",
    "                    test_idx = i + lag\n",
    "                    if test_idx >= len(episodes):\n",
    "                        continue\n",
    "                    test_ep = episodes[test_idx]\n",
    "                    print(episodes[test_idx])\n",
    "                    try:\n",
    "                        #test_df, _, _ = train_env.get_episode_by_start_date(ticker, test_ep[\"start\"])\n",
    "                        train_env.set_episode_sequence([[ticker, test_ep[\"start\"]]])\n",
    "                        valid_test_episodes += 1\n",
    "                        train_env.reset()\n",
    "                        test_df = train_env.episode_df.copy()\n",
    "                    except Exception as e:\n",
    "                        print(f\"[SKIP] Test episode failed for {ticker} {test_ep['start']}: {e}\")\n",
    "                        continue\n",
    "                    # ... rest of logic ...\n",
    "                    \n",
    "                    print('will test')\n",
    "                    meta_test = compute_meta_features(test_df)\n",
    "                    meta_train = compute_meta_features(test_df)\n",
    "                    meta_test[\"date\"] = test_ep[\"date\"]\n",
    "                    meta_train[\"date\"] = train_ep[\"date\"]\n",
    "                    #meta_test[\"date\"] = test_ep[\"date\"]\n",
    "\n",
    "                    train_sequence = [[ticker, train_ep[\"start\"]]]\n",
    "                    test_sequence = [[ticker, test_ep[\"start\"]]]\n",
    "                    agent_rewards, random_rewards, t_pval, mw_pval, results = test_transferability(\n",
    "                        env_maker,\n",
    "                        agent_maker,\n",
    "                        ohlcv_df,\n",
    "                        train_sequence,\n",
    "                        test_sequence,\n",
    "                        feature_cols=FEATURE_COLS,\n",
    "                        episode_length=EPISODE_LENGTH,\n",
    "                        random_seeds=RANDOM_SEEDS,\n",
    "                        n_updates=N_UPDATES,\n",
    "                        window_length=WINDOW_LENGTH,\n",
    "                        episode_id_train=train_ep[\"id\"],\n",
    "                        episode_id_test=test_ep[\"id\"],\n",
    "                        policy_class=ablation[\"policy_class\"],\n",
    "                        agent_class=ablation[\"agent_class\"],\n",
    "                        ablation_tag=ablation[\"ablation_tag\"],\n",
    "                        meta_train=meta_train,\n",
    "                        meta_test=meta_test\n",
    "                    )\n",
    "                print(f\"{ticker}: Valid train episodes: {valid_train_episodes}, Valid test episodes: {valid_test_episodes}\")\n",
    "        elapsed = time.time() - run_start_time\n",
    "        notification.info(f\"Train complete for {ticker} | {datetime.now().strftime('%Y-%m-%d %H:%M')} | Exec time: {elapsed:.1f}s\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "# --- Visualization Example: Transfer Matrix -----------------------------\n",
    "def plot_transfer_matrix(results_csv=RESULTS_CSV, ticker=None):\n",
    "    df = pd.read_csv(results_csv)\n",
    "    if ticker is not None:\n",
    "        df = df[df[\"ticker\"] == ticker]\n",
    "    # Pivot: rows=train_date, cols=test_date, values=advantage or t_pval\n",
    "    matrix = df.pivot_table(index=\"train_date\", columns=\"test_date\", values=\"advantage\")\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
    "    plt.title(f\"Transferability Matrix ({ticker})\")\n",
    "    plt.ylabel(\"Train Month\")\n",
    "    plt.xlabel(\"Test Month\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccbbcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_transfer_matrix(\"episode_learning_transferability_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc1a4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "e= env_maker(1,ohlcv_df,FEATURE_COLS,EPISODE_LENGTH,WINDOW_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a1985a",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.set_episode_sequence([['AAPL',100]])\n",
    "e.reset()\n",
    "e.episode_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0129377",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.set_episode_sequence([['AAPL',200]])\n",
    "e.reset()\n",
    "e.episode_df\n",
    "rolling_sharpe(e.episode_df['return_1d'], window=EPISODE_LENGTH).dropna().iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a791a0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.episode_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df29a7fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca534d24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
