{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33beca1f",
   "metadata": {},
   "source": [
    "# 03 - Predictability & Universe Filtering\n",
    "\n",
    "1. Compute rolling predictability metrics for each ticker\n",
    "2. Visualize and compare scores across universe and time\n",
    "3. Select top-N most “learnable” tickers for RL agent\n",
    "4. Document all decisions, assumptions, and open questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cab993d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP: Imports & Paths ===========================\n",
    "import jupyter\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "from src.data.feature_pipeline import basic_chart_features,load_base_dataframe\n",
    "from src.predictability.easiness import rolling_sharpe, rolling_r2, rolling_info_ratio, rolling_autocorr\n",
    "from src.predictability.pipeline import generate_universe_easiness_report\n",
    "from IPython import display\n",
    "from src.utils.system import boot,notify\n",
    "from src.experiments.experiment_tracker import ExperimentTracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cc3b9c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1000,\n",
       " 'learning_rate': 0.05,\n",
       " 'max_depth': 6,\n",
       " 'random_state': 42,\n",
       " 'regime': 'rolling_mean',\n",
       " 'features': ['day',\n",
       "  'dayofweek',\n",
       "  'family',\n",
       "  'is_holiday',\n",
       "  'lag_14',\n",
       "  'lag_7',\n",
       "  'month',\n",
       "  'onpromo_lag_7',\n",
       "  'onpromo_mean_14',\n",
       "  'rolling_mean_14',\n",
       "  'rolling_mean_7',\n",
       "  'rolling_std_14',\n",
       "  'rolling_std_7',\n",
       "  'store_nbr',\n",
       "  'trans_lag_14',\n",
       "  'trans_lag_7',\n",
       "  'trans_roll_mean_14',\n",
       "  'trans_roll_mean_7',\n",
       "  'transactions',\n",
       "  'week']}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [\n",
    "        'store_nbr', 'family', 'dayofweek', 'month', 'day', 'week', 'is_holiday',\n",
    "        'transactions', 'lag_7', 'lag_14', 'trans_lag_7', 'trans_lag_14',\n",
    "        'rolling_mean_7', 'rolling_std_7', 'rolling_mean_14', 'rolling_std_14',\n",
    "        'trans_roll_mean_7', 'trans_roll_mean_14',\n",
    "        'onpromo_lag_7', 'onpromo_mean_14'\n",
    "]\n",
    "\n",
    "run_settings={\n",
    "    \"n_estimators\":1000, \n",
    "    \"learning_rate\":0.05, \n",
    "    \"max_depth\":6, \n",
    "    \"random_state\":42,\n",
    "    \"regime\": \"rolling_mean\",\n",
    "    \"features\": features.copy()\n",
    "}\n",
    "run_settings[\"features\"].sort()\n",
    "run_settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7bc8a817",
   "metadata": {},
   "outputs": [],
   "source": [
    "boot()\n",
    "notify('03 - Predictability & Universe Filtering',title=\"Train complete\", level=\"info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1b684e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD OHLCV ==========================================\n",
    "ohlcv_df = load_base_dataframe()\n",
    "ohlcv_df.tail()\n",
    "_ohlcv=ohlcv_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "de704137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CROP THE SAMPLE =======================================\n",
    "tickers = ohlcv_df['symbol'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d706a1b",
   "metadata": {},
   "source": [
    "## How to intrepret\n",
    "| Metric                             | Good Sign                  | Bad Sign                            |\n",
    "| ---------------------------------- | -------------------------- | ----------------------------------- |\n",
    "| R² > 0.3                           | Model captures real signal | R² ≈ 0: model is guessing           |\n",
    "| MAE low (e.g., < 0.05)             | Close predictions          | MAE > 0.1 is noisy                  |\n",
    "| Scatter points cluster on diagonal | High correlation           | Wide dispersion = model uncertainty |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b52aaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "notify('teste')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6367294c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_r2</th>\n",
       "      <th>predicted_r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.023697</td>\n",
       "      <td>0.048580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.027648</td>\n",
       "      <td>0.024395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.015993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.003473</td>\n",
       "      <td>0.028728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.009950</td>\n",
       "      <td>0.044306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.045028</td>\n",
       "      <td>0.065263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.098219</td>\n",
       "      <td>0.096468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         true_r2  predicted_r2\n",
       "count  18.000000     18.000000\n",
       "mean    0.023697      0.048580\n",
       "std     0.027648      0.024395\n",
       "min     0.000226      0.015993\n",
       "25%     0.003473      0.028728\n",
       "50%     0.009950      0.044306\n",
       "75%     0.045028      0.065263\n",
       "max     0.098219      0.096468"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "18a05cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 AAPL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 1/3 [00:16<00:32, 16.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 GOOG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 2/3 [00:32<00:16, 16.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 MSFT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:48<00:00, 16.07s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 2 AAPL\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'bool' object has no attribute 'any'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[124], line 95\u001b[0m\n\u001b[0;32m     93\u001b[0m y \u001b[38;5;241m=\u001b[39m df_t1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreturn_1d\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m     94\u001b[0m X_dummy \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(y))\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 95\u001b[0m base_model \u001b[38;5;241m=\u001b[39m LinearRegression()\u001b[38;5;241m.\u001b[39mfit(X_dummy, y)\n\u001b[0;32m     96\u001b[0m r2 \u001b[38;5;241m=\u001b[39m base_model\u001b[38;5;241m.\u001b[39mscore(X_dummy, y)\n\u001b[0;32m     98\u001b[0m label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(r2 \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.1\u001b[39m)  \u001b[38;5;66;03m# Predictable if R² > 0.1\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_base.py:601\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    597\u001b[0m n_jobs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[0;32m    599\u001b[0m accept_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 601\u001b[0m X, y \u001b[38;5;241m=\u001b[39m validate_data(\n\u001b[0;32m    602\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    603\u001b[0m     X,\n\u001b[0;32m    604\u001b[0m     y,\n\u001b[0;32m    605\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m    606\u001b[0m     y_numeric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    607\u001b[0m     multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    608\u001b[0m     force_writeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    609\u001b[0m )\n\u001b[0;32m    611\u001b[0m has_sw \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    612\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_sw:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:2961\u001b[0m, in \u001b[0;36mvalidate_data\u001b[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[0;32m   2959\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m   2960\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2961\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m   2962\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m   2964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:1387\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1368\u001b[0m ensure_all_finite \u001b[38;5;241m=\u001b[39m _deprecate_force_all_finite(force_all_finite, ensure_all_finite)\n\u001b[0;32m   1370\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1371\u001b[0m     X,\n\u001b[0;32m   1372\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1384\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1385\u001b[0m )\n\u001b[1;32m-> 1387\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1389\u001b[0m check_consistent_length(X, y)\n\u001b[0;32m   1391\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:1397\u001b[0m, in \u001b[0;36m_check_y\u001b[1;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1395\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Isolated part of check_X_y dedicated to y validation\"\"\"\u001b[39;00m\n\u001b[0;32m   1396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m multi_output:\n\u001b[1;32m-> 1397\u001b[0m     y \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1398\u001b[0m         y,\n\u001b[0;32m   1399\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1400\u001b[0m         ensure_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   1401\u001b[0m         ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1402\u001b[0m         dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1403\u001b[0m         input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1404\u001b[0m         estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m   1405\u001b[0m     )\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1407\u001b[0m     estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:1107\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1102\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1103\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m   1104\u001b[0m     )\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_all_finite:\n\u001b[1;32m-> 1107\u001b[0m     _assert_all_finite(\n\u001b[0;32m   1108\u001b[0m         array,\n\u001b[0;32m   1109\u001b[0m         input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m   1110\u001b[0m         estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m   1111\u001b[0m         allow_nan\u001b[38;5;241m=\u001b[39mensure_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1112\u001b[0m     )\n\u001b[0;32m   1114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[0;32m   1115\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[0;32m   1116\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:104\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;66;03m# for object dtype data, we only check for NaNs (GH-13254)\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_array_api \u001b[38;5;129;01mand\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nan:\n\u001b[1;32m--> 104\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _object_dtype_isnan(X)\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m    105\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput contains NaN\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    107\u001b[0m \u001b[38;5;66;03m# We need only consider float arrays, hence can early return for all else.\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'bool' object has no attribute 'any'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from scipy.stats import skew, kurtosis, entropy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# === Simulate a realistic dataset ===\n",
    "np.random.seed(42)\n",
    "#dates = pd.date_range(start=\"2022-01-01\", end=\"2024-12-31\", freq=\"D\")\n",
    "dates = pd.date_range(start=\"2022-01-01\", end=\"2022-06-01\", freq=\"D\")\n",
    "symbols = ['AAPL', 'GOOG', 'MSFT' ]\n",
    "data = []\n",
    "\n",
    "for symbol in tqdm(symbols):\n",
    "    print('Round 1',symbol)\n",
    "    #trend = np.linspace(100, 200, len(dates)) + np.random.normal(0, 5, len(dates))\n",
    "    for i, date in enumerate(dates):\n",
    "        ret = np.random.randn() * 0.01\n",
    "\n",
    "        data.append({\n",
    "            'date': date,\n",
    "            'symbol': symbol,\n",
    "            'close': ohlcv_df[ohlcv_df['symbol']==symbol]['close'].values,#np.random.rand() * 100 + 100,\n",
    "            'return_1d': ohlcv_df[ohlcv_df['symbol']==symbol]['return_1d'].values,\n",
    "            'volume': ohlcv_df[ohlcv_df['symbol']==symbol]['volume'].values#np.random.randint(1e5, 1e6)\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df['month'] = df['date'].dt.to_period('M')\n",
    "df['return_1d'] = df['return_1d'].fillna(0)\n",
    "\n",
    "# === Extract enriched features and labels ===\n",
    "feature_rows = []\n",
    "label_rows = []\n",
    "def flatten_cell(x):\n",
    "    if isinstance(x, (list, np.ndarray)):\n",
    "        return float(x[0]) if len(x) > 0 else np.nan\n",
    "    return float(x)\n",
    "\n",
    "\n",
    "\n",
    "for symbol in tqdm(symbols):\n",
    "    print('Round 2',symbol)\n",
    "    symbol_data = df[df['symbol'] == symbol].sort_values('date')\n",
    "    grouped = symbol_data.groupby('month')\n",
    "\n",
    "    months = list(grouped.groups.keys())\n",
    "    for i in range(len(months) - 1):\n",
    "        m_t = months[i]\n",
    "        m_t1 = months[i + 1]\n",
    "\n",
    "        df_t = grouped.get_group(m_t)\n",
    "        df_t1 = grouped.get_group(m_t1)\n",
    "\n",
    "        if len(df_t1) < 10:\n",
    "            continue\n",
    "        def flatten_cell(x):\n",
    "            if isinstance(x, (list, np.ndarray)):\n",
    "                return float(x[0]) if len(x) > 0 else np.nan\n",
    "            return float(x)\n",
    "\n",
    "        r1d = df_t['return_1d'].apply(flatten_cell)\n",
    "        v = df_t['volume'].apply(flatten_cell)\n",
    "\n",
    "        # === Features from T ===\n",
    "        # Ensure return_1d is flat and numeric\n",
    "        returns = df_t['return_1d'].apply(lambda x: x[0] if isinstance(x, (list, np.ndarray)) else x).astype(np.float64).values\n",
    "\n",
    "        features = {\n",
    "            'symbol': symbol,\n",
    "            'month': str(m_t),\n",
    "            'mean_return': returns.mean(),\n",
    "            'std_return': returns.std(),\n",
    "            'skew_return': skew(returns),\n",
    "            'kurtosis_return': kurtosis(returns),\n",
    "            'entropy_return': entropy(np.histogram(returns, bins=10, density=True)[0] + 1e-8),\n",
    "            'volume_mean': v.mean(),#df_t['volume'].mean(),\n",
    "            'volume_std': v.std() #df_t['volume'].std()\n",
    "        }\n",
    "\n",
    "\n",
    "        # === Label from T+1 ===\n",
    "        y = df_t1['return_1d'].values\n",
    "        X_dummy = np.arange(len(y)).reshape(-1, 1)\n",
    "        base_model = LinearRegression().fit(X_dummy, y)\n",
    "        r2 = base_model.score(X_dummy, y)\n",
    "\n",
    "        label = int(r2 > 0.1)  # Predictable if R² > 0.1\n",
    "\n",
    "        feature_rows.append(features)\n",
    "        label_rows.append(label)\n",
    "\n",
    "# === Build dataset ===\n",
    "X_df = pd.DataFrame(feature_rows)\n",
    "y_df = pd.Series(label_rows, name='is_predictable')\n",
    "\n",
    "metadata = X_df[['symbol', 'month']]\n",
    "X = X_df.drop(['symbol', 'month'], axis=1)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# === Train classifier ===\n",
    "X_train, X_test, y_train, y_test, meta_train, meta_test = train_test_split(\n",
    "    X_scaled, y_df, metadata, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=300, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# === Report and confusion matrix ===\n",
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# === Create full report DataFrame ===\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "report_df['support'] = report_df['support'].astype(int)\n",
    "\n",
    "# === Identify top-k easiest stocks (predicted = 1) ===\n",
    "predictions_df = meta_test.copy()\n",
    "predictions_df['predicted_label'] = y_pred\n",
    "predictions_df['true_label'] = y_test.values\n",
    "top_predictable = predictions_df[predictions_df['predicted_label'] == 1]\n",
    "\n",
    "print(\"Top Predictable Stock-Months:\")\n",
    "display(top_predictable.head(10))\n",
    "\n",
    "# === Plot confusion matrix ===\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues', xticklabels=['Not Predictable', 'Predictable'], yticklabels=['Not Predictable', 'Predictable'])\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "display(report_df.round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440b7007",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/504 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 MMM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 1/504 [00:00<03:06,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 AOS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 2/504 [00:00<03:19,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 ABT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 3/504 [00:01<03:23,  2.47it/s]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from scipy.stats import skew, kurtosis, entropy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# === Simulate a realistic dataset ===\n",
    "np.random.seed(42)\n",
    "dates = ohlcv_df[ohlcv_df['symbol']==\"AAPL\"]\n",
    "#dates =  dates[dates['date']>=\"2022-01-01\"&dates['date']<\"2022-06-01\"]\n",
    "#dates = dates['date']\n",
    "dates=dates[(dates['date']>=\"2022-01-01\")&(dates['date']<\"2024-01-01\")]['date'].values\n",
    "#pd.date_range(start=\"2022-01-01\", end=\"2022-06-01\", freq=\"D\")\n",
    "symbols = ohlcv_df['symbol'].unique() #['AAPL', 'GOOG']\n",
    "data = []\n",
    "\n",
    "# Replace with your actual ohlcv_df if not simulating\n",
    "#ohlcv_df = pd.DataFrame()\n",
    "\n",
    "for symbol in tqdm(symbols):\n",
    "    print('Round 1', symbol)\n",
    "    _ohlcv_df= ohlcv_df[ohlcv_df['symbol']==symbol]\n",
    "    for date in dates:\n",
    "        #print(\"date\",date)\n",
    "        d = _ohlcv_df[_ohlcv_df['date']==date]#.iloc[0]\n",
    "        #print(d)\n",
    "        close = d['close']#np.random.rand() * 100 + 100\n",
    "        return_1d = d['return_1d']#np.random.randn() * 0.01\n",
    "        volume = d['volume']#np.random.randint(1e5, 1e6)\n",
    "        data.append({\n",
    "            'date': date,\n",
    "            'symbol': symbol,\n",
    "            'close': close,\n",
    "            'return_1d': return_1d,\n",
    "            'volume': volume\n",
    "        })\n",
    "        # data.append({\n",
    "        #   'date': date,\n",
    "        #    'symbol': symbol,\n",
    "        #    'close': ['close'].values,#np.random.rand() * 100 + 100,\n",
    "        #    'return_1d': ohlcv_df[ohlcv_df['symbol']==symbol]['return_1d'].values,\n",
    "        #    'volume': ohlcv_df[ohlcv_df['symbol']==symbol]['volume'].values#np.random.randint(1e5, 1e6)\n",
    "        #})\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df['month'] = df['date'].dt.to_period('M')\n",
    "df['return_1d'] = df['return_1d'].fillna(0)\n",
    "\n",
    "# === Extract enriched features and labels ===\n",
    "feature_rows = []\n",
    "label_rows = []\n",
    "\n",
    "def flatten_cell(x):\n",
    "    if isinstance(x, (list, np.ndarray)):\n",
    "        return float(x[0]) if len(x) > 0 else np.nan\n",
    "    return float(x)\n",
    "\n",
    "for symbol in tqdm(symbols):\n",
    "    print('Round 2', symbol)\n",
    "    symbol_data = df[df['symbol'] == symbol].sort_values('date')\n",
    "    grouped = symbol_data.groupby('month')\n",
    "\n",
    "    months = list(grouped.groups.keys())\n",
    "    for i in range(len(months) - 1):\n",
    "        m_t = months[i]\n",
    "        m_t1 = months[i + 1]\n",
    "\n",
    "        df_t = grouped.get_group(m_t)\n",
    "        df_t1 = grouped.get_group(m_t1)\n",
    "\n",
    "        if len(df_t1) < 10:\n",
    "            continue\n",
    "\n",
    "        r1d = df_t['return_1d'].apply(flatten_cell)\n",
    "        v = df_t['volume'].apply(flatten_cell)\n",
    "\n",
    "        # Features from T\n",
    "        returns = r1d.astype(np.float64).values\n",
    "\n",
    "        features = {\n",
    "            'symbol': symbol,\n",
    "            'month': str(m_t),\n",
    "            'mean_return': returns.mean(),\n",
    "            'std_return': returns.std(),\n",
    "            'skew_return': skew(returns),\n",
    "            'kurtosis_return': kurtosis(returns),\n",
    "            'entropy_return': entropy(np.histogram(returns, bins=10, density=True)[0] + 1e-8),\n",
    "            'volume_mean': v.mean(),\n",
    "            'volume_std': v.std()\n",
    "        }\n",
    "\n",
    "        # Label from T+1\n",
    "        y = df_t1['return_1d'].astype(np.float64).values\n",
    "        X_dummy = np.arange(len(y)).reshape(-1, 1)\n",
    "        base_model = LinearRegression().fit(X_dummy, y)\n",
    "        r2 = base_model.score(X_dummy, y)\n",
    "        label = int(r2 > 0.1)\n",
    "\n",
    "        feature_rows.append(features)\n",
    "        label_rows.append(label)\n",
    "\n",
    "# === Build dataset ===\n",
    "X_df = pd.DataFrame(feature_rows)\n",
    "y_df = pd.Series(label_rows, name='is_predictable')\n",
    "\n",
    "metadata = X_df[['symbol', 'month']]\n",
    "X = X_df.drop(['symbol', 'month'], axis=1)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# === Train classifier ===\n",
    "X_train, X_test, y_train, y_test, meta_train, meta_test = train_test_split(\n",
    "    X_scaled, y_df, metadata, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=300, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# === Report and confusion matrix ===\n",
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# === Create full report DataFrame ===\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "report_df['support'] = report_df['support'].astype(int)\n",
    "\n",
    "# === Identify top-k easiest stocks (predicted = 1) ===\n",
    "predictions_df = meta_test.copy()\n",
    "predictions_df['predicted_label'] = y_pred\n",
    "predictions_df['true_label'] = y_test.values\n",
    "top_predictable = predictions_df[predictions_df['predicted_label'] == 1]\n",
    "\n",
    "print(\"Top Predictable Stock-Months:\")\n",
    "display(top_predictable.head(10))\n",
    "\n",
    "# === Plot confusion matrix ===\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues', xticklabels=['Not Predictable', 'Predictable'], yticklabels=['Not Predictable', 'Predictable'])\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "display(report_df.round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "29db51f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>symbol</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>trade_count</th>\n",
       "      <th>...</th>\n",
       "      <th>vwap_change</th>\n",
       "      <th>trade_count_change</th>\n",
       "      <th>sector_id</th>\n",
       "      <th>industry_id</th>\n",
       "      <th>return_1d</th>\n",
       "      <th>vix</th>\n",
       "      <th>vix_norm</th>\n",
       "      <th>sp500</th>\n",
       "      <th>sp500_norm</th>\n",
       "      <th>market_return_1d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17140</th>\n",
       "      <td>17141</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>2022-01-04 05:00:00</td>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>2911.010</td>\n",
       "      <td>2932.2000</td>\n",
       "      <td>2876.3225</td>\n",
       "      <td>2888.33</td>\n",
       "      <td>1305838.0</td>\n",
       "      <td>78071.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034145</td>\n",
       "      <td>0.988062</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-0.046830</td>\n",
       "      <td>0.1691</td>\n",
       "      <td>0.018675</td>\n",
       "      <td>47.9354</td>\n",
       "      <td>-0.000630</td>\n",
       "      <td>-0.000630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17141</th>\n",
       "      <td>17142</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>2022-01-05 05:00:00</td>\n",
       "      <td>2022-01-05</td>\n",
       "      <td>2883.620</td>\n",
       "      <td>2885.9600</td>\n",
       "      <td>2750.4700</td>\n",
       "      <td>2753.07</td>\n",
       "      <td>2493515.0</td>\n",
       "      <td>155210.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034145</td>\n",
       "      <td>0.988062</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-0.046830</td>\n",
       "      <td>0.1973</td>\n",
       "      <td>0.166765</td>\n",
       "      <td>47.0058</td>\n",
       "      <td>-0.019393</td>\n",
       "      <td>-0.019393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17142</th>\n",
       "      <td>17143</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>2022-01-06 05:00:00</td>\n",
       "      <td>2022-01-06</td>\n",
       "      <td>2749.950</td>\n",
       "      <td>2793.7200</td>\n",
       "      <td>2735.2700</td>\n",
       "      <td>2751.02</td>\n",
       "      <td>1621973.0</td>\n",
       "      <td>94830.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012839</td>\n",
       "      <td>-0.389021</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-0.000745</td>\n",
       "      <td>0.1961</td>\n",
       "      <td>-0.006082</td>\n",
       "      <td>46.9605</td>\n",
       "      <td>-0.000964</td>\n",
       "      <td>-0.000964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17143</th>\n",
       "      <td>17144</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>2022-01-07 05:00:00</td>\n",
       "      <td>2022-01-07</td>\n",
       "      <td>2758.100</td>\n",
       "      <td>2765.0949</td>\n",
       "      <td>2715.7800</td>\n",
       "      <td>2740.09</td>\n",
       "      <td>1064522.0</td>\n",
       "      <td>73778.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006637</td>\n",
       "      <td>-0.221997</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-0.003973</td>\n",
       "      <td>0.1876</td>\n",
       "      <td>-0.043345</td>\n",
       "      <td>46.7703</td>\n",
       "      <td>-0.004050</td>\n",
       "      <td>-0.004050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17144</th>\n",
       "      <td>17145</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>2022-01-10 05:00:00</td>\n",
       "      <td>2022-01-10</td>\n",
       "      <td>2701.980</td>\n",
       "      <td>2772.8000</td>\n",
       "      <td>2662.8100</td>\n",
       "      <td>2771.48</td>\n",
       "      <td>1868448.0</td>\n",
       "      <td>126154.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002569</td>\n",
       "      <td>0.709914</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.011456</td>\n",
       "      <td>0.1940</td>\n",
       "      <td>0.034115</td>\n",
       "      <td>46.7029</td>\n",
       "      <td>-0.001441</td>\n",
       "      <td>-0.001441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17992</th>\n",
       "      <td>17993</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>2025-05-29 04:00:00</td>\n",
       "      <td>2025-05-29</td>\n",
       "      <td>175.000</td>\n",
       "      <td>175.4000</td>\n",
       "      <td>171.7800</td>\n",
       "      <td>172.96</td>\n",
       "      <td>21233590.0</td>\n",
       "      <td>361880.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006075</td>\n",
       "      <td>0.020047</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-0.002422</td>\n",
       "      <td>0.1918</td>\n",
       "      <td>-0.006732</td>\n",
       "      <td>59.1217</td>\n",
       "      <td>0.004011</td>\n",
       "      <td>0.004011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17993</th>\n",
       "      <td>17994</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>2025-05-30 04:00:00</td>\n",
       "      <td>2025-05-30</td>\n",
       "      <td>172.410</td>\n",
       "      <td>173.4400</td>\n",
       "      <td>168.5250</td>\n",
       "      <td>172.85</td>\n",
       "      <td>36258254.0</td>\n",
       "      <td>439038.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007872</td>\n",
       "      <td>0.213214</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-0.000636</td>\n",
       "      <td>0.1857</td>\n",
       "      <td>-0.031804</td>\n",
       "      <td>59.1169</td>\n",
       "      <td>-0.000081</td>\n",
       "      <td>-0.000081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17994</th>\n",
       "      <td>17995</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>2025-06-02 04:00:00</td>\n",
       "      <td>2025-06-02</td>\n",
       "      <td>169.010</td>\n",
       "      <td>171.0624</td>\n",
       "      <td>168.6500</td>\n",
       "      <td>170.37</td>\n",
       "      <td>24742877.0</td>\n",
       "      <td>364732.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009509</td>\n",
       "      <td>-0.169247</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-0.014348</td>\n",
       "      <td>0.1836</td>\n",
       "      <td>-0.011309</td>\n",
       "      <td>59.3594</td>\n",
       "      <td>0.004102</td>\n",
       "      <td>0.004102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17995</th>\n",
       "      <td>17996</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>2025-06-03 04:00:00</td>\n",
       "      <td>2025-06-03</td>\n",
       "      <td>168.865</td>\n",
       "      <td>169.8000</td>\n",
       "      <td>166.6800</td>\n",
       "      <td>167.71</td>\n",
       "      <td>25386713.0</td>\n",
       "      <td>452653.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011214</td>\n",
       "      <td>0.241056</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-0.015613</td>\n",
       "      <td>0.1769</td>\n",
       "      <td>-0.036492</td>\n",
       "      <td>59.7037</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.005800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17996</th>\n",
       "      <td>17997</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>2025-06-04 04:00:00</td>\n",
       "      <td>2025-06-04</td>\n",
       "      <td>168.280</td>\n",
       "      <td>169.5800</td>\n",
       "      <td>167.7950</td>\n",
       "      <td>169.39</td>\n",
       "      <td>18508735.0</td>\n",
       "      <td>305251.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003753</td>\n",
       "      <td>-0.325640</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.010017</td>\n",
       "      <td>0.1761</td>\n",
       "      <td>-0.004522</td>\n",
       "      <td>59.7081</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>857 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id symbol           timestamp       date      open       high  \\\n",
       "17140  17141   GOOG 2022-01-04 05:00:00 2022-01-04  2911.010  2932.2000   \n",
       "17141  17142   GOOG 2022-01-05 05:00:00 2022-01-05  2883.620  2885.9600   \n",
       "17142  17143   GOOG 2022-01-06 05:00:00 2022-01-06  2749.950  2793.7200   \n",
       "17143  17144   GOOG 2022-01-07 05:00:00 2022-01-07  2758.100  2765.0949   \n",
       "17144  17145   GOOG 2022-01-10 05:00:00 2022-01-10  2701.980  2772.8000   \n",
       "...      ...    ...                 ...        ...       ...        ...   \n",
       "17992  17993   GOOG 2025-05-29 04:00:00 2025-05-29   175.000   175.4000   \n",
       "17993  17994   GOOG 2025-05-30 04:00:00 2025-05-30   172.410   173.4400   \n",
       "17994  17995   GOOG 2025-06-02 04:00:00 2025-06-02   169.010   171.0624   \n",
       "17995  17996   GOOG 2025-06-03 04:00:00 2025-06-03   168.865   169.8000   \n",
       "17996  17997   GOOG 2025-06-04 04:00:00 2025-06-04   168.280   169.5800   \n",
       "\n",
       "             low    close      volume  trade_count  ...  vwap_change  \\\n",
       "17140  2876.3225  2888.33   1305838.0      78071.0  ...    -0.034145   \n",
       "17141  2750.4700  2753.07   2493515.0     155210.0  ...    -0.034145   \n",
       "17142  2735.2700  2751.02   1621973.0      94830.0  ...    -0.012839   \n",
       "17143  2715.7800  2740.09   1064522.0      73778.0  ...    -0.006637   \n",
       "17144  2662.8100  2771.48   1868448.0     126154.0  ...    -0.002569   \n",
       "...          ...      ...         ...          ...  ...          ...   \n",
       "17992   171.7800   172.96  21233590.0     361880.0  ...    -0.006075   \n",
       "17993   168.5250   172.85  36258254.0     439038.0  ...    -0.007872   \n",
       "17994   168.6500   170.37  24742877.0     364732.0  ...    -0.009509   \n",
       "17995   166.6800   167.71  25386713.0     452653.0  ...    -0.011214   \n",
       "17996   167.7950   169.39  18508735.0     305251.0  ...     0.003753   \n",
       "\n",
       "       trade_count_change  sector_id  industry_id  return_1d     vix  \\\n",
       "17140            0.988062       None         None  -0.046830  0.1691   \n",
       "17141            0.988062       None         None  -0.046830  0.1973   \n",
       "17142           -0.389021       None         None  -0.000745  0.1961   \n",
       "17143           -0.221997       None         None  -0.003973  0.1876   \n",
       "17144            0.709914       None         None   0.011456  0.1940   \n",
       "...                   ...        ...          ...        ...     ...   \n",
       "17992            0.020047       None         None  -0.002422  0.1918   \n",
       "17993            0.213214       None         None  -0.000636  0.1857   \n",
       "17994           -0.169247       None         None  -0.014348  0.1836   \n",
       "17995            0.241056       None         None  -0.015613  0.1769   \n",
       "17996           -0.325640       None         None   0.010017  0.1761   \n",
       "\n",
       "       vix_norm    sp500  sp500_norm  market_return_1d  \n",
       "17140  0.018675  47.9354   -0.000630         -0.000630  \n",
       "17141  0.166765  47.0058   -0.019393         -0.019393  \n",
       "17142 -0.006082  46.9605   -0.000964         -0.000964  \n",
       "17143 -0.043345  46.7703   -0.004050         -0.004050  \n",
       "17144  0.034115  46.7029   -0.001441         -0.001441  \n",
       "...         ...      ...         ...               ...  \n",
       "17992 -0.006732  59.1217    0.004011          0.004011  \n",
       "17993 -0.031804  59.1169   -0.000081         -0.000081  \n",
       "17994 -0.011309  59.3594    0.004102          0.004102  \n",
       "17995 -0.036492  59.7037    0.005800          0.005800  \n",
       "17996 -0.004522  59.7081    0.000074          0.000074  \n",
       "\n",
       "[857 rows x 34 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_ohlcv_df['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed4fbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[y_train == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bc7bf48b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[94], line 10\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(x)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#df['return_1d'] = df['return_1d'].apply(flatten_cell)\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#df['volume'] = df['volume'].apply(flatten_cell)\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m returns \u001b[38;5;241m=\u001b[39m df_t[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreturn_1d\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64)\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m     11\u001b[0m volume_mean \u001b[38;5;241m=\u001b[39m df_t[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolume\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m     12\u001b[0m volume_std \u001b[38;5;241m=\u001b[39m df_t[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolume\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstd()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\generic.py:6662\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6656\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   6657\u001b[0m         ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   6658\u001b[0m     ]\n\u001b[0;32m   6660\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6661\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[1;32m-> 6662\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mastype(dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   6663\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m   6664\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\internals\\managers.py:430\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    428\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 430\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\n\u001b[0;32m    431\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    432\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    433\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    434\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    435\u001b[0m     using_cow\u001b[38;5;241m=\u001b[39musing_copy_on_write(),\n\u001b[0;32m    436\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\internals\\managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\internals\\blocks.py:784\u001b[0m, in \u001b[0;36mBlock.astype\u001b[1;34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[0m\n\u001b[0;32m    781\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan not squeeze with more than one column.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    782\u001b[0m     values \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[1;32m--> 784\u001b[0m new_values \u001b[38;5;241m=\u001b[39m astype_array_safe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m    786\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[0;32m    788\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\dtypes\\astype.py:237\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    234\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 237\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m astype_array(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\dtypes\\astype.py:182\u001b[0m, in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    179\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 182\u001b[0m     values \u001b[38;5;241m=\u001b[39m _astype_nansafe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    184\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\dtypes\\astype.py:133\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[1;32m--> 133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
    "# Ensure return_1d is flat and numeric\n",
    "# Ensure return_1d and volume contain only floats, not arrays/lists\n",
    "def flatten_cell(x):\n",
    "    if isinstance(x, (list, np.ndarray)):\n",
    "        return float(x[0]) if len(x) > 0 else np.nan\n",
    "    return float(x)\n",
    "\n",
    "df['return_1d'] = df['return_1d'].apply(flatten_cell)\n",
    "df['volume'] = df['volume'].apply(flatten_cell)\n",
    "returns = df_t['return_1d'].astype(np.float64).values\n",
    "volume_mean = df_t['volume'].mean()\n",
    "volume_std = df_t['volume'].std()\n",
    "\n",
    "returns = df_t['return_1d'].apply(lambda x: x[0] if isinstance(x, (list, np.ndarray)) else x).astype(np.float64).values\n",
    "\n",
    "features = {\n",
    "    'symbol': symbol,\n",
    "    'month': str(m_t),\n",
    "    'mean_return': returns.mean(),\n",
    "    'std_return': returns.std(),\n",
    "    'skew_return': skew(returns),\n",
    "    'kurtosis_return': kurtosis(returns),\n",
    "    'entropy_return': entropy(np.histogram(returns, bins=10, density=True)[0] + 1e-8),\n",
    "    'volume_mean': df_t['volume'].mean(),\n",
    "    'volume_std': df_t['volume'].std()\n",
    "}\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "09aa7cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     -0.026600\n",
       "1     -0.026600\n",
       "2     -0.026600\n",
       "3     -0.026600\n",
       "4     -0.026600\n",
       "         ...   \n",
       "755   -0.018893\n",
       "756   -0.018893\n",
       "757   -0.018893\n",
       "758   -0.018893\n",
       "759   -0.018893\n",
       "Name: return_1d, Length: 760, dtype: float64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['return_1d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c3d4d090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02659989, -0.02659989, -0.01669335, ...,  0.00423201,\n",
       "        0.00778384, -0.0022138 ])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns = np.concatenate(df_t['return_1d'].values).astype(np.float64)\n",
    "returns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6df70fc",
   "metadata": {},
   "source": [
    "# OLD CODE BELOW\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978c2af7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06732b35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f6ac4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985d87b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1570f163",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ae1f01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81ea433",
   "metadata": {},
   "outputs": [],
   "source": [
    "xxxxxxxxxxxxxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6962392d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 22\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m symbol \u001b[38;5;129;01min\u001b[39;00m symbols:\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m date \u001b[38;5;129;01min\u001b[39;00m dates:\n\u001b[0;32m     19\u001b[0m         data\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m     20\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m: date,\n\u001b[0;32m     21\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msymbol\u001b[39m\u001b[38;5;124m'\u001b[39m: symbol,\n\u001b[1;32m---> 22\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m'\u001b[39m: ohlcv_df[ohlcv_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msymbol\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39msymbol][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues,\u001b[38;5;66;03m#np.random.rand() * 100 + 100,\u001b[39;00m\n\u001b[0;32m     23\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreturn_1d\u001b[39m\u001b[38;5;124m'\u001b[39m: ohlcv_df[ohlcv_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msymbol\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39msymbol][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreturn_1d\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues,\n\u001b[0;32m     24\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolume\u001b[39m\u001b[38;5;124m'\u001b[39m: ohlcv_df[ohlcv_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msymbol\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39msymbol][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolume\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;66;03m#np.random.randint(1e5, 1e6)\u001b[39;00m\n\u001b[0;32m     25\u001b[0m         })\n\u001b[0;32m     27\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Convert date to month\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\ops\\common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m method(\u001b[38;5;28mself\u001b[39m, other)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\arraylike.py:40\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cmp_method(other, operator\u001b[38;5;241m.\u001b[39meq)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\series.py:6130\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   6127\u001b[0m lvalues \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m   6128\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 6130\u001b[0m res_values \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mcomparison_op(lvalues, rvalues, op)\n\u001b[0;32m   6132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\ops\\array_ops.py:344\u001b[0m, in \u001b[0;36mcomparison_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m lvalues\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rvalues, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 344\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m comp_method_OBJECT_ARRAY(op, lvalues, rvalues)\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    347\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m _na_arithmetic_op(lvalues, rvalues, op, is_cmp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\ops\\array_ops.py:130\u001b[0m, in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[1;34m(op, x, y)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     result \u001b[38;5;241m=\u001b[39m libops\u001b[38;5;241m.\u001b[39mscalar_compare(x\u001b[38;5;241m.\u001b[39mravel(), y, op)\n\u001b[1;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mreshape(x\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Simulate a basic dataframe for demonstration\n",
    "np.random.seed(42)\n",
    "dates = pd.date_range(start=\"2022-01-01\", end=\"2024-12-31\", freq=\"D\")\n",
    "symbols = ohlcv_df['symbol'].unique()\n",
    "data = []\n",
    "\n",
    "for symbol in tqdm(symbols):\n",
    "    for date in dates:\n",
    "        data.append({\n",
    "            'date': date,\n",
    "            'symbol': symbol,\n",
    "            'close': ohlcv_df[ohlcv_df['symbol']==symbol]['close'].values,#np.random.rand() * 100 + 100,\n",
    "            'return_1d': ohlcv_df[ohlcv_df['symbol']==symbol]['return_1d'].values,\n",
    "            'volume': ohlcv_df[ohlcv_df['symbol']==symbol]['volume'].values#np.random.randint(1e5, 1e6)\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert date to month\n",
    "df['month'] = df['date'].dt.to_period('M')\n",
    "df['return_1d'] = df['return_1d'].fillna(0)\n",
    "df.sort_values(by=\"date\",inplace=True)\n",
    "df_train = df[df['date']<'2024-06-01']#.sort_values(by=\"date\")\n",
    "df_test =df[df['date']>='2024-06-01']#.sort_values(by=\"date\")\n",
    "\n",
    "def generate_datasets(_df):\n",
    "    # Compute monthly features per stock\n",
    "    monthly_features = _df.groupby(['symbol', 'month']).agg({\n",
    "        'return_1d': ['mean', 'std', 'skew'],\n",
    "        'volume': ['mean', 'std']\n",
    "    })\n",
    "\n",
    "    monthly_features.columns = ['_'.join(col) for col in monthly_features.columns]\n",
    "    monthly_features = monthly_features.reset_index()\n",
    "\n",
    "    # Prepare sliding window (T, T+1)\n",
    "    s_rows = []\n",
    "    m_rows = []\n",
    "    X_rows = []\n",
    "    y_values = []\n",
    "\n",
    "    for symbol in monthly_features['symbol'].unique():\n",
    "        symbol_data = monthly_features[monthly_features['symbol'] == symbol].sort_values('month')\n",
    "        for i in range(len(symbol_data) - 1):\n",
    "            X_t = symbol_data.iloc[i]\n",
    "            T_plus_1 = symbol_data.iloc[i + 1]\n",
    "\n",
    "            # Train a simple model on T+1 return_1d using only lagged return as a proxy\n",
    "            y = _df[(_df['symbol'] == symbol) & (_df['month'] == T_plus_1['month'])]['return_1d'].values\n",
    "            if len(y) < 10:\n",
    "                continue\n",
    "            X_simple = np.arange(len(y)).reshape(-1, 1)\n",
    "            model = LinearRegression().fit(X_simple, y)\n",
    "            r2 = r2_score(y, model.predict(X_simple))\n",
    "\n",
    "            X_rows.append(X_t.drop(['symbol', 'month']).values)\n",
    "            y_values.append(r2)\n",
    "            s_rows.append(X_t['symbol'])\n",
    "            m_rows.append(X_t['month'])\n",
    "\n",
    "    # Final dataset\n",
    "    X = np.array(X_rows)\n",
    "    y = np.array(y_values)\n",
    "    tickers = s_rows\n",
    "    months = m_rows\n",
    "    return X,y,tickers,months\n",
    "    # Train-test split and regress\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "\n",
    "X_train, y_train,_,_= generate_datasets(df_train)\n",
    "X_test, y_test,s_test,m_test= generate_datasets(df_test)\n",
    "regressor = RandomForestRegressor(n_estimators=200, random_state=42)\n",
    "regressor.fit(X_train, y_train)\n",
    "preds = regressor.predict(X_test)\n",
    "\n",
    "# Display results\n",
    "result_df = pd.DataFrame({\n",
    "    'symbol': s_test,\n",
    "    'month': m_test,\n",
    "    'true_r2': y_test,\n",
    "    'predicted_r2': preds\n",
    "})\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "mae = mean_absolute_error(y_test, preds)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "r2 = r2_score(y_test, preds)\n",
    "\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"R² Score: {r2:.4f}\")\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, preds, alpha=0.6)\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], '--', color='red', label='Perfect Prediction')\n",
    "plt.xlabel(\"True R²\")\n",
    "plt.ylabel(\"Predicted R²\")\n",
    "plt.title(\"True vs Predicted R² (Predictability Score)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
