{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33beca1f",
   "metadata": {},
   "source": [
    "# Meta-RL Predictability Study: Stock-Month Advantage Classifier\n",
    "\n",
    "## Objective\n",
    "\n",
    "Identify and classify stock-month environments where a reinforcement learning (RL) agent (PPO) outperforms a random strategy. These environments are considered \"predictable\" or advantageous for training trading agents.\n",
    "\n",
    "---\n",
    "\n",
    "## Dataset\n",
    "\n",
    "* **Source:** Cleaned OHLCV data (daily resolution)\n",
    "* **Date range:** 2022-01-01 to 2023-01-01\n",
    "* **Universe:** Top US equities (e.g., AAPL, MSFT, JPM, AMZN, TSLA, etc.)\n",
    "* **Exclusions:** Tickers with missing or corrupted data\n",
    "\n",
    "---\n",
    "\n",
    "##  Meta-Feature Engineering\n",
    "\n",
    "For each stock-month pair (symbol, month):\n",
    "\n",
    "1. **Return Distribution** from month *t*:\n",
    "\n",
    "   * Mean Return\n",
    "   * Std Return\n",
    "   * Skewness\n",
    "   * Kurtosis\n",
    "   * Shannon Entropy (10-bin histogram)\n",
    "\n",
    "2. **Volume Features**:\n",
    "\n",
    "   * Mean Volume\n",
    "   * Std Volume\n",
    "\n",
    "3. **Residual Diagnostics (month t+1)**:\n",
    "\n",
    "   * Fit `RandomForestRegressor` on lagged returns (lags=5)\n",
    "   * Compute residuals: `actual - predicted`\n",
    "   * Ljung-Box p-value (autocorrelation)\n",
    "   * Residual ACF(1)\n",
    "   * Residual Std, Skew, Kurtosis\n",
    "\n",
    "4. **Rolling R² (CV)**\n",
    "\n",
    "   * Use 3-fold cross-validation on the same model\n",
    "   * Target: `cv_r2` as a proxy for local predictability\n",
    "\n",
    "---\n",
    "\n",
    "## Meta-RL Labeling Pipeline\n",
    "\n",
    "1. **Custom Gym Environment**: `CumulativeTradingEnv`\n",
    "2. **Per stock-month**:\n",
    "\n",
    "   * Train PPO agent (stable-baselines3)\n",
    "   * Evaluate cumulative reward\n",
    "   * Compare against baseline (random policy)\n",
    "   * Compute:\n",
    "\n",
    "     * `agent_reward`, `random_reward`\n",
    "     * `advantage = agent_reward - random_reward`\n",
    "     * Other metrics: `sharpe`, `alpha`, `cumulative_return`\n",
    "3. **Label Definition**:\n",
    "\n",
    "   * Binary target: `1` if advantage > 0 else `0`\n",
    "\n",
    "---\n",
    "\n",
    "## Final Feature Set\n",
    "\n",
    "```\n",
    "['mean_return', 'std_return', 'skew', 'kurtosis', 'entropy',\n",
    " 'vol_mean', 'vol_std',\n",
    " 'ljung_pval', 'resid_acf1', 'resid_std', 'resid_skew', 'resid_kurtosis',\n",
    " 'sharpe', 'cum_return', 'alpha']\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Classifier Results\n",
    "\n",
    "**Model**: `RandomForestClassifier(n_estimators=200, class_weight=\"balanced\")`\n",
    "\n",
    "**Train/Test Split**: 80/20 (Stratified)\n",
    "\n",
    "### Classification Report:\n",
    "\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.84      0.95      0.89       420\n",
    "           1       0.97      0.89      0.93       675\n",
    "\n",
    "    accuracy                           0.91      1095\n",
    "   macro avg       0.91      0.92      0.91      1095\n",
    "weighted avg       0.92      0.91      0.91      1095\n",
    "```\n",
    "\n",
    "### Confusion Matrix:\n",
    "\n",
    "```\n",
    "[[400  20]\n",
    " [ 74 601]]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Interpretation\n",
    "\n",
    "* High overall accuracy (91%) and balanced class performance\n",
    "* The model is especially good at predicting when RL **will** work (class 1)\n",
    "* A powerful tool for **pre-filtering environments** before launching full RL training\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "* ✅ Feature importance (SHAP, permutation)\n",
    "* ✅ Add volatility-based meta-features (GARCH, Hurst exponent)\n",
    "* ✅ Try ranking models: `A > B` if `adv_A > adv_B`\n",
    "* ✅ Out-of-time validation on 2023+ data\n",
    "* ✅ Use this model to control which environments enter RL portfolios\n",
    "\n",
    "---\n",
    "\n",
    "## Files\n",
    "\n",
    "* `features_<EXPERIENCE_NAME>.pkl`: Engineered features\n",
    "* `targets_<EXPERIENCE_NAME>.pkl`: CV R² scores\n",
    "* `meta_rl_labels_<EXPERIENCE_NAME>.pkl`: Advantage labeling\n",
    "\n",
    "---\n",
    "\n",
    "## Requirements\n",
    "\n",
    "* `scikit-learn`\n",
    "* `statsmodels`\n",
    "* `stable-baselines3`\n",
    "* `gymnasium`\n",
    "* `pandas`, `numpy`, `joblib`\n",
    "\n",
    "---\n",
    "\n",
    "## Authors\n",
    "\n",
    "* Filipe Mota de Sá @ github.io/pihh\n",
    "* ChatGPT (OpenAI)\n",
    "\n",
    "---\n",
    "\n",
    "*\"Not all environments are created equal. Filter wisely.\"*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cab993d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francisco Sá\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\arrays\\masked.py:61: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "# SETUP: Imports & Paths ===========================\n",
    "import jupyter\n",
    "from src.utils.system import boot, Notify\n",
    "\n",
    "boot()\n",
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.data.feature_pipeline import basic_chart_features,load_base_dataframe\n",
    "from src.predictability.easiness import rolling_sharpe, rolling_r2, rolling_info_ratio, rolling_autocorr\n",
    "from src.predictability.pipeline import generate_universe_easiness_report\n",
    "from IPython import display\n",
    "\n",
    "from src.experiments.experiment_tracker import ExperimentTracker\n",
    "from src.config import TOP2_STOCK_BY_SECTOR\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy.stats import skew, kurtosis, entropy\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from statsmodels.tsa.stattools import acf, acovf\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "955d6b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "EXPERIENCE_NAME = \"stock_universe_predictability_selection__MetaFeatures__MetaRlLabeling\"\n",
    "FEATURES_PATH = f\"../data/cache/features_{EXPERIENCE_NAME}.pkl\"\n",
    "TARGETS_PATH = f\"../data/cache/targets_{EXPERIENCE_NAME}.pkl\"\n",
    "META_PATH = f\"../data/cache/meta_{EXPERIENCE_NAME}.pkl\"\n",
    "\n",
    "excluded_tickers=['CEG', 'GEHC', 'GEV', 'KVUE', 'SOLV']\n",
    "excluded_tickers.sort()\n",
    "#tickers = TOP2_STOCK_BY_SECTOR\n",
    "\n",
    "config={\n",
    "    \"regressor\":\"RandomForestRegressor\",\n",
    "    \"n_estimators\": 100,\n",
    "    \"random_state\":314\n",
    "}\n",
    "run_settings={\n",
    "    \"excluded_tickers\": excluded_tickers,\n",
    "    \"min_samples\": 10,\n",
    "    \"cv_folds\": 3,\n",
    "    \"lags\": 5,\n",
    "    \"start_date\":\"2022-01-01\",\n",
    "    \"end_date\":\"2023-01-01\"\n",
    "}\n",
    "\n",
    "# Config section\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bd2209",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b684e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD OHLCV ==========================================\n",
    "\n",
    "\n",
    "ohlcv_df = load_base_dataframe()\n",
    "ohlcv_df['date'] = pd.to_datetime(ohlcv_df['date'])\n",
    "ohlcv_df = ohlcv_df[(ohlcv_df['date'] >= run_settings[\"start_date\"]) & (ohlcv_df['date'] < run_settings[\"end_date\"])]\n",
    "ohlcv_df['month'] = ohlcv_df['date'].dt.to_period('M')\n",
    "ohlcv_df['return_1d'] = ohlcv_df['return_1d'].fillna(0)\n",
    "ohlcv_df['sector_id'] = ohlcv_df['sector_id'].fillna('unknown')\n",
    "ohlcv_df['industry_id'] = ohlcv_df['industry_id'].fillna('unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08c57433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cached feature/target/meta lists.\n"
     ]
    }
   ],
   "source": [
    "# Meta-feature & Label Extraction =======================\n",
    "\"\"\"\n",
    "# BASIC PREPROCESSING ===================================\n",
    "excluded_tickers = run_settings[\"excluded_tickers\"]\n",
    "min_samples = run_settings[\"min_samples\"]\n",
    "cv_folds = run_settings[\"cv_folds\"]\n",
    "lags = run_settings[\"lags\"]\n",
    "start_date = run_settings[\"start_date\"]\n",
    "end_date = run_settings[\"end_date\"]\n",
    "\n",
    "# CROP THE SAMPLE =======================================\n",
    "tickers = ohlcv_df['symbol'].unique()[:100]\n",
    "tickers = tickers[~np.isin(tickers, excluded_tickers)]\n",
    "tickers = [\"AAPL\",\"MSFT\",\"JPM\",\"V\",'LLY','UNH','AMZN','TSLA','META','GOOGL','GE','UBER','COST','WMT','XOM','CVX'.'NEE','SO','AMT','PLD','LIN','SHW']\n",
    "\n",
    "# FOR POC ONLY\n",
    "\n",
    "\n",
    "ohlcv_df = ohlcv_df.copy()\n",
    "ohlcv_df['date'] = pd.to_datetime(ohlcv_df['date'])\n",
    "ohlcv_df = ohlcv_df[(ohlcv_df['date'] >= start_date) & (ohlcv_df['date'] < end_date)]\n",
    "ohlcv_df['month'] = ohlcv_df['date'].dt.to_period('M')\n",
    "ohlcv_df['return_1d'] = ohlcv_df['return_1d'].fillna(0)\n",
    "\"\"\"\n",
    "tickers = ohlcv_df['symbol'].unique()\n",
    "tickers = tickers[~np.isin(tickers, excluded_tickers)]\n",
    "def mean_policy(arr):\n",
    "    # return np.median(arr)\n",
    "    return pd.Series(arr).ewm(span=5).mean().iloc[-1]\n",
    "\n",
    "# Attempt to load if already exists (resumability)\n",
    "if all([os.path.exists(path) for path in [FEATURES_PATH, TARGETS_PATH, META_PATH]]):\n",
    "    features = joblib.load(FEATURES_PATH)\n",
    "    targets = joblib.load(TARGETS_PATH)\n",
    "    metadata = joblib.load(META_PATH)\n",
    "    print(\"Loaded cached feature/target/meta lists.\")\n",
    "    \n",
    "else:\n",
    "    features, targets, metadata = [], [], []\n",
    "    #tickers = ohlcv_df['symbol'].unique()\n",
    "    #tickers = [t for t in tickers if t not in run_settings[\"excluded_tickers\"]]\n",
    "    for symbol in tqdm(tickers):\n",
    "        df = ohlcv_df[ohlcv_df['symbol'] == symbol].sort_values('date').copy()\n",
    "        months = df['month'].unique()\n",
    "        for i in range(1, len(months)):\n",
    "            m_t = months[i-1]\n",
    "            m_t1 = months[i]\n",
    "            df_t = df[df['month'] == m_t]\n",
    "            df_t1 = df[df['month'] == m_t1]\n",
    "            if len(df_t1) < run_settings[\"min_samples\"]:\n",
    "                continue\n",
    "            r1d = df_t['return_1d'].astype(float).values\n",
    "            v = df_t['volume'].astype(float).values\n",
    "            feat = {\n",
    "                'symbol': symbol,\n",
    "                'month_str': str(m_t),\n",
    "                'mean_return': mean_policy(r1d),\n",
    "                'std_return': r1d.std(),\n",
    "                'skew': skew(r1d),\n",
    "                'kurtosis': kurtosis(r1d),\n",
    "                'entropy': entropy(np.histogram(r1d, bins=10, density=True)[0] + 1e-8),\n",
    "                'vol_mean': mean_policy(v),\n",
    "                'vol_std': v.std()\n",
    "            }\n",
    "            # Residual diagnostics from simple RF on t+1\n",
    "            df_lag = df_t1.copy()\n",
    "            for lag in range(1, run_settings['lags'] + 1):\n",
    "                df_lag[f'return_lag_{lag}'] = df_lag['return_1d'].shift(lag)\n",
    "            df_lag = df_lag.dropna()\n",
    "            if len(df_lag) < run_settings[\"min_samples\"]:\n",
    "                continue\n",
    "            X = df_lag[[f'return_lag_{i}' for i in range(1, run_settings['lags'] + 1)]].values\n",
    "            y = df_lag['return_1d'].values\n",
    "            model = RandomForestRegressor(n_estimators=config['n_estimators'], random_state=config['random_state'])\n",
    "            model.fit(X, y)\n",
    "            residuals = y - model.predict(X)\n",
    "            # Meta-diagnostics\n",
    "            ljung_pval = acorr_ljungbox(residuals, lags=[run_settings['lags']], return_df=True).iloc[0]['lb_pvalue']\n",
    "            feat['ljung_pval'] = ljung_pval\n",
    "            feat['resid_acf1'] = pd.Series(residuals).autocorr(lag=1)\n",
    "            feat['resid_std'] = residuals.std()\n",
    "            feat['resid_skew'] = skew(residuals)\n",
    "            feat['resid_kurtosis'] = kurtosis(residuals)\n",
    "            # Predictability label (cross-val R²)\n",
    "            cv_r2 = mean_policy(cross_val_score(model, X, y, cv=run_settings[\"cv_folds\"], scoring='r2'))\n",
    "            features.append(feat)\n",
    "            targets.append(cv_r2)\n",
    "            metadata.append((symbol, str(m_t)))\n",
    "    # Save for future resumes\n",
    "    joblib.dump(features, FEATURES_PATH)\n",
    "    joblib.dump(targets, TARGETS_PATH)\n",
    "    joblib.dump(metadata, META_PATH)\n",
    "    print(\"Feature/target/meta lists saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2332da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame Construction  ============================\n",
    "X_df = pd.DataFrame(features)\n",
    "y_df = pd.Series(targets, name='cv_r2')\n",
    "meta_df = pd.DataFrame(metadata, columns=['symbol', 'month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49de6d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling & Preparation ==============================\n",
    "\n",
    "X = X_df.drop(columns=['symbol', 'month_str'])\n",
    "scaler = RobustScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42b91fd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>month_str</th>\n",
       "      <th>mean_return</th>\n",
       "      <th>std_return</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>entropy</th>\n",
       "      <th>vol_mean</th>\n",
       "      <th>vol_std</th>\n",
       "      <th>ljung_pval</th>\n",
       "      <th>resid_acf1</th>\n",
       "      <th>resid_std</th>\n",
       "      <th>resid_skew</th>\n",
       "      <th>resid_kurtosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MMM</td>\n",
       "      <td>2022-01</td>\n",
       "      <td>-0.005358</td>\n",
       "      <td>0.014943</td>\n",
       "      <td>-0.917692</td>\n",
       "      <td>0.261870</td>\n",
       "      <td>1.955084</td>\n",
       "      <td>5.306873e+06</td>\n",
       "      <td>1.376213e+06</td>\n",
       "      <td>0.886434</td>\n",
       "      <td>-0.210568</td>\n",
       "      <td>0.011435</td>\n",
       "      <td>1.832094</td>\n",
       "      <td>3.398314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MMM</td>\n",
       "      <td>2022-02</td>\n",
       "      <td>0.001679</td>\n",
       "      <td>0.017579</td>\n",
       "      <td>0.814226</td>\n",
       "      <td>2.843657</td>\n",
       "      <td>1.590270</td>\n",
       "      <td>5.706021e+06</td>\n",
       "      <td>1.373277e+06</td>\n",
       "      <td>0.505866</td>\n",
       "      <td>0.119984</td>\n",
       "      <td>0.006063</td>\n",
       "      <td>-1.128147</td>\n",
       "      <td>0.402776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MMM</td>\n",
       "      <td>2022-03</td>\n",
       "      <td>-0.003659</td>\n",
       "      <td>0.014061</td>\n",
       "      <td>-0.485777</td>\n",
       "      <td>-1.162192</td>\n",
       "      <td>2.074097</td>\n",
       "      <td>3.501205e+06</td>\n",
       "      <td>2.003990e+06</td>\n",
       "      <td>0.700678</td>\n",
       "      <td>-0.169013</td>\n",
       "      <td>0.005657</td>\n",
       "      <td>-0.729054</td>\n",
       "      <td>-0.444286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MMM</td>\n",
       "      <td>2022-04</td>\n",
       "      <td>-0.005525</td>\n",
       "      <td>0.012495</td>\n",
       "      <td>0.065468</td>\n",
       "      <td>0.467243</td>\n",
       "      <td>1.963829</td>\n",
       "      <td>4.301652e+06</td>\n",
       "      <td>9.406939e+05</td>\n",
       "      <td>0.711076</td>\n",
       "      <td>0.163132</td>\n",
       "      <td>0.006389</td>\n",
       "      <td>-0.567922</td>\n",
       "      <td>-0.850302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MMM</td>\n",
       "      <td>2022-05</td>\n",
       "      <td>0.004323</td>\n",
       "      <td>0.017465</td>\n",
       "      <td>-0.008367</td>\n",
       "      <td>-0.379037</td>\n",
       "      <td>1.857123</td>\n",
       "      <td>3.591724e+06</td>\n",
       "      <td>8.993571e+05</td>\n",
       "      <td>0.786330</td>\n",
       "      <td>0.001595</td>\n",
       "      <td>0.007651</td>\n",
       "      <td>0.674921</td>\n",
       "      <td>1.893767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5470</th>\n",
       "      <td>SPY</td>\n",
       "      <td>2022-07</td>\n",
       "      <td>0.010781</td>\n",
       "      <td>0.011772</td>\n",
       "      <td>0.329663</td>\n",
       "      <td>-0.951383</td>\n",
       "      <td>2.055845</td>\n",
       "      <td>7.726631e+07</td>\n",
       "      <td>1.048544e+07</td>\n",
       "      <td>0.952517</td>\n",
       "      <td>-0.152453</td>\n",
       "      <td>0.005413</td>\n",
       "      <td>-0.929827</td>\n",
       "      <td>1.288795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5471</th>\n",
       "      <td>SPY</td>\n",
       "      <td>2022-08</td>\n",
       "      <td>-0.008836</td>\n",
       "      <td>0.011893</td>\n",
       "      <td>-0.388961</td>\n",
       "      <td>0.848996</td>\n",
       "      <td>1.825026</td>\n",
       "      <td>7.652040e+07</td>\n",
       "      <td>1.403157e+07</td>\n",
       "      <td>0.452747</td>\n",
       "      <td>-0.158132</td>\n",
       "      <td>0.007806</td>\n",
       "      <td>-0.515058</td>\n",
       "      <td>0.510301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5472</th>\n",
       "      <td>SPY</td>\n",
       "      <td>2022-09</td>\n",
       "      <td>-0.009335</td>\n",
       "      <td>0.014769</td>\n",
       "      <td>-0.392043</td>\n",
       "      <td>0.294917</td>\n",
       "      <td>1.929729</td>\n",
       "      <td>1.252384e+08</td>\n",
       "      <td>2.141793e+07</td>\n",
       "      <td>0.528805</td>\n",
       "      <td>-0.458920</td>\n",
       "      <td>0.008030</td>\n",
       "      <td>0.086436</td>\n",
       "      <td>-1.084477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5473</th>\n",
       "      <td>SPY</td>\n",
       "      <td>2022-10</td>\n",
       "      <td>0.003589</td>\n",
       "      <td>0.017147</td>\n",
       "      <td>0.080973</td>\n",
       "      <td>-1.173194</td>\n",
       "      <td>1.867774</td>\n",
       "      <td>9.657081e+07</td>\n",
       "      <td>1.877312e+07</td>\n",
       "      <td>0.469245</td>\n",
       "      <td>-0.337390</td>\n",
       "      <td>0.008210</td>\n",
       "      <td>1.430019</td>\n",
       "      <td>2.145926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5474</th>\n",
       "      <td>SPY</td>\n",
       "      <td>2022-11</td>\n",
       "      <td>0.008735</td>\n",
       "      <td>0.017158</td>\n",
       "      <td>1.165741</td>\n",
       "      <td>2.079128</td>\n",
       "      <td>1.753308</td>\n",
       "      <td>8.651564e+07</td>\n",
       "      <td>2.808960e+07</td>\n",
       "      <td>0.642504</td>\n",
       "      <td>0.052701</td>\n",
       "      <td>0.005009</td>\n",
       "      <td>-0.087810</td>\n",
       "      <td>-0.244880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5475 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     symbol month_str  mean_return  std_return      skew  kurtosis   entropy  \\\n",
       "0       MMM   2022-01    -0.005358    0.014943 -0.917692  0.261870  1.955084   \n",
       "1       MMM   2022-02     0.001679    0.017579  0.814226  2.843657  1.590270   \n",
       "2       MMM   2022-03    -0.003659    0.014061 -0.485777 -1.162192  2.074097   \n",
       "3       MMM   2022-04    -0.005525    0.012495  0.065468  0.467243  1.963829   \n",
       "4       MMM   2022-05     0.004323    0.017465 -0.008367 -0.379037  1.857123   \n",
       "...     ...       ...          ...         ...       ...       ...       ...   \n",
       "5470    SPY   2022-07     0.010781    0.011772  0.329663 -0.951383  2.055845   \n",
       "5471    SPY   2022-08    -0.008836    0.011893 -0.388961  0.848996  1.825026   \n",
       "5472    SPY   2022-09    -0.009335    0.014769 -0.392043  0.294917  1.929729   \n",
       "5473    SPY   2022-10     0.003589    0.017147  0.080973 -1.173194  1.867774   \n",
       "5474    SPY   2022-11     0.008735    0.017158  1.165741  2.079128  1.753308   \n",
       "\n",
       "          vol_mean       vol_std  ljung_pval  resid_acf1  resid_std  \\\n",
       "0     5.306873e+06  1.376213e+06    0.886434   -0.210568   0.011435   \n",
       "1     5.706021e+06  1.373277e+06    0.505866    0.119984   0.006063   \n",
       "2     3.501205e+06  2.003990e+06    0.700678   -0.169013   0.005657   \n",
       "3     4.301652e+06  9.406939e+05    0.711076    0.163132   0.006389   \n",
       "4     3.591724e+06  8.993571e+05    0.786330    0.001595   0.007651   \n",
       "...            ...           ...         ...         ...        ...   \n",
       "5470  7.726631e+07  1.048544e+07    0.952517   -0.152453   0.005413   \n",
       "5471  7.652040e+07  1.403157e+07    0.452747   -0.158132   0.007806   \n",
       "5472  1.252384e+08  2.141793e+07    0.528805   -0.458920   0.008030   \n",
       "5473  9.657081e+07  1.877312e+07    0.469245   -0.337390   0.008210   \n",
       "5474  8.651564e+07  2.808960e+07    0.642504    0.052701   0.005009   \n",
       "\n",
       "      resid_skew  resid_kurtosis  \n",
       "0       1.832094        3.398314  \n",
       "1      -1.128147        0.402776  \n",
       "2      -0.729054       -0.444286  \n",
       "3      -0.567922       -0.850302  \n",
       "4       0.674921        1.893767  \n",
       "...          ...             ...  \n",
       "5470   -0.929827        1.288795  \n",
       "5471   -0.515058        0.510301  \n",
       "5472    0.086436       -1.084477  \n",
       "5473    1.430019        2.145926  \n",
       "5474   -0.087810       -0.244880  \n",
       "\n",
       "[5475 rows x 14 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c8cbed9",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (base_trading_env.py, line 393)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[0;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:3508\u001b[0m in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[1;36m  Cell \u001b[1;32mIn[8], line 5\u001b[1;36m\n\u001b[1;33m    from src.env.base_trading_env import CumulativeTradingEnv\u001b[1;36m\n",
      "\u001b[1;36m  File \u001b[1;32m~\\Dev\\RL-Stock-Market-Masterpiece-Human-x-AI-Collab\\src\\env\\base_trading_env.py:393\u001b[1;36m\u001b[0m\n\u001b[1;33m    self.env = BaseTradingEnv((*args, **kwargs))\u001b[0m\n\u001b[1;37m                                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "import joblib\n",
    "from src.env.base_trading_env import CumulativeTradingEnv\n",
    "\n",
    "RL_LABELS_PATH = f\"../../data/cache/meta_rl_labels_{EXPERIENCE_NAME}.pkl\"\n",
    "\n",
    "feature_cols = [\"return_1d\", \"volume\"]  # Or your preferred features\n",
    "episode_length = 18  # Or whatever fits your month\n",
    "train_steps = 300    # Fast!\n",
    "min_ep_len = 18\n",
    "# Resume logic: Load meta_df with RL columns if available\n",
    "if os.path.exists(RL_LABELS_PATH):\n",
    "    meta_df_rl = pd.read_pickle(RL_LABELS_PATH)\n",
    "    print(\"Loaded meta_df with RL columns.\")\n",
    "else:\n",
    "    # Copy original meta_df and initialize RL columns\n",
    "    meta_df_rl = meta_df.copy()\n",
    "    meta_df_rl['agent_reward'] = np.nan\n",
    "    meta_df_rl['random_reward'] = np.nan\n",
    "    meta_df_rl['advantage'] = np.nan\n",
    "    meta_df_rl['sharpe'] = np.nan\n",
    "    meta_df_rl['cum_return'] = np.nan\n",
    "    meta_df_rl['alpha'] = np.nan\n",
    "\n",
    "\n",
    "for i, row in tqdm(meta_df_rl.iterrows(), total=len(meta_df_rl), desc=\"Meta-RL Agent Loop\"):\n",
    "    # Skip if already computed\n",
    "    if not np.isnan(meta_df_rl.loc[i, 'agent_reward']):\n",
    "        continue\n",
    "\n",
    "    symbol, month = row['symbol'], row['month']\n",
    "    df_env = ohlcv_df[(ohlcv_df['symbol'] == symbol) & (ohlcv_df['month'] == month)].sort_values(\"date\")\n",
    "    if len(df_env) < min_ep_len:\n",
    "        min_ep_len = len(df_env)\n",
    "        print('new min',min_ep_len)\n",
    "    if len(df_env) < episode_length:\n",
    "        print('x',len(df_env) ,episode_length)\n",
    "        continue  # Not enough data, skip\n",
    "\n",
    "    try:\n",
    "        env = CumulativeTradingEnv(\n",
    "            df=df_env,\n",
    "            feature_cols=feature_cols,\n",
    "            episode_length=episode_length,\n",
    "            transaction_cost=0.0001,\n",
    "            seed=42\n",
    "        )\n",
    "        env = gym.wrappers.FlattenObservation(env)\n",
    "        check_env(env, warn=True)\n",
    "\n",
    "        model = PPO(\"MlpPolicy\", env, verbose=0, n_steps=64, batch_size=16, learning_rate=0.001, seed=42)\n",
    "        model.learn(total_timesteps=train_steps)\n",
    "\n",
    "        # Evaluate PPO\n",
    "        obs, _ = env.reset()\n",
    "        agent_rewards, done = [], False\n",
    "        while not done:\n",
    "            action, _ = model.predict(obs, deterministic=True)\n",
    "            obs, reward, done, truncated, info = env.step(action)\n",
    "            agent_rewards.append(reward)\n",
    "        agent_reward = np.sum(agent_rewards)\n",
    "\n",
    "        # Evaluate Random\n",
    "        obs, _ = env.reset()\n",
    "        random_rewards, done = [], False\n",
    "        while not done:\n",
    "            action = env.action_space.sample()\n",
    "            obs, reward, done, truncated, info = env.step(action)\n",
    "            random_rewards.append(reward)\n",
    "        random_reward = np.sum(random_rewards)\n",
    "\n",
    "        advantage = agent_reward - random_reward\n",
    "\n",
    "        meta_df_rl.loc[i, 'agent_reward'] = agent_reward\n",
    "        meta_df_rl.loc[i, 'random_reward'] = random_reward\n",
    "        meta_df_rl.loc[i, 'advantage'] = advantage\n",
    "        meta_df_rl.loc[i, 'sharpe'] = info.get(\"episode_sharpe\", np.nan)\n",
    "        meta_df_rl.loc[i, 'cum_return'] = info.get(\"cumulative_return\", np.nan)\n",
    "        meta_df_rl.loc[i, 'alpha'] = info.get(\"alpha\", np.nan)\n",
    "        #print(info)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Skipped ({symbol})\",e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cddf7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df_rl.to_csv('mrl.csv')\n",
    "meta_df_rl['target'] = (meta_df_rl['advantage'] > 0).astype(int)\n",
    "meta_df_rl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0bdf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [col for col in meta_df_rl.columns if col not in ['symbol', 'month', 'agent_reward', 'random_reward', 'advantage', 'target']]\n",
    "feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01f462f",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df_rl['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028898a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure columns are compatible for merge\n",
    "X_df['month'] = X_df['month_str']\n",
    "merged = pd.merge(X_df, meta_df_rl, on=['symbol', 'month'], how='inner')\n",
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e590d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\n",
    "    col for col in merged.columns\n",
    "    if col not in ['symbol', 'month', 'month_str', 'agent_reward', 'random_reward', 'advantage', 'target']\n",
    "]\n",
    "\n",
    "X = merged[feature_cols]\n",
    "y = merged['target']\n",
    "\n",
    "# Scale features\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler = RobustScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ce8dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ohlcv_df.sort_values(by=\"date\").head().to_csv('ohlcv_to_upload.csv')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=200, random_state=42, class_weight='balanced')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668a6e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "importances = clf.feature_importances_\n",
    "sorted_idx = np.argsort(importances)[::-1]\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(range(len(importances)), importances[sorted_idx])\n",
    "plt.xticks(range(len(importances)), [feature_cols[i] for i in sorted_idx], rotation=90)\n",
    "plt.title(\"Meta-Feature Importances for Predicting RL Agent Advantage\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce75301",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# y_true: true labels, y_pred: predicted labels\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=plt.cm.Blues)  # Optional: color map\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "class_names = ['Will Learn', 'Wont learn']  # Adjust to your problem\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "disp.plot(cmap=plt.cm.Oranges)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41b6f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "xxxxxxxxxx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b430a9d9",
   "metadata": {},
   "source": [
    "## Quick Recap\n",
    "We want to estimate how \"predictable\" each stock is in a given month, using meta-features of its behavior.\n",
    "\n",
    "#### Pipeline: \n",
    "**Loop: For each (stock, month)**\n",
    "From Previous Month (t) we will extract features. From the returns in month t, we compute:\n",
    "* Mean\n",
    "* Std \n",
    "* Skew \n",
    "* Kurtosis\n",
    "* Entropy of returns\n",
    "* Mean of volumne\n",
    "* Std of volume\n",
    "\n",
    "These become the meta-features for that stock-month.\n",
    "\n",
    "**From Following Month (t+1) we will compute \"predictability\"**\n",
    "\n",
    "* With 5 lags of daily returns from month t+1 will try to predict daily returns using a RandomForestRegressor\n",
    "* Evaluate performance with cross-validated R² (cv_r2)\n",
    "* Analyze residuals from this model with the Ljung–Box test for autocorrelation ⇒ gives ljung_pval\n",
    "\n",
    "These become the target labels or diagnostic scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6719145c",
   "metadata": {},
   "source": [
    "| Feature                 | Description                                        |\n",
    "| ----------------------- | -------------------------------------------------- |\n",
    "| `resid_acf1`            | Autocorrelation of residuals (lag 1)               |\n",
    "| `resid_std`             | Std of residuals                                   |\n",
    "| `resid_skew`            | Skewness of residuals                              |\n",
    "| `resid_kurtosis`        | Kurtosis of residuals                              |\n",
    "| `resid_ljung_pval`      | p-value of Ljung-Box test for residual autocorr    |\n",
    "| `return_autocorr_1d`    | Lag-1 autocorrelation of raw 1D returns            |\n",
    "| `volatility_clustering` | Rolling std autocorrelation (vol clustering proxy) |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76777804",
   "metadata": {},
   "outputs": [],
   "source": [
    "2. Feature engineering:\n",
    "Add features that measure uncertainty, volatility clustering, or market randomness like:\n",
    "\n",
    "Hurst exponent\n",
    "\n",
    "GARCH volatility\n",
    "\n",
    "Rolling ADF p-values\n",
    "\n",
    "Change-point detection count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d930e609",
   "metadata": {},
   "source": [
    "| Stage                 | Description                                                                                             |\n",
    "| --------------------- | ------------------------------------------------------------------------------------------------------- |\n",
    "| 🧹 Preprocessing      | Clean stock OHLCV data, compute lagged returns                                                          |\n",
    "| 📈 Forecast Models    | Run simple regressors on next-month returns                                                             |\n",
    "| 🔍 Diagnostics        | Extract residual meta-features, R², forecast entropy, etc.                                              |\n",
    "| 🧠 Labeling           | - Regression: R² as target<br>- Ranking: (A > B)<br>- RL Reward: agent learnability                     |\n",
    "| 📊 Feature Extraction | Use summary stats + diagnostic/meta features                                                            |\n",
    "| 🧬 Modeling           | - Regression: Predict R²<br>- Classification: Predict \"learnable\"<br>- Contrastive: Rank predictability |\n",
    "| 🏆 Output             | Sorted top-k stock-months or environments where RL thrives                                              |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281bdc7e",
   "metadata": {},
   "source": [
    "| Section                             | Purpose                                                                                                                                                                                                          |\n",
    "| ----------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| 🔧 **Setup & Pipeline Description** | High-level explanation of your RL pipeline, feature engineering, and data sources                                                                                                                                |\n",
    "| 🧪 **Completed Studies**            | Summary table or list of ablation studies, e.g.:<br>`01 - Reward Function Impact`<br>`02 - Predictability Filters via R²`<br>`03 - Meta-Learnability Scores`                                                     |\n",
    "| ✅ **Conclusions So Far**            | Bullet points of key findings from each experiment, e.g.:<br>– Simple R² doesn't generalize across time<br>– Residual-based features offer better stability<br>– Meta-RL proxy labels correlate with test Sharpe |\n",
    "| 🔬 **Ongoing Work**                 | One-liner of what’s running or planned, so future you remembers                                                                                                                                                  |\n",
    "| 📎 **Notebook Index**               | List of notebooks and what each one covers                                                                                                                                                                       |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
