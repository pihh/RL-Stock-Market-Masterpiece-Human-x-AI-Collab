{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ae04683",
   "metadata": {},
   "source": [
    "# 03 - Predictability & Universe Filtering\n",
    "\n",
    "1. Compute rolling predictability metrics for each ticker\n",
    "2. Visualize and compare scores across universe and time\n",
    "3. Select top-N most “learnable” tickers for RL agent\n",
    "4. Document all decisions, assumptions, and open questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8abebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francisco Sá\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\arrays\\masked.py:61: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "# SETUP: Imports & Paths ===========================\n",
    "import jupyter\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "from src.data.feature_pipeline import basic_chart_features,load_base_dataframe\n",
    "from src.predictability.easiness import rolling_sharpe, rolling_r2, rolling_info_ratio, rolling_autocorr\n",
    "from src.predictability.pipeline import generate_universe_easiness_report\n",
    "from IPython import display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b03dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD OHLCV ==========================================\n",
    "ohlcv_df = load_base_dataframe()\n",
    "ohlcv_df.tail()\n",
    "_ohlcv=ohlcv_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5d625a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CROP THE SAMPLE =======================================\n",
    "tickers = ohlcv_df['symbol'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be8d347",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cda1f4f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#all_metric = generate_universe_easiness_report(ohlcv_df,tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b395aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_metric.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba7a46e",
   "metadata": {},
   "source": [
    "# Walkforward study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8beed8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#ohlcv_df['date'] = pd.to_datetime(ohlcv_df['date'])\n",
    "ohlcv_df = _ohlcv.copy()\n",
    "# Walkforward parameters\n",
    "start_date = pd.to_datetime('2023-05-01')\n",
    "end_date = ohlcv_df['date'].max()\n",
    "freq = '6MS'   # Month Start, use 'W' for weekly, etc\n",
    "window_length = 60\n",
    "#tickers = ohlcv_df['ticker'].unique()\n",
    "\n",
    "walkforward_dates = pd.date_range(start=start_date + pd.Timedelta(days=window_length), end=end_date, freq=freq)\n",
    "\n",
    "walkforward_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05c4604",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_date = \"2023-01-01\"\n",
    "tickers = ohlcv_df['symbol'].unique()\n",
    "tickers = ['AAPL']\n",
    "for cutoff in tqdm(walkforward_dates):\n",
    "    df = ohlcv_df.copy()\n",
    "    cutoff_str = cutoff.strftime('%Y-%m-%d')\n",
    "    \n",
    "    print(f\"\\n=== Universe study up to {cutoff_str} ===\")\n",
    "    _ = generate_universe_easiness_report(\n",
    "        ohlcv_df=df,\n",
    "        tickers=tickers,\n",
    "        window_length=window_length,\n",
    "        target=\"return_1d\",\n",
    "        benchmark_col=\"market_return_1d\",\n",
    "        visualize=False,   # Skip plotting for speed, or True for debug\n",
    "        cutoff_end_date=cutoff_str,\n",
    "        cutoff_start_date=prev_date,\n",
    "        save_csv_path=\"data/experiments/predictability_metrics-{hash}-{start}-{cutoff}.csv\".format(hash=\"{hash}\", cutoff=cutoff_str,start=prev_date)\n",
    "    )\n",
    "    prev_date = cutoff_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcec7c49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2e1fb8e",
   "metadata": {},
   "source": [
    "# Futures and nice to haves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5caf8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "EXPERIMENTS_DIR = \"data/experiments\"\n",
    "\n",
    "# List all experiment result CSVs\n",
    "all_files = [f for f in os.listdir(EXPERIMENTS_DIR) if f.startswith('predictability_metrics-') and f.endswith('.csv')]\n",
    "\n",
    "studies = []\n",
    "for fname in all_files:\n",
    "    df = pd.read_csv(os.path.join(EXPERIMENTS_DIR, fname))\n",
    "    # Parse config from first row (all rows have same config)\n",
    "    config = json.loads(df['config_json'].iloc[0])\n",
    "    studies.append({'df': df, 'config': config, 'hash': df['config_hash'].iloc[0], 'filename': fname})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce64bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for study in studies:\n",
    "    print(f\"--- Study Hash: {study['hash']} | File: {study['filename']}\")\n",
    "    print(json.dumps(study['config'], indent=2))\n",
    "    df = study['df']\n",
    "    metrics = [col for col in df.columns if col not in [\"ticker\", \"date\", \"config_hash\", \"config_json\", \"symbol\"]]\n",
    "    for metric in metrics:\n",
    "        print(f\"Metric: {metric}\")\n",
    "        print(f\"  Mean: {df[metric].mean():.4f}, Std: {df[metric].std():.4f}\")\n",
    "        # Top and bottom tickers (by mean)\n",
    "        agg = df.groupby('ticker')[metric].mean().sort_values(ascending=False)\n",
    "        print(\"    Top 3 tickers:\", agg.head(3).to_dict())\n",
    "        print(\"    Bottom 3 tickers:\", agg.tail(3).to_dict())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cba62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_metric_across_studies(metric_name):\n",
    "    plt.figure(figsize=(12,6))\n",
    "    for study in studies:\n",
    "        df = study['df']\n",
    "        if metric_name not in df.columns:\n",
    "            continue\n",
    "        plt.hist(df[metric_name], bins=80, alpha=0.3, label=f\"Study {study['hash'][:6]}\")\n",
    "    plt.legend()\n",
    "    plt.title(f\"Distribution of {metric_name} across studies\")\n",
    "    plt.show()\n",
    "\n",
    "# Example: Compare sharpe distributions\n",
    "plot_metric_across_studies(\"sharpe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d892a54e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
