{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a83a608",
   "metadata": {},
   "source": [
    "# 01 - Environment Reward System Ablation Test\n",
    "\n",
    "1. Compute rolling predictability metrics for each ticker\n",
    "2. Visualize and compare scores across universe and time\n",
    "3. Select top-N most “learnable” tickers for RL agent\n",
    "4. Document all decisions, assumptions, and open questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b42b5e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Ablation: all_features ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francisco Sá\\AppData\\Roaming\\Python\\Python311\\site-packages\\stable_baselines3\\ppo\\ppo.py:155: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 50`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 50\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=50 and n_envs=1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['position', 'holding_period', 'cumulative_reward', 'pct_time', 'drawdown', 'rel_perf', 'unrealized_pnl', 'entry_price', 'time_in_position'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 169\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ablation_name, feature_set \u001b[38;5;129;01min\u001b[39;00m ablation_variants:\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m==== Ablation: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mablation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ====\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 169\u001b[0m     ablation_df \u001b[38;5;241m=\u001b[39m evaluate_feature_set(\n\u001b[0;32m    170\u001b[0m         feature_set\u001b[38;5;241m=\u001b[39mfeature_set,\n\u001b[0;32m    171\u001b[0m         config\u001b[38;5;241m=\u001b[39mCONFIG,\n\u001b[0;32m    172\u001b[0m         walk_forward_splits\u001b[38;5;241m=\u001b[39mwalk_forward_splits,\n\u001b[0;32m    173\u001b[0m         RL_ENV_CLASS\u001b[38;5;241m=\u001b[39mCumulativeTradingEnv,  \u001b[38;5;66;03m# Use the chosen reward/env for now\u001b[39;00m\n\u001b[0;32m    174\u001b[0m         BaselineAgentClass\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# If needed for more baselines\u001b[39;00m\n\u001b[0;32m    175\u001b[0m         ohlcv_df\u001b[38;5;241m=\u001b[39mohlcv_df,\n\u001b[0;32m    176\u001b[0m         EXCLUDED_TICKERS\u001b[38;5;241m=\u001b[39mEXCLUDED_TICKERS,\n\u001b[0;32m    177\u001b[0m         EPISODE_LENGTH\u001b[38;5;241m=\u001b[39mEPISODE_LENGTH,\n\u001b[0;32m    178\u001b[0m         TOTAL_TRAIN_EPISODES\u001b[38;5;241m=\u001b[39mTOTAL_TRAIN_EPISODES,\n\u001b[0;32m    179\u001b[0m         TOTAL_TEST_EPISODES\u001b[38;5;241m=\u001b[39mTOTAL_TEST_EPISODES,\n\u001b[0;32m    180\u001b[0m         SEED\u001b[38;5;241m=\u001b[39mSEED,\n\u001b[0;32m    181\u001b[0m     )\n\u001b[0;32m    182\u001b[0m     ablation_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mablation\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m ablation_name\n\u001b[0;32m    183\u001b[0m     results_table\u001b[38;5;241m.\u001b[39mappend(ablation_df)\n",
      "Cell \u001b[1;32mIn[2], line 126\u001b[0m, in \u001b[0;36mevaluate_feature_set\u001b[1;34m(feature_set, config, walk_forward_splits, RL_ENV_CLASS, BaselineAgentClass, ohlcv_df, EXCLUDED_TICKERS, EPISODE_LENGTH, TOTAL_TRAIN_EPISODES, TOTAL_TEST_EPISODES, SEED)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstable_baselines3\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PPO\n\u001b[0;32m    125\u001b[0m agent \u001b[38;5;241m=\u001b[39m PPO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMlpPolicy\u001b[39m\u001b[38;5;124m\"\u001b[39m, train_env, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, n_steps\u001b[38;5;241m=\u001b[39mEPISODE_LENGTH, seed\u001b[38;5;241m=\u001b[39mSEED)\n\u001b[1;32m--> 126\u001b[0m agent\u001b[38;5;241m.\u001b[39mlearn(total_timesteps\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_timesteps\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    128\u001b[0m \u001b[38;5;66;03m# Evaluate PPO agent\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_env\u001b[39m(env, agent, n_episodes, agent_type):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\stable_baselines3\\ppo\\ppo.py:311\u001b[0m, in \u001b[0;36mPPO.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfPPO,\n\u001b[0;32m    304\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    309\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    310\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfPPO:\n\u001b[1;32m--> 311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mlearn(\n\u001b[0;32m    312\u001b[0m         total_timesteps\u001b[38;5;241m=\u001b[39mtotal_timesteps,\n\u001b[0;32m    313\u001b[0m         callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[0;32m    314\u001b[0m         log_interval\u001b[38;5;241m=\u001b[39mlog_interval,\n\u001b[0;32m    315\u001b[0m         tb_log_name\u001b[38;5;241m=\u001b[39mtb_log_name,\n\u001b[0;32m    316\u001b[0m         reset_num_timesteps\u001b[38;5;241m=\u001b[39mreset_num_timesteps,\n\u001b[0;32m    317\u001b[0m         progress_bar\u001b[38;5;241m=\u001b[39mprogress_bar,\n\u001b[0;32m    318\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:311\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    301\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfOnPolicyAlgorithm,\n\u001b[0;32m    302\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    307\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    308\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfOnPolicyAlgorithm:\n\u001b[0;32m    309\u001b[0m     iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 311\u001b[0m     total_timesteps, callback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_learn(\n\u001b[0;32m    312\u001b[0m         total_timesteps,\n\u001b[0;32m    313\u001b[0m         callback,\n\u001b[0;32m    314\u001b[0m         reset_num_timesteps,\n\u001b[0;32m    315\u001b[0m         tb_log_name,\n\u001b[0;32m    316\u001b[0m         progress_bar,\n\u001b[0;32m    317\u001b[0m     )\n\u001b[0;32m    319\u001b[0m     callback\u001b[38;5;241m.\u001b[39mon_training_start(\u001b[38;5;28mlocals\u001b[39m(), \u001b[38;5;28mglobals\u001b[39m())\n\u001b[0;32m    321\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\stable_baselines3\\common\\base_class.py:424\u001b[0m, in \u001b[0;36mBaseAlgorithm._setup_learn\u001b[1;34m(self, total_timesteps, callback, reset_num_timesteps, tb_log_name, progress_bar)\u001b[0m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reset_num_timesteps \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_obs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    423\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 424\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_obs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mreset()  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m    425\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_episode_starts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mnum_envs,), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[0;32m    426\u001b[0m     \u001b[38;5;66;03m# Retrieve unnormalized observation for saving into the buffer\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:78\u001b[0m, in \u001b[0;36mDummyVecEnv.reset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m env_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs):\n\u001b[0;32m     77\u001b[0m     maybe_options \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptions\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options[env_idx]} \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options[env_idx] \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m---> 78\u001b[0m     obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_infos[env_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvs[env_idx]\u001b[38;5;241m.\u001b[39mreset(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_seeds[env_idx], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmaybe_options)\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_obs(env_idx, obs)\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m# Seeds and options are only used once\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\stable_baselines3\\common\\monitor.py:83\u001b[0m, in \u001b[0;36mMonitor.reset\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected you to pass keyword argument \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m into reset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_reset_info[key] \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m---> 83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mreset(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Dev\\RL-Stock-Market-Masterpiece-Human-x-AI-Collab\\src\\env\\base_trading_env.py:126\u001b[0m, in \u001b[0;36mBaseTradingEnv.reset\u001b[1;34m(self, seed, options, start_index)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_wealth \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpeak_wealth \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_obs(), {}\n",
      "File \u001b[1;32m~\\Dev\\RL-Stock-Market-Masterpiece-Human-x-AI-Collab\\src\\env\\base_trading_env.py:129\u001b[0m, in \u001b[0;36mBaseTradingEnv._get_obs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_obs\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 129\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepisode_df\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_step][\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_cols]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;66;03m# Compose internal state as a dict\u001b[39;00m\n\u001b[0;32m    131\u001b[0m     internal_state \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    132\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mposition\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition,\n\u001b[0;32m    133\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mholding_period\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mholding_period,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime_in_position\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_in_position,\n\u001b[0;32m    141\u001b[0m     }\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\series.py:1162\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1159\u001b[0m     key \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(key, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[0;32m   1160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_rows_with_mask(key)\n\u001b[1;32m-> 1162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_with(key)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\series.py:1203\u001b[0m, in \u001b[0;36mSeries._get_with\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1200\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miloc[key]\n\u001b[0;32m   1202\u001b[0m \u001b[38;5;66;03m# handle the dup indexing case GH#4246\u001b[39;00m\n\u001b[1;32m-> 1203\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc[key]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\indexing.py:1191\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1189\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m   1190\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[1;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_axis(maybe_callable, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\indexing.py:1420\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1417\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1418\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index with multidimensional key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_iterable(key, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m   1422\u001b[0m \u001b[38;5;66;03m# nested tuple slicing\u001b[39;00m\n\u001b[0;32m   1423\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\indexing.py:1360\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1357\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m   1359\u001b[0m \u001b[38;5;66;03m# A collection of keys\u001b[39;00m\n\u001b[1;32m-> 1360\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_listlike_indexer(key, axis)\n\u001b[0;32m   1361\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[0;32m   1362\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1363\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\indexing.py:1558\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1555\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[0;32m   1556\u001b[0m axis_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis_name(axis)\n\u001b[1;32m-> 1558\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, axis_name)\n\u001b[0;32m   1560\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:6212\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6209\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6210\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6212\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6214\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6216\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:6264\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6263\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6264\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['position', 'holding_period', 'cumulative_reward', 'pct_time', 'drawdown', 'rel_perf', 'unrealized_pnl', 'entry_price', 'time_in_position'] not in index\""
     ]
    }
   ],
   "source": [
    "import jupyter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import ttest_ind, mannwhitneyu\n",
    "from src.env.base_trading_env import CumulativeTradingEnv\n",
    "\n",
    "\n",
    "from src.utils.system import boot\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "boot()\n",
    "from tqdm import tqdm\n",
    "from src.data.feature_pipeline import load_base_dataframe\n",
    "from src.predictability.easiness import rolling_sharpe, rolling_r2, rolling_info_ratio, rolling_autocorr\n",
    "from src.predictability.pipeline import generate_universe_easiness_report\n",
    "from IPython import display\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from src.experiments.experiment_tracker import ExperimentTracker  \n",
    "from src.env.base_trading_env import (  \n",
    "    BaseTradingEnv, SharpeTradingEnv, SortinoTradingEnv, AlphaTradingEnv,\n",
    "    DrawdownTradingEnv, CumulativeTradingEnv, CalmarTradingEnv, HybridTradingEnv,BaselineTradingAgent\n",
    ")\n",
    "\n",
    "# ---- 1. Define features ----\n",
    "MARKET_FEATURES = [\n",
    "    \"day_of_month\", \"day_of_week\", \"order_flow\", \"candle_body\",\n",
    "    \"upper_shadow\", \"lower_shadow\", \"price_change\", \"candle_change\",\n",
    "    \"order_flow_change\", \"overnight_price_change\", \"volume_change\",\n",
    "    \"vwap_change\", \"trade_count_change\", \"return_1d\", \"vix_norm\", \"market_return_1d\"\n",
    "]\n",
    "INTERNAL_FEATURES = [\n",
    "    \"position\", \"holding_period\", \"cumulative_reward\", \"pct_time\", \n",
    "    \"drawdown\", \"rel_perf\", \"unrealized_pnl\", \"entry_price\", \"time_in_position\"\n",
    "]\n",
    "\n",
    "ablation_variants = [\n",
    "    (\"all_features\", MARKET_FEATURES, INTERNAL_FEATURES),\n",
    "    (\"market_only\", MARKET_FEATURES, []),\n",
    "    (\"internal_only\", [], INTERNAL_FEATURES),\n",
    "]\n",
    "for f in INTERNAL_FEATURES:\n",
    "    ablation_variants.append((f\"no_{f}\", MARKET_FEATURES, [i for i in INTERNAL_FEATURES if i != f]))\n",
    "\n",
    "EXPERIMENT_NAME = \"walkforward_ablation_base_env_internal_features\"\n",
    "EXCLUDED_TICKERS = ['CEG', 'GEHC', 'GEV', 'KVUE', 'SOLV']\n",
    "\n",
    "\n",
    "\n",
    "TOTAL_TIMESTEPS=20000\n",
    "EPISODE_LENGTH = 50\n",
    "TOTAL_TRAIN_EPISODES = int(TOTAL_TIMESTEPS/EPISODE_LENGTH )+1\n",
    "TOTAL_TEST_EPISODES = 5\n",
    "\n",
    "SEED = 314\n",
    "TRANSACTION_COST=0#0.0001\n",
    "\n",
    "# --- Walk-forward Splits ---\n",
    "walk_forward_splits = [\n",
    "    (\"2023-01-01\", \"2023-07-01\", \"2023-09-01\", \"2023-12-01\"),\n",
    "    (\"2024-01-01\", \"2024-07-01\", \"2024-09-01\", \"2024-12-01\"),\n",
    "]\n",
    "\n",
    "# --- Ablation Variants ---\n",
    "\n",
    "CONFIG = {\n",
    "    \"feature_cols\":ALL_FEATURES,\n",
    "    \"total_train_episodes\":TOTAL_TRAIN_EPISODES,\n",
    "    \"total_test_episodes\":TOTAL_TEST_EPISODES,\n",
    "    \"episode_length\":EPISODE_LENGTH,\n",
    "    \"seed\":SEED,\n",
    "    \"transaction_cost\":TRANSACTION_COST,\n",
    "    \"total_timesteps\":TOTAL_TIMESTEPS,\n",
    "    \"agent\":\"PPO\"\n",
    "}\n",
    "\n",
    "# LOAD OHLCV ==========================================\n",
    "ohlcv_df = load_base_dataframe()\n",
    "ohlcv_df.tail()\n",
    "_ohlcv=ohlcv_df.copy()\n",
    "\n",
    "# Drop-one ablations\n",
    "for f in INTERNAL_FEATURES:\n",
    "    ablation_variants.append((f\"no_{f}\", MARKET_FEATURES + [i for i in INTERNAL_FEATURES if i != f]))\n",
    "\n",
    "# ---- 3. Walk-forward evaluation function ----\n",
    "def evaluate_feature_set(feature_set, config, walk_forward_splits, RL_ENV_CLASS, BaselineAgentClass, ohlcv_df, EXCLUDED_TICKERS, EPISODE_LENGTH, TOTAL_TRAIN_EPISODES, TOTAL_TEST_EPISODES, SEED):\n",
    "    all_rows = []\n",
    "    for split_idx, (train_start, train_end, test_start, test_end) in enumerate(walk_forward_splits):\n",
    "        # Data splits\n",
    "        df_train = ohlcv_df[(ohlcv_df['date'] >= train_start) & (ohlcv_df['date'] < train_end) & ~ohlcv_df['symbol'].isin(EXCLUDED_TICKERS)].reset_index(drop=True)\n",
    "        df_test = ohlcv_df[(ohlcv_df['date'] >= test_start) & (ohlcv_df['date'] < test_end) & ~ohlcv_df['symbol'].isin(EXCLUDED_TICKERS)].reset_index(drop=True)\n",
    "\n",
    "        # Deterministic episode generator (use your actual logic here)\n",
    "        def generate_episode_sequences(df, episode_length, n_episodes, excluded_tickers, seed=314):\n",
    "            rng = np.random.default_rng(seed)\n",
    "            eligible_tickers = [t for t in df['symbol'].unique() if t not in excluded_tickers]\n",
    "            sequences = []\n",
    "            for _ in range(n_episodes):\n",
    "                ticker = rng.choice(eligible_tickers)\n",
    "                stock_df = df[df['symbol'] == ticker]\n",
    "                max_start = len(stock_df) - episode_length - 1\n",
    "                if max_start < 1: continue\n",
    "                start_idx = rng.integers(0, max_start)\n",
    "                sequences.append((ticker, int(start_idx)))\n",
    "            return sequences\n",
    "\n",
    "        split_seed = int(pd.Timestamp(test_start).timestamp())\n",
    "        train_seq = generate_episode_sequences(df_train, EPISODE_LENGTH, TOTAL_TRAIN_EPISODES, EXCLUDED_TICKERS, seed=split_seed)\n",
    "        test_seq = generate_episode_sequences(df_test, EPISODE_LENGTH, TOTAL_TEST_EPISODES, EXCLUDED_TICKERS, seed=split_seed + 1)\n",
    "\n",
    "        # RL Agent Training (PPO) -- instantiate env with current features\n",
    "        train_env = RL_ENV_CLASS(df_train, feature_cols=feature_set, episode_length=EPISODE_LENGTH, seed=SEED)\n",
    "        train_env.set_episode_sequence(train_seq)\n",
    "        test_env = RL_ENV_CLASS(df_test, feature_cols=feature_set, episode_length=EPISODE_LENGTH, seed=SEED)\n",
    "        test_env.set_episode_sequence(test_seq)\n",
    "\n",
    "        # Train PPO agent\n",
    "        from stable_baselines3 import PPO\n",
    "        agent = PPO(\"MlpPolicy\", train_env, verbose=0, n_steps=EPISODE_LENGTH, seed=SEED)\n",
    "        agent.learn(total_timesteps=config['total_timesteps'])\n",
    "\n",
    "        # Evaluate PPO agent\n",
    "        def evaluate_env(env, agent, n_episodes, agent_type):\n",
    "            metrics = []\n",
    "            for _ in range(n_episodes):\n",
    "                obs, _ = env.reset()\n",
    "                done = False\n",
    "                while not done:\n",
    "                    action, _ = agent.predict(obs, deterministic=True)\n",
    "                    obs, reward, done, truncated, info = env.step(action)\n",
    "                info = info.copy()\n",
    "                info['agent'] = agent_type\n",
    "                metrics.append(info)\n",
    "            return metrics\n",
    "\n",
    "        rl_metrics = evaluate_env(test_env, agent, len(test_seq), \"RL\")\n",
    "\n",
    "        # Evaluate random agent\n",
    "        def evaluate_random(env, n_episodes):\n",
    "            metrics = []\n",
    "            for _ in range(n_episodes):\n",
    "                obs, _ = env.reset()\n",
    "                done = False\n",
    "                while not done:\n",
    "                    action = env.action_space.sample()\n",
    "                    obs, reward, done, truncated, info = env.step(action)\n",
    "                info = info.copy()\n",
    "                info['agent'] = \"Random\"\n",
    "                metrics.append(info)\n",
    "            return metrics\n",
    "\n",
    "        random_metrics = evaluate_random(test_env, len(test_seq))\n",
    "        # Store all results\n",
    "        for row in rl_metrics + random_metrics:\n",
    "            row.update({\"split\": f\"{test_start}--{test_end}\"})\n",
    "            all_rows.append(row)\n",
    "    return pd.DataFrame(all_rows)\n",
    "\n",
    "# ---- 4. Run ablation study ----\n",
    "results_table = []\n",
    "for ablation_name, feature_set in ablation_variants:\n",
    "    print(f\"\\n==== Ablation: {ablation_name} ====\")\n",
    "    ablation_df = evaluate_feature_set(\n",
    "        feature_set=feature_set,\n",
    "        config=CONFIG,\n",
    "        walk_forward_splits=walk_forward_splits,\n",
    "        RL_ENV_CLASS=CumulativeTradingEnv,  # Use the chosen reward/env for now\n",
    "        BaselineAgentClass=None,  # If needed for more baselines\n",
    "        ohlcv_df=ohlcv_df,\n",
    "        EXCLUDED_TICKERS=EXCLUDED_TICKERS,\n",
    "        EPISODE_LENGTH=EPISODE_LENGTH,\n",
    "        TOTAL_TRAIN_EPISODES=TOTAL_TRAIN_EPISODES,\n",
    "        TOTAL_TEST_EPISODES=TOTAL_TEST_EPISODES,\n",
    "        SEED=SEED,\n",
    "    )\n",
    "    ablation_df[\"ablation\"] = ablation_name\n",
    "    results_table.append(ablation_df)\n",
    "\n",
    "# ---- 5. Combine all results\n",
    "feature_ablation_df = pd.concat(results_table, ignore_index=True)\n",
    "\n",
    "# ---- 6. Analyze and visualize ----\n",
    "summary = []\n",
    "for ablation, group in feature_ablation_df.groupby(\"ablation\"):\n",
    "    rl_sharpes = group.loc[group['agent']=='RL', 'episode_sharpe'].dropna()\n",
    "    random_sharpes = group.loc[group['agent']=='Random', 'episode_sharpe'].dropna()\n",
    "    mean_rl = rl_sharpes.mean() if len(rl_sharpes) > 0 else np.nan\n",
    "    mean_random = random_sharpes.mean() if len(random_sharpes) > 0 else np.nan\n",
    "    t_p = np.nan\n",
    "    u_p = np.nan\n",
    "    if len(rl_sharpes) > 1 and len(random_sharpes) > 1:\n",
    "        t_stat, t_p = ttest_ind(rl_sharpes, random_sharpes, equal_var=False)\n",
    "        u_stat, u_p = mannwhitneyu(rl_sharpes, random_sharpes, alternative='greater')\n",
    "    summary.append({\n",
    "        \"ablation\": ablation,\n",
    "        \"mean_sharpe_rl\": mean_rl,\n",
    "        \"mean_sharpe_random\": mean_random,\n",
    "        \"t_pvalue\": t_p,\n",
    "        \"u_pvalue\": u_p,\n",
    "        \"RL>Random\": mean_rl > mean_random,\n",
    "    })\n",
    "summary_df = pd.DataFrame(summary)\n",
    "summary_df = summary_df.sort_values(by=\"mean_sharpe_rl\", ascending=False)\n",
    "\n",
    "# ---- 7. Visualization ----\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.barplot(x='mean_sharpe_rl', y='ablation', data=summary_df)\n",
    "plt.title(\"Feature Ablation: Mean RL Sharpe by Feature Set\")\n",
    "plt.xlabel(\"Mean Test Sharpe (RL Agent)\")\n",
    "plt.ylabel(\"Ablation (Feature Set)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n### Feature Ablation Summary Table:\")\n",
    "print(summary_df.to_markdown(index=False, floatfmt=\".3g\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef9c866",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
