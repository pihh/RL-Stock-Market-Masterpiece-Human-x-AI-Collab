{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cab993d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP: Imports & Paths ===========================\n",
    "import jupyter\n",
    "from src.utils.system import boot, Notify\n",
    "\n",
    "boot()\n",
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.data.feature_pipeline import basic_chart_features,load_base_dataframe\n",
    "from src.predictability.easiness import rolling_sharpe, rolling_r2, rolling_info_ratio, rolling_autocorr\n",
    "from src.predictability.pipeline import generate_universe_easiness_report\n",
    "from IPython import display\n",
    "\n",
    "from src.experiments.experiment_tracker import ExperimentTracker\n",
    "from src.config import TOP2_STOCK_BY_SECTOR\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy.stats import skew, kurtosis, entropy\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from statsmodels.tsa.stattools import acf, acovf\n",
    "from src.defaults import TOP2_STOCK_BY_SECTOR\n",
    "from src.agent.base_model import TransformerPpo\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import  RobustScaler\n",
    "from IPython.display import display\n",
    "\n",
    "# FRAMEWORK STUFF =========================\n",
    "\n",
    "from src.data.feature_pipeline import load_base_dataframe\n",
    "from src.experiments.experiment_tracker import ExperimentTracker\n",
    "from src.env.base_trading_env import CumulativeTradingEnv,AlphaTradingEnv\n",
    "from src.env.base_timeseries_trading_env import SequenceAwareAlphaTradingEnv,SequenceAwareCumulativeTradingEnv\n",
    "from src.agent.base_model import TransformerPpo\n",
    "from src.defaults import RANDOM_SEEDS\n",
    "from src.utils.db import ConfigurableMixin\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "955d6b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "EXPERIENCE_NAME = \"episode_learning_transferability_v2\"\n",
    "FEATURE_COLS= [\"return_1d\", \"volume\", \"vix\"]\n",
    "# Prepare your dataframes for two consecutive episodes:\n",
    "SEEDS = RANDOM_SEEDS\n",
    "EPISODE_LENGTH = 21\n",
    "WINDOW_LENGTH = EPISODE_LENGTH*2\n",
    "N_UPDATES = 10\n",
    "\n",
    "excluded_tickers=['CEG', 'GEHC', 'GEV', 'KVUE', 'SOLV']\n",
    "excluded_tickers.sort()\n",
    "\n",
    "config={\n",
    "    \"excluded_tickers\": excluded_tickers,\n",
    "    \"episode_length\":EPISODE_LENGTH,\n",
    "    \"window_length\":WINDOW_LENGTH,\n",
    "    \"n_updates\":N_UPDATES,\n",
    "    \"agent\":\"TransformerPpoAgent\",\n",
    "    \"environment\":\"SequenceAwareCumulativeTradingEnv\"\n",
    "}\n",
    "run_settings={\n",
    "    \"excluded_tickers\": excluded_tickers,\n",
    "    \"start_date\": '2024-01-01',\n",
    "    \"end_date\":\"2026-01-01\",\n",
    "    \"episode_length\":EPISODE_LENGTH,\n",
    "    \"window_length\":WINDOW_LENGTH,\n",
    "    \"n_updates\":N_UPDATES\n",
    "}\n",
    "\n",
    "# Config section\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bd2209",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1b684e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD OHLCV ==========================================\n",
    "\n",
    "\n",
    "ohlcv_df = load_base_dataframe()\n",
    "ohlcv_df['date'] = pd.to_datetime(ohlcv_df['date'])\n",
    "ohlcv_df = ohlcv_df[(ohlcv_df['date'] >= run_settings[\"start_date\"]) & (ohlcv_df['date'] < run_settings[\"end_date\"])]\n",
    "ohlcv_df['month'] = ohlcv_df['date'].dt.to_period('M')\n",
    "ohlcv_df['return_1d'] = ohlcv_df['return_1d'].fillna(0)\n",
    "ohlcv_df['sector_id'] = ohlcv_df['sector_id'].fillna('unknown')\n",
    "ohlcv_df['industry_id'] = ohlcv_df['industry_id'].fillna('unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6643b935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP ===================================\n",
    "import jupyter\n",
    "import warnings\n",
    "\n",
    "from src.utils.system import boot, Notify\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b83a636e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohlcv_df = load_base_dataframe()\n",
    "notification = Notify(EXPERIENCE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bf8ae0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# --- Imports & Setup ----------------------------------------------------\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import hashlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import ttest_ind, mannwhitneyu, skew, kurtosis, entropy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Your custom imports:\n",
    "from src.utils.system import boot, Notify\n",
    "from src.data.feature_pipeline import load_base_dataframe, basic_chart_features\n",
    "from src.predictability.easiness import rolling_sharpe, rolling_r2, rolling_info_ratio, rolling_autocorr\n",
    "from src.experiments.experiment_tracker import ExperimentTracker\n",
    "from src.env.base_trading_env import CumulativeTradingEnv, AlphaTradingEnv\n",
    "from src.env.base_timeseries_trading_env import SequenceAwareAlphaTradingEnv, SequenceAwareCumulativeTradingEnv\n",
    "from src.agent.base_model import TransformerPpo\n",
    "from src.defaults import RANDOM_SEEDS, TOP2_STOCK_BY_SECTOR\n",
    "from src.utils.db import ConfigurableMixin\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from sb3_contrib import RecurrentPPO\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from stable_baselines3.common.policies import ActorCriticPolicy\n",
    "from stable_baselines3.common.callbacks import EvalCallback, CheckpointCallback\n",
    "from sb3_contrib.common.recurrent.policies import RecurrentActorCriticPolicy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "boot()\n",
    "\n",
    "# --- Config -------------------------------------------------------------\n",
    "\n",
    "EXPERIENCE_NAME = \"episode_learning_transferability_v2\"\n",
    "RESULTS_CSV = EXPERIENCE_NAME + \".csv\"\n",
    "FEATURE_COLS = [\"return_1d\", \"volume\", \"vix\"]\n",
    "\n",
    "EPISODE_LENGTH = 21\n",
    "WINDOW_LENGTH = EPISODE_LENGTH * 2\n",
    "N_UPDATES = 10\n",
    "MAX_LAG = 3   # How many months ahead to test (multi-lag transfer)\n",
    "RANDOM_SEEDS = [7, 314, 42]\n",
    "excluded_tickers = ['CEG', 'GEHC', 'GEV', 'KVUE', 'SOLV']\n",
    "excluded_tickers.sort()\n",
    "tickers = [t for t in TOP2_STOCK_BY_SECTOR if t not in excluded_tickers]\n",
    "\n",
    "run_settings = {\n",
    "    \"excluded_tickers\": excluded_tickers,\n",
    "    \"start_date\": '2023-01-01',\n",
    "    \"end_date\": \"2026-01-01\",\n",
    "    \"episode_length\": EPISODE_LENGTH,\n",
    "    \"window_length\": WINDOW_LENGTH,\n",
    "    \"n_updates\": N_UPDATES,\n",
    "    \"max_lag\": MAX_LAG,\n",
    "    \"random_seeds\": RANDOM_SEEDS\n",
    "}\n",
    "\n",
    "notification = Notify(EXPERIENCE_NAME)\n",
    "\n",
    "# --- Utilities ----------------------------------------------------------\n",
    "\n",
    "def encode_hash(run_config: dict) -> str:\n",
    "    xx = json.dumps(run_config, sort_keys=True)\n",
    "    return hashlib.sha256(xx.encode()).hexdigest()\n",
    "\n",
    "def month_ranges(start_date_str):\n",
    "    start = pd.Timestamp(start_date_str).replace(day=1)\n",
    "    today = pd.Timestamp.today().replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "    next_month = (today + pd.offsets.MonthBegin(1)).replace(day=1)\n",
    "    final_month = (next_month + pd.offsets.MonthBegin(1)).replace(day=1)\n",
    "    ranges = []\n",
    "    d = start\n",
    "    while d < final_month:\n",
    "        next_d = (d + pd.offsets.MonthBegin(1)).replace(day=1)\n",
    "        ranges.append([d.strftime('%Y-%m-%d'), next_d.strftime('%Y-%m-%d')])\n",
    "        d = next_d\n",
    "    return ranges\n",
    "\n",
    "def compute_meta_features(episode_df, returns_col='return_1d'):\n",
    "    \"\"\"Compute meta-features for a window/episode.\"\"\"\n",
    "    r = episode_df[returns_col].values\n",
    "\n",
    "    features = {\n",
    "        'volatility': np.std(r),\n",
    "        'mean_return': np.mean(r),\n",
    "        'skew': skew(r),\n",
    "        'kurtosis': kurtosis(r),\n",
    "        'entropy': entropy(np.histogram(r, bins=10, density=True)[0] + 1e-8),\n",
    "        'sharpe':rolling_sharpe(episode_df['return_1d'], window=EPISODE_LENGTH),\n",
    "        'autocorr':rolling_autocorr(episode_df['return_1d'], window=EPISODE_LENGTH),\n",
    "        'info_ratio': rolling_info_ratio(\n",
    "    episode_df['return_1d'],\n",
    "    episode_df['market_return_1d'],  # replace with actual column\n",
    "    window=EPISODE_LENGTH\n",
    ").iloc[-1],\n",
    "        'rolling_r2':rolling_r2(episode_df['return_1d'], window=EPISODE_LENGTH),\n",
    "        #'sharpe': rolling_sharpe(episode_df[['return_1d']], window=EPISODE_LENGTH).iloc[-1],\n",
    "        #' rolling_autocorr(episode_df[['return_1d']], window=EPISODE_LENGTH).iloc[-1],\n",
    "        #' rolling_info_ratio(episode_df[['return_1d']], window=EPISODE_LENGTH).iloc[-1],\n",
    "        #' rolling_r2(episode_df['return_1d'], window=EPISODE_LENGTH).iloc[-1],\n",
    "        'drawdown': episode_df['close'].cummax() - episode_df['return_1d'],\n",
    "    }\n",
    "    # Optionally: add regime label if available\n",
    "    if \"regime\" in episode_df.columns:\n",
    "        features[\"regime\"] = episode_df[\"regime\"].iloc[-1]\n",
    "    else:\n",
    "        features[\"regime\"] = 0  # Or compute via your regime classifier\n",
    "    return features\n",
    "\n",
    "# --- Environment & Agent Factory ----------------------------------------\n",
    "\n",
    "def env_maker(seed, ohlcv_df, feature_cols, episode_length, window_length):\n",
    "    return SequenceAwareCumulativeTradingEnv(\n",
    "        ohlcv_df,\n",
    "        feature_cols=feature_cols,\n",
    "        episode_length=episode_length,\n",
    "        transaction_cost=0,\n",
    "        seed=seed,\n",
    "        window_length=window_length\n",
    "    )\n",
    "\n",
    "def agent_maker(environment, seed, policy_class, agent_class=TransformerPpo, **kwargs):\n",
    "    agent = agent_class(\n",
    "        RecurrentPPO,\n",
    "        TransformerPolicy,\n",
    "        environment,\n",
    "        model_config={\n",
    "            \"n_steps\": EPISODE_LENGTH,\n",
    "            \"batch_size\": EPISODE_LENGTH,\n",
    "        },\n",
    "        run_config={\"seed\": seed, \"verbose\": 0},\n",
    "        **kwargs\n",
    "    )\n",
    "    return agent\n",
    "\n",
    "# --- Transferability Test Function --------------------------------------\n",
    "\n",
    "def test_transferability(\n",
    "    env_maker, agent_maker, ohlcv_df,\n",
    "    episode_sequence_train, episode_sequence_test, feature_cols, episode_length,\n",
    "    episode_id_train, episode_id_test, n_updates=8, window_length=10,\n",
    "    random_seeds=[7, 314], policy_class=None, agent_class=None,\n",
    "    ablation_tag=None, verbose=True, meta_train=None, meta_test=None\n",
    "):\n",
    "    agent_rewards_B, random_rewards_B = [], []\n",
    "    total_timesteps = episode_length * n_updates\n",
    "    run_results = []\n",
    "\n",
    "    run_hash = encode_hash({\n",
    "        \"policy_class\": str(policy_class),\n",
    "        \"agent_class\": str(agent_class),\n",
    "        \"n_updates\": n_updates,\n",
    "        \"train_episode_id\": episode_id_train,\n",
    "        \"test_episode_id\": episode_id_test,\n",
    "        \"ablation\": ablation_tag\n",
    "    })\n",
    "\n",
    "    # --- CSV result caching -----------\n",
    "    if os.path.exists(RESULTS_CSV):\n",
    "        df = pd.read_csv(RESULTS_CSV)\n",
    "        if not df.empty and (df['hash'] == run_hash).any():\n",
    "            return [], [], 0, 0, {}\n",
    "    else:\n",
    "        df = pd.DataFrame()\n",
    "\n",
    "    for run, seed in enumerate(random_seeds):\n",
    "        np.random.seed(seed)\n",
    "        # Train on Episode A\n",
    "        envA = env_maker(seed, ohlcv_df, feature_cols, episode_length, window_length)\n",
    "        envA.set_episode_sequence(episode_sequence_train)\n",
    "        print(envA)\n",
    "        model = agent_maker(envA, seed, policy_class, agent_class)\n",
    "        agent = model.agent\n",
    "        agent.learn(total_timesteps=total_timesteps)\n",
    "\n",
    "        # Test trained agent on Episode B\n",
    "        envB = env_maker(seed, ohlcv_df, feature_cols, episode_length, window_length)\n",
    "        envB.set_episode_sequence(episode_sequence_test)\n",
    "        obs, _ = envB.reset()\n",
    "        rewards = []\n",
    "        done = False\n",
    "        while not done:\n",
    "            action, _ = agent.predict(obs)\n",
    "            obs, reward, done, truncated, info = envB.step(action)\n",
    "            rewards.append(reward)\n",
    "        agent_rewards_B.append(np.sum(rewards))\n",
    "\n",
    "        # Random policy on Episode B\n",
    "        envB_rand = env_maker(seed, ohlcv_df, feature_cols, episode_length, window_length)\n",
    "        envB_rand.set_episode_sequence(episode_sequence_test)\n",
    "        obs, _ = envB_rand.reset()\n",
    "        rand_rewards = []\n",
    "        done = False\n",
    "        while not done:\n",
    "            action = envB_rand.action_space.sample()\n",
    "            obs, reward, done, truncated, info = envB_rand.step(action)\n",
    "            rand_rewards.append(reward)\n",
    "        random_rewards_B.append(np.sum(rand_rewards))\n",
    "\n",
    "    # --- Statistical testing on Episode B\n",
    "    agent_rewards_B = np.array(agent_rewards_B)\n",
    "    random_rewards_B = np.array(random_rewards_B)\n",
    "\n",
    "    t_stat, t_pval = ttest_ind(agent_rewards_B, random_rewards_B, equal_var=False)\n",
    "    mw_stat, mw_pval = mannwhitneyu(agent_rewards_B, random_rewards_B, alternative='greater')\n",
    "\n",
    "    # --- Save meta-features, report, and results\n",
    "    study_result = {\n",
    "        \"experience_name\": EXPERIENCE_NAME,\n",
    "        \"policy_class\": str(policy_class),\n",
    "        \"agent_class\": str(agent_class),\n",
    "        \"ablation\": ablation_tag,\n",
    "        \"train_meta\": json.dumps(meta_train),\n",
    "        \"test_meta\": json.dumps(meta_test),\n",
    "        \"train_episode_id\": episode_id_train,\n",
    "        \"test_episode_id\": episode_id_test,\n",
    "        \"hash\": run_hash,\n",
    "        \"agent_rewards_mean\": np.median(agent_rewards_B),\n",
    "        \"agent_rewards_std\": agent_rewards_B.std(),\n",
    "        \"random_rewards_mean\": np.median(random_rewards_B),\n",
    "        \"random_rewards_std\": random_rewards_B.std(),\n",
    "        \"t_pval\": float(t_pval),\n",
    "        \"mw_pval\": float(mw_pval),\n",
    "        \"advantage\": np.median(agent_rewards_B) - np.median(random_rewards_B),\n",
    "        \"agent_rewards\": json.dumps(agent_rewards_B.tolist()),\n",
    "        \"random_rewards\": json.dumps(random_rewards_B.tolist()),\n",
    "        \"train_date\": meta_train.get(\"date\") if meta_train else \"\",\n",
    "        \"test_date\": meta_test.get(\"date\") if meta_test else \"\",\n",
    "    }\n",
    "    df = pd.concat([df, pd.DataFrame([study_result])], ignore_index=True)\n",
    "    print(RESULTS_CSV)\n",
    "    df.to_csv(RESULTS_CSV, index=False)\n",
    "\n",
    "    # Optionally: Save a per-run markdown/HTML report here for later\n",
    "    with open(f\"report_{run_hash}.md\", \"w\") as f:\n",
    "        f.write(f\"# Transferability Run: {run_hash}\\n\")\n",
    "        f.write(f\"## Train Meta\\n{json.dumps(meta_train, indent=2)}\\n\")\n",
    "        f.write(f\"## Test Meta\\n{json.dumps(meta_test, indent=2)}\\n\")\n",
    "        f.write(f\"### Results\\n\")\n",
    "        f.write(json.dumps(study_result, indent=2))\n",
    "\n",
    "    return agent_rewards_B, random_rewards_B, t_pval, mw_pval, study_result\n",
    "\n",
    "# --- Multi-Lag Transfer, Meta-Features, NxN Matrix ----------------------\n",
    "def safe_get_episode(env, ticker, start):\n",
    "    try:\n",
    "        return env.get_episode_by_start_date(ticker, start)\n",
    "    except Exception as e:\n",
    "        print(f\"[SKIP] get_episode_by_start_date failed for {ticker} {start}: {e}\")\n",
    "        return None, None, None\n",
    "    \n",
    "def main():\n",
    "    ohlcv_df = load_base_dataframe()\n",
    "    ohlcv_df['date'] = pd.to_datetime(ohlcv_df['date'])\n",
    "    ohlcv_df = ohlcv_df[\n",
    "        (ohlcv_df['date'] >= run_settings[\"start_date\"]) &\n",
    "        (ohlcv_df['date'] < run_settings[\"end_date\"])\n",
    "    ]\n",
    "    ohlcv_df['month'] = ohlcv_df['date'].dt.to_period('M')\n",
    "    ohlcv_df['return_1d'] = ohlcv_df['return_1d'].fillna(0)\n",
    "    ohlcv_df['sector_id'] = ohlcv_df['sector_id'].fillna('unknown')\n",
    "    ohlcv_df['industry_id'] = ohlcv_df['industry_id'].fillna('unknown')\n",
    "\n",
    "    month_pairs = month_ranges(run_settings['start_date'])[:-3]\n",
    "    ablation_settings = [\n",
    "        {\"policy_class\": \"TransformerPolicy\", \"agent_class\": TransformerPpo, \"ablation_tag\": \"full\"},\n",
    "        # Add ablation variants here, e.g., no regime, different policies, etc.\n",
    "        # {\"policy_class\": \"SimpleMLPPolicy\", \"agent_class\": MlpPpo, \"ablation_tag\": \"mlp\"},\n",
    "    ]\n",
    "\n",
    "    # For each ticker, perform NxN transfer, meta-feature logging, and multi-lag evaluation\n",
    "    for ticker in tqdm(tickers):\n",
    "        run_start_time = time.time()\n",
    "        notification.info(f\"Train start for {ticker} | {datetime.now().strftime('%Y-%m-%d %H:%M')}\")\n",
    "        # --- Precompute episodes for all months for this ticker\n",
    "        episodes = []\n",
    "        train_env = SequenceAwareCumulativeTradingEnv(\n",
    "            ohlcv_df,\n",
    "            feature_cols=FEATURE_COLS,\n",
    "            episode_length=EPISODE_LENGTH,\n",
    "            transaction_cost=0,\n",
    "            seed=RANDOM_SEEDS[0],\n",
    "            window_length=WINDOW_LENGTH\n",
    "        )\n",
    "        skipped = 0\n",
    "        for p in month_pairs:\n",
    "            try:\n",
    "                _, start_train, id_train = train_env.get_episode_by_start_date(ticker, p[0])\n",
    "                episodes.append({\"ticker\": ticker, \"start\": start_train, \"id\": id_train, \"date\": p[0]})\n",
    "            except ValueError as e:\n",
    "                # Optionally print or log this skip for traceability\n",
    "                print(f\"[SKIP] {ticker} {p[0]}: {e}\")\n",
    "                skipped += 1\n",
    "                print(f\"{ticker}: Skipped {skipped}/{len(month_pairs)} episodes due to insufficient lookback.\")\n",
    "\n",
    "                continue\n",
    "        # --- NxN transfer matrix loop\n",
    "        for ablation in ablation_settings:\n",
    "            valid_train_episodes = 0\n",
    "            valid_test_episodes = 0\n",
    "            for i, train_ep in enumerate(episodes):\n",
    "                try:\n",
    "                    print(train_ep)\n",
    "                    train_env.set_episode_sequence([[ticker, train_ep[\"start\"]]])\n",
    "               \n",
    "                    train_env.reset()\n",
    "                    train_df = train_env.episode_df.copy()\n",
    "                    #train_df, _, _ = train_env.get_episode_by_start_date(ticker, train_ep[\"start\"])\n",
    "                    #valid_train_episodes += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"[SKIP] Train episode failed for {ticker} {train_ep['start']}: {e}\")\n",
    "                    continue\n",
    "                for lag in range(1, MAX_LAG+1):\n",
    "                    test_idx = i + lag\n",
    "                    if test_idx >= len(episodes):\n",
    "                        continue\n",
    "                    test_ep = episodes[test_idx]\n",
    "                    print(episodes[test_idx])\n",
    "                    try:\n",
    "                        #test_df, _, _ = train_env.get_episode_by_start_date(ticker, test_ep[\"start\"])\n",
    "                        train_env.set_episode_sequence([[ticker, test_ep[\"start\"]]])\n",
    "                        valid_test_episodes += 1\n",
    "                        train_env.reset()\n",
    "                        test_df = train_env.episode_df.copy()\n",
    "                    except Exception as e:\n",
    "                        print(f\"[SKIP] Test episode failed for {ticker} {test_ep['start']}: {e}\")\n",
    "                        continue\n",
    "                    # ... rest of logic ...\n",
    "                    \n",
    "                    print('will test')\n",
    "                    meta_test = compute_meta_features(test_df)\n",
    "                    meta_train = compute_meta_features(test_df)\n",
    "                    meta_test[\"date\"] = test_ep[\"date\"]\n",
    "                    meta_train[\"date\"] = train_ep[\"date\"]\n",
    "                    #meta_test[\"date\"] = test_ep[\"date\"]\n",
    "\n",
    "                    train_sequence = [[ticker, train_ep[\"start\"]]]\n",
    "                    test_sequence = [[ticker, test_ep[\"start\"]]]\n",
    "                    agent_rewards, random_rewards, t_pval, mw_pval, results = test_transferability(\n",
    "                        env_maker,\n",
    "                        agent_maker,\n",
    "                        ohlcv_df,\n",
    "                        train_sequence,\n",
    "                        test_sequence,\n",
    "                        feature_cols=FEATURE_COLS,\n",
    "                        episode_length=EPISODE_LENGTH,\n",
    "                        random_seeds=RANDOM_SEEDS,\n",
    "                        n_updates=N_UPDATES,\n",
    "                        window_length=WINDOW_LENGTH,\n",
    "                        episode_id_train=train_ep[\"id\"],\n",
    "                        episode_id_test=test_ep[\"id\"],\n",
    "                        policy_class=ablation[\"policy_class\"],\n",
    "                        agent_class=ablation[\"agent_class\"],\n",
    "                        ablation_tag=ablation[\"ablation_tag\"],\n",
    "                        meta_train=meta_train,\n",
    "                        meta_test=meta_test\n",
    "                    )\n",
    "                print(f\"{ticker}: Valid train episodes: {valid_train_episodes}, Valid test episodes: {valid_test_episodes}\")\n",
    "        elapsed = time.time() - run_start_time\n",
    "        notification.info(f\"Train complete for {ticker} | {datetime.now().strftime('%Y-%m-%d %H:%M')} | Exec time: {elapsed:.1f}s\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "# --- Visualization Example: Transfer Matrix -----------------------------\n",
    "def plot_transfer_matrix(results_csv=RESULTS_CSV, ticker=None):\n",
    "    df = pd.read_csv(results_csv)\n",
    "    if ticker is not None:\n",
    "        df = df[df[\"ticker\"] == ticker]\n",
    "    # Pivot: rows=train_date, cols=test_date, values=advantage or t_pval\n",
    "    matrix = df.pivot_table(index=\"train_date\", columns=\"test_date\", values=\"advantage\")\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
    "    plt.title(f\"Transferability Matrix ({ticker})\")\n",
    "    plt.ylabel(\"Train Month\")\n",
    "    plt.xlabel(\"Test Month\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccbbcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_transfer_matrix(\"episode_learning_transferability_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc1a4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "e= env_maker(1,ohlcv_df,FEATURE_COLS,EPISODE_LENGTH,WINDOW_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a1985a",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.set_episode_sequence([['AAPL',100]])\n",
    "e.reset()\n",
    "e.episode_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3d2b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.set_episode_sequence([['AAPL',200]])\n",
    "e.reset()\n",
    "e.episode_df\n",
    "rolling_sharpe(e.episode_df['return_1d'], window=EPISODE_LENGTH).dropna().iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59501291",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.episode_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40683969",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21664fea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
