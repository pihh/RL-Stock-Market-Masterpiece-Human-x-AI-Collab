{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e062bcb7",
   "metadata": {},
   "source": [
    "# Rolling Method Sanity Check: Study Description & Results\n",
    "\n",
    "## **Study Overview**\n",
    "\n",
    "The goal of this experiment was to **benchmark different rolling aggregation strategies** for time series features in a tabular modeling task (e.g., sales or trading prediction). Four rolling methods were evaluated for their effect on model performance across training, validation, and test splits.\n",
    "\n",
    "**Methods Compared:**\n",
    "\n",
    "* Rolling Mean (`rolling_mean`)\n",
    "* Rolling Median (`rolling_median`)\n",
    "* Rolling Weighted Mean (`rolling_weighted_mean`)\n",
    "* Rolling Winsorized Mean (`rolling_winsorized_mean`)\n",
    "\n",
    "**Metric:**\n",
    "Model performance was assessed using an error metric (likely RMSLE or similar) on three dataset splits: train, validation, and test.\n",
    "\n",
    "---\n",
    "\n",
    "## **Experiment Steps**\n",
    "\n",
    "1. **Data Preparation:**\n",
    "\n",
    "   * Data was split into three periods: train, validation, and test.\n",
    "2. **Rolling Feature Engineering:**\n",
    "\n",
    "   * Each rolling method was applied to generate features.\n",
    "3. **Model Training:**\n",
    "\n",
    "   * A consistent model pipeline was trained for each feature variant.\n",
    "4. **Performance Logging:**\n",
    "\n",
    "   * Errors were logged for each split and rolling method.\n",
    "5. **Analysis:**\n",
    "\n",
    "   * Differences and stability across splits were analyzed, with visualizations (e.g., heatmaps).\n",
    "\n",
    "---\n",
    "\n",
    "## **Results Table**\n",
    "\n",
    "| Rolling Method          | Train Error | Val Error  | Test Error |\n",
    "| ----------------------- | ----------- | ---------- | ---------- |\n",
    "| Rolling Mean            | 0.3917      | 0.3967     | 0.3825     |\n",
    "| Rolling Median          | 0.3974      | 0.4046     | 0.3850     |\n",
    "| Rolling Weighted Mean   | **0.3876**  | **0.3892** | 0.3896     |\n",
    "| Rolling Winsorized Mean | 0.3920      | 0.3960     | **0.3797** |\n",
    "\n",
    "**Stability Across Splits (Mean Absolute Drift):**\n",
    "\n",
    "| Method                  | Mean Drift | Train-Test Abs Diff |\n",
    "| ----------------------- | ---------- | ------------------- |\n",
    "| Rolling Mean            | 0.0071     | 0.0093              |\n",
    "| Rolling Median          | 0.0098     | 0.0124              |\n",
    "| Rolling Weighted Mean   | **0.0018** | **0.0020**          |\n",
    "| Rolling Winsorized Mean | 0.0082     | 0.0122              |\n",
    "\n",
    "---\n",
    "\n",
    "## **Key Findings & Interpretation**\n",
    "\n",
    "* **Best Test Error:**\n",
    "\n",
    "  * The **Winsorized Mean** achieved the lowest error on the test split, but not by a large margin.\n",
    "* **Best Stability/Generalization:**\n",
    "\n",
    "  * The **Weighted Mean** was by far the most stable, with nearly identical performance across all splits. Its train–test drift was substantially lower than all other methods.\n",
    "* **Rolling Mean** and **Median** performed worse than either advanced method, with both higher error and more drift.\n",
    "\n",
    "**Summary Table:**\n",
    "\n",
    "| Method                  | Best For                  | Drawbacks                  |\n",
    "| ----------------------- | ------------------------- | -------------------------- |\n",
    "| Rolling Weighted Mean   | Stability, generalization | Slightly higher test error |\n",
    "| Rolling Winsorized Mean | Test error                | Higher drift               |\n",
    "| Rolling Mean            | Simplicity                | Not best on any metric     |\n",
    "| Rolling Median          | Outlier resistance        | Most unstable              |\n",
    "\n",
    "---\n",
    "\n",
    "## **Conclusion**\n",
    "\n",
    "* **Rolling Weighted Mean** is recommended for **robustness and stability**—it generalizes well and minimizes overfitting.\n",
    "* **Winsorized Mean** may provide the best absolute test result, but at the cost of less stability.\n",
    "* **Classic mean/median** approaches are outperformed by the above for both stability and test performance.\n",
    "\n",
    "---\n",
    "\n",
    "## **Next Steps & Suggestions**\n",
    "\n",
    "* **If the priority is reliability and robustness in production or real-world deployment, stick with Rolling Weighted Mean.**\n",
    "* For maximum accuracy on the specific test split (e.g., competitions), consider Winsorized Mean, but monitor for overfitting or distribution shifts.\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f72cda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store Sales Forecasting - Real Dataset with RMSLE Optimization\n",
    "import jupyter\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "from scipy.stats import mstats\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from src.utils.system import boot,notify\n",
    "from src.experiments.experiment_tracker import ExperimentTracker\n",
    "\n",
    "boot()\n",
    "\n",
    "experience_name = \"sanity-check__evaluate_efficiency_of_averaging_policies\"\n",
    "target_date = \"2025-06-01\"\n",
    "experiment_tracker = ExperimentTracker(experience_name)\n",
    "config={\n",
    "    \"dataset\":\"kaggle-sales-prediction\",\n",
    "    \"model\": \"xgb.XGBRegressor\",\n",
    "    \"rolling_window\":\"14,21\"\n",
    "}\n",
    "\n",
    "features = [\n",
    "        'store_nbr', 'family', 'dayofweek', 'month', 'day', 'week', 'is_holiday',\n",
    "        'transactions', 'lag_21', 'lag_14', 'trans_lag_21', 'trans_lag_14',\n",
    "        'rolling_mean_21', 'rolling_std_21', 'rolling_mean_14', 'rolling_std_14',\n",
    "        'trans_roll_mean_21', 'trans_roll_mean_14',\n",
    "        'onpromo_lag_21', 'onpromo_mean_14'\n",
    "]\n",
    "\n",
    "run_settings={\n",
    "    \"n_estimators\":750, \n",
    "    \"learning_rate\":0.05, \n",
    "    \"max_depth\":6, \n",
    "    \"random_state\":42,\n",
    "    \"regime\": \"rolling_mean\",\n",
    "    \"features\": features.copy()\n",
    "}\n",
    "run_settings[\"features\"].sort()\n",
    "\n",
    "\n",
    "#def save_run(\n",
    "#        self,\n",
    "#        config: Dict,\n",
    "#        results: Dict,\n",
    "#        target_date: str,\n",
    "#        run_settings: Dict,\n",
    "#        files: Optional[Dict] = None\n",
    "#    ) -> None:\n",
    "#        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "712a6ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ExecutionTimeTracker]::preprocess_dataset - Start.\n",
      "[ExecutionTimeTracker]::preprocess_dataset - Complete. Took 4s to complete.\n",
      "\n",
      "rolling_mean\n",
      "Preprocessing features\n",
      "[ExecutionTimeTracker]::preprocess_feature_dataset - Start.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francisco Sá\\AppData\\Local\\Temp\\ipykernel_26160\\2488502499.py:182: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[features].dropna(inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ExecutionTimeTracker]::preprocess_feature_dataset - Complete. Took 497s to complete.\n",
      "\n",
      "[ExecutionTimeTracker]::xgb_train__1000 - Start.\n",
      "[0]\tvalidation_0-rmse:2.94943\n",
      "[25]\tvalidation_0-rmse:0.99390\n",
      "[50]\tvalidation_0-rmse:0.59147\n",
      "[75]\tvalidation_0-rmse:0.52518\n",
      "[100]\tvalidation_0-rmse:0.50579\n",
      "[125]\tvalidation_0-rmse:0.49457\n",
      "[150]\tvalidation_0-rmse:0.48777\n",
      "[175]\tvalidation_0-rmse:0.47980\n",
      "[200]\tvalidation_0-rmse:0.47349\n",
      "[225]\tvalidation_0-rmse:0.46901\n",
      "[250]\tvalidation_0-rmse:0.46471\n",
      "[275]\tvalidation_0-rmse:0.46127\n",
      "[300]\tvalidation_0-rmse:0.45901\n",
      "[325]\tvalidation_0-rmse:0.45508\n",
      "[350]\tvalidation_0-rmse:0.45333\n",
      "[375]\tvalidation_0-rmse:0.45111\n",
      "[400]\tvalidation_0-rmse:0.44939\n",
      "[425]\tvalidation_0-rmse:0.44715\n",
      "[450]\tvalidation_0-rmse:0.44751\n",
      "[475]\tvalidation_0-rmse:0.44641\n",
      "[500]\tvalidation_0-rmse:0.44529\n",
      "[525]\tvalidation_0-rmse:0.44398\n",
      "[550]\tvalidation_0-rmse:0.44388\n",
      "[575]\tvalidation_0-rmse:0.44309\n",
      "[600]\tvalidation_0-rmse:0.44247\n",
      "[625]\tvalidation_0-rmse:0.44184\n",
      "[650]\tvalidation_0-rmse:0.44101\n",
      "[675]\tvalidation_0-rmse:0.43911\n",
      "[700]\tvalidation_0-rmse:0.43782\n",
      "[725]\tvalidation_0-rmse:0.43680\n",
      "[749]\tvalidation_0-rmse:0.43687\n",
      "[ExecutionTimeTracker]::xgb_train__1000 - Complete. Took 148s to complete.\n",
      "\n",
      "RMSLE:0.4027, 0.4369,0.3954\n",
      "rolling_median\n",
      "Preprocessing features\n",
      "[ExecutionTimeTracker]::preprocess_feature_dataset - Start.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francisco Sá\\AppData\\Local\\Temp\\ipykernel_26160\\2488502499.py:182: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[features].dropna(inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ExecutionTimeTracker]::preprocess_feature_dataset - Complete. Took 668s to complete.\n",
      "\n",
      "[ExecutionTimeTracker]::xgb_train__1000 - Start.\n",
      "[0]\tvalidation_0-rmse:2.94932\n",
      "[25]\tvalidation_0-rmse:0.98895\n",
      "[50]\tvalidation_0-rmse:0.57529\n",
      "[75]\tvalidation_0-rmse:0.51446\n",
      "[100]\tvalidation_0-rmse:0.49689\n",
      "[125]\tvalidation_0-rmse:0.48738\n",
      "[150]\tvalidation_0-rmse:0.48059\n",
      "[175]\tvalidation_0-rmse:0.47263\n",
      "[200]\tvalidation_0-rmse:0.46674\n",
      "[225]\tvalidation_0-rmse:0.46388\n",
      "[250]\tvalidation_0-rmse:0.46181\n",
      "[275]\tvalidation_0-rmse:0.45928\n",
      "[300]\tvalidation_0-rmse:0.45912\n",
      "[325]\tvalidation_0-rmse:0.45861\n",
      "[350]\tvalidation_0-rmse:0.46001\n",
      "[375]\tvalidation_0-rmse:0.46025\n",
      "[400]\tvalidation_0-rmse:0.46079\n",
      "[425]\tvalidation_0-rmse:0.46219\n",
      "[450]\tvalidation_0-rmse:0.46172\n",
      "[475]\tvalidation_0-rmse:0.46082\n",
      "[500]\tvalidation_0-rmse:0.46125\n",
      "[525]\tvalidation_0-rmse:0.46131\n",
      "[550]\tvalidation_0-rmse:0.46011\n",
      "[575]\tvalidation_0-rmse:0.45984\n",
      "[600]\tvalidation_0-rmse:0.45851\n",
      "[625]\tvalidation_0-rmse:0.45734\n",
      "[650]\tvalidation_0-rmse:0.45800\n",
      "[675]\tvalidation_0-rmse:0.45782\n",
      "[700]\tvalidation_0-rmse:0.45927\n",
      "[725]\tvalidation_0-rmse:0.45938\n",
      "[749]\tvalidation_0-rmse:0.45932\n",
      "[ExecutionTimeTracker]::xgb_train__1000 - Complete. Took 168s to complete.\n",
      "\n",
      "RMSLE:0.4131, 0.4593,0.4057\n",
      "rolling_weighted_mean\n",
      "Preprocessing features\n",
      "[ExecutionTimeTracker]::preprocess_feature_dataset - Start.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francisco Sá\\AppData\\Local\\Temp\\ipykernel_26160\\2488502499.py:182: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[features].dropna(inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ExecutionTimeTracker]::preprocess_feature_dataset - Complete. Took 577s to complete.\n",
      "\n",
      "[ExecutionTimeTracker]::xgb_train__1000 - Start.\n",
      "[0]\tvalidation_0-rmse:2.94789\n",
      "[25]\tvalidation_0-rmse:0.97262\n",
      "[50]\tvalidation_0-rmse:0.55940\n",
      "[75]\tvalidation_0-rmse:0.49652\n",
      "[100]\tvalidation_0-rmse:0.47886\n",
      "[125]\tvalidation_0-rmse:0.47072\n",
      "[150]\tvalidation_0-rmse:0.46422\n",
      "[175]\tvalidation_0-rmse:0.45856\n",
      "[200]\tvalidation_0-rmse:0.45385\n",
      "[225]\tvalidation_0-rmse:0.44905\n",
      "[250]\tvalidation_0-rmse:0.44713\n",
      "[275]\tvalidation_0-rmse:0.44399\n",
      "[300]\tvalidation_0-rmse:0.44044\n",
      "[325]\tvalidation_0-rmse:0.43894\n",
      "[350]\tvalidation_0-rmse:0.43589\n",
      "[375]\tvalidation_0-rmse:0.43358\n",
      "[400]\tvalidation_0-rmse:0.43175\n",
      "[425]\tvalidation_0-rmse:0.42901\n",
      "[450]\tvalidation_0-rmse:0.42701\n",
      "[475]\tvalidation_0-rmse:0.42513\n",
      "[500]\tvalidation_0-rmse:0.42296\n",
      "[525]\tvalidation_0-rmse:0.42194\n",
      "[550]\tvalidation_0-rmse:0.42050\n",
      "[575]\tvalidation_0-rmse:0.41958\n",
      "[600]\tvalidation_0-rmse:0.41878\n",
      "[625]\tvalidation_0-rmse:0.41770\n",
      "[650]\tvalidation_0-rmse:0.41635\n",
      "[675]\tvalidation_0-rmse:0.41600\n",
      "[700]\tvalidation_0-rmse:0.41515\n",
      "[725]\tvalidation_0-rmse:0.41458\n",
      "[749]\tvalidation_0-rmse:0.41495\n",
      "[ExecutionTimeTracker]::xgb_train__1000 - Complete. Took 152s to complete.\n",
      "\n",
      "RMSLE:0.3984, 0.4149,0.3862\n",
      "rolling_winsorized_mean\n",
      "Preprocessing features\n",
      "[ExecutionTimeTracker]::preprocess_feature_dataset - Start.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francisco Sá\\AppData\\Local\\Temp\\ipykernel_26160\\2488502499.py:182: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[features].dropna(inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ExecutionTimeTracker]::preprocess_feature_dataset - Complete. Took 2884s to complete.\n",
      "\n",
      "[ExecutionTimeTracker]::xgb_train__1000 - Start.\n",
      "[0]\tvalidation_0-rmse:2.94917\n",
      "[25]\tvalidation_0-rmse:0.99416\n",
      "[50]\tvalidation_0-rmse:0.59289\n",
      "[75]\tvalidation_0-rmse:0.52797\n",
      "[100]\tvalidation_0-rmse:0.50964\n",
      "[125]\tvalidation_0-rmse:0.49935\n",
      "[150]\tvalidation_0-rmse:0.49065\n",
      "[175]\tvalidation_0-rmse:0.48325\n",
      "[200]\tvalidation_0-rmse:0.47600\n",
      "[225]\tvalidation_0-rmse:0.46826\n",
      "[250]\tvalidation_0-rmse:0.46503\n",
      "[275]\tvalidation_0-rmse:0.46197\n",
      "[300]\tvalidation_0-rmse:0.45996\n",
      "[325]\tvalidation_0-rmse:0.45695\n",
      "[350]\tvalidation_0-rmse:0.45441\n",
      "[375]\tvalidation_0-rmse:0.45319\n",
      "[400]\tvalidation_0-rmse:0.45149\n",
      "[425]\tvalidation_0-rmse:0.45026\n",
      "[450]\tvalidation_0-rmse:0.44812\n",
      "[475]\tvalidation_0-rmse:0.44543\n",
      "[500]\tvalidation_0-rmse:0.44377\n",
      "[525]\tvalidation_0-rmse:0.44163\n",
      "[550]\tvalidation_0-rmse:0.43944\n",
      "[575]\tvalidation_0-rmse:0.43724\n",
      "[600]\tvalidation_0-rmse:0.43601\n",
      "[625]\tvalidation_0-rmse:0.43470\n",
      "[650]\tvalidation_0-rmse:0.43505\n",
      "[675]\tvalidation_0-rmse:0.43556\n",
      "[700]\tvalidation_0-rmse:0.43611\n",
      "[725]\tvalidation_0-rmse:0.43561\n",
      "[749]\tvalidation_0-rmse:0.43516\n",
      "[ExecutionTimeTracker]::xgb_train__1000 - Complete. Took 210s to complete.\n",
      "\n",
      "RMSLE:0.4056, 0.4352,0.3991\n"
     ]
    }
   ],
   "source": [
    "# Store Sales Forecasting - Real Dataset with RMSLE Optimization\n",
    "import jupyter\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from scipy.stats import mstats\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from src.utils.system import boot,notify\n",
    "\n",
    "\n",
    "boot()\n",
    "\n",
    "\n",
    "class ExecutionTimeTracker:\n",
    "    def __init__(self,name):\n",
    "        self.name = name\n",
    "        self.start = time.time()\n",
    "        self.end = None\n",
    "        self.signature = f\"[ExecutionTimeTracker]::{self.name} -\"\n",
    "        print(f\"{self.signature} Start.\")\n",
    "\n",
    "    def done(self):\n",
    "        if self.end == None:\n",
    "            self.end =time.time()\n",
    "            self.duration = self.end -self.start\n",
    "            \n",
    "        print(f\"{self.signature} Complete. Took {int(self.end-self.start)}s to complete.\")\n",
    "        print('')\n",
    "        \n",
    "# REGIME FUNCTIONS =================================================\n",
    "def rolling_mean(x):\n",
    "    if len(x) == 0 or np.all(np.isnan(x)):\n",
    "        return np.nan\n",
    "    return np.nanmean(x)\n",
    "\n",
    "def rolling_median(x):\n",
    "    if len(x) == 0 or np.all(np.isnan(x)):\n",
    "        return np.nan\n",
    "    return np.nanmedian(x)\n",
    "\n",
    "def rolling_weighted_mean(x): \n",
    "    if len(x) == 0 or np.all(np.isnan(x)):\n",
    "        return np.nan\n",
    "    weights = np.arange(1, len(x)+1)\n",
    "    valid = ~np.isnan(x)\n",
    "    if np.sum(valid) == 0:\n",
    "        return np.nan\n",
    "    return np.average(x[valid], weights=weights[valid])\n",
    "\n",
    "def rolling_winsorized_mean(x):\n",
    "    if len(x) < 2 or np.all(np.isnan(x)):\n",
    "        return np.nan\n",
    "    x_clean = x[~np.isnan(x)]\n",
    "    if len(x_clean) < 2:\n",
    "        return np.nan\n",
    "    return mstats.winsorize(x_clean, limits=(0.1, 0.1)).mean()\n",
    "\n",
    "# REGIME FUNCTIONS REGISTRY =======================================\n",
    "regimes = {\n",
    "    'rolling_mean': rolling_mean,\n",
    "    'rolling_median': rolling_median,\n",
    "    'rolling_weighted_mean': rolling_weighted_mean,\n",
    "    'rolling_winsorized_mean': rolling_winsorized_mean,\n",
    "}\n",
    "\n",
    "# Feature engineering pipeline with regime-based rolling =========\n",
    "def add_lag_rolling(df, train_func, train_name, lag_days=[14, 21], rolling_windows=[14, 21],mode=\"train\"):\n",
    "    FOLDER = 'data/experiments/kaggle-sales-prediction/'\n",
    "    file_path = os.path.join(FOLDER, train_name+'__21_'+mode+'.csv')\n",
    "    exists = os.path.exists(file_path)\n",
    "    \n",
    "    if exists:\n",
    "        cached_df = pd.read_csv(file_path, parse_dates=['date'])\n",
    "        if not cached_df.empty:\n",
    "            print(f\"Loaded cached features from {file_path}\")\n",
    "            return cached_df\n",
    "    \n",
    "    df = df.sort_values(['store_nbr', 'family', 'date'])\n",
    "\n",
    "    for lag in [14, 21]:\n",
    "        df[f'lag_{lag}'] = df.groupby(['store_nbr', 'family'])['sales'].shift(lag)\n",
    "        df[f'trans_lag_{lag}'] = df.groupby(['store_nbr'])['transactions'].shift(lag)\n",
    "\n",
    "    for window in [14, 21]:\n",
    "        df[f'rolling_mean_{window}'] = df.groupby(['store_nbr', 'family'])['sales'].transform(lambda x: x.shift(1).rolling(window, min_periods=1).apply(train_func, raw=True))#.shift(1)#.rolling(window, min_periods=1).mean()\n",
    "        df[f'rolling_std_{window}'] = df.groupby(['store_nbr', 'family'])['sales'].shift(1).rolling(window, min_periods=1).std()\n",
    "        df[f'trans_roll_mean_{window}'] = df.groupby(['store_nbr'])['transactions'].transform(lambda x: x.shift(1).rolling(window, min_periods=1).apply(train_func, raw=True))#.shift(1)#.rolling(window, min_periods=1).mean()\n",
    "\n",
    "    df['onpromo_lag_21'] = df.groupby(['store_nbr', 'family'])['onpromotion'].shift(7)\n",
    "    df['onpromo_mean_14'] = df.groupby(['store_nbr', 'family'])['onpromotion'].transform(lambda x: x.shift(1).rolling(14, min_periods=1).apply(train_func, raw=True))#.shift(1)#.rolling(14, min_periods=1).mean()\n",
    "\n",
    "    df.to_csv(file_path, index=False)\n",
    "    return df\n",
    "\n",
    "# GENERATE BASE TRAIN/TEST DATASET ======================================\n",
    "\n",
    "\n",
    "def preprocess_dataset():\n",
    "    FOLDER = 'data/experiments/kaggle-sales-prediction/'\n",
    "    _train = pd.read_csv(FOLDER+'train.csv', parse_dates=['date'])\n",
    "    _test = pd.read_csv(FOLDER+'test.csv', parse_dates=['date'])\n",
    "    _stores = pd.read_csv(FOLDER+'stores.csv')\n",
    "    _holidays = pd.read_csv(FOLDER+'holidays_events.csv', parse_dates=['date'])\n",
    "    _transactions = pd.read_csv(FOLDER+'transactions.csv', parse_dates=['date'])\n",
    "    _df = pd.concat([_train,_test]).sort_values(by=\"date\")\n",
    "    _separator = _test.iloc[0]['date']\n",
    "    def preprocess(df,stores,holidays,transactions):\n",
    "        train = df\n",
    "        \n",
    "        # 2. Merge External Features\n",
    "        train = train.merge(stores, on='store_nbr', how='left')\n",
    "        train = train.merge(transactions, on=['date', 'store_nbr'], how='left')\n",
    "\n",
    "        holidays = holidays[(holidays['locale'] == 'National') & (holidays['transferred'] == False)]\n",
    "        holidays = holidays[['date']].drop_duplicates()\n",
    "        holidays['is_holiday'] = 1\n",
    "        train = train.merge(holidays, on='date', how='left')\n",
    "        train['is_holiday'] = train['is_holiday'].fillna(0)\n",
    "\n",
    "        # Merge onpromotion before encoding 'family'\n",
    "        #train = train.merge(test[['date', 'store_nbr', 'family', 'onpromotion']],\n",
    "        #                    on=['date', 'store_nbr', 'family'], how='left')\n",
    "\n",
    "        # Clean up column names\n",
    "        if 'onpromotion_x' in train.columns:\n",
    "            train['onpromotion'] = train['onpromotion_x'].fillna(0).astype(int)\n",
    "            train.drop(columns=['onpromotion_x', 'onpromotion_'], errors='ignore', inplace=True)\n",
    "        else:\n",
    "            train['onpromotion'] = train['onpromotion'].fillna(0).astype(int)\n",
    "\n",
    "        # Now encode 'family'\n",
    "        train['family'] = train['family'].astype('category').cat.codes\n",
    "    \n",
    "        train['dayofweek'] = train['date'].dt.dayofweek\n",
    "        train['month'] = train['date'].dt.month\n",
    "        train['day'] = train['date'].dt.day\n",
    "        train['week'] = train['date'].dt.isocalendar().week.astype(int)\n",
    "        train['transactions'] = train['transactions'].fillna(0)\n",
    "\n",
    "        # 4. Lag and Rolling Features\n",
    "        train = train.sort_values(['store_nbr', 'family', 'date'])\n",
    "        return train\n",
    "    \n",
    "    processed =preprocess(_df.copy(),_stores.copy(),_holidays.copy(),_transactions.copy())\n",
    "    train = processed[processed['date'] < _separator]\n",
    "    test = processed[processed['date'] >= _separator]\n",
    "                      #test  =preprocess(_test.copy(),_stores.copy(),_holidays.copy(),_transactions.copy())\n",
    "    \n",
    "    return train,test\n",
    "\n",
    "def preprocess_feature_dataset(dataset,train_func,train_name,mode):\n",
    "   \n",
    "    df=add_lag_rolling(dataset.copy(),train_func,train_name,mode=mode)\n",
    "    for col in ['lag_21', 'lag_14', 'rolling_mean_21', 'rolling_std_21', 'rolling_mean_14', 'rolling_std_14']:\n",
    "        df[col] = np.log1p(df[col])\n",
    "    for col in ['trans_lag_21', 'trans_lag_14', 'trans_roll_mean_21', 'trans_roll_mean_14']:\n",
    "        df[col] = np.log1p(df[col] + 1e-5)\n",
    "    features = [\n",
    "        'store_nbr', 'family', 'dayofweek', 'month', 'day', 'week', 'is_holiday',\n",
    "        'transactions', 'lag_21', 'lag_14', 'trans_lag_21', 'trans_lag_14',\n",
    "        'rolling_mean_21', 'rolling_std_21', 'rolling_mean_14', 'rolling_std_14',\n",
    "        'trans_roll_mean_21', 'trans_roll_mean_14',\n",
    "\n",
    "        #'store_dow', \n",
    "        #'family_month', \n",
    "        'onpromo_lag_21', 'onpromo_mean_14'\n",
    "    ]\n",
    "                             \n",
    "    \n",
    "    df = df[df[features].notna().all(axis=1)].copy()     \n",
    "                             \n",
    " \n",
    "    df[features].dropna(inplace=True)\n",
    "                      \n",
    "    X = df[features]\n",
    "    y = np.log1p(df['sales'])\n",
    "    if mode ==\"train\":\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "        return X_train,X_val,y_train,y_val\n",
    "    else:\n",
    "        return X,X,y,y\n",
    "    \n",
    "# START EXPERIENCE =====================================================\n",
    "results = {}\n",
    "preprocess_execution_tracker = ExecutionTimeTracker('preprocess_dataset')\n",
    "train_df,test_df = preprocess_dataset()\n",
    "preprocess_execution_tracker.done()                         \n",
    "                             \n",
    "for train_name, train_func in regimes.items():\n",
    "    \n",
    "    run_settings['regime'] = train_name\n",
    "    if experiment_tracker.did_run(config,target_date,run_settings):\n",
    "        continue\n",
    "    else:\n",
    "   \n",
    "        print(train_name)\n",
    "        # 1. Load Dataset\n",
    "\n",
    "        print('Preprocessing features')\n",
    "        preprocess_features_execution_tracker = ExecutionTimeTracker('preprocess_feature_dataset')  \n",
    "\n",
    "        X_train,X_val,y_train,y_val= preprocess_feature_dataset(train_df.copy(),train_func,train_name,\"train\")\n",
    "\n",
    "        _test_val_separator = int(len(X_val)/2)\n",
    "\n",
    "        X_val_full = X_val.copy()\n",
    "        y_val_full = y_val.copy()\n",
    "\n",
    "        X_val = X_val_full.iloc[:_test_val_separator]\n",
    "        X_test = X_val_full.iloc[_test_val_separator:]\n",
    "    \n",
    "        y_val = y_val_full.iloc[:_test_val_separator]\n",
    "        y_test = y_val_full.iloc[_test_val_separator:]\n",
    "\n",
    "\n",
    "        preprocess_features_execution_tracker.done()\n",
    "\n",
    "        xgb_train_execution_tracker = ExecutionTimeTracker('xgb_train__1000')   \n",
    "\n",
    "        model = xgb.XGBRegressor(\n",
    "            n_estimators=run_settings[\"n_estimators\"], \n",
    "            learning_rate=run_settings[\"learning_rate\"], \n",
    "            max_depth=run_settings[\"max_depth\"], \n",
    "            random_state=run_settings[\"random_state\"])\n",
    "\n",
    "        model.fit(X_train, y_train,\n",
    "                  eval_set=[(X_val, y_val)],\n",
    "\n",
    "                  verbose=25)\n",
    "\n",
    "        xgb_train_execution_tracker.done()\n",
    "        y_pred = np.expm1(model.predict(X_train))\n",
    "        y_real = np.expm1(y_train)\n",
    "        rmsle_train = np.sqrt(mean_squared_log_error(y_real, y_pred))\n",
    "\n",
    "        # 6. Evaluation\n",
    "        y_pred = np.expm1(model.predict(X_val))\n",
    "        y_real = np.expm1(y_val)\n",
    "\n",
    "        rmsle_val = np.sqrt(mean_squared_log_error(y_real, y_pred))\n",
    "\n",
    "        y_pred = np.expm1(model.predict(X_test))\n",
    "        y_real = np.expm1(y_test)\n",
    "\n",
    "        rmsle_test = np.sqrt(mean_squared_log_error(y_real, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "        #results[train_name]=[rmsle]\n",
    "        results[train_name]=[rmsle_train,rmsle_val,rmsle_test]\n",
    "\n",
    " \n",
    "        experiment_tracker.save_run(\n",
    "            config,\n",
    "            {\"train\":rmsle_train,\"val\":rmsle_val,\"test\":rmsle_test},\n",
    "            target_date,\n",
    "            run_settings\n",
    "        )\n",
    "        print(f\"RMSLE:{rmsle_train:.4f}, {rmsle_val:.4f},{rmsle_test:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1284e575",
   "metadata": {},
   "source": [
    "### What’s a Good Score?\n",
    "For Store Sales (Kaggle):\n",
    "\n",
    "🥉 RMSLE > 0.60 → Baseline or simple model\n",
    "\n",
    "🥈 RMSLE ≈ 0.45 → Reasonable with lags + rolling + calendar features\n",
    "\n",
    "🥇 RMSLE < 0.40 → Competitive (you’re doing very well)\n",
    "\n",
    "🏆 RMSLE < 0.38 → Likely leaderboard top 10%\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44852939",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499a2fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[7,14]\n",
    "prev_results = {'rolling_mean': [0.39173891701038477,\n",
    "  0.39667409264677866,\n",
    "  0.38245842805848546],\n",
    " 'rolling_median': [0.3974037983694567,\n",
    "  0.40459857824155593,\n",
    "  0.3850072307441535],\n",
    " 'rolling_weighted_mean': [0.38756927881069714,\n",
    "  0.38920871379602145,\n",
    "  0.38959106223497975],\n",
    " 'rolling_winsorized_mean': [0.39197364429035875,\n",
    "  0.3960417851284805,\n",
    "  0.3797409070979486]}\n",
    "\n",
    "def print_diffs(metric):\n",
    "    print(metric)\n",
    "    diff = abs(prev_results[metric][0]-prev_results[metric][1])+abs((prev_results[metric][0]-prev_results[metric][2]))#+abs((prev_results[metric][1]-prev_results[metric][2]))\n",
    "    print(diff/2,abs((prev_results[metric][0]-prev_results[metric][2])))\n",
    "    \n",
    "print_diffs('rolling_mean')\n",
    "print_diffs('rolling_median')\n",
    "print_diffs('rolling_weighted_mean')\n",
    "print_diffs('rolling_winsorized_mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec148437",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "{'rolling_mean': [0.39173891701038477,\n",
    "  0.39667409264677866,\n",
    "  0.38245842805848546],\n",
    " 'rolling_median': [0.3974037983694567,\n",
    "  0.40459857824155593,\n",
    "  0.3850072307441535],\n",
    " 'rolling_weighted_mean': [0.38756927881069714,\n",
    "  0.38920871379602145,\n",
    "  0.38959106223497975],\n",
    " 'rolling_winsorized_mean': [0.39197364429035875,\n",
    "  0.3960417851284805,\n",
    "  0.3797409070979486]}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25aa7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "sns.heatmap(\n",
    "    pd.DataFrame(prev_results),\n",
    "    #er=0,\n",
    "    \n",
    "    annot=True, fmt=\".1f\", cmap=\"RdYlGn\", \n",
    "    linewidths=0.5, linecolor='black'\n",
    "           )\n",
    "#plt.title(\"Train/Test Regime Mean Total Reward\\n(rows=train, cols=test)\")\n",
    "plt.xlabel(\"Test Regime\")\n",
    "plt.ylabel(\"Train Regime\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b7915a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63255297",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2d1dd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
