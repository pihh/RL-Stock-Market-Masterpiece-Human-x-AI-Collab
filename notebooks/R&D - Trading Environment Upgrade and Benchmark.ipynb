{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1d0c662",
   "metadata": {},
   "source": [
    "Fantastic ‚Äî your answers make it clear: we're building a **free-thinking, risk-aware, market-grounded learning trader**, with the potential to become not just profitable, but deeply **adaptive** and **introspective**. This will be like training a real human trader, starting simple and layering on cognition and tools.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Summary of Your Vision\n",
    "\n",
    "| Category              | Your Decision                                                          |\n",
    "| --------------------- | ---------------------------------------------------------------------- |\n",
    "| **Self-Awareness**    | Track PnL, trade history, confidence per trade                         |\n",
    "| **Market Context**    | Allow multi-timeframe (1D, 1W, maybe 1H later), and any usable feature |\n",
    "| **External Signals**  | Include events like earnings/fed/news if available                     |\n",
    "| **Risk Management**   | Wants liquidation/capital erosion + learned position sizing (v2+)      |\n",
    "| **Strategy Modeling** | Enable strategy playbooks and adaptive behavior                        |\n",
    "| **Meta-Learning**     | Agent should retain memory of past conditions, learn from meta-signals |\n",
    "| **Limitations**       | No peeking into future ‚Äî only prediction from available past           |\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Now Here's the Plan: \"The Trader Intelligence Stack\"\n",
    "\n",
    "We'll organize this into **four layers** that build on each other. Each layer adds trader-like qualities and improves survivability and strategy creation.\n",
    "\n",
    "---\n",
    "\n",
    "### **üîπ Layer 1: Survival & Orientation (v1)**\n",
    "\n",
    "> Minimal working agent that can hold/sell one stock, one timeframe, rewarded by position-based score.\n",
    "\n",
    "**Inputs:**\n",
    "\n",
    "* OHLCV (daily)\n",
    "* Agent‚Äôs current position\n",
    "* Time since position opened\n",
    "* Estimated profit/loss if selling now\n",
    "\n",
    "**Internal features:**\n",
    "\n",
    "* Current PnL (unrealized)\n",
    "* Position duration\n",
    "* Action history (last N actions ‚Äî optional at this stage)\n",
    "\n",
    "**Reward:**\n",
    "\n",
    "* Oracle-relative reward between 0‚Äì100 per episode (‚úÖ already implemented)\n",
    "\n",
    "**Goal:** Learn to enter/exit positions intelligently on one stock.\n",
    "\n",
    "---\n",
    "\n",
    "### **üîπ Layer 2: Market Perception & Meta-Features**\n",
    "\n",
    "> Now the agent *reads the environment*, and we open it to *multi-feature* inputs.\n",
    "\n",
    "**Additions:**\n",
    "\n",
    "* Volatility, momentum, kurtosis, entropy, regime label, VIX, etc.\n",
    "* Optional: add price features from 3-day, 1-week trailing windows\n",
    "\n",
    "**Goal:** Learn to recognize **conditions** that precede profitable trends.\n",
    "\n",
    "---\n",
    "\n",
    "### **üîπ Layer 3: Portfolio & Risk Awareness**\n",
    "\n",
    "> The agent now becomes a risk-aware trader.\n",
    "\n",
    "**Additions:**\n",
    "\n",
    "* Realized volatility, trailing drawdown\n",
    "* Simulated liquidation: episode ends if capital drops below X%\n",
    "* Optional: reward penalty for big drawdowns\n",
    "\n",
    "**Later upgrade:**\n",
    "\n",
    "* Learn dynamic position sizing (0%, 25%, 50%, 100%) or continuous size\n",
    "\n",
    "**Goal:** Survive, control risk, avoid death by bad trades.\n",
    "\n",
    "---\n",
    "\n",
    "### **üîπ Layer 4: Strategic Thinking & Memory**\n",
    "\n",
    "> Agent becomes *introspective* and *adaptive* ‚Äî career-trader-level.\n",
    "\n",
    "**Additions:**\n",
    "\n",
    "* Confidence score (learned or predicted)\n",
    "* Episodic memory (compare current conditions to prior wins/losses)\n",
    "* Strategy archetype detection (trend following, mean reversion, etc.)\n",
    "* Meta-reward: evaluate *how well the agent acted*, not just profit\n",
    "\n",
    "**Goal:** Develop strategic behavior that generalizes to new situations.\n",
    "\n",
    "---\n",
    "\n",
    "### **üîπ Layer 5: Real World Awareness (Optional Later)**\n",
    "\n",
    "> External signals from scraping/news pipelines and macro indicators.\n",
    "\n",
    "* Earnings day, Fed announcement, news sentiment\n",
    "* Sector rotation features (sector-relative strength)\n",
    "* Macro ETFs (SPY, QQQ, TLT, etc.)\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Next Step: We Start at Layer 1\n",
    "\n",
    "Let‚Äôs:\n",
    "\n",
    "1. **Solidify internal features**: PnL, duration, trade history, position status.\n",
    "2. **Wrap it into the `PositionTradingEnv`** ‚Äî this becomes part of the observation.\n",
    "3. **Optionally**: Add rolling average reward, confidence, or simple position score.\n",
    "\n",
    "---\n",
    "\n",
    "### üîß Can I proceed to implement a Layer 1 `env.get_observation()` that includes:\n",
    "\n",
    "* Agent's current position (0 = flat, 1 = long)\n",
    "* Time since entry\n",
    "* Unrealized PnL (oracle-relative)\n",
    "* Normalized current price vs. entry price\n",
    "* One-hot day-of-week (already done)\n",
    "* Rolling average return over past N days\n",
    "* Optional: last 3 actions (as one-hot vectors)\n",
    "\n",
    "?\n",
    "\n",
    "Once this is done, we‚Äôll run the first agent and start logging learnability under **\"Survival Mode\"**.\n",
    "\n",
    "Ready to code this?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dbdf015",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e1d6324",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francisco S√°\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\arrays\\masked.py:61: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from src.utils.system import boot\n",
    "from src.defaults import RANDOM_SEEDS\n",
    "from src.data.feature_pipeline import load_base_dataframe\n",
    "from experiments import check_if_experiment_exists, register_experiment ,experiment_hash\n",
    "from environments import PositionTradingEnv,PositionTradingEnvV1\n",
    "\n",
    "# ========== SYSTEM BOOT ==========\n",
    "DEVICE = boot()\n",
    "EXPERIMENT_NAME = \"trading_environment_development\"\n",
    "DEFAULT_PATH = \"data/experiments/\" + EXPERIMENT_NAME\n",
    "\n",
    "# ========== CONFIG ==========\n",
    "TICKER = \"AAPL\"\n",
    "TIMESTEPS = 10_000\n",
    "EVAL_EPISODES = 5\n",
    "N_TIMESTEPS = 60\n",
    "LOOKBACK = 0\n",
    "SEEDS = RANDOM_SEEDS\n",
    "MARKET_FEATURES = ['close']\n",
    "BENCHMARK_PATH = DEFAULT_PATH+\"/benchmark_episodes.json\"\n",
    "CHECKPOINT_DIR = DEFAULT_PATH+\"/checkpoints\"\n",
    "SCORES_DIR = DEFAULT_PATH+\"/scores\"\n",
    "META_PATH = DEFAULT_PATH+\"/meta_df.csv\"\n",
    "\n",
    "MARKET_FEATURES.sort()\n",
    "SEEDS.sort()\n",
    "\n",
    "DEVICE = boot()\n",
    "OHLCV_DF = load_base_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6768a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "128650a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import hashlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Callable\n",
    "from stable_baselines3 import PPO,A2C\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from environments import PositionTradingEnv\n",
    "from data import extract_meta_features\n",
    "\n",
    "def compute_additional_metrics(env):\n",
    "    if hasattr(env, \"env\"):  # unwrap Monitor\n",
    "        env = env.env\n",
    "    values = np.array(env.values)\n",
    "    rewards = np.array(env.rewards)\n",
    "    actions = np.array(env.actions)\n",
    "\n",
    "    returns = pd.Series(values).pct_change().dropna()\n",
    "    volatility = returns.std()\n",
    "    entropy = -np.sum(np.bincount(actions, minlength=2)/len(actions) * np.log2(np.bincount(actions, minlength=2)/len(actions) + 1e-9))\n",
    "    max_drawdown = (values / np.maximum.accumulate(values)).min() - 1\n",
    "    sharpe = returns.mean() / (returns.std() + 1e-9) * np.sqrt(252)\n",
    "    sortino = returns.mean() / (returns[returns < 0].std() + 1e-9) * np.sqrt(252)\n",
    "    calmar = returns.mean() / abs(max_drawdown + 1e-9)\n",
    "    success_trades = np.sum((np.diff(values) > 0) & (actions[1:] == 1)) + np.sum((np.diff(values) < 0) & (actions[1:] == 0))\n",
    "\n",
    "    return {\n",
    "        \"volatility\": volatility,\n",
    "        \"entropy\": entropy,\n",
    "        \"max_drawdown\": max_drawdown,\n",
    "        \"sharpe\": sharpe,\n",
    "        \"sortino\": sortino,\n",
    "        \"calmar\": calmar,\n",
    "        \"success_trades\": success_trades,\n",
    "        \"action_hold_ratio\": np.mean(actions == 0),\n",
    "        \"action_long_ratio\": np.mean(actions == 1)\n",
    "    }\n",
    "\n",
    "def formalized_transferability_evaluation(\n",
    "    df: pd.DataFrame,\n",
    "    ticker: str,\n",
    "    env_cls: Callable = PositionTradingEnv,\n",
    "    benchmark_path: str = \"data/experiments/learnability_test/benchmark_episodes.json\",\n",
    "    result_path: str = \"data/experiments/learnability_test/meta_df_transfer.csv\",\n",
    "    timesteps: int = 10_000,\n",
    "    n_timesteps: int = 60,\n",
    "    lookback: int = 0,\n",
    "    seeds: list = [42, 52, 62],\n",
    "    checkpoint_dir: str = \"data/experiments/learnability_test/checkpoints\",\n",
    "    agent_cls: Callable = PPO,\n",
    "    \n",
    "    agent_config: dict = None,\n",
    "    env_config: dict = None\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    os.makedirs(os.path.dirname(result_path), exist_ok=True)\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    agent_name: str = agent_cls.__name__\n",
    "    env_version: str = f\"v{env_cls.__version__}\"\n",
    "        \n",
    "    def generate_config_hash(config):\n",
    "        raw = json.dumps(config, sort_keys=True)\n",
    "        return hashlib.sha256(raw.encode()).hexdigest()\n",
    "\n",
    "    def save_model(model, config_full, config_hash):\n",
    "        path = os.path.join(checkpoint_dir, f\"agent_{config_hash}.zip\")\n",
    "        model.save(path)\n",
    "        with open(path.replace(\".zip\", \"_config.json\"), \"w\") as f:\n",
    "            json.dump(config_full, f, indent=2)\n",
    "\n",
    "    print(\"[INFO] Loading benchmark episodes...\")\n",
    "    with open(benchmark_path) as f:\n",
    "        benchmark_episodes = json.load(f)\n",
    "    \n",
    "    meta_records = []\n",
    "    df_ticker = df[df['symbol'] == ticker].reset_index(drop=True)\n",
    "\n",
    "    if os.path.exists(result_path):\n",
    "        existing = pd.read_csv(result_path)\n",
    "        seen_hashes = set(existing['config_hash'].unique())\n",
    "    else:\n",
    "        seen_hashes = set()\n",
    "  \n",
    "    for seed in seeds:\n",
    "        for start_idx in benchmark_episodes:\n",
    "            \n",
    "            test_idx = start_idx + n_timesteps\n",
    "            if test_idx + n_timesteps >= len(df_ticker):\n",
    "                print(\"[WARN] Skipping episode ‚Äî test idx out of range\")\n",
    "                continue\n",
    "\n",
    "            config = {\n",
    "                \"ticker\": ticker,\n",
    "                \"train_idx\": int(start_idx),\n",
    "                \"test_idx\": int(test_idx),\n",
    "                \"timesteps\": timesteps,\n",
    "                \"episode_steps\":n_timesteps,\n",
    "                #\"seed\": seed,\n",
    "                \"env_version\": env_version,\n",
    "                \"env_config\": env_config,\n",
    "                #\"agent_name\": agent_name,\n",
    "                \"agent_config\": agent_config,\n",
    "            }\n",
    "            config_hash = generate_config_hash(config)\n",
    "            if config_hash in seen_hashes:\n",
    "                print(f\"[INFO] Skipping previously completed run: {config_hash}\")\n",
    "                continue\n",
    "\n",
    "            print(f\"[INFO] Transferability: seed={seed}, start_idx={start_idx}, config_hash={config_hash}\")\n",
    "\n",
    " \n",
    "            env_train = Monitor(env_cls(df_ticker, ticker=ticker, seed=seed, start_idx=start_idx, **(env_config or {})))\n",
    "            model = agent_cls(\"MlpPolicy\", env_train, verbose=0, seed=seed, **(agent_config or {}))\n",
    "            model.learn(total_timesteps=timesteps)\n",
    "\n",
    "            obs, _ = env_train.reset()\n",
    "            done, score_train = False, 0\n",
    "            while not done:\n",
    "                action, _ = model.predict(obs, deterministic=True)\n",
    "                obs, reward, done, _, _ = env_train.step(action)\n",
    "                score_train += reward\n",
    "\n",
    "            obs, _ = env_train.reset()\n",
    "            done, rand_train = False, 0\n",
    "            while not done:\n",
    "                action = env_train.action_space.sample()\n",
    "                obs, reward, done, _, _ = env_train.step(action)\n",
    "                rand_train += reward\n",
    "\n",
    "            env_test = Monitor(env_cls(df_ticker, ticker=ticker, seed=seed, start_idx=test_idx, **(env_config or {})))\n",
    "            obs, _ = env_test.reset()\n",
    "            done, score_test = False, 0\n",
    "            while not done:\n",
    "                action, _ = model.predict(obs, deterministic=True)\n",
    "                obs, reward, done, _, _ = env_test.step(action)\n",
    "                score_test += reward\n",
    "\n",
    "            obs, _ = env_test.reset()\n",
    "            done, rand_test = False, 0\n",
    "            while not done:\n",
    "                action = env_test.action_space.sample()\n",
    "                obs, reward, done, _, _ = env_test.step(action)\n",
    "                rand_test += reward\n",
    "\n",
    "            advantage_train = score_train - rand_train\n",
    "            advantage_test = score_test - rand_test\n",
    "            transfer_delta = score_test - score_train\n",
    "\n",
    "            save_model(model, config, config_hash)\n",
    "\n",
    "            meta = extract_meta_features(df_ticker.iloc[start_idx:start_idx + n_timesteps])\n",
    "            diagnostics = compute_additional_metrics(env_test)\n",
    "\n",
    "            meta.update({\n",
    "                \"config_hash\": config_hash,\n",
    "                \"env_version\": env_version,\n",
    "                \"agent_name\": agent_name,\n",
    "                \"score_train\": score_train,\n",
    "                \"score_test\": score_test,\n",
    "                \"advantage_train\": advantage_train,\n",
    "                \"advantage_test\": advantage_test,\n",
    "                \"transfer_delta\": transfer_delta,\n",
    "                \"transfer_success\": int(transfer_delta > 0),\n",
    "                \"ticker\": ticker,\n",
    "                \"config\":json.dumps(config),\n",
    "                \"seed\": seed,\n",
    "                \"ticker\": ticker,\n",
    "                \"train_idx\": int(start_idx),\n",
    "                \"test_idx\": int(test_idx),\n",
    "                \"timesteps\": timesteps,\n",
    "                \"episode_steps\":n_timesteps,\n",
    "                \"seed\": seed,\n",
    "                **diagnostics\n",
    "            })\n",
    "            meta_records.append(meta)\n",
    "\n",
    "    result_df = pd.DataFrame(meta_records)\n",
    "    if os.path.exists(result_path):\n",
    "        result_df = pd.concat([pd.read_csv(result_path), result_df], ignore_index=True)\n",
    "    result_df.to_csv(result_path, index=False)\n",
    "    print(\"[INFO] Transferability test complete. Results saved to:\", result_path)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "453a0986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Epis√≥dios de benchmark salvos em: data/experiments/trading_environment_development/benchmark_episodes.json\n",
      "[INFO] Loading benchmark episodes...\n"
     ]
    },
    {
     "ename": "EmptyDataError",
     "evalue": "No columns to parse from file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmptyDataError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m env_cls \u001b[38;5;129;01min\u001b[39;00m [PositionTradingEnv,PositionTradingEnvV1]:\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m agent_cls \u001b[38;5;129;01min\u001b[39;00m [PPO, A2C]:\n\u001b[1;32m---> 14\u001b[0m         result_df \u001b[38;5;241m=\u001b[39m formalized_transferability_evaluation(\n\u001b[0;32m     15\u001b[0m             df\u001b[38;5;241m=\u001b[39mOHLCV_DF\u001b[38;5;241m.\u001b[39mcopy(),\n\u001b[0;32m     16\u001b[0m             ticker\u001b[38;5;241m=\u001b[39mTICKER,\n\u001b[0;32m     17\u001b[0m             env_cls\u001b[38;5;241m=\u001b[39menv_cls,\n\u001b[0;32m     18\u001b[0m             agent_cls\u001b[38;5;241m=\u001b[39magent_cls,\n\u001b[0;32m     19\u001b[0m             benchmark_path\u001b[38;5;241m=\u001b[39mDEFAULT_PATH\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/benchmark_episodes.json\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     20\u001b[0m             result_path\u001b[38;5;241m=\u001b[39mDEFAULT_PATH\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/meta_df_transfer.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     21\u001b[0m             timesteps\u001b[38;5;241m=\u001b[39mTIMESTEPS,\n\u001b[0;32m     22\u001b[0m             n_timesteps\u001b[38;5;241m=\u001b[39mN_TIMESTEPS,\n\u001b[0;32m     23\u001b[0m             lookback\u001b[38;5;241m=\u001b[39mLOOKBACK,\n\u001b[0;32m     24\u001b[0m             seeds\u001b[38;5;241m=\u001b[39mSEEDS,  \u001b[38;5;66;03m# or just [42] for quick run\u001b[39;00m\n\u001b[0;32m     25\u001b[0m             checkpoint_dir\u001b[38;5;241m=\u001b[39mDEFAULT_PATH\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/checkpoints\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     26\u001b[0m             env_config\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarket_features\u001b[39m\u001b[38;5;124m\"\u001b[39m:MARKET_FEATURES}\n\u001b[0;32m     27\u001b[0m )\n",
      "Cell \u001b[1;32mIn[5], line 80\u001b[0m, in \u001b[0;36mformalized_transferability_evaluation\u001b[1;34m(df, ticker, env_cls, benchmark_path, result_path, timesteps, n_timesteps, lookback, seeds, checkpoint_dir, agent_cls, agent_config, env_config)\u001b[0m\n\u001b[0;32m     77\u001b[0m df_ticker \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msymbol\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m ticker]\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(result_path):\n\u001b[1;32m---> 80\u001b[0m     existing \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(result_path)\n\u001b[0;32m     81\u001b[0m     seen_hashes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(existing[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig_hash\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1898\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1895\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1897\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1898\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mapping[engine](f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions)\n\u001b[0;32m   1899\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1900\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:93\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype_backend\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;66;03m# Fail here loudly instead of in cython after reading\u001b[39;00m\n\u001b[0;32m     92\u001b[0m     import_optional_dependency(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 93\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m parsers\u001b[38;5;241m.\u001b[39mTextReader(src, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munnamed_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39munnamed_cols\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:581\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mEmptyDataError\u001b[0m: No columns to parse from file"
     ]
    }
   ],
   "source": [
    "if os.path.exists(BENCHMARK_PATH):\n",
    "    with open(BENCHMARK_PATH) as f:\n",
    "        benchmark_episodes = json.load(f)\n",
    "else:\n",
    "    print(\"[INFO] Sampling benchmark episodes...\")\n",
    "    np.random.seed(0)\n",
    "    benchmark_episodes = sample_valid_episodes(OHLCV_DF[OHLCV_DF['symbol']==TICKER], TICKER, N_TIMESTEPS, LOOKBACK, EVAL_EPISODES)\n",
    "    with open(BENCHMARK_PATH, \"w\") as f:\n",
    "        json.dump(benchmark_episodes.tolist(), f)  # ‚Üê ‚úÖ Convert to list here\n",
    "\n",
    "print(\"[INFO] Epis√≥dios de benchmark salvos em:\", BENCHMARK_PATH)\n",
    "for env_cls in [PositionTradingEnv,PositionTradingEnvV1]:\n",
    "    for agent_cls in [PPO, A2C]:\n",
    "        result_df = formalized_transferability_evaluation(\n",
    "            df=OHLCV_DF.copy(),\n",
    "            ticker=TICKER,\n",
    "            env_cls=env_cls,\n",
    "            agent_cls=agent_cls,\n",
    "            benchmark_path=DEFAULT_PATH+\"/benchmark_episodes.json\",\n",
    "            result_path=DEFAULT_PATH+\"/meta_df_transfer.csv\",\n",
    "            timesteps=TIMESTEPS,\n",
    "            n_timesteps=N_TIMESTEPS,\n",
    "            lookback=LOOKBACK,\n",
    "            seeds=SEEDS,  # or just [42] for quick run\n",
    "            checkpoint_dir=DEFAULT_PATH+\"/checkpoints\",\n",
    "            env_config={\"market_features\":MARKET_FEATURES}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c4023d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.read_csv(BENCHMARK_PATH)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ae4675",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28118cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "\n",
    "def compare_environments(result_df,env_version_a=\"v0\",env_version_b = \"v1\"):\n",
    "    \n",
    "\n",
    "    summary = result_df.groupby(\"env_version\")[[\n",
    "        \"score_train\", \"score_test\", \"advantage_train\", \"advantage_test\",\n",
    "        \"transfer_delta\", \"success_trades\", \"sharpe\", \"sortino\", \"calmar\",\n",
    "        \"max_drawdown\", \"volatility\", \"action_hold_ratio\", \"action_long_ratio\"\n",
    "    ]].agg([\"mean\", \"std\", \"median\"]).T\n",
    "    \n",
    "\n",
    "    mean_df = summary.xs('mean', level=1)\n",
    "    # Compute absolute difference between env_version 1 and 0\n",
    "    diffs = (mean_df[env_version_a] - mean_df[env_version_b]).abs().sort_values(ascending=False)\n",
    "  \n",
    "    # Plot using this sorted order\n",
    "    mean_df.loc[diffs.index].plot.bar(\n",
    "        figsize=(14, 6),\n",
    "        title=f\"Env {env_version_a} vs {env_version_b} ‚Äì Mean metric comparison (sorted by difference)\",\n",
    "        ylabel=\"Mean Value\"\n",
    "    )\n",
    "    metrics = [\"score_test\", \"advantage_test\", \"transfer_delta\", \"sharpe\", \"sortino\"]\n",
    "\n",
    "    for metric in metrics:\n",
    "        v0 = result_df[result_df.env_version == env_version_a][metric]\n",
    "        v1 = result_df[result_df.env_version == env_version_b][metric]\n",
    "        stat, pval = ttest_ind(v0, v1)\n",
    "        print(f\"{metric}: p={pval:.4f} | {env_version_a}_mean={v0.mean():.3f}, {env_version_b}_mean={v1.mean():.3f}\")\n",
    "\n",
    "    for metric in metrics:\n",
    "        sns.boxplot(data=result_df, x=\"env_version\", y=metric)\n",
    "        plt.title(f\"{metric} by Environment Version\")\n",
    "        plt.show()\n",
    "        \n",
    "    result_df['composite_score'] = (\n",
    "        result_df['advantage_test'] +\n",
    "        result_df['transfer_delta'] +\n",
    "        result_df['sharpe'] * 5 -\n",
    "        result_df['max_drawdown'] * 10\n",
    "    )\n",
    "\n",
    "    return result_df,result_df.groupby(\"env_version\")[\"composite_score\"].mean()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e3604a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "summary = compare_environments(result_df)\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b93e88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c0021a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(DEFAULT_PATH+\"/meta_df_transfer.csv\")\n",
    "results.groupby('env_version').mean(numeric_only=True).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77887819",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b49f17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c352753",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
