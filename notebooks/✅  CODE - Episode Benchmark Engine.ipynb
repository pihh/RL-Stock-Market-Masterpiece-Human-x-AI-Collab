{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dbdf015",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e1d6324",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francisco Sá\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\arrays\\masked.py:61: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import gymnasium as gym\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy.stats import skew, kurtosis, entropy\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "\n",
    "from src.utils.system import boot\n",
    "from src.defaults import RANDOM_SEEDS, TOP2_STOCK_BY_SECTOR\n",
    "from tracker import OHLCV_DF, EpisodeTracker, EnvironmentTracker, AgentTracker\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d468acb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration ======================\n",
    "excluded_tickers = sorted(['CEG', 'GEHC', 'GEV', 'KVUE', 'SOLV'])\n",
    "\n",
    "config = {\n",
    "    \"regressor\": \"RandomForestRegressor\",\n",
    "    \"n_estimators\": 300,\n",
    "    \"random_state\": 314,\n",
    "    \"transaction_cost\": 0\n",
    "}\n",
    "\n",
    "run_settings = {\n",
    "    \"excluded_tickers\": excluded_tickers,\n",
    "    \"min_samples\": 10,\n",
    "    \"cv_folds\": 3,\n",
    "    \"lags\": 5,\n",
    "    \"start_date\": \"2023-12-31\",\n",
    "    \"end_date\": \"2025-05-01\",\n",
    "    \"seed\": 314,\n",
    "    \"episode_length\": 50,\n",
    "    \"noise_feature_cols\": [\"return_1d\", \"volume\"],\n",
    "    \"train_steps\": 50_000,\n",
    "    \"lookback\": 0,\n",
    "    \n",
    "}\n",
    "\n",
    "# System Boot =======================\n",
    "DEVICE = boot()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "122db33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Prepare Data ================\n",
    "ohlcv_df = OHLCV_DF.copy()\n",
    "ohlcv_df['month'] = ohlcv_df['date'].dt.to_period('M')\n",
    "ohlcv_df['return_1d'] = ohlcv_df['return_1d'].fillna(0)\n",
    "ohlcv_df['sector_id'] = ohlcv_df['sector_id'].fillna('unknown')\n",
    "ohlcv_df['industry_id'] = ohlcv_df['industry_id'].fillna('unknown')\n",
    "\n",
    "# Filter Tickers ======================\n",
    "tickers = ohlcv_df['symbol'].unique()\n",
    "tickers = tickers[~np.isin(tickers, excluded_tickers)]\n",
    "tickers = [\"AAPL\"]  # Force test with AAPL\n",
    "#tickers = TOP2_STOCK_BY_SECTOR\n",
    "# Load and prepare trackers\n",
    "ep_tracker    = EpisodeTracker()\n",
    "env_tracker   = EnvironmentTracker()\n",
    "agent_tracker = AgentTracker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e39e7bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions ====================\n",
    "import numpy as np\n",
    "\n",
    "def compute_returns_curve(curve):\n",
    "    returns = np.diff(curve) / curve[:-1]\n",
    "    return returns\n",
    "\n",
    "def sharpe_ratio(returns, risk_free_rate=0.0):\n",
    "    excess = returns - risk_free_rate\n",
    "    return np.mean(excess) / (np.std(excess) + 1e-8)\n",
    "\n",
    "def sortino_ratio(returns, risk_free_rate=0.0):\n",
    "    returns = np.array(returns)\n",
    "    excess = returns - risk_free_rate\n",
    "    downside = excess[excess < 0]\n",
    "    \n",
    "    # Avoid division by zero: if no downside, assume very small downside deviation\n",
    "    if len(downside) == 0:\n",
    "        downside_std = 1e-8\n",
    "    else:\n",
    "        downside_std = np.std(downside)\n",
    "    \n",
    "    return np.mean(excess) / downside_std\n",
    "\n",
    "\n",
    "def calmar_ratio(returns_curve):\n",
    "    total_return = returns_curve[-1] / returns_curve[0] - 1\n",
    "    drawdown = np.maximum.accumulate(returns_curve) - returns_curve\n",
    "    max_drawdown = np.max(drawdown) / returns_curve[0]\n",
    "    return total_return / (max_drawdown + 1e-8)\n",
    "\n",
    "def central_tendency_difference (mean,median,std):\n",
    "    return abs(mean-median)/(abs(std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eacd598e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import hashlib\n",
    "from collections import defaultdict\n",
    "STORAGE_PATH = \"data/experiments/episode_benchmark_engine/runs.csv\"\n",
    "\n",
    "\n",
    "EXCLUDED_TICKERS = sorted([\"CEG\", \"GEHC\", \"GEV\", \"KVUE\", \"SOLV\"])\n",
    "\n",
    "CONFIG = {\n",
    "    \"regressor\": \"RandomForestRegressor\",\n",
    "    \"n_estimators\": 300,\n",
    "    \"random_state\": 314,\n",
    "    \"transaction_cost\": 0,\n",
    "}\n",
    "LOOKBACK = 0\n",
    "EPISODE_LENGTH = 50\n",
    "\n",
    "RUN_SETTINGS = {\n",
    "    \"excluded_tickers\": EXCLUDED_TICKERS,\n",
    "    \"cv_folds\": 3,\n",
    "    \"lags\": 5,\n",
    "    \"seed\": 314,\n",
    "    'total_timesteps':50_000,\n",
    "    \"episode\": {\n",
    "        \"episode_length\": EPISODE_LENGTH,\n",
    "        \"lookback\": LOOKBACK,\n",
    "    },\n",
    "    \"environment\": {\n",
    "        \"market_features\": [\"close\", \"price_change\", \"volume_change\"],\n",
    "        \"version\": \"v2\",\n",
    "        \"lookback\": LOOKBACK,\n",
    "        \"n_timesteps\": EPISODE_LENGTH,\n",
    "        \"transaction_cost\": 0,\n",
    "    },\n",
    "    \"agent\": {\n",
    "        \"model_class\": \"PPO\",\n",
    "        \"policy_class\": \"MlpPolicy\",\n",
    "        \"config\": {\n",
    "            \"verbose\": 1,\n",
    "            \"ent_coef\":0.1,\n",
    "            \"policy_kwargs\": \n",
    "                {\n",
    "                \n",
    "                    \"net_arch\": [64, 64]\n",
    "                    }\n",
    "                },\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "class EpisodeBenchmark:\n",
    "    def __init__(\n",
    "        self,\n",
    "        tickers=[\"AAPL\"],\n",
    "        config=CONFIG,\n",
    "        run_settings=RUN_SETTINGS,\n",
    "        start_date=\"2024-01-01\",\n",
    "    ):\n",
    "        self.ohlcv_df = OHLCV_DF.copy()\n",
    "        self.tickers = tickers  # Force test with AAPL\n",
    "        self.start_date = start_date\n",
    "\n",
    "        self.config = CONFIG\n",
    "        self.run_settings = RUN_SETTINGS\n",
    "        self.run_settings['environment']['market_features'].sort()\n",
    "        self.ep_tracker = EpisodeTracker()\n",
    "        self.env_tracker = EnvironmentTracker()\n",
    "        self.agent_tracker = AgentTracker()\n",
    "        \n",
    "        self.boot()\n",
    "        \n",
    "    def boot(self):\n",
    "        if os.path.exists(STORAGE_PATH):\n",
    "            self.completed_runs_df = pd.read_csv(STORAGE_PATH)\n",
    "\n",
    "            # Fix: use self.completed_runs_df, not df\n",
    "            self.completed_hashes = set(self.completed_runs_df[\"run_hash\"].unique())\n",
    "            self.seen_seeds = defaultdict(set)\n",
    "            for _, row in self.completed_runs_df.iterrows():\n",
    "                self.seen_seeds[row[\"run_hash\"]].add(row[\"seed\"])\n",
    "        else:\n",
    "            self.completed_runs_df = pd.DataFrame()\n",
    "            self.completed_hashes = set()\n",
    "            self.seen_seeds = defaultdict(set)\n",
    "\n",
    "    def compute_run_hash(self, agent_id, train_episode_id,train_environment_id):\n",
    "        market_features =self.run_settings['environment']['market_features']\n",
    "        market_features.sort()\n",
    "        payload = {\n",
    "            \"agent_id\": agent_id,\n",
    "            \"episode_id\": train_episode_id,\n",
    "            \"environment_id\":train_environment_id,\n",
    "            \"timesteps\": self.run_settings['total_timesteps'],\n",
    "            \"lookback\":self.run_settings['episode']['lookback'],\n",
    "            \"episode_length\":self.run_settings['episode']['episode_length'],\n",
    "            \"market_features\":json.dumps(market_features)\n",
    "        }\n",
    "        return hashlib.md5(json.dumps(payload, sort_keys=True).encode()).hexdigest()\n",
    "    \n",
    "    def extract_agent_diagnostics(self,env, model, mode=\"train\"):\n",
    "        \"\"\"\n",
    "        Runs agent through environment and extracts residual diagnostics\n",
    "        from reward trajectory, wallet progression, and optionally oracle and market.\n",
    "        \"\"\"\n",
    "        rewards = []\n",
    "        residuals_oracle = []\n",
    "        obs = env.reset()[0]\n",
    "        done = False\n",
    "\n",
    "        oracle_progress = []\n",
    "        while not done:\n",
    "            action, _ = model.predict(obs, deterministic=True)\n",
    "            obs, reward, done, _, info = env.step(action)\n",
    "            rewards.append(reward)\n",
    "\n",
    "            # Oracle fallback\n",
    "            oracle_score = info.get(\"oracle_score\", None)\n",
    "            if oracle_score is not None:\n",
    "                oracle_progress.append(oracle_score)\n",
    "                residuals_oracle.append(oracle_score - reward)\n",
    "            else:\n",
    "                oracle_progress.append(abs(reward))\n",
    "\n",
    "        # Agent vs Oracle residuals\n",
    "        if residuals_oracle:\n",
    "            r_oracle = np.array(residuals_oracle)\n",
    "        else:\n",
    "            smoothed = pd.Series(rewards).rolling(window=5, min_periods=1).mean()\n",
    "            r_oracle = np.array(rewards) - smoothed.values\n",
    "\n",
    "        # Agent vs Market residuals\n",
    "        agent_returns = np.array(env.wallet_progress)\n",
    "        market_returns = np.array(env.market_progress)\n",
    "        r_market = agent_returns - market_returns\n",
    "\n",
    "        # Daily returns\n",
    "        returns = pd.Series(agent_returns).pct_change().dropna().values\n",
    "        market_pct_returns = pd.Series(market_returns).pct_change().dropna().values\n",
    "\n",
    "        diagnostics = {\n",
    "            f\"{mode}_total_reward\": env.total_reward,\n",
    "            f\"{mode}_wallet\":env.wallet,\n",
    "            f\"{mode}_market\":env.market_progress[-1],\n",
    "\n",
    "            # Residuals vs Oracle\n",
    "            f\"{mode}_resid_oracle_std\": np.std(r_oracle),\n",
    "            f\"{mode}_resid_oracle_skew\": skew(r_oracle),\n",
    "            f\"{mode}_resid_oracle_kurtosis\": kurtosis(r_oracle),\n",
    "            f\"{mode}_resid_oracle_acf1\": pd.Series(r_oracle).autocorr(lag=1),\n",
    "            f\"{mode}_resid_oracle_mean\": np.mean(r_oracle),\n",
    "            f\"{mode}_resid_oracle_median\": np.median(r_oracle),\n",
    "            f\"{mode}_resid_oracle_max\": np.max(r_oracle),\n",
    "            f\"{mode}_resid_oracle_min\": np.min(r_oracle),\n",
    "            f\"{mode}_ljung_oracle_pval\": (\n",
    "                acorr_ljungbox(r_oracle, lags=[min(10, len(r_oracle) - 1)], return_df=True).iloc[0]['lb_pvalue']\n",
    "                if len(r_oracle) > 10 else np.nan\n",
    "            ),\n",
    "\n",
    "            # Residuals vs Market\n",
    "            f\"{mode}_resid_market_std\": np.std(r_market),\n",
    "            f\"{mode}_resid_market_skew\": skew(r_market),\n",
    "            f\"{mode}_resid_market_kurtosis\": kurtosis(r_market),\n",
    "            f\"{mode}_resid_market_acf1\": pd.Series(r_market).autocorr(lag=1),\n",
    "            f\"{mode}_resid_market_mean\": np.mean(r_market),\n",
    "            f\"{mode}_resid_market_median\": np.median(r_market),\n",
    "            f\"{mode}_resid_market_max\": np.max(r_market),\n",
    "            f\"{mode}_resid_market_min\": np.min(r_market),\n",
    "            f\"{mode}_ljung_market_pval\": (\n",
    "                acorr_ljungbox(r_market, lags=[min(10, len(r_market) - 1)], return_df=True).iloc[0]['lb_pvalue']\n",
    "                if len(r_market) > 10 else np.nan\n",
    "            ),\n",
    "\n",
    "            # Financial performance\n",
    "            f\"{mode}_sharpe\": sharpe_ratio(returns),\n",
    "            f\"{mode}_sortino\": sortino_ratio(returns),\n",
    "            f\"{mode}_calmar\": calmar_ratio(agent_returns),\n",
    "            f\"{mode}_market_sharpe\": sharpe_ratio(market_pct_returns),\n",
    "            f\"{mode}_market_sortino\": sortino_ratio(market_pct_returns),\n",
    "            f\"{mode}_market_calmar\": calmar_ratio(market_returns),\n",
    "        }\n",
    "\n",
    "        return diagnostics\n",
    "\n",
    "\n",
    "    def run(self, tickers=None):\n",
    "        # Configurations =============================\n",
    "        config = self.config\n",
    "        run_settings = self.run_settings\n",
    "\n",
    "        # Feature Extraction Loop ====================\n",
    "        features, targets, metadata, runs = [], [], [], []\n",
    "        ohlcv_df = self.ohlcv_df.copy()\n",
    "\n",
    "        if tickers == None:\n",
    "            tickers = self.tickers\n",
    "        \n",
    "        seed = 314\n",
    "        boot(seed)\n",
    "        \n",
    "        for symbol in tqdm(tickers):\n",
    "            df = ohlcv_df[ohlcv_df[\"symbol\"] == symbol].sort_values(\"date\").copy()\n",
    "            df = df[df[\"date\"] > self.start_date]\n",
    "            df = df.iloc[: -self.run_settings[\"episode\"][\"episode_length\"]]\n",
    "            months = df[\"month\"].unique()\n",
    "            \n",
    "            for i  in range(len(months)):\n",
    "                try:\n",
    "\n",
    "                    target_date = str(months[i]) + \"-01\"\n",
    "                    \n",
    "                    episodes = self.ep_tracker.findEpisode(\n",
    "                        target_date,\n",
    "                        symbol,\n",
    "                        episode_length=self.run_settings[\"episode\"][\"episode_length\"],\n",
    "                        lookback=self.run_settings[\"episode\"][\"lookback\"],\n",
    "                        mode=\"both\",\n",
    "                    )\n",
    "\n",
    "                    train_episode = episodes[\"train\"]\n",
    "                    test_episode = episodes[\"test\"]\n",
    "\n",
    "                    env_tracker = EnvironmentTracker()\n",
    "\n",
    "                    train_env_config = {\n",
    "                        \"ticker\": symbol,\n",
    "                        \"n_timesteps\": self.run_settings[\"episode\"][\"episode_length\"],\n",
    "                        \"lookback\": self.run_settings[\"episode\"][\"lookback\"],\n",
    "                        \"market_features\":self.run_settings['environment']['market_features'],\n",
    "                        \"seed\": seed,\n",
    "                        \"start_idx\": train_episode[\"df_start_iloc\"],  # type: ignore\n",
    "                    }\n",
    "                    test_env_config = train_env_config.copy()\n",
    "                    test_env_config[\"start_idx\"] = test_episode[\"df_start_iloc\"] # type: ignore\n",
    "\n",
    "                    env_info = env_tracker.findEnvironment(\n",
    "                        version=\"v2\", config=train_env_config\n",
    "                    )\n",
    "                    \n",
    "                    train_env = env_info[\"environment\"]\n",
    "                    #train_config[\"start_idx\"] = test_episode[\"start_idx\"]\n",
    "                    \n",
    "                    test_env = env_tracker.findEnvironment(\n",
    "                        version=\"v2\", config=test_env_config\n",
    "                    )\n",
    "                   \n",
    "                    test_env = test_env[\"environment\"]\n",
    "\n",
    "                    tracker = AgentTracker()\n",
    "                    \n",
    "                    agent = tracker.findAgent(\n",
    "                        **self.run_settings['agent']\n",
    "                   \n",
    "                    )\n",
    "                    \n",
    "                    run_hash = self.compute_run_hash(\n",
    "                        agent_id=agent[\"id\"],\n",
    "                        train_episode_id=train_episode[\"id\"],\n",
    "                        train_environment_id=env_info['id']\n",
    "                    )\n",
    "                    if run_hash in self.completed_hashes and seed in self.seen_seeds[run_hash]:\n",
    "                        continue  # Skip\n",
    "                        \n",
    "                    _model = agent[\"model\"].boot(train_env)\n",
    "                    _model.learn(total_timesteps=self.run_settings['total_timesteps'])\n",
    "                    \n",
    "                    # diagnostics \n",
    "                     \n",
    "                    train_diagnostics =self.extract_agent_diagnostics(train_env,_model,mode=\"train\")\n",
    "                    test_diagnostics =self.extract_agent_diagnostics(test_env,_model,mode=\"test\")\n",
    "                    full_diagnostics = {\n",
    "                        **train_diagnostics,\n",
    "                        **test_diagnostics\n",
    "                    }\n",
    "                    #ddf.append(full_diagnostics)\n",
    "                    results =  {\n",
    "                        'run_hash':run_hash,\n",
    "                        'seed':seed,\n",
    "                        'target_date':target_date,\n",
    "                            \"agent\":self.run_settings['agent']['model_class'],\n",
    "                            \"policy\":self.run_settings['agent']['policy_class'],\n",
    "                            \"env_version\":env_info['version'],\n",
    "                            \"train_episode_id\": train_episode[\"id\"],\n",
    "                            \"test_episode_id\":  test_episode[\"id\"],\n",
    "                            \"total_timesteps\": self.run_settings['total_timesteps'],\n",
    "                            \"ticker\": symbol,\n",
    "                            \"target_date\": target_date,\n",
    "                            \"environment_id\": env_info[\"id\"],\n",
    "                            \"agent_id\": agent[\"id\"],\n",
    "                            \"episode_length\":self.run_settings['episode']['episode_length'],\n",
    "                            \"lookback\":self.run_settings['episode']['lookback'],\n",
    "                            \"market_features\":json.dumps(self.run_settings['environment']['market_features']),\n",
    "                            **full_diagnostics\n",
    "                        }\n",
    "                    if run_hash in self.completed_hashes and seed in self.seen_seeds[run_hash]:\n",
    "                        print(f\"Skipping already completed run {run_hash} with seed {seed}\")\n",
    "                    else:\n",
    "                        self.completed_runs_df = pd.concat([self.completed_runs_df, pd.DataFrame([results])], ignore_index=True)\n",
    "                        self.completed_hashes.add(run_hash)\n",
    "                        self.seen_seeds[run_hash].add(seed)\n",
    "                        self.completed_runs_df.to_csv(STORAGE_PATH,index=False)\n",
    "\n",
    "                    runs.append(\n",
    "                        {\n",
    "                            \"agent\":self.run_settings['agent']['model_class'],\n",
    "                            \"policy\":self.run_settings['agent']['policy_class'],\n",
    "                            \"env_version\":\"v2\",\n",
    "                     \n",
    "                            \"train_episode_id\": train_episode[\"id\"],\n",
    "                            \"test_episode_id\":  test_episode[\"id\"],\n",
    "                            \"total_timesteps\": self.run_settings['total_timesteps'],\n",
    "                            \"ticker\": symbol,\n",
    "                            \"target_date\": target_date,\n",
    "                            \"environment_id\": env_info[\"id\"],\n",
    "                            \"agent_id\": agent[\"id\"],\n",
    "                            \"model\": _model,\n",
    "                            \"train_env\": train_env,\n",
    "                            \"test_env\": test_env,\n",
    "                            **full_diagnostics\n",
    "                        }\n",
    "                    )\n",
    "               \n",
    "                    print('next')\n",
    "                except Exception as e:\n",
    "                    print(f\"Skipping {symbol} {months[i]} due to error: {e}\")\n",
    "             \n",
    "        return runs    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67ad7f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eb = EpisodeBenchmark(tickers=TOP2_STOCK_BY_SECTOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76269543",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/22 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next\n",
      "next\n",
      "next\n",
      "next\n",
      "next\n",
      "next\n",
      "next\n",
      "next\n",
      "next\n",
      "next\n",
      "next\n",
      "next\n",
      "next\n",
      "next\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francisco Sá\\AppData\\Local\\Temp\\ipykernel_17148\\2757300406.py:23: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  return np.mean(excess) / downside_std\n",
      "\r",
      "  5%|▍         | 1/22 [31:50<11:08:45, 1910.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next\n",
      "next\n",
      "next\n",
      "next\n",
      "next\n",
      "next\n",
      "next\n",
      "next\n",
      "next\n",
      "next\n",
      "next\n",
      "next\n",
      "next\n",
      "next\n",
      "next\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 2/22 [1:20:19<13:52:33, 2497.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next\n",
      "next\n",
      "next\n",
      "next\n"
     ]
    }
   ],
   "source": [
    "runs = eb.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd36187",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7316bf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "pddf= pd.DataFrame(runs)\n",
    "pddf['train_episode_id'],pddf['test_episode_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94780d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [col for col in pddf.columns if col.startswith('test_') and col != 'test_total_reward']\n",
    "pddf_cleaned = pddf.drop(columns=cols_to_drop)\n",
    "\n",
    "# Now you can compute correlation\n",
    "correlations = pddf_cleaned.corr(numeric_only=True)['test_total_reward'].sort_values(ascending=False)\n",
    "correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa9b834",
   "metadata": {},
   "outputs": [],
   "source": [
    "pddf[['train_wallet','test_wallet','train_market','test_market','test_total_reward',\"train_total_reward\",\n",
    "\"train_sortino\"                  ,\n",
    "\"train_calmar\"                   ,\n",
    "\"train_resid_market_acf1\"        ,\n",
    "\"train_resid_oracle_kurtosis\"    ,\n",
    "\"train_sharpe\"                   ,\n",
    "\"train_resid_oracle_max\"         ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746c74c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppdf['train_episode_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b062bd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
