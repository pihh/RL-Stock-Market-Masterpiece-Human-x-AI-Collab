{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4010eee4",
   "metadata": {},
   "source": [
    "Treina os vários agents base, nos vários ambientes que criarmos em várias seeds para cada episódio predefinido.\n",
    "\n",
    "A ideia é ir buscar o máximo de dados para poder entender o quão eficaz um ambiente,agente ou episódio está a ser\n",
    "\n",
    "Desta forma, no futuro pode-se escolher a combinação episódio,ambiente,agente com maior probabilidade de sucesso na transferibilidade de um timeframe para outro\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **Meta-Features (Input for prediction)**\n",
    "\n",
    "These are all continuous, float64:\n",
    "\n",
    "* `mean_return`, `median_return`, `std_return`, `skew_return`, `kurtosis_return`\n",
    "* `return_trend`, `ewm_mean_return`, `hurst`, `adf_stat`, `adf_pval`, `entropy`\n",
    "* `volatility`, `max_drawdown`, `sharpe`, `sortino`, `calmar`\n",
    "\n",
    "### ✅ **Experiment Identity Columns**\n",
    "\n",
    "These identify the agent, environment, and run setup:\n",
    "\n",
    "* `config_hash`, `env_version`, `agent_name`, `ticker`, `config`, `seed`, `train_idx`, `test_idx`, `config_dict`\n",
    "\n",
    "### ✅ **Outcome Scores**\n",
    "\n",
    "Direct outputs of agent evaluation:\n",
    "\n",
    "* `score_train`, `score_test`\n",
    "* `advantage_train`, `advantage_test`\n",
    "* `transfer_delta`, `transfer_success` *(int: 1 if advantage improved)*\n",
    "\n",
    "### ✅ **Diagnostics / Behavior Metrics**\n",
    "\n",
    "Agent behavior across episode:\n",
    "\n",
    "* `success_trades`, `action_hold_ratio`, `action_long_ratio`\n",
    "\n",
    "### ✅ **Control Parameters**\n",
    "\n",
    "* `timesteps`, `episode_steps` *(both int64)*\n",
    "\n",
    "---\n",
    "\n",
    "**This dataframe is ready** for:\n",
    "\n",
    "* Scoring (learnability, transferability, difficulty)\n",
    "* Meta-model training\n",
    "* Autoencoder or representation learning\n",
    "* Filtering based on any metric\n",
    "\n",
    "Let’s proceed to the next module you want to implement or improve. Should we work on the **meta-model enhancer** (autoencoder + predictive model) in PyTorch next?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dbdf015",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e1d6324",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from src.utils.system import boot, Notify\n",
    "from src.defaults import RANDOM_SEEDS\n",
    "from src.data.feature_pipeline import load_base_dataframe\n",
    "from experiments import check_if_experiment_exists, register_experiment ,experiment_hash\n",
    "from environments import PositionTradingEnv,PositionTradingEnvV1,PositionTradingEnvV2\n",
    "\n",
    "# ========== SYSTEM BOOT ==========\n",
    "DEVICE = boot()\n",
    "EXPERIMENT_NAME = \"trading_environment_development\"\n",
    "DEFAULT_PATH = \"data/experiments/\" + EXPERIMENT_NAME\n",
    "\n",
    "# ========== CONFIG ==========\n",
    "TICKER = \"AAPL\"\n",
    "TIMESTEPS = 100_000\n",
    "EVAL_EPISODES = 5\n",
    "N_TIMESTEPS = 120\n",
    "LOOKBACK = 0\n",
    "SEEDS = RANDOM_SEEDS\n",
    "MARKET_FEATURES = ['close']\n",
    "BENCHMARK_PATH = DEFAULT_PATH+\"/benchmark_episodes.json\"\n",
    "CHECKPOINT_DIR = DEFAULT_PATH+\"/checkpoints\"\n",
    "SCORES_DIR = DEFAULT_PATH+\"/scores\"\n",
    "META_PATH = DEFAULT_PATH+\"/meta_df.csv\"\n",
    "\n",
    "MARKET_FEATURES.sort()\n",
    "SEEDS.sort()\n",
    "\n",
    "DEVICE = boot()\n",
    "OHLCV_DF = load_base_dataframe()\n",
    "\n",
    "NOTIFICATION = Notify(EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a902650d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import hashlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Callable\n",
    "from stable_baselines3 import PPO, A2C\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from environments import PositionTradingEnv, PositionTradingEnvV1, PositionTradingEnvV2\n",
    "from data import extract_meta_features\n",
    "from scipy.stats import ttest_ind\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class TradingEnvironmentLearningQuality:\n",
    "    def __init__(self, df, benchmark_path=BENCHMARK_PATH, result_path=DEFAULT_PATH+\"/meta_df_transfer.csv\", checkpoint_dir=CHECKPOINT_DIR):\n",
    "        self.df = df\n",
    "        self.benchmark_path = benchmark_path\n",
    "        self.result_path = result_path\n",
    "        self.checkpoint_dir = checkpoint_dir\n",
    "        self.benchmark_episodes = self.load_benchmark_episodes()\n",
    "        os.makedirs(os.path.dirname(self.result_path), exist_ok=True)\n",
    "        os.makedirs(self.checkpoint_dir, exist_ok=True)\n",
    "\n",
    "    def load_benchmark_episodes(self):\n",
    "        if os.path.exists(self.benchmark_path):\n",
    "            with open(self.benchmark_path) as f:\n",
    "                return json.load(f)\n",
    "        else:\n",
    "            print(\"[INFO] Sampling benchmark episodes...\")\n",
    "            np.random.seed(0)\n",
    "            from data import sample_valid_episodes\n",
    "            ticker = self.df['symbol'].iloc[0]\n",
    "            benchmark_episodes = sample_valid_episodes(self.df[self.df['symbol'] == ticker], ticker, 120, 0, 5)\n",
    "            with open(self.benchmark_path, \"w\") as f:\n",
    "                json.dump(benchmark_episodes.tolist(), f)\n",
    "            return benchmark_episodes\n",
    "\n",
    "    def evaluate(self, ticker, env_cls, agent_cls, timesteps=TIMESTEPS, n_timesteps=N_TIMESTEPS, lookback=LOOKBACK, seeds=SEEDS,  env_config={\"market_features\":MARKET_FEATURES}, agent_config=None):\n",
    "        def generate_config_hash(config):\n",
    "            raw = json.dumps(config, sort_keys=True)\n",
    "            return hashlib.sha256(raw.encode()).hexdigest()\n",
    "\n",
    "        def save_model(model, config_full, config_hash):\n",
    "            path = os.path.join(self.checkpoint_dir, f\"agent_{config_hash}.zip\")\n",
    "            model.save(path)\n",
    "            with open(path.replace(\".zip\", \"_config.json\"), \"w\") as f:\n",
    "                json.dump(config_full, f, indent=2)\n",
    "\n",
    "        agent_name = agent_cls.__name__\n",
    "        env_version = f\"v{env_cls.__version__}\"\n",
    "        df_ticker = self.df[self.df['symbol'] == ticker].reset_index(drop=True)\n",
    "        meta_records = []\n",
    "\n",
    "        if os.path.exists(self.result_path):\n",
    "            existing = pd.read_csv(self.result_path)\n",
    "            seen_hashes = set(zip(existing['config_hash'], existing['agent_name'], existing['seed']))\n",
    "        else:\n",
    "            seen_hashes = set()\n",
    "\n",
    "        for seed in seeds:\n",
    "            for start_idx in self.benchmark_episodes:\n",
    "                test_idx = start_idx + n_timesteps\n",
    "                if test_idx + n_timesteps >= len(df_ticker):\n",
    "                    continue\n",
    "\n",
    "                config = {\n",
    "                    \"ticker\": ticker, \"train_idx\": int(start_idx), \"test_idx\": int(test_idx),\n",
    "                    \"timesteps\": timesteps, \"episode_steps\": n_timesteps,\n",
    "                    \"env_version\": env_version, \"env_config\": env_config,\n",
    "                    \"agent_config\": agent_config\n",
    "                }\n",
    "                config_hash = generate_config_hash(config)\n",
    "                if (config_hash, agent_name, seed) in seen_hashes:\n",
    "                    continue\n",
    "\n",
    "                env_train = Monitor(env_cls(df_ticker, ticker=ticker, seed=seed, start_idx=start_idx, **(env_config or {})))\n",
    "                model = agent_cls(\"MlpPolicy\", env_train, verbose=0, seed=seed, **(agent_config or {}))\n",
    "                model.learn(total_timesteps=timesteps)\n",
    "\n",
    "                score_train = self._evaluate_model(model, env_train)\n",
    "                rand_train = self._evaluate_random(env_train)\n",
    "\n",
    "                env_test = Monitor(env_cls(df_ticker, ticker=ticker, seed=seed, start_idx=test_idx, **(env_config or {})))\n",
    "                score_test = self._evaluate_model(model, env_test)\n",
    "                rand_test = self._evaluate_random(env_test)\n",
    "\n",
    "                advantage_train = score_train - rand_train\n",
    "                advantage_test = score_test - rand_test\n",
    "                transfer_delta = score_test - score_train\n",
    "\n",
    "                save_model(model, config, config_hash)\n",
    "\n",
    "                meta = extract_meta_features(df_ticker.iloc[start_idx:start_idx + n_timesteps])\n",
    "                diagnostics = self._compute_additional_metrics(env_test)\n",
    "\n",
    "                meta.update({\n",
    "                    \"config_hash\": config_hash, \"env_version\": env_version,\n",
    "                    \"agent_name\": agent_name, \"score_train\": score_train,\n",
    "                    \"score_test\": score_test, \"advantage_train\": advantage_train,\n",
    "                    \"advantage_test\": advantage_test, \"transfer_delta\": transfer_delta,\n",
    "                    \"transfer_success\": int(transfer_delta > 0), \"ticker\": ticker,\n",
    "                    \"seed\": seed, \"train_idx\": int(start_idx), \"test_idx\": int(test_idx),\n",
    "                    \"timesteps\": timesteps, \"episode_steps\": n_timesteps,\n",
    "                    **diagnostics\n",
    "                })\n",
    "                meta_records.append(meta)\n",
    "\n",
    "        result_df = pd.DataFrame(meta_records)\n",
    "        if os.path.exists(self.result_path):\n",
    "            result_df = pd.concat([pd.read_csv(self.result_path), result_df], ignore_index=True)\n",
    "        result_df.to_csv(self.result_path, index=False)\n",
    "        return result_df\n",
    "\n",
    "    def _evaluate_model(self, model, env):\n",
    "        obs, _ = env.reset()\n",
    "        done, score = False, 0\n",
    "        while not done:\n",
    "            action, _ = model.predict(obs, deterministic=True)\n",
    "            obs, reward, done, _, _ = env.step(action)\n",
    "            score += reward\n",
    "        return score\n",
    "\n",
    "    def _evaluate_random(self, env):\n",
    "        obs, _ = env.reset()\n",
    "        done, score = False, 0\n",
    "        while not done:\n",
    "            action = env.action_space.sample()\n",
    "            obs, reward, done, _, _ = env.step(action)\n",
    "            score += reward\n",
    "        return score\n",
    "\n",
    "    def _compute_additional_metrics(self, env):\n",
    "        if hasattr(env, \"env\"):  # unwrap Monitor\n",
    "            env = env.env\n",
    "        values = np.array(env.values)\n",
    "        rewards = np.array(env.rewards)\n",
    "        actions = np.array(env.actions)\n",
    "        returns = pd.Series(values).pct_change().dropna()\n",
    "        volatility = returns.std()\n",
    "        entropy = -np.sum(np.bincount(actions, minlength=2)/len(actions) * np.log2(np.bincount(actions, minlength=2)/len(actions) + 1e-9))\n",
    "        max_drawdown = (values / np.maximum.accumulate(values)).min() - 1\n",
    "        sharpe = returns.mean() / (returns.std() + 1e-9) * np.sqrt(252)\n",
    "        sortino = returns.mean() / (returns[returns < 0].std() + 1e-9) * np.sqrt(252)\n",
    "        calmar = returns.mean() / abs(max_drawdown + 1e-9)\n",
    "        success_trades = np.sum((np.diff(values) > 0) & (actions[1:] == 1)) + np.sum((np.diff(values) < 0) & (actions[1:] == 0))\n",
    "        return {\n",
    "            \"volatility\": volatility, \"entropy\": entropy, \"max_drawdown\": max_drawdown,\n",
    "            \"sharpe\": sharpe, \"sortino\": sortino, \"calmar\": calmar,\n",
    "            \"success_trades\": success_trades,\n",
    "            \"action_hold_ratio\": np.mean(actions == 0),\n",
    "            \"action_long_ratio\": np.mean(actions == 1)\n",
    "        }\n",
    "\n",
    "    def compare_environments(self, result_df, env_version_a=\"v0\", env_version_b=\"v1\"):\n",
    "        summary = result_df.groupby(\"env_version\")[[\n",
    "            \"score_train\", \"score_test\", \"advantage_train\", \"advantage_test\",\n",
    "            \"transfer_delta\", \"success_trades\", \"sharpe\", \"sortino\", \"calmar\",\n",
    "            \"max_drawdown\", \"volatility\", \"action_hold_ratio\", \"action_long_ratio\"\n",
    "        ]].agg([\"mean\", \"std\", \"median\"]).T\n",
    "\n",
    "        mean_df = summary.xs('mean', level=1)\n",
    "        diffs = (mean_df[env_version_a] - mean_df[env_version_b]).abs().sort_values(ascending=False)\n",
    "        mean_df.loc[diffs.index].plot.bar(\n",
    "            figsize=(14, 6),\n",
    "            title=f\"Env {env_version_a} vs {env_version_b} – Mean metric comparison (sorted by difference)\",\n",
    "            ylabel=\"Mean Value\"\n",
    "        )\n",
    "\n",
    "        metrics = [\"score_test\", \"advantage_test\", \"transfer_delta\", \"sharpe\", \"sortino\"]\n",
    "        for metric in metrics:\n",
    "            v0 = result_df[result_df.env_version == env_version_a][metric]\n",
    "            v1 = result_df[result_df.env_version == env_version_b][metric]\n",
    "            stat, pval = ttest_ind(v0, v1)\n",
    "            print(f\"{metric}: p={pval:.4f} | {env_version_a}_mean={v0.mean():.3f}, {env_version_b}_mean={v1.mean():.3f}\")\n",
    "            sns.boxplot(data=result_df, x=\"env_version\", y=metric)\n",
    "            plt.title(f\"{metric} by Environment Version\")\n",
    "            plt.show()\n",
    "\n",
    "        result_df['composite_score'] = (\n",
    "            result_df['advantage_test'] +\n",
    "            result_df['transfer_delta'] +\n",
    "            result_df['sharpe'] * 5 -\n",
    "            result_df['max_drawdown'] * 10\n",
    "        )\n",
    "        return result_df, result_df.groupby(\"env_version\")[\"composite_score\"].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea433d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Callable\n",
    "from stable_baselines3 import PPO, A2C\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from environments import PositionTradingEnv, PositionTradingEnvV1, PositionTradingEnvV2\n",
    "from data import extract_meta_features\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "class TradingEnvironmentBattleground:\n",
    "    def __init__(self, \n",
    "                 df: pd.DataFrame,\n",
    "                 benchmark_path: str,\n",
    "                 result_path: str,\n",
    "                 checkpoint_dir: str,\n",
    "                 seeds: list,\n",
    "                 timesteps: int,\n",
    "                 n_timesteps: int,\n",
    "                 lookback: int,\n",
    "                 agents: list,\n",
    "                 envs: list,\n",
    "                 market_features: list):\n",
    "        self.df = df\n",
    "        self.benchmark_path = benchmark_path\n",
    "        self.result_path = result_path\n",
    "        self.checkpoint_dir = checkpoint_dir\n",
    "        self.seeds = seeds\n",
    "        self.timesteps = timesteps\n",
    "        self.n_timesteps = n_timesteps\n",
    "        self.lookback = lookback\n",
    "        self.agents = agents\n",
    "        self.envs = envs\n",
    "        self.market_features = market_features\n",
    "\n",
    "    def load_benchmark_episodes(self, ticker, eval_episodes):\n",
    "        if os.path.exists(self.benchmark_path):\n",
    "            with open(self.benchmark_path) as f:\n",
    "                self.benchmark_episodes = json.load(f)\n",
    "        else:\n",
    "            print(\"[INFO] Sampling benchmark episodes...\")\n",
    "            np.random.seed(0)\n",
    "            from src.utils.episode_sampling import sample_valid_episodes\n",
    "            self.benchmark_episodes = sample_valid_episodes(\n",
    "                self.df[self.df['symbol'] == ticker], ticker, self.n_timesteps, self.lookback, eval_episodes)\n",
    "            with open(self.benchmark_path, \"w\") as f:\n",
    "                json.dump(self.benchmark_episodes, f)\n",
    "        print(\"[INFO] Episódios de benchmark carregados.\")\n",
    "\n",
    "    def _generate_config_hash(self, config):\n",
    "        return hashlib.sha256(json.dumps(config, sort_keys=True).encode()).hexdigest()\n",
    "\n",
    "    def _compute_additional_metrics(self, env):\n",
    "        if hasattr(env, \"env\"):  # unwrap Monitor\n",
    "            env = env.env\n",
    "        values = np.array(env.values)\n",
    "        rewards = np.array(env.rewards)\n",
    "        actions = np.array(env.actions)\n",
    "        returns = pd.Series(values).pct_change().dropna()\n",
    "        return {\n",
    "            \"volatility\": returns.std(),\n",
    "            \"entropy\": -np.sum(np.bincount(actions, minlength=2)/len(actions) * np.log2(np.bincount(actions, minlength=2)/len(actions) + 1e-9)),\n",
    "            \"max_drawdown\": (values / np.maximum.accumulate(values)).min() - 1,\n",
    "            \"sharpe\": returns.mean() / (returns.std() + 1e-9) * np.sqrt(252),\n",
    "            \"sortino\": returns.mean() / (returns[returns < 0].std() + 1e-9) * np.sqrt(252),\n",
    "            \"calmar\": returns.mean() / abs((values / np.maximum.accumulate(values)).min() - 1 + 1e-9),\n",
    "            \"success_trades\": np.sum((np.diff(values) > 0) & (actions[1:] == 1)) + np.sum((np.diff(values) < 0) & (actions[1:] == 0)),\n",
    "            \"action_hold_ratio\": np.mean(actions == 0),\n",
    "            \"action_long_ratio\": np.mean(actions == 1)\n",
    "        }\n",
    "\n",
    "    def evaluate(self, ticker: str):\n",
    "        df_ticker = self.df[self.df['symbol'] == ticker].reset_index(drop=True)\n",
    "        os.makedirs(self.checkpoint_dir, exist_ok=True)\n",
    "        os.makedirs(os.path.dirname(self.result_path), exist_ok=True)\n",
    "        meta_records = []\n",
    "\n",
    "        if os.path.exists(self.result_path):\n",
    "            existing = pd.read_csv(self.result_path)\n",
    "            seen_hashes = set(zip(existing['config_hash'], existing['agent_name'], existing['seed']))\n",
    "        else:\n",
    "            seen_hashes = set()\n",
    "\n",
    "        for env_cls in self.envs:\n",
    "            for agent_cls in self.agents:\n",
    "                for seed in self.seeds:\n",
    "                    for start_idx in self.benchmark_episodes:\n",
    "                        test_idx = start_idx + self.n_timesteps\n",
    "                        if test_idx + self.n_timesteps >= len(df_ticker):\n",
    "                            continue\n",
    "\n",
    "                        config = {\n",
    "                            \"ticker\": ticker,\n",
    "                            \"train_idx\": int(start_idx),\n",
    "                            \"test_idx\": int(test_idx),\n",
    "                            \"timesteps\": self.timesteps,\n",
    "                            \"episode_steps\": self.n_timesteps,\n",
    "                            \"env_version\": f\"v{env_cls.__version__}\",\n",
    "                            \"env_config\": {\"market_features\": self.market_features},\n",
    "                            \"agent_config\": {},\n",
    "                        }\n",
    "                        config_hash = self._generate_config_hash(config)\n",
    "                        if (config_hash, agent_cls.__name__, seed) in seen_hashes:\n",
    "                            continue\n",
    "\n",
    "                        env_train = Monitor(env_cls(df_ticker, ticker=ticker, seed=seed, start_idx=start_idx, market_features=self.market_features))\n",
    "                        model = agent_cls(\"MlpPolicy\", env_train, verbose=0, seed=seed)\n",
    "                        model.learn(total_timesteps=self.timesteps)\n",
    "\n",
    "                        def eval_agent(env):\n",
    "                            obs, _ = env.reset()\n",
    "                            done, score = False, 0\n",
    "                            while not done:\n",
    "                                action, _ = model.predict(obs, deterministic=True)\n",
    "                                obs, reward, done, _, _ = env.step(action)\n",
    "                                score += reward\n",
    "                            return score\n",
    "\n",
    "                        def eval_random(env):\n",
    "                            obs, _ = env.reset()\n",
    "                            done, score = False, 0\n",
    "                            while not done:\n",
    "                                action = env.action_space.sample()\n",
    "                                obs, reward, done, _, _ = env.step(action)\n",
    "                                score += reward\n",
    "                            return score\n",
    "\n",
    "                        score_train = eval_agent(env_train)\n",
    "                        rand_train = eval_random(env_train)\n",
    "\n",
    "                        env_test = Monitor(env_cls(df_ticker, ticker=ticker, seed=seed, start_idx=test_idx, market_features=self.market_features))\n",
    "                        score_test = eval_agent(env_test)\n",
    "                        rand_test = eval_random(env_test)\n",
    "\n",
    "                        advantage_train = score_train - rand_train\n",
    "                        advantage_test = score_test - rand_test\n",
    "                        transfer_delta = score_test - score_train\n",
    "\n",
    "                        meta = extract_meta_features(df_ticker.iloc[start_idx:start_idx + self.n_timesteps])\n",
    "                        diagnostics = self._compute_additional_metrics(env_test)\n",
    "\n",
    "                        meta.update({\n",
    "                            \"config_hash\": config_hash,\n",
    "                            \"env_version\": f\"v{env_cls.__version__}\",\n",
    "                            \"agent_name\": agent_cls.__name__,\n",
    "                            \"score_train\": score_train,\n",
    "                            \"score_test\": score_test,\n",
    "                            \"advantage_train\": advantage_train,\n",
    "                            \"advantage_test\": advantage_test,\n",
    "                            \"transfer_delta\": transfer_delta,\n",
    "                            \"transfer_success\": int(transfer_delta > 0),\n",
    "                            \"ticker\": ticker,\n",
    "                            \"train_idx\": int(start_idx),\n",
    "                            \"test_idx\": int(test_idx),\n",
    "                            \"timesteps\": self.timesteps,\n",
    "                            \"episode_steps\": self.n_timesteps,\n",
    "                            \"seed\": seed,\n",
    "                            **diagnostics\n",
    "                        })\n",
    "\n",
    "                        meta_records.append(meta)\n",
    "\n",
    "        result_df = pd.DataFrame(meta_records)\n",
    "        if os.path.exists(self.result_path):\n",
    "            result_df = pd.concat([pd.read_csv(self.result_path), result_df], ignore_index=True)\n",
    "        result_df.to_csv(self.result_path, index=False)\n",
    "        print(\"[INFO] Evaluation complete.\")\n",
    "        return result_df\n",
    "\n",
    "    def compare_environments(self, result_df, env_version_a=\"v0\", env_version_b=\"v1\"):\n",
    "        summary = result_df.groupby(\"env_version\")[[\n",
    "            \"score_train\", \"score_test\", \"advantage_train\", \"advantage_test\",\n",
    "            \"transfer_delta\", \"success_trades\", \"sharpe\", \"sortino\", \"calmar\",\n",
    "            \"max_drawdown\", \"volatility\", \"action_hold_ratio\", \"action_long_ratio\"\n",
    "        ]].agg([\"mean\", \"std\", \"median\"]).T\n",
    "\n",
    "        mean_df = summary.xs('mean', level=1)\n",
    "        diffs = (mean_df[env_version_a] - mean_df[env_version_b]).abs().sort_values(ascending=False)\n",
    "\n",
    "        mean_df.loc[diffs.index].plot.bar(\n",
    "            figsize=(14, 6),\n",
    "            title=f\"Env {env_version_a} vs {env_version_b} – Mean metric comparison\",\n",
    "            ylabel=\"Mean Value\"\n",
    "        )\n",
    "\n",
    "        metrics = [\"score_test\", \"advantage_test\", \"transfer_delta\", \"sharpe\", \"sortino\"]\n",
    "        for metric in metrics:\n",
    "            v0 = result_df[result_df.env_version == env_version_a][metric]\n",
    "            v1 = result_df[result_df.env_version == env_version_b][metric]\n",
    "            stat, pval = ttest_ind(v0, v1)\n",
    "            print(f\"{metric}: p={pval:.4f} | {env_version_a}_mean={v0.mean():.3f}, {env_version_b}_mean={v1.mean():.3f}\")\n",
    "\n",
    "        for metric in metrics:\n",
    "            sns.boxplot(data=result_df, x=\"env_version\", y=metric)\n",
    "            plt.title(f\"{metric} by Environment Version\")\n",
    "            plt.show()\n",
    "\n",
    "        result_df['composite_score'] = (\n",
    "            result_df['advantage_test'] +\n",
    "            result_df['transfer_delta'] +\n",
    "            result_df['sharpe'] * 5 -\n",
    "            result_df['max_drawdown'] * 10\n",
    "        )\n",
    "\n",
    "        return result_df, result_df.groupby(\"env_version\")[\"composite_score\"].mean()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
