{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fb32084",
   "metadata": {},
   "source": [
    "Perfect. Here's a full **implementation plan** to build an AI trading system that mirrors how professional traders operate ‚Äî including **statistical validation and confidence estimation** of its performance.\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Goal\n",
    "\n",
    "Build a **self-aware AI trading system** that can:\n",
    "\n",
    "1. Specialize and trade only in predictable environments.\n",
    "2. Adapt across market regimes.\n",
    "3. Monitor its own edge and deactivate when performance decays.\n",
    "4. Backtest and validate statistically that it adds value beyond random chance.\n",
    "\n",
    "---\n",
    "\n",
    "## üîß Implementation Blueprint\n",
    "\n",
    "### üì¶ 1. **Data Preparation**\n",
    "\n",
    "#### A. Split Market into Rolling Windows\n",
    "\n",
    "* Train: `T_train` (e.g., 2 months)\n",
    "* Test: `T_test` (next month)\n",
    "* Repeat walkforward stock-by-stock\n",
    "\n",
    "#### B. Feature Engineering (per stock)\n",
    "\n",
    "* Technical indicators (volatility, momentum)\n",
    "* Chaos indicators (entropy, Hurst, recurrence)\n",
    "* Regime labels (from market clustering or HMM)\n",
    "* Sentiment (optional)\n",
    "\n",
    "---\n",
    "\n",
    "### ü§ñ 2. **Agent Training per Episode**\n",
    "\n",
    "Train **PPO** and optionally **A2C** using:\n",
    "\n",
    "* Our `RecurrentPPO + TransformerPolicy`\n",
    "* `SequenceAwareNormAbsMoveEnv`\n",
    "* Early stopping if reward plateaus\n",
    "* Use `Monitor` wrapper to track episode stats\n",
    "\n",
    "---\n",
    "\n",
    "### üè∑Ô∏è 3. **Label Advantage for Predictability**\n",
    "\n",
    "Evaluate each stock-month:\n",
    "\n",
    "* Compute agent reward vs. random agent:\n",
    "\n",
    "  $$\n",
    "  \\text{Advantage} = \\mathbb{E}[R_{\\text{agent}} - R_{\\text{random}}]\n",
    "  $$\n",
    "* Run **t-test** and **Mann-Whitney U test**:\n",
    "\n",
    "  * `p_value < 0.05` ‚áí statistically significant edge\n",
    "  * Log these in the metadata\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ö†Ô∏è 4. **Only Keep Statistically Significant Runs**\n",
    "\n",
    "* Filter episodes where agent significantly beats random.\n",
    "* Label those stock-months as **\"predictable.\"**\n",
    "* Store mean/variance/confidence intervals for advantage.\n",
    "\n",
    "---\n",
    "\n",
    "### üìà 5. **Meta-Model: Predictable Environment Classifier**\n",
    "\n",
    "* Train a contrastive classifier:\n",
    "\n",
    "  * Input: Meta-features (residuals, entropy, etc.)\n",
    "  * Target: A > B if `Advantage_A > Advantage_B`\n",
    "* Use:\n",
    "\n",
    "  * Logistic Regression or LightGBM\n",
    "  * CV-AUC as performance metric\n",
    "  * Optionally include `Agent Agreement Score` (PPO vs A2C)\n",
    "\n",
    "---\n",
    "\n",
    "### üîÅ 6. **Walk-Forward Pipeline**\n",
    "\n",
    "For each window:\n",
    "\n",
    "1. **Train agents** and evaluate advantage\n",
    "2. **Update predictability model**\n",
    "3. **Predict where to deploy agent next window**\n",
    "4. **Deploy agent only in predicted-advantageous environments**\n",
    "\n",
    "---\n",
    "\n",
    "### üìä 7. **Statistical Confidence System**\n",
    "\n",
    "Every time a trade decision is made, store:\n",
    "\n",
    "* Current episode meta-features\n",
    "* Agent's predicted advantage\n",
    "* Historical advantage CI from similar episodes\n",
    "* Disagreement between PPO vs A2C\n",
    "\n",
    "This enables confidence scores like:\n",
    "\n",
    "```python\n",
    "if p_value < 0.01 and agent_agreement > 0.8:\n",
    "    trust_score = \"HIGH\"\n",
    "elif p_value < 0.05:\n",
    "    trust_score = \"MODERATE\"\n",
    "else:\n",
    "    trust_score = \"LOW\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üßæ 8. **Evaluation Metrics per Walk**\n",
    "\n",
    "For each test window:\n",
    "\n",
    "* Sharpe ratio vs. random\n",
    "* Hit rate (profitable trades / total)\n",
    "* Advantage significance count\n",
    "* Meta-model AUC / accuracy\n",
    "* Breakdown by regime\n",
    "\n",
    "We store these in a dataframe for long-term system health monitoring.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Optional Diagnostics\n",
    "\n",
    "* **Visualize attention weights** of Transformer to explain decisions.\n",
    "* **Track per-agent equity curve** and max drawdown.\n",
    "* Highlight statistically unreliable runs (p > 0.05) in red.\n",
    "\n",
    "---\n",
    "\n",
    "## üìÅ Output Artifacts\n",
    "\n",
    "| File                       | Description                                  |\n",
    "| -------------------------- | -------------------------------------------- |\n",
    "| `advantage_labels.pkl`     | Agent vs Random reward stats per episode     |\n",
    "| `meta_features.csv`        | Per stock-month feature set                  |\n",
    "| `predictability_model.pkl` | Trained contrastive classifier               |\n",
    "| `walkforward_report.md`    | Summary of all periods with confidence stats |\n",
    "| `trust_scores.csv`         | Deployment period trust flags                |\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Final Benefits\n",
    "\n",
    "This system behaves like a **professional trader**:\n",
    "\n",
    "* Only trades when it knows it can win\n",
    "* Tracks when it‚Äôs losing edge\n",
    "* Has statistical proof to back up decisions\n",
    "* Can say ‚ÄúI don‚Äôt know‚Äù and step out\n",
    "* Improves itself over time\n",
    "\n",
    "---\n",
    "\n",
    "Would you like this pipeline turned into executable Python code? I can build it modular, resumable, and log everything per window/stock.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "77b1c105",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "56c03131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.utils.system import boot\n",
    "from src.defaults import TOP2_STOCK_BY_SECTOR, RANDOM_SEEDS\n",
    "from src.data.feature_pipeline import load_base_dataframe\n",
    "\n",
    "DEVICE = boot()\n",
    "OHLCV_DF = load_base_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "49b52980",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hurst import compute_Hc\n",
    "from pyts.image import RecurrencePlot\n",
    "\n",
    "# PROJECT SETUP ==================================\n",
    "TICKERS = OHLCV_DF['symbol'].unique()#TOP2_STOCK_BY_SECTOR #[\"TSLA\"]\n",
    "CHAOS_THRESHOLD = 0.45\n",
    "WINDOW_SIZE = 120\n",
    "ENTROPY_BINS=10\n",
    "STEP_SIZE = 20\n",
    "MAX_LEN = 64\n",
    "LOOKBACK= 40\n",
    "ROLLING = 5\n",
    "SEEDS = RANDOM_SEEDS[:5]\n",
    "BASIC_FEATURES=[\"close\"\t, #Core price for reward and trend awareness\n",
    "\"volume\",#\tVolume for activity level\n",
    "\"candle_body\",#\tPrice strength (close-open)\n",
    "\"upper_shadow\",#\tWick size = volatility / exhaustion\n",
    "\"lower_shadow\",#\tSame as above\n",
    "\"order_flow\",#\tFlow = pressure indicator (buy/sell imbalance)\n",
    "\"price_change\",#\tPrice momentum short term\n",
    "\"volatility\",#\tRecent price dispersion\n",
    "\"momentum\",#\tRolling price trend\n",
    "\"vix_norm\",#\tImplied market risk normalized\n",
    "\"market_return_1d\"#\tMarket regime alignment\n",
    "]\n",
    "\n",
    "# That‚Äôs 11 columns, enough to:\n",
    "# * See price movement\n",
    "# * Detect regime shifts\n",
    "# * Respond to risk\n",
    "\n",
    "# Second Round:\n",
    "# * overnight_price_change ‚Üí if overnight gaps matter to your strategy\n",
    "# * trade_count_change ‚Üí intraday activity shifts\n",
    "# * sp500_norm ‚Üí macro regime normalization\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "627e052d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 - walkforward\n",
    "import pandas as pd\n",
    "import ace_tools_open as tools\n",
    "from typing import List, Tuple\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "\n",
    "\n",
    "def generate_walkforward_windows(\n",
    "    df: pd.DataFrame,\n",
    "    symbol_col: str = \"symbol\",\n",
    "    date_col: str = \"date\",\n",
    "    start_date: str = \"2023-01-01\",\n",
    "    end_date: str = \"2025-05-01\",\n",
    "    train_months: int = 2,\n",
    "    test_months: int = 1,\n",
    "    min_days_per_window: int = 20,\n",
    "    max_feature_rolling_window:int=5,\n",
    "    lookback_buffer_days: int = 30\n",
    "\n",
    ") -> List[dict]:\n",
    "    \"\"\"\n",
    "    Splits a dataframe into walkforward windows (train and test) per symbol.\n",
    "\n",
    "    Parameters:\n",
    "        df: Full OHLCV dataframe with at least [date_col, symbol_col]\n",
    "        symbol_col: Name of the symbol column\n",
    "        date_col: Name of the date column\n",
    "        start_date: Start date of walkforward (string or datetime)\n",
    "        end_date: End date of walkforward (string or datetime)\n",
    "        train_months: Number of months in training window\n",
    "        test_months: Number of months in test window\n",
    "        min_days_per_window: Minimum number of rows to consider a window valid\n",
    "\n",
    "    Returns:\n",
    "        List of window dicts with keys:\n",
    "            - symbol\n",
    "            - train_start\n",
    "            - train_end\n",
    "            - test_start\n",
    "            - test_end\n",
    "            - train_df\n",
    "            - test_df\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df[date_col] = pd.to_datetime(df[date_col])\n",
    "    start_date = pd.to_datetime(start_date)\n",
    "    end_date = pd.to_datetime(end_date)\n",
    "\n",
    "    windows = []\n",
    "    symbols = df[symbol_col].unique()\n",
    "\n",
    "    for symbol in symbols:\n",
    "        symbol_df = df[df[symbol_col] == symbol].sort_values(date_col).reset_index()\n",
    "        current_start = start_date\n",
    "\n",
    "        while True:\n",
    "            # Train window with padded lookback\n",
    "            episode_start = current_start\n",
    "            buffer_size = lookback_buffer_days + max_feature_rolling_window\n",
    "            episode_idx = symbol_df[symbol_df[date_col] >= current_start].index[0]\n",
    "            #print(current_start,episode_idx)\n",
    "            train_start_idx = episode_idx - buffer_size\n",
    "\n",
    "            if train_start_idx < 0:\n",
    "                current_start = current_start + relativedelta(months=1)  # skip this episode\n",
    "                continue\n",
    "\n",
    "            train_start = symbol_df.iloc[train_start_idx][date_col]\n",
    "            train_end = episode_start + relativedelta(months=train_months)\n",
    "            \n",
    "            \n",
    "            test_start_idx = symbol_df[symbol_df[date_col] >= train_end].index[0] - buffer_size\n",
    "            \n",
    "            if test_start_idx < 0:\n",
    "                break\n",
    "\n",
    "            test_start = symbol_df.iloc[test_start_idx][date_col]\n",
    "            test_end = train_end + relativedelta(months=test_months)\n",
    "            \n",
    "            if test_end > end_date:\n",
    "                break\n",
    "\n",
    "            train_df = symbol_df[(symbol_df[date_col] >= train_start) & (symbol_df[date_col] < train_end)]\n",
    "            test_df = symbol_df[(symbol_df[date_col] >= test_start) & (symbol_df[date_col] < test_end)]\n",
    "            #print(len(train_df),len(test_df))\n",
    "            #print(len(test_df))\n",
    "            if len(train_df) >= min_days_per_window and len(test_df) >= min_days_per_window:\n",
    "                windows.append({\n",
    "                    \"symbol\": symbol,\n",
    "                    \"train_start\": train_start,\n",
    "                    \"train_end\": train_end,\n",
    "                    \"test_start\": test_start,\n",
    "                    \"test_end\": test_end,\n",
    "                    \"true_train_start\": episode_start,\n",
    "                    \"true_test_start\": train_end,\n",
    "                    \"train_df\": train_df,\n",
    "                    \"test_df\": test_df\n",
    "                })\n",
    "\n",
    "            current_start = test_end\n",
    "\n",
    "    def visualize():\n",
    "        display_df = pd.DataFrame([{\n",
    "            \"symbol\": w[\"symbol\"],\n",
    "            \"train_start\": w[\"train_start\"],\n",
    "            \"true_train_start\": w[\"true_train_start\"],\n",
    "            \"train_end\": w[\"train_end\"],\n",
    "            \"test_start\": w[\"test_start\"],\n",
    "            \"test_end\": w[\"test_end\"],\n",
    "             \"true_train_start\": episode_start,\n",
    "            \"true_test_start\": train_end,\n",
    "            \"train_days\": len(w[\"train_df\"]),\n",
    "            \"test_days\": len(w[\"test_df\"])\n",
    "        } for w in windows])\n",
    "       \n",
    "        tools.display_dataframe_to_user(name=\"Walkforward Windows (Buffered)\", dataframe=display_df)\n",
    "\n",
    "    return windows, visualize\n",
    "\n",
    "from scipy.stats import entropy, kurtosis\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Utility functions\n",
    "def rolling_volatility(series: pd.Series, window: int = 10):\n",
    "    return series.rolling(window).std()\n",
    "\n",
    "def rolling_momentum(series: pd.Series, window: int = 10):\n",
    "    return series.diff(window)\n",
    "\n",
    "def calculate_hurst_exponent(ts: np.ndarray, max_lag: int = 20):\n",
    "    lags = range(2, max_lag)\n",
    "    tau = [np.std(np.subtract(ts[lag:], ts[:-lag])) for lag in lags]\n",
    "    poly = np.polyfit(np.log(lags), np.log(tau), 1)\n",
    "    return poly[0]\n",
    "\n",
    "def calculate_chaos_metrics(df: pd.DataFrame) -> dict:\n",
    "    price = df['close'].values\n",
    "    returns = df['close'].pct_change().dropna()\n",
    "\n",
    "    return {\n",
    "        \"std\": np.std(returns),\n",
    "        \"kurt\": kurtosis(returns),\n",
    "        \"entropy\": entropy(np.histogram(returns, bins=10)[0] + 1),\n",
    "        \"hurst\": calculate_hurst_exponent(price),\n",
    "        \"adf_pval\": adfuller(returns)[1] if len(returns) > 10 else np.nan,\n",
    "    }\n",
    "\n",
    "def extract_features_per_window(windows: List[dict], feature_cols=BASIC_FEATURES) -> pd.DataFrame:\n",
    "    feature_rows = []\n",
    "\n",
    "    for w in windows:\n",
    "        train_df = w['train_df'].copy()\n",
    "        test_df = w['test_df'].copy()\n",
    "        train_df['Close']= train_df['close']\n",
    "        test_df['Close']= test_df['close']\n",
    "        meta = {\n",
    "            \"symbol\": w['symbol'],\n",
    "            \"train_start\": w['train_start'],\n",
    "            \"train_end\": w['train_end'],\n",
    "            \"test_start\": w['test_start'],\n",
    "            \"test_end\": w['test_end'],\n",
    "        }\n",
    "\n",
    "        # === Chaos features from training window ===\n",
    "        chaos_features = calculate_chaos_metrics(train_df)\n",
    "        meta.update(chaos_features)\n",
    "\n",
    "        # === Rolling Features ===\n",
    "        window_size = 5 if len(train_df) >= ROLLING else max(2, len(train_df))\n",
    "\n",
    "        train_df['volatility'] = train_df['close'].rolling(window_size).std()\n",
    "        train_df['momentum'] = train_df['close'].diff(window_size)\n",
    "\n",
    "        test_df['volatility'] = test_df['close'].rolling(window_size).std()\n",
    "        test_df['momentum'] = test_df['close'].diff(window_size)\n",
    "\n",
    "        # Fallback if iloc[-1] is NaN\n",
    "        meta[\"volatility\"] = train_df['volatility'].dropna().iloc[-1] if train_df['volatility'].dropna().any() else 0.0\n",
    "        meta[\"momentum\"] = train_df['momentum'].dropna().iloc[-1] if train_df['momentum'].dropna().any() else 0.0\n",
    "\n",
    "        scaler = RobustScaler()\n",
    "     \n",
    "        train_df.dropna(inplace=True)\n",
    "        test_df.dropna(inplace=True)\n",
    "     \n",
    "        train_df[feature_cols] = scaler.fit_transform(train_df[feature_cols])\n",
    "        test_df[feature_cols] = scaler.transform(test_df[feature_cols])\n",
    "        #print(train_df.iloc[40]['date'])\n",
    "        # === Patch into original dicts ===\n",
    "        w['train_df'] = train_df.dropna()\n",
    "        w['test_df'] = test_df.dropna()\n",
    "        # === Patch into original dicts ===\n",
    "        #w['train_df'] = train_df.dropna(0)\n",
    "        #w['test_df'] = test_df.dropna(0)\n",
    "        \n",
    "        #scaler = RobustScaler()\n",
    "        feature_rows.append(meta)\n",
    "\n",
    "    feature_df = pd.DataFrame(feature_rows)\n",
    "\n",
    "    def visualize():\n",
    "        tools.display_dataframe_to_user(name=\"Meta-Features per Stock Episode\", dataframe=feature_df)\n",
    "\n",
    "    return feature_df, visualize\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "69feb907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Walkforward Windows (Buffered)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<!--| quarto-html-table-processing: none -->\n",
       "<table id=\"itables_fed3159d_4dad_4891_91b0_ddf9d1d15379\"><tbody><tr>\n",
       "    <td style=\"vertical-align:middle; text-align:left\">\n",
       "    <a href=https://mwouts.github.io/itables/><svg class=\"main-svg\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n",
       "width=\"64\" viewBox=\"0 0 500 400\" style=\"font-family: 'Droid Sans', sans-serif;\">\n",
       "    <g style=\"fill:#d9d7fc\">\n",
       "        <path d=\"M100,400H500V357H100Z\" />\n",
       "        <path d=\"M100,300H400V257H100Z\" />\n",
       "        <path d=\"M0,200H400V157H0Z\" />\n",
       "        <path d=\"M100,100H500V57H100Z\" />\n",
       "        <path d=\"M100,350H500V307H100Z\" />\n",
       "        <path d=\"M100,250H400V207H100Z\" />\n",
       "        <path d=\"M0,150H400V107H0Z\" />\n",
       "        <path d=\"M100,50H500V7H100Z\" />\n",
       "    </g>\n",
       "    <g style=\"fill:#1a1366;stroke:#1a1366;\">\n",
       "   <rect x=\"100\" y=\"7\" width=\"400\" height=\"43\">\n",
       "    <animate\n",
       "      attributeName=\"width\"\n",
       "      values=\"0;400;0\"\n",
       "      dur=\"5s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "      <animate\n",
       "      attributeName=\"x\"\n",
       "      values=\"100;100;500\"\n",
       "      dur=\"5s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "  </rect>\n",
       "        <rect x=\"0\" y=\"107\" width=\"400\" height=\"43\">\n",
       "    <animate\n",
       "      attributeName=\"width\"\n",
       "      values=\"0;400;0\"\n",
       "      dur=\"3.5s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "    <animate\n",
       "      attributeName=\"x\"\n",
       "      values=\"0;0;400\"\n",
       "      dur=\"3.5s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "  </rect>\n",
       "        <rect x=\"100\" y=\"207\" width=\"300\" height=\"43\">\n",
       "    <animate\n",
       "      attributeName=\"width\"\n",
       "      values=\"0;300;0\"\n",
       "      dur=\"3s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "    <animate\n",
       "      attributeName=\"x\"\n",
       "      values=\"100;100;400\"\n",
       "      dur=\"3s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "  </rect>\n",
       "        <rect x=\"100\" y=\"307\" width=\"400\" height=\"43\">\n",
       "    <animate\n",
       "      attributeName=\"width\"\n",
       "      values=\"0;400;0\"\n",
       "      dur=\"4s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "      <animate\n",
       "      attributeName=\"x\"\n",
       "      values=\"100;100;500\"\n",
       "      dur=\"4s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "  </rect>\n",
       "        <g style=\"fill:transparent;stroke-width:8; stroke-linejoin:round\" rx=\"5\">\n",
       "            <g transform=\"translate(45 50) rotate(-45)\">\n",
       "                <circle r=\"33\" cx=\"0\" cy=\"0\" />\n",
       "                <rect x=\"-8\" y=\"32\" width=\"16\" height=\"30\" />\n",
       "            </g>\n",
       "\n",
       "            <g transform=\"translate(450 152)\">\n",
       "                <polyline points=\"-15,-20 -35,-20 -35,40 25,40 25,20\" />\n",
       "                <rect x=\"-15\" y=\"-40\" width=\"60\" height=\"60\" />\n",
       "            </g>\n",
       "\n",
       "            <g transform=\"translate(50 352)\">\n",
       "                <polygon points=\"-35,-5 0,-40 35,-5\" />\n",
       "                <polygon points=\"-35,10 0,45 35,10\" />\n",
       "            </g>\n",
       "\n",
       "            <g transform=\"translate(75 250)\">\n",
       "                <polyline points=\"-30,30 -60,0 -30,-30\" />\n",
       "                <polyline points=\"0,30 -30,0 0,-30\" />\n",
       "            </g>\n",
       "\n",
       "            <g transform=\"translate(425 250) rotate(180)\">\n",
       "                <polyline points=\"-30,30 -60,0 -30,-30\" />\n",
       "                <polyline points=\"0,30 -30,0 0,-30\" />\n",
       "            </g>\n",
       "        </g>\n",
       "    </g>\n",
       "</svg>\n",
       "</a>\n",
       "    Loading ITables v2.4.0 from the internet...\n",
       "    (need <a href=https://mwouts.github.io/itables/troubleshooting.html>help</a>?)</td>\n",
       "    </tr></tbody></table>\n",
       "<link href=\"https://www.unpkg.com/dt_for_itables@2.3.2/dt_bundle.css\" rel=\"stylesheet\">\n",
       "<script type=\"module\">\n",
       "    import { ITable, jQuery as $ } from 'https://www.unpkg.com/dt_for_itables@2.3.2/dt_bundle.js';\n",
       "\n",
       "    document.querySelectorAll(\"#itables_fed3159d_4dad_4891_91b0_ddf9d1d15379:not(.dataTable)\").forEach(table => {\n",
       "        if (!(table instanceof HTMLTableElement))\n",
       "            return;\n",
       "\n",
       "        let dt_args = {\"layout\": {\"topStart\": null, \"topEnd\": null, \"bottomStart\": null, \"bottomEnd\": null}, \"classes\": [\"display\", \"nowrap\"], \"order\": [], \"text_in_header_can_be_selected\": true, \"style\": {\"table-layout\": \"auto\", \"width\": \"auto\", \"margin\": \"auto\", \"caption-side\": \"bottom\"}, \"table_html\": \"<table><thead>\\n    <tr style=\\\"text-align: right;\\\">\\n      \\n      <th>symbol</th>\\n      <th>train_start</th>\\n      <th>true_train_start</th>\\n      <th>train_end</th>\\n      <th>test_start</th>\\n      <th>test_end</th>\\n      <th>true_test_start</th>\\n      <th>train_days</th>\\n      <th>test_days</th>\\n    </tr>\\n  </thead></table>\", \"data_json\": \"[[\\\"AAPL\\\", \\\"2022-10-27\\\", \\\"2025-04-01\\\", \\\"2023-03-01\\\", \\\"2022-12-22\\\", \\\"2023-04-01\\\", \\\"2025-06-01\\\", 79, 63], [\\\"AAPL\\\", \\\"2023-01-27\\\", \\\"2025-04-01\\\", \\\"2023-06-01\\\", \\\"2023-03-28\\\", \\\"2023-07-01\\\", \\\"2025-06-01\\\", 81, 61], [\\\"AAPL\\\", \\\"2023-04-27\\\", \\\"2025-04-01\\\", \\\"2023-09-01\\\", \\\"2023-06-29\\\", \\\"2023-10-01\\\", \\\"2025-06-01\\\", 83, 60], [\\\"AAPL\\\", \\\"2023-07-28\\\", \\\"2025-04-01\\\", \\\"2023-12-01\\\", \\\"2023-09-28\\\", \\\"2024-01-01\\\", \\\"2025-06-01\\\", 83, 60], [\\\"AAPL\\\", \\\"2023-10-26\\\", \\\"2025-04-01\\\", \\\"2024-03-01\\\", \\\"2023-12-26\\\", \\\"2024-04-01\\\", \\\"2025-06-01\\\", 81, 60], [\\\"AAPL\\\", \\\"2024-01-25\\\", \\\"2025-04-01\\\", \\\"2024-06-01\\\", \\\"2024-03-28\\\", \\\"2024-07-01\\\", \\\"2025-06-01\\\", 84, 59], [\\\"AAPL\\\", \\\"2024-04-25\\\", \\\"2025-04-01\\\", \\\"2024-09-01\\\", \\\"2024-06-28\\\", \\\"2024-10-01\\\", \\\"2025-06-01\\\", 84, 60], [\\\"AAPL\\\", \\\"2024-07-29\\\", \\\"2025-04-01\\\", \\\"2024-12-01\\\", \\\"2024-09-27\\\", \\\"2025-01-01\\\", \\\"2025-06-01\\\", 83, 61], [\\\"AAPL\\\", \\\"2024-10-28\\\", \\\"2025-04-01\\\", \\\"2025-03-01\\\", \\\"2024-12-23\\\", \\\"2025-04-01\\\", \\\"2025-06-01\\\", 79, 61]]\"};\n",
       "        new ITable(table, dt_args);\n",
       "    });\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-Features per Stock Episode\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<!--| quarto-html-table-processing: none -->\n",
       "<table id=\"itables_230353da_32b2_4d8c_8537_b1dc65b23514\"><tbody><tr>\n",
       "    <td style=\"vertical-align:middle; text-align:left\">\n",
       "    <a href=https://mwouts.github.io/itables/><svg class=\"main-svg\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n",
       "width=\"64\" viewBox=\"0 0 500 400\" style=\"font-family: 'Droid Sans', sans-serif;\">\n",
       "    <g style=\"fill:#d9d7fc\">\n",
       "        <path d=\"M100,400H500V357H100Z\" />\n",
       "        <path d=\"M100,300H400V257H100Z\" />\n",
       "        <path d=\"M0,200H400V157H0Z\" />\n",
       "        <path d=\"M100,100H500V57H100Z\" />\n",
       "        <path d=\"M100,350H500V307H100Z\" />\n",
       "        <path d=\"M100,250H400V207H100Z\" />\n",
       "        <path d=\"M0,150H400V107H0Z\" />\n",
       "        <path d=\"M100,50H500V7H100Z\" />\n",
       "    </g>\n",
       "    <g style=\"fill:#1a1366;stroke:#1a1366;\">\n",
       "   <rect x=\"100\" y=\"7\" width=\"400\" height=\"43\">\n",
       "    <animate\n",
       "      attributeName=\"width\"\n",
       "      values=\"0;400;0\"\n",
       "      dur=\"5s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "      <animate\n",
       "      attributeName=\"x\"\n",
       "      values=\"100;100;500\"\n",
       "      dur=\"5s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "  </rect>\n",
       "        <rect x=\"0\" y=\"107\" width=\"400\" height=\"43\">\n",
       "    <animate\n",
       "      attributeName=\"width\"\n",
       "      values=\"0;400;0\"\n",
       "      dur=\"3.5s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "    <animate\n",
       "      attributeName=\"x\"\n",
       "      values=\"0;0;400\"\n",
       "      dur=\"3.5s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "  </rect>\n",
       "        <rect x=\"100\" y=\"207\" width=\"300\" height=\"43\">\n",
       "    <animate\n",
       "      attributeName=\"width\"\n",
       "      values=\"0;300;0\"\n",
       "      dur=\"3s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "    <animate\n",
       "      attributeName=\"x\"\n",
       "      values=\"100;100;400\"\n",
       "      dur=\"3s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "  </rect>\n",
       "        <rect x=\"100\" y=\"307\" width=\"400\" height=\"43\">\n",
       "    <animate\n",
       "      attributeName=\"width\"\n",
       "      values=\"0;400;0\"\n",
       "      dur=\"4s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "      <animate\n",
       "      attributeName=\"x\"\n",
       "      values=\"100;100;500\"\n",
       "      dur=\"4s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "  </rect>\n",
       "        <g style=\"fill:transparent;stroke-width:8; stroke-linejoin:round\" rx=\"5\">\n",
       "            <g transform=\"translate(45 50) rotate(-45)\">\n",
       "                <circle r=\"33\" cx=\"0\" cy=\"0\" />\n",
       "                <rect x=\"-8\" y=\"32\" width=\"16\" height=\"30\" />\n",
       "            </g>\n",
       "\n",
       "            <g transform=\"translate(450 152)\">\n",
       "                <polyline points=\"-15,-20 -35,-20 -35,40 25,40 25,20\" />\n",
       "                <rect x=\"-15\" y=\"-40\" width=\"60\" height=\"60\" />\n",
       "            </g>\n",
       "\n",
       "            <g transform=\"translate(50 352)\">\n",
       "                <polygon points=\"-35,-5 0,-40 35,-5\" />\n",
       "                <polygon points=\"-35,10 0,45 35,10\" />\n",
       "            </g>\n",
       "\n",
       "            <g transform=\"translate(75 250)\">\n",
       "                <polyline points=\"-30,30 -60,0 -30,-30\" />\n",
       "                <polyline points=\"0,30 -30,0 0,-30\" />\n",
       "            </g>\n",
       "\n",
       "            <g transform=\"translate(425 250) rotate(180)\">\n",
       "                <polyline points=\"-30,30 -60,0 -30,-30\" />\n",
       "                <polyline points=\"0,30 -30,0 0,-30\" />\n",
       "            </g>\n",
       "        </g>\n",
       "    </g>\n",
       "</svg>\n",
       "</a>\n",
       "    Loading ITables v2.4.0 from the internet...\n",
       "    (need <a href=https://mwouts.github.io/itables/troubleshooting.html>help</a>?)</td>\n",
       "    </tr></tbody></table>\n",
       "<link href=\"https://www.unpkg.com/dt_for_itables@2.3.2/dt_bundle.css\" rel=\"stylesheet\">\n",
       "<script type=\"module\">\n",
       "    import { ITable, jQuery as $ } from 'https://www.unpkg.com/dt_for_itables@2.3.2/dt_bundle.js';\n",
       "\n",
       "    document.querySelectorAll(\"#itables_230353da_32b2_4d8c_8537_b1dc65b23514:not(.dataTable)\").forEach(table => {\n",
       "        if (!(table instanceof HTMLTableElement))\n",
       "            return;\n",
       "\n",
       "        let dt_args = {\"layout\": {\"topStart\": null, \"topEnd\": null, \"bottomStart\": null, \"bottomEnd\": null}, \"classes\": [\"display\", \"nowrap\"], \"order\": [], \"text_in_header_can_be_selected\": true, \"style\": {\"table-layout\": \"auto\", \"width\": \"auto\", \"margin\": \"auto\", \"caption-side\": \"bottom\"}, \"table_html\": \"<table><thead>\\n    <tr style=\\\"text-align: right;\\\">\\n      \\n      <th>symbol</th>\\n      <th>train_start</th>\\n      <th>train_end</th>\\n      <th>test_start</th>\\n      <th>test_end</th>\\n      <th>std</th>\\n      <th>kurt</th>\\n      <th>entropy</th>\\n      <th>hurst</th>\\n      <th>adf_pval</th>\\n      <th>volatility</th>\\n      <th>momentum</th>\\n    </tr>\\n  </thead></table>\", \"data_json\": \"[[\\\"AAPL\\\", \\\"2022-10-27\\\", \\\"2023-03-01\\\", \\\"2022-12-22\\\", \\\"2023-04-01\\\", 0.022459, 2.813119, 1.93116, 0.496599, 0.04776042, 1.093412, -1.07], [\\\"AAPL\\\", \\\"2023-01-27\\\", \\\"2023-06-01\\\", \\\"2023-03-28\\\", \\\"2023-07-01\\\", 0.013749, 0.645238, 2.047618, 0.238327, 8.407263e-10, 2.477694, 5.69], [\\\"AAPL\\\", \\\"2023-04-27\\\", \\\"2023-09-01\\\", \\\"2023-06-29\\\", \\\"2023-10-01\\\", 0.012037, 3.8065, 1.715863, 0.535045, 5.51381e-14, 4.224786, 11.49], [\\\"AAPL\\\", \\\"2023-07-28\\\", \\\"2023-12-01\\\", \\\"2023-09-28\\\", \\\"2024-01-01\\\", 0.013023, 1.320281, 1.99994, 0.439358, 3.503117e-11, 0.370918, -1.36], [\\\"AAPL\\\", \\\"2023-10-26\\\", \\\"2024-03-01\\\", \\\"2023-12-26\\\", \\\"2024-04-01\\\", 0.010786, 1.01312, 1.938361, 0.509016, 9.03183e-13, 0.838111, -3.62], [\\\"AAPL\\\", \\\"2024-01-25\\\", \\\"2024-06-01\\\", \\\"2024-03-28\\\", \\\"2024-07-01\\\", 0.014027, 3.619261, 1.785333, 0.551446, 1.820703e-14, 0.990353, 5.37], [\\\"AAPL\\\", \\\"2024-04-25\\\", \\\"2024-09-01\\\", \\\"2024-06-28\\\", \\\"2024-10-01\\\", 0.016488, 4.099618, 1.7519, 0.449654, 2.565317e-15, 1.33318, 2.16], [\\\"AAPL\\\", \\\"2024-07-29\\\", \\\"2024-12-01\\\", \\\"2024-09-27\\\", \\\"2025-01-01\\\", 0.012878, 1.958462, 1.876494, 0.24596, 0.02483448, 2.802253, 8.81], [\\\"AAPL\\\", \\\"2024-10-28\\\", \\\"2025-03-01\\\", \\\"2024-12-23\\\", \\\"2025-04-01\\\", 0.014175, 0.542436, 2.028978, 0.543359, 7.533574e-13, 4.288557, -3.71]]\"};\n",
       "        new ITable(table, dt_args);\n",
       "    });\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Execute on walkforward windows\n",
    "#feature_df = extract_features_per_window(walkforward_windows,    max_feature_rolling_window=ROLLING,lookback_buffer_days=LOOKBACK)\n",
    "\n",
    "df = OHLCV_DF[OHLCV_DF['symbol']==\"AAPL\"].copy()\n",
    "walkforward_windows, visualize_walkforward_windows = generate_walkforward_windows(df ,max_feature_rolling_window=ROLLING,lookback_buffer_days=LOOKBACK)\n",
    "feature_df,visualize_feature_df = extract_features_per_window(walkforward_windows,feature_cols=BASIC_FEATURES)\n",
    "visualize_walkforward_windows()\n",
    "visualize_feature_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6eca7e",
   "metadata": {},
   "source": [
    "### ü§ñ 2. **Agent Training per Episode**\n",
    "\n",
    "Train **PPO** and optionally **A2C** using:\n",
    "\n",
    "* Our `RecurrentPPO + TransformerPolicy`\n",
    "* `SequenceAwareNormAbsMoveEnv`\n",
    "* Early stopping if reward plateaus\n",
    "* Use `Monitor` wrapper to track episode stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "1372dee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SequenceAwareNormAbsMoveEnv for walkforward context + full training episode\n",
    "import gym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gym import spaces\n",
    "\n",
    "class SequenceAwareNormAbsMoveEnv(gym.Env):\n",
    "    def __init__(self, df: pd.DataFrame,feature_cols=BASIC_FEATURES, context_window: int = 20, seed: int = 42, episode_steps:int=100):\n",
    "        super().__init__()\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.context_window = context_window\n",
    "        self.seed_value = seed\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "\n",
    "        self.feature_cols = feature_cols#[col for col in self.df.columns if col not in ['date', 'symbol']]\n",
    "        self.feature_dim = len(self.feature_cols)\n",
    "        self.action_space = spaces.Discrete(3)\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=-np.inf, high=np.inf,\n",
    "            shape=(self.context_window, self.feature_dim), dtype=np.float32\n",
    "        )\n",
    "\n",
    "        # Reward normalization\n",
    "        self.reward_scale = 1.0\n",
    "        self.reward_centering = True\n",
    "        self._price_diffs = self.df['close'].diff().fillna(0)\n",
    "\n",
    "        # Indices\n",
    "        self.start_index = self.context_window\n",
    "        self.end_index = len(self.df)\n",
    "        self.current_index = self.start_index\n",
    "\n",
    "    def reset(self):\n",
    "        self.start_index = self.context_window\n",
    "        self.current_index = self.start_index\n",
    "        self.step_counter = 0\n",
    "        self.max_steps = self.end_index - self.start_index\n",
    "        return self._get_observation()\n",
    "\n",
    "    def _get_observation(self):\n",
    "        obs_window = self.df.iloc[self.current_index - self.context_window:self.current_index][self.feature_cols]\n",
    "        return obs_window.values.astype(np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        reward = self._compute_reward(action)\n",
    "        self.current_index += 1\n",
    "        self.step_counter += 1\n",
    "        done = self.current_index >= self.end_index\n",
    "\n",
    "        obs = self._get_observation() if not done else np.zeros((self.context_window, self.feature_dim), dtype=np.float32)\n",
    "        return obs, reward, done, {}\n",
    "\n",
    "    def _compute_reward(self, action):\n",
    "        price_change = self._price_diffs.iloc[self.current_index] if self.current_index > 0 else 0\n",
    "        direction = 0 if action == 0 else (1 if action == 1 else -1)\n",
    "        reward = direction * price_change\n",
    "        if self.reward_centering:\n",
    "            reward -= self._price_diffs.mean()\n",
    "        return reward * self.reward_scale\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        self.seed_value = seed\n",
    "        self.rng = np.random.default_rng(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "ea3fa72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer Feature Extractor ======================================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "\n",
    "MAX_LEN = 64\n",
    "\n",
    "def generate_causal_mask(seq_len):\n",
    "    return torch.triu(torch.ones((seq_len, seq_len), dtype=torch.bool), diagonal=1)\n",
    "\n",
    "class TransformerFeatureExtractor(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space, d_model=64, n_heads=4, n_layers=2, max_len=MAX_LEN):\n",
    "        super().__init__(observation_space, features_dim=d_model)\n",
    "        self.d_model = d_model\n",
    "        input_dim = observation_space.shape[-1]\n",
    "\n",
    "        self.input_proj = nn.Sequential(\n",
    "            nn.LayerNorm(input_dim),\n",
    "            nn.Linear(input_dim, d_model),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.positional_encoding = nn.Parameter(torch.zeros(max_len, d_model))\n",
    "        nn.init.normal_(self.positional_encoding, std=0.02)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=n_heads, batch_first=True, norm_first=True, dropout=0.1\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n",
    "\n",
    "    def forward(self, obs):\n",
    "        x = self.input_proj(obs)\n",
    "        seq_len = x.size(1)\n",
    "        x = x + self.positional_encoding[:seq_len]\n",
    "        mask = generate_causal_mask(seq_len).to(x.device)\n",
    "        x = self.transformer(x, mask=mask)\n",
    "        return x[:, -1]\n",
    "\n",
    "\n",
    "# Transformer Policy ================================================\n",
    "from sb3_contrib.common.recurrent.policies import RecurrentActorCriticPolicy\n",
    "\n",
    "class TransformerPolicy(RecurrentActorCriticPolicy):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(\n",
    "            *args,\n",
    "            **kwargs,\n",
    "            features_extractor_class=TransformerFeatureExtractor,\n",
    "            features_extractor_kwargs=dict(\n",
    "                d_model=64, n_heads=4, n_layers=2, max_len=MAX_LEN\n",
    "            ),\n",
    "            share_features_extractor=True  # ‚úÖ Ensures SB3_contrib uses recurrent interface correctly\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547c7410",
   "metadata": {},
   "source": [
    "### üè∑Ô∏è 3. **Label Advantage for Predictability**\n",
    "\n",
    "Evaluate each stock-month:\n",
    "\n",
    "* Compute agent reward vs. random agent:\n",
    "\n",
    "  $$\n",
    "  \\text{Advantage} = \\mathbb{E}[R_{\\text{agent}} - R_{\\text{random}}]\n",
    "  $$\n",
    "* Run **t-test** and **Mann-Whitney U test**:\n",
    "\n",
    "  * `p_value < 0.05` ‚áí statistically significant edge\n",
    "  * Log these in the metadata\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "842884f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ttest_ind, mannwhitneyu\n",
    "\n",
    "def compute_advantage_statistics(agent_rewards, random_rewards, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Compute the statistical advantage of the agent over a random policy.\n",
    "\n",
    "    Parameters:\n",
    "        agent_rewards: List or np.array of total rewards from trained agent\n",
    "        random_rewards: List or np.array of total rewards from random actions\n",
    "        alpha: Significance threshold (default = 0.05)\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with advantage stats and significance flag\n",
    "    \"\"\"\n",
    "    agent_rewards = np.array(agent_rewards)\n",
    "    random_rewards = np.array(random_rewards)\n",
    "\n",
    "    advantage = agent_rewards.mean() - random_rewards.mean()\n",
    "    t_stat, t_pval = ttest_ind(agent_rewards, random_rewards, equal_var=False)\n",
    "    mw_stat, mw_pval = mannwhitneyu(agent_rewards, random_rewards, alternative='greater')\n",
    "\n",
    "    return {\n",
    "        \"advantage\": advantage,\n",
    "        \"agent_mean\": agent_rewards.mean(),\n",
    "        \"random_mean\": random_rewards.mean(),\n",
    "        \"t_stat\": t_stat,\n",
    "        \"t_pval\": t_pval,\n",
    "        \"mw_stat\": mw_stat,\n",
    "        \"mw_pval\": mw_pval,\n",
    "        \"significant\": (t_pval < alpha) and (mw_pval < alpha)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dd6070",
   "metadata": {},
   "source": [
    "### ‚ö†Ô∏è 4. **Only Keep Statistically Significant Runs**\n",
    "\n",
    "* Filter episodes where agent significantly beats random.\n",
    "* Label those stock-months as **\"predictable.\"**\n",
    "* Store mean/variance/confidence intervals for advantage.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "e49258dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind, mannwhitneyu\n",
    "\n",
    "def evaluate_episode_significance(episode_id, agent_rewards, random_rewards, alpha=0.05):\n",
    "    \"\"\"Compute statistical tests and determine predictability.\"\"\"\n",
    "    t_stat, p_val_t = ttest_ind(agent_rewards, random_rewards, equal_var=False)\n",
    "    u_stat, p_val_mw = mannwhitneyu(agent_rewards, random_rewards, alternative='two-sided')\n",
    "\n",
    "    advantage = np.mean(agent_rewards) - np.mean(random_rewards)\n",
    "    result = {\n",
    "        \"episode_id\": episode_id,\n",
    "        \"advantage_mean\": advantage,\n",
    "        \"agent_mean\": np.mean(agent_rewards),\n",
    "        \"agent_std\": np.std(agent_rewards),\n",
    "        \"random_mean\": np.mean(random_rewards),\n",
    "        \"random_std\": np.std(random_rewards),\n",
    "        \"ttest_pval\": p_val_t,\n",
    "        \"mw_pval\": p_val_mw,\n",
    "        \"predictable\": (p_val_t < alpha) and (p_val_mw < alpha)\n",
    "    }\n",
    "    return result\n",
    "\n",
    "def evaluate_all_episodes(agent_data_dict, save_path=None, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Evaluate multiple episodes for statistical significance and optionally save results.\n",
    "\n",
    "    agent_data_dict: {\n",
    "        episode_id: {\n",
    "            'agent': [...],\n",
    "            'random': [...]\n",
    "        }\n",
    "    }\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for episode_id, data in agent_data_dict.items():\n",
    "        agent_rewards = data['agent']\n",
    "        random_rewards = data['random']\n",
    "        result = evaluate_episode_significance(episode_id, agent_rewards, random_rewards, alpha=alpha)\n",
    "        results.append(result)\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    if save_path:\n",
    "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "        df.to_csv(save_path, index=False)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "82cb5d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Dict\n",
    "from scipy.stats import ttest_ind, mannwhitneyu\n",
    "\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from sb3_contrib.ppo_recurrent import RecurrentPPO\n",
    "\n",
    "\n",
    "\n",
    "def compute_advantage_statistics(agent_rewards, random_rewards, alpha=0.05):\n",
    "    t_stat, p_val_t = ttest_ind(agent_rewards, random_rewards, equal_var=False)\n",
    "    u_stat, p_val_mw = mannwhitneyu(agent_rewards, random_rewards, alternative='two-sided')\n",
    "    advantage = np.mean(agent_rewards) - np.mean(random_rewards)\n",
    "\n",
    "    return {\n",
    "        \"agent_mean\": np.mean(agent_rewards),\n",
    "        \"agent_std\": np.std(agent_rewards),\n",
    "        \"random_mean\": np.mean(random_rewards),\n",
    "        \"random_std\": np.std(random_rewards),\n",
    "        \"advantage\": advantage,\n",
    "        \"ttest_pval\": p_val_t,\n",
    "        \"mw_pval\": p_val_mw,\n",
    "        \"predictable\": (p_val_t < alpha) and (p_val_mw < alpha)\n",
    "    }\n",
    "\n",
    "\n",
    "def run_walkforward_pipeline(windows: List[Dict],\n",
    "                             policy_class,\n",
    "                             seeds=SEEDS,\n",
    "                             steps: int = 200,\n",
    "                             context_window: int = 20,\n",
    "                             episode_steps: int = 21,\n",
    "                             alpha: float = 0.05) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each stock-month window:\n",
    "    - Trains agents\n",
    "    - Collects rewards vs random\n",
    "    - Computes statistical advantage\n",
    "    - Filters significant episodes\n",
    "    - Returns labeled dataframe\n",
    "    \"\"\"\n",
    "    records = []\n",
    "\n",
    "    for window in [windows[0]]:\n",
    "        symbol = window['symbol']\n",
    "        train_df = window['train_df']\n",
    "        test_df = window['test_df']\n",
    "        train_start = window['train_start']\n",
    "        train_end = window['train_end']\n",
    "        test_start = window['test_start']\n",
    "        test_end = window['test_end']\n",
    "\n",
    "        agent_rewards = []\n",
    "        random_rewards = []\n",
    "\n",
    "        for seed in [seeds[0]]:\n",
    "            print(f\"[{symbol}] Seed {seed} ‚Äî training agent\")\n",
    "\n",
    "            # ==== Train PPO Agent ====\n",
    "            env_fn = lambda: SequenceAwareNormAbsMoveEnv(train_df, context_window=context_window,\n",
    "                                                          episode_steps=episode_steps, seed=seed)\n",
    "            env = DummyVecEnv([env_fn])\n",
    "            model = RecurrentPPO(\n",
    "                policy_class,\n",
    "                env,\n",
    "                verbose=1,\n",
    "                seed=seed,\n",
    "                n_steps=128,\n",
    "                policy_kwargs=dict(\n",
    "                    lstm_hidden_size=64,\n",
    "                )\n",
    "            )\n",
    "            model.learn(total_timesteps=steps)\n",
    "\n",
    "            # ==== Evaluate PPO Agent ====\n",
    "            test_env = SequenceAwareNormAbsMoveEnv(test_df, context_window=context_window,\n",
    "                                                   episode_steps=episode_steps, seed=seed)\n",
    "            obs = test_env.reset()\n",
    "            print(\"obs shape:\", obs.shape)\n",
    "            print(\"expected shape:\", model.observation_space.shape)\n",
    "            done = False\n",
    "            total_reward = 0\n",
    "            lstm_states = None\n",
    "            episode_starts = np.ones((1,), dtype=bool)\n",
    "\n",
    "            while not done:\n",
    "                action, lstm_states = model.predict(obs, state=lstm_states, episode_start=episode_starts, deterministic=True)\n",
    "                obs, reward, done, _ = test_env.step(action)\n",
    "                total_reward += reward\n",
    "                episode_starts = np.zeros((1,), dtype=bool)\n",
    "            agent_rewards.append(total_reward)\n",
    "\n",
    "            # ==== Random Policy ====\n",
    "            test_env = SequenceAwareNormAbsMoveEnv(test_df, context_window=context_window,\n",
    "                                                   episode_steps=episode_steps, seed=seed)\n",
    "            obs = test_env.reset()\n",
    "            done = False\n",
    "            total_reward = 0\n",
    "\n",
    "            while not done:\n",
    "                action = test_env.action_space.sample()\n",
    "                obs, reward, done, _ = test_env.step(action)\n",
    "                total_reward += reward\n",
    "            random_rewards.append(total_reward)\n",
    "\n",
    "        # ==== Stats & Label ====\n",
    "        print('x')\n",
    "        stats = compute_advantage_statistics(agent_rewards, random_rewards, alpha)\n",
    "        stats.update({\n",
    "            \"symbol\": symbol,\n",
    "            \"train_start\": train_start,\n",
    "            \"train_end\": train_end,\n",
    "            \"test_start\": test_start,\n",
    "            \"test_end\": test_end\n",
    "        })\n",
    "        records.append(stats)\n",
    "\n",
    "    df = pd.DataFrame(records)\n",
    "    df.to_csv(\"advantage_labels_predictability.csv\", index=False)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fdf945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AAPL] Seed 66923877 ‚Äî training agent\n",
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francisco S√°\\AppData\\Roaming\\Python\\Python311\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Francisco S√°\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "| time/              |     |\n",
      "|    fps             | 252 |\n",
      "|    iterations      | 1   |\n",
      "|    time_elapsed    | 0   |\n",
      "|    total_timesteps | 128 |\n",
      "----------------------------\n"
     ]
    }
   ],
   "source": [
    "run_walkforward_pipeline(walkforward_windows,TransformerPolicy, context_window=LOOKBACK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "267cbb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = walkforward_windows[0]['train_df']\n",
    "test_env = SequenceAwareNormAbsMoveEnv(test_df, context_window=40,\n",
    "                                                   episode_steps=20, seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "1146fcd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 11)"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_env.reset().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "a6e1870c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                                   33673\n",
       "id                                      33674\n",
       "symbol                                   AAPL\n",
       "timestamp                 2023-01-03 05:00:00\n",
       "date                      2023-01-03 00:00:00\n",
       "open                                   130.28\n",
       "high                                    130.9\n",
       "low                                    124.17\n",
       "close                                -1.38795\n",
       "volume                               2.260277\n",
       "trade_count                         1021067.0\n",
       "vwap                               125.660032\n",
       "weekday                                   1.0\n",
       "day_of_month                                3\n",
       "day_of_week                                 1\n",
       "candle_size                              6.73\n",
       "order_flow                          -1.562455\n",
       "candle_body                          0.500351\n",
       "upper_shadow                        -0.431747\n",
       "lower_shadow                        -0.244813\n",
       "price_change                         -1.48388\n",
       "candle_change                        1.670635\n",
       "order_flow_change                   -4.427632\n",
       "overnight_price_change               0.002694\n",
       "volume_change                        0.447492\n",
       "vwap_change                         -0.025253\n",
       "trade_count_change                   0.727238\n",
       "sector_id                                10.0\n",
       "industry_id                           unknown\n",
       "return_1d                           -0.037405\n",
       "vix                                     0.229\n",
       "vix_norm                             1.006929\n",
       "sp500                                 38.2414\n",
       "sp500_norm                          -0.004001\n",
       "market_return_1d                    -0.197339\n",
       "Close                                  125.07\n",
       "volatility                           0.094812\n",
       "momentum                            -0.662791\n",
       "Name: 40, dtype: object"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_env.df.iloc[40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c28899",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
