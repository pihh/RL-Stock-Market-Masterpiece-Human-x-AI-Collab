{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33beca1f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cab993d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP ===================================\n",
    "import jupyter\n",
    "import warnings\n",
    "\n",
    "from src.utils.system import boot, Notify\n",
    "\n",
    "boot()\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "# PACKAGES ================================\n",
    "import os\n",
    "import torch\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import  RobustScaler\n",
    "\n",
    "# FRAMEWORK STUFF =========================\n",
    "from src.config import TOP2_STOCK_BY_SECTOR, FEATURE_COLS\n",
    "from src.data.feature_pipeline import load_base_dataframe\n",
    "from src.experiments.experiment_tracker import ExperimentTracker\n",
    "from src.env.base_timeseries_trading_env import BaseSequenceAwareTradingEnv,SequenceAwareAlphaTradingEnv,SequenceAwareBaselineTradingAgent,SequenceAwareCalmarTradingEnv,SequenceAwareCumulativeTradingEnv,SequenceAwareDrawdownTradingEnv,SequenceAwareHybridTradingEnv,SequenceAwareHybridTradingEnv,SequenceAwareSharpeTradingEnv,SequenceAwareSortinoTradingEnv\n",
    "\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from stable_baselines3.common.policies import ActorCriticPolicy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a26ed462",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ========== CONFIG ==========\n",
    "EXPERIENCE_NAME = \"sequence_awate_agent_design\"\n",
    "RESULTS_PATH = f\"data/experiments/{EXPERIENCE_NAME}_barebones_results.csv\"\n",
    "N_EPISODES = 20\n",
    "N_SEEDS = 3\n",
    "N_EVAL_EPISODES = 3\n",
    "AGENT_TYPES = ['mlp', 'lstm', 'transformer_single', 'transformer_multi']\n",
    "WINDOW_LENGTH = 10  # or any value you want\n",
    "\n",
    "\n",
    "TRANSACTION_COST = 0\n",
    "\n",
    "CONFIG = {\n",
    "    \"batch_size\": 32,\n",
    "    \"n_steps\": 128,\n",
    "    \"total_timesteps\": 5000,   \n",
    "}\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "features_extractor_kwargs={\n",
    "    'window_length': WINDOW_LENGTH,\n",
    "    'n_features': len(FEATURE_COLS),\n",
    "    'd_model': 32,\n",
    "    'nhead': ...,\n",
    "    'num_layers': ...,\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# --- Load data ---\n",
    "ohlcv_df = load_base_dataframe()\n",
    "\n",
    "# --- Experiment tracker ---\n",
    "experiment_tracker = ExperimentTracker(EXPERIENCE_NAME)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5e26f921",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env(df, ticker, feature_cols, episode_length, window_length):\n",
    "    df_ticker = df[df['symbol'] == ticker].copy()\n",
    "    return CumulativeTradingEnv(\n",
    "        df=df_ticker,\n",
    "        feature_cols=feature_cols,\n",
    "        episode_length=episode_length,\n",
    "        transaction_cost=TRANSACTION_COST,\n",
    "        window_length=window_length,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4ee24017",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerExtractor(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space, window_length, n_features, d_model=32, nhead=1, num_layers=1):\n",
    "        super().__init__(observation_space, features_dim=d_model)\n",
    "        self.window_length = window_length\n",
    "        self.n_features = n_features\n",
    "        self.embedding = nn.Linear(n_features, d_model)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "    def forward(self, obs):\n",
    "        # obs: [batch, window_length * n_features]\n",
    "        batch = obs.shape[0]\n",
    "        # reshape flat vector to (batch, window_length, n_features)\n",
    "        x = obs.view(batch, self.window_length, self.n_features)\n",
    "        x = self.embedding(x)      # (batch, window_length, d_model)\n",
    "        x = x.permute(1, 0, 2)    # (window_length, batch, d_model)\n",
    "        x = self.transformer(x)    # (window_length, batch, d_model)\n",
    "        # Use last token as pooled output\n",
    "        return x[-1]              # (batch, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9b734521",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerPolicy(ActorCriticPolicy):\n",
    "    def __init__(self, *args, nhead=1, num_layers=1, window_length=10, n_features=2, **kwargs):\n",
    "        super().__init__(\n",
    "            *args,\n",
    "            features_extractor_class=TransformerExtractor,\n",
    "            features_extractor_kwargs={\n",
    "                'window_length': window_length,\n",
    "                'n_features': n_features,\n",
    "                'd_model': 32,\n",
    "                'nhead': nhead,\n",
    "                'num_layers': num_layers,\n",
    "            },\n",
    "            **kwargs\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae33ee08",
   "metadata": {},
   "source": [
    "# Unit tests:\n",
    "1. Output Shapes\n",
    "2. Window Consistency (Padding at Episode Start)\n",
    "3. Step Through Environment\n",
    "4. SB3 Policy Compatibility\n",
    "5. Transformer Policy Compatibility\n",
    "6. Action Space and Reward Consistency\n",
    "7. Episode Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "91e9eceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D window shape: (5, 25)\n",
      "Flat window shape: (125,)\n"
     ]
    }
   ],
   "source": [
    "# Test 1: Output Shapes\n",
    "\n",
    "# Test windowed obs shape (flat vs. 2D)\n",
    "df = ohlcv_df.copy()\n",
    "feature_cols = FEATURE_COLS\n",
    "env = BaseSequenceAwareTradingEnv(\n",
    "    df, feature_cols=feature_cols, episode_length=30, window_length=5, return_sequences=True\n",
    ")\n",
    "obs, _ = env.reset()\n",
    "print(\"2D window shape:\", obs.shape)  # Expect (5, obs_dim)\n",
    "\n",
    "env_flat = BaseSequenceAwareTradingEnv(\n",
    "    df, feature_cols=feature_cols, episode_length=30, window_length=5, return_sequences=False\n",
    ")\n",
    "obs_flat, _ = env_flat.reset()\n",
    "print(\"Flat window shape:\", obs_flat.shape)  # Expect (5*obs_dim,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0eb33328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padding and shape OK\n"
     ]
    }
   ],
   "source": [
    "# Test 2: Window consistency\n",
    "env = BaseSequenceAwareTradingEnv(\n",
    "    df, feature_cols=feature_cols, episode_length=10, window_length=5, return_sequences=True\n",
    ")\n",
    "obs, _ = env.reset()\n",
    "assert np.allclose(obs[0], obs[1]), \"Padding at start should repeat first row\"\n",
    "assert obs.shape == (5, len(feature_cols) + len(env.internal_features))\n",
    "print(\"Padding and shape OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c0faeb1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 | Obs shape: (3, 25) | Reward: 0.00067\n",
      "Step 1 | Obs shape: (3, 25) | Reward: -0.00168\n",
      "Step 2 | Obs shape: (3, 25) | Reward: 0.00280\n",
      "Step 3 | Obs shape: (3, 25) | Reward: -0.00415\n",
      "Step 4 | Obs shape: (3, 25) | Reward: 0.00380\n",
      "Step 5 | Obs shape: (3, 25) | Reward: 0.00045\n",
      "Step 6 | Obs shape: (3, 25) | Reward: 0.00595\n",
      "Step 7 | Obs shape: (3, 25) | Reward: -0.00463\n"
     ]
    }
   ],
   "source": [
    "# Test 3: Step Through Environment\n",
    "\n",
    "env = BaseSequenceAwareTradingEnv(\n",
    "    df, feature_cols=feature_cols, episode_length=10, window_length=3, return_sequences=True\n",
    ")\n",
    "obs, _ = env.reset()\n",
    "for i in range(8):\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, done, trunc, info = env.step(action)\n",
    "    print(f\"Step {i} | Obs shape: {obs.shape} | Reward: {reward:.5f}\")\n",
    "    if done:\n",
    "        print(\"Episode done:\", info)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "36f19d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "---------------------------\n",
      "| time/              |    |\n",
      "|    fps             | 88 |\n",
      "|    iterations      | 1  |\n",
      "|    time_elapsed    | 0  |\n",
      "|    total_timesteps | 8  |\n",
      "---------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 86          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 0           |\n",
      "|    total_timesteps      | 16          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009850413 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | -33.8       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00883    |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0274     |\n",
      "|    value_loss           | 0.0939      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 81          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 0           |\n",
      "|    total_timesteps      | 24          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007381819 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | -919        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0753     |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    value_loss           | 0.0276      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 70          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 0           |\n",
      "|    total_timesteps      | 32          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020876229 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | -10.3       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.129      |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0538     |\n",
      "|    value_loss           | 0.000746    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 0           |\n",
      "|    total_timesteps      | 40          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008006714 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | -2.93       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0732     |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.03       |\n",
      "|    value_loss           | 0.0662      |\n",
      "-----------------------------------------\n",
      "SB3 PPO MLP works!\n"
     ]
    }
   ],
   "source": [
    "# SB3 Policy Compatibility\n",
    "# Train an MLP agent on env with return_sequences=False (flat). \n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "env = BaseSequenceAwareTradingEnv(\n",
    "    df, feature_cols=feature_cols, episode_length=30, window_length=5, return_sequences=False\n",
    ")\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "vec_env = DummyVecEnv([lambda: env])\n",
    "\n",
    "model = PPO(\"MlpPolicy\", vec_env, n_steps=8, batch_size=4, verbose=1)\n",
    "model.learn(total_timesteps=40)\n",
    "print(\"SB3 PPO MLP works!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "133e04f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer output shape: torch.Size([2, 32])\n"
     ]
    }
   ],
   "source": [
    "# Test 5: Transformer Policy Compatibility\n",
    "# Make sure custom transformer can process the 2D obs by running a forward pass \n",
    "# through the extractor to check for shape errors\n",
    "\n",
    "\n",
    "obs = np.random.randn(2, 5*8).astype(np.float32)  # batch=2, window_length=5, n_features=8\n",
    "# Extractor expects (batch, window_length*n_features), will reshape internally.\n",
    "extractor = TransformerExtractor(\n",
    "    gym.spaces.Box(-np.inf, np.inf, shape=(5*8,), dtype=np.float32), 5, 8\n",
    ")\n",
    "with torch.no_grad():\n",
    "    torch_out = extractor(torch.from_numpy(obs))\n",
    "print(\"Transformer output shape:\", torch_out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "053b1364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished | Cumulative reward: -0.00028617333906170994\n",
      "Info dict: {'episode_sharpe': 0.07692172235020756, 'episode_sortino': 0.07812661503558227, 'episode_total_reward': -0.00028617333906170994, 'cumulative_return': -4.035402182833714e-05, 'calmar': -0.002803658747317024, 'max_drawdown': 0.014393342936958407, 'win_rate': 0.0, 'alpha': -0.02852024595121727, 'returns': array([-0.        , -0.00168237, -0.00279924,  0.0041545 ,  0.00380186,\n",
      "        0.00044898,  0.00595171,  0.00463172, -0.01439334]), 'downside': array([-0.00168237, -0.00279924, -0.01439334])}\n"
     ]
    }
   ],
   "source": [
    "# Test 6: Action Space and Reward Consistency\n",
    "# mini-episode ti check action output and cumulative reward:\n",
    "\n",
    "env = BaseSequenceAwareTradingEnv(\n",
    "    df, feature_cols=feature_cols, episode_length=10, window_length=5, return_sequences=False\n",
    ")\n",
    "obs, _ = env.reset()\n",
    "cumulative = 0\n",
    "for _ in range(10):\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, done, trunc, info = env.step(action)\n",
    "    cumulative += reward\n",
    "    if done:\n",
    "        print(\"Episode finished | Cumulative reward:\", cumulative)\n",
    "        print(\"Info dict:\", info)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7fbeb9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode generator determinism OK\n"
     ]
    }
   ],
   "source": [
    "# Test 7: Episode Generator\n",
    "# Check that the same seed produces the same episode list across runs.\n",
    "\n",
    "env = BaseSequenceAwareTradingEnv(df, feature_cols=feature_cols, episode_length=10, window_length=5)\n",
    "seq1 = env.generate_episode_sequences(train_steps=1000)\n",
    "env2 = BaseSequenceAwareTradingEnv(df, feature_cols=feature_cols, episode_length=10, window_length=5)\n",
    "seq2 = env2.generate_episode_sequences(train_steps=1000)\n",
    "assert seq1 == seq2, \"Episode sequences should be the same for same seed!\"\n",
    "print(\"Episode generator determinism OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3e5be3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
