{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bfee827",
   "metadata": {},
   "source": [
    "This is gold, Pi ‚Äî thank you for laying it out so clearly. What you built is already stronger than many academic meta-RL setups. Now let‚Äôs **merge the best of your past success with this current Battleground framework** and push it to the next level.\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Current Goal\n",
    "\n",
    "**Predict, with ‚â•75% confidence, whether a given RL training episode is transferable.**\n",
    "\n",
    "To do that, we need a **rich and expressive feature space** that captures **structure, uncertainty, dynamics, and regime information** ‚Äî just like your Stock-Month Predictability Study.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ What We Already Have\n",
    "\n",
    "From your current `result_df`, we already extract:\n",
    "\n",
    "| Group                 | Features                                                                 |\n",
    "| --------------------- | ------------------------------------------------------------------------ |\n",
    "| Statistical Moments   | `mean_return`, `std_return`, `skew_return`, `kurtosis_return`, `entropy` |\n",
    "| Price Trend           | `return_trend`, `ewm_mean_return`                                        |\n",
    "| Chaos / Regime        | `hurst`, `adf_stat`, `adf_pval`                                          |\n",
    "| Risk & Reward Metrics | `volatility`, `max_drawdown`, `sharpe`, `sortino`, `calmar`              |\n",
    "| Agent Diagnostics     | `success_trades`, `action_hold_ratio`, `action_long_ratio`               |\n",
    "| Outcome Labels        | `score_train`, `score_test`, `advantage_test`, `transfer_delta`          |\n",
    "\n",
    "---\n",
    "\n",
    "## üîÅ Let‚Äôs Extend: Feature Suggestions\n",
    "\n",
    "Below are **10 additional meta-features** we can compute **either now or as next step**, all in PyTorch/Numpy-friendly form:\n",
    "\n",
    "| Feature Name               | Why Add It?                                                                |\n",
    "| -------------------------- | -------------------------------------------------------------------------- |\n",
    "| `resid_std`                | From RF prediction of t+1 returns ‚Üí measures noise                         |\n",
    "| `resid_skew`, `resid_kurt` | Shape of the error ‚Üí asymmetry or tails                                    |\n",
    "| `resid_acf1`               | Temporal memory in prediction error                                        |\n",
    "| `ljung_pval`               | Statistical confirmation of noise/randomness                               |\n",
    "| `cv_r2`                    | Proxy for model learnability/predictability                                |\n",
    "| `garch_volatility`         | Conditional volatility ‚áí market stress estimation                          |\n",
    "| `change_point_count`       | Regime switch count (e.g. via ruptures or cusum)                           |\n",
    "| `rolling_adf_pval`         | Stationarity evolution over time                                           |\n",
    "| `forecast_entropy`         | Entropy of predictions from RF or AE                                       |\n",
    "| `price_entropy_peak`       | Local entropy spike detection before regime breaks (good for online usage) |\n",
    "\n",
    "These build on your previous success and aim at:\n",
    "\n",
    "* **Residual structure**\n",
    "* **Volatility structure**\n",
    "* **Forecast structure**\n",
    "* **Regime changes**\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Architecture Suggestion (Final Plan)\n",
    "\n",
    "```bash\n",
    "[Episode -> Raw OHLCV]\n",
    "         |\n",
    "         v\n",
    "[Feature Extractor (Meta + Residual + Chaos)]\n",
    "         |\n",
    "         v\n",
    "[Representation Learner (AE, Transformer Encoder, etc)]\n",
    "         |\n",
    "         v\n",
    "[Predictor (Classifier or Ranker)]\n",
    "         |\n",
    "         v\n",
    "[Score: Learnability + Transferability + Difficulty]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Action Plan (Ordered)\n",
    "\n",
    "**Phase 1 ‚Äì Today**\n",
    "\n",
    "1. ‚úÖ Implement `EpisodeMetaFeatureExtractor` (done or in progress)\n",
    "2. ‚úÖ Implement `TradingEnvironmentBattleground` (done!)\n",
    "3. üîÅ Add new diagnostics: `resid_std`, `resid_acf1`, `cv_r2`, `ljung_pval`\n",
    "4. üß† Train `EpisodeTransferabilityPredictor` with new features\n",
    "\n",
    "**Phase 2 ‚Äì Next**\n",
    "5\\. üß¨ Add `AutoencoderRepresentation` wrapper\n",
    "6\\. üîÑ Train contrastive ranking model: \"Is A > B?\"\n",
    "7\\. ‚è± Evaluate with out-of-time validation (e.g., train on 2023 Q1, test on Q2)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dbdf015",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e1d6324",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from src.utils.system import boot\n",
    "from src.data.feature_pipeline import load_base_dataframe\n",
    "from experiments import check_if_experiment_exists, register_experiment ,experiment_hash\n",
    "from environments import PositionTradingEnv,PositionTradingEnvV1\n",
    "\n",
    "# ========== SYSTEM BOOT ==========\n",
    "DEVICE = boot()\n",
    "EXPERIMENT_NAME = \"trading_environment_development\"\n",
    "DEFAULT_PATH = \"data/experiments/\" + EXPERIMENT_NAME\n",
    "\n",
    "# ========== CONFIG ==========\n",
    "TICKER = \"AAPL\"\n",
    "TIMESTEPS = 10_000\n",
    "EVAL_EPISODES = 5\n",
    "N_TIMESTEPS = 60\n",
    "LOOKBACK = 0\n",
    "SEEDS = [42, 52, 62]\n",
    "MARKET_FEATURES = ['close']\n",
    "BENCHMARK_PATH = DEFAULT_PATH+\"/benchmark_episodes.json\"\n",
    "CHECKPOINT_DIR = DEFAULT_PATH+\"/checkpoints\"\n",
    "SCORES_DIR = DEFAULT_PATH+\"/scores\"\n",
    "META_PATH = DEFAULT_PATH+\"/meta_df_transfer.csv\"\n",
    "\n",
    "MODEL_PATH = CHECKPOINT_DIR+\"/episode_quality_model.pkl\"\n",
    "MARKET_FEATURES.sort()\n",
    "SEEDS.sort()\n",
    "\n",
    "DEVICE = boot()\n",
    "OHLCV_DF = load_base_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71afee1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([615, 360, 528,  71, 355], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.read_csv(DEFAULT_PATH+\"/meta_df_transfer.csv\")\n",
    "train_ep_ids = result_df['train_idx'].unique()\n",
    "#[615, 360, 528,  71, 355],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ffbb5ef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nOrganiza-te :\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Organiza-te :\n",
    "\n",
    "feature_dict = {\n",
    "            'mean_return': returns.mean(),\n",
    "            'median_return':np.median(returns),\n",
    "            'std_return': returns.std(),\n",
    "            'skew': skew(returns),\n",
    "            'kurtosis': kurtosis(returns),\n",
    "            'entropy': entropy(np.histogram(returns, bins=10, density=True)[0] + 1e-8),\n",
    "            'volatility': returns.std(),\n",
    "            'drawdown': (values / np.maximum.accumulate(values)).min() - 1,\n",
    "            ['adf_pvalue'] = adf_result[1]\n",
    "        }\n",
    "        \n",
    "        df_ep[f'return_lag_{lag}'] = df_ep['close'].pct_change().shift(lag)\n",
    "        'resid_std': residuals.std(),\n",
    "                'resid_skew': skew(residuals),\n",
    "                'resid_kurtosis': kurtosis(residuals),\n",
    "                'ljung_pval': acorr_ljungbox(residuals, lags=[1], return_df=True).iloc[0]['lb_pvalue'],\n",
    "                'resid_acf1': pd.Series(residuals).autocorr(lag=1)\n",
    "        \n",
    "\"\"\"\n",
    "\n",
    "print('ver como o classifier se comporta ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d254cfd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>volume</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33494</th>\n",
       "      <td>74493604.0</td>\n",
       "      <td>165.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33495</th>\n",
       "      <td>75240221.0</td>\n",
       "      <td>167.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33496</th>\n",
       "      <td>73954306.0</td>\n",
       "      <td>167.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33497</th>\n",
       "      <td>93153701.0</td>\n",
       "      <td>166.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33498</th>\n",
       "      <td>93535037.0</td>\n",
       "      <td>161.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33609</th>\n",
       "      <td>141390692.0</td>\n",
       "      <td>138.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33610</th>\n",
       "      <td>124534891.0</td>\n",
       "      <td>142.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33611</th>\n",
       "      <td>96785630.0</td>\n",
       "      <td>146.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33612</th>\n",
       "      <td>83933253.0</td>\n",
       "      <td>146.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33613</th>\n",
       "      <td>72586982.0</td>\n",
       "      <td>145.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            volume   close\n",
       "33494   74493604.0  165.07\n",
       "33495   75240221.0  167.40\n",
       "33496   73954306.0  167.23\n",
       "33497   93153701.0  166.42\n",
       "33498   93535037.0  161.79\n",
       "...            ...     ...\n",
       "33609  141390692.0  138.20\n",
       "33610  124534891.0  142.45\n",
       "33611   96785630.0  146.10\n",
       "33612   83933253.0  146.40\n",
       "33613   72586982.0  145.43\n",
       "\n",
       "[120 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ep = OHLCV_DF[OHLCV_DF['symbol']==\"AAPL\"].iloc[71:71+120].copy()\n",
    "train_ep.reset_index()\n",
    "MARKET_FEATURES = ['volume','close']\n",
    "train_ep[MARKET_FEATURES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f92a797",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21e51f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42d3bcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b48f6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f99b374",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0d6cfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb5da46f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>symbol</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>...</th>\n",
       "      <th>vwap_change</th>\n",
       "      <th>trade_count_change</th>\n",
       "      <th>sector_id</th>\n",
       "      <th>industry_id</th>\n",
       "      <th>return_1d</th>\n",
       "      <th>vix</th>\n",
       "      <th>vix_norm</th>\n",
       "      <th>sp500</th>\n",
       "      <th>sp500_norm</th>\n",
       "      <th>market_return_1d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33494</td>\n",
       "      <td>33495</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2022-04-18 04:00:00</td>\n",
       "      <td>2022-04-18</td>\n",
       "      <td>163.920</td>\n",
       "      <td>166.5984</td>\n",
       "      <td>163.570</td>\n",
       "      <td>165.07</td>\n",
       "      <td>74493604.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013575</td>\n",
       "      <td>-0.033606</td>\n",
       "      <td>10.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>-0.001331</td>\n",
       "      <td>0.2217</td>\n",
       "      <td>-0.023348</td>\n",
       "      <td>43.9169</td>\n",
       "      <td>-0.000205</td>\n",
       "      <td>-0.000205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33495</td>\n",
       "      <td>33496</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2022-04-19 04:00:00</td>\n",
       "      <td>2022-04-19</td>\n",
       "      <td>165.020</td>\n",
       "      <td>167.8200</td>\n",
       "      <td>163.910</td>\n",
       "      <td>167.40</td>\n",
       "      <td>75240221.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010325</td>\n",
       "      <td>-0.049385</td>\n",
       "      <td>10.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0.014115</td>\n",
       "      <td>0.2137</td>\n",
       "      <td>-0.036085</td>\n",
       "      <td>44.6221</td>\n",
       "      <td>0.016058</td>\n",
       "      <td>0.016058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33496</td>\n",
       "      <td>33497</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2022-04-20 04:00:00</td>\n",
       "      <td>2022-04-20</td>\n",
       "      <td>168.760</td>\n",
       "      <td>168.8800</td>\n",
       "      <td>166.100</td>\n",
       "      <td>167.23</td>\n",
       "      <td>73954306.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004275</td>\n",
       "      <td>0.085275</td>\n",
       "      <td>10.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>-0.001016</td>\n",
       "      <td>0.2032</td>\n",
       "      <td>-0.049134</td>\n",
       "      <td>44.5945</td>\n",
       "      <td>-0.000619</td>\n",
       "      <td>-0.000619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33497</td>\n",
       "      <td>33498</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2022-04-21 04:00:00</td>\n",
       "      <td>2022-04-21</td>\n",
       "      <td>168.910</td>\n",
       "      <td>171.5300</td>\n",
       "      <td>165.910</td>\n",
       "      <td>166.42</td>\n",
       "      <td>93153701.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008196</td>\n",
       "      <td>0.263759</td>\n",
       "      <td>10.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>-0.004844</td>\n",
       "      <td>0.2268</td>\n",
       "      <td>0.116142</td>\n",
       "      <td>43.9366</td>\n",
       "      <td>-0.014753</td>\n",
       "      <td>-0.014753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33498</td>\n",
       "      <td>33499</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2022-04-22 04:00:00</td>\n",
       "      <td>2022-04-22</td>\n",
       "      <td>166.460</td>\n",
       "      <td>167.8699</td>\n",
       "      <td>161.500</td>\n",
       "      <td>161.79</td>\n",
       "      <td>93535037.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027863</td>\n",
       "      <td>-0.033611</td>\n",
       "      <td>10.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>-0.027821</td>\n",
       "      <td>0.2821</td>\n",
       "      <td>0.243827</td>\n",
       "      <td>42.7178</td>\n",
       "      <td>-0.027740</td>\n",
       "      <td>-0.027740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>33609</td>\n",
       "      <td>33610</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2022-09-30 04:00:00</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>141.280</td>\n",
       "      <td>143.1000</td>\n",
       "      <td>138.000</td>\n",
       "      <td>138.20</td>\n",
       "      <td>141390692.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018747</td>\n",
       "      <td>-0.117879</td>\n",
       "      <td>10.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>-0.030039</td>\n",
       "      <td>0.3162</td>\n",
       "      <td>-0.006910</td>\n",
       "      <td>35.8562</td>\n",
       "      <td>-0.015067</td>\n",
       "      <td>-0.015067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>33610</td>\n",
       "      <td>33611</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2022-10-03 04:00:00</td>\n",
       "      <td>2022-10-03</td>\n",
       "      <td>138.210</td>\n",
       "      <td>143.0700</td>\n",
       "      <td>137.685</td>\n",
       "      <td>142.45</td>\n",
       "      <td>124534891.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008126</td>\n",
       "      <td>-0.109068</td>\n",
       "      <td>10.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0.030753</td>\n",
       "      <td>0.3010</td>\n",
       "      <td>-0.048071</td>\n",
       "      <td>36.7843</td>\n",
       "      <td>0.025884</td>\n",
       "      <td>0.025884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>33611</td>\n",
       "      <td>33612</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2022-10-04 04:00:00</td>\n",
       "      <td>2022-10-04</td>\n",
       "      <td>145.030</td>\n",
       "      <td>146.2200</td>\n",
       "      <td>144.260</td>\n",
       "      <td>146.10</td>\n",
       "      <td>96785630.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030161</td>\n",
       "      <td>-0.180357</td>\n",
       "      <td>10.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0.025623</td>\n",
       "      <td>0.2907</td>\n",
       "      <td>-0.034219</td>\n",
       "      <td>37.9093</td>\n",
       "      <td>0.030584</td>\n",
       "      <td>0.030584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>33612</td>\n",
       "      <td>33613</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2022-10-05 04:00:00</td>\n",
       "      <td>2022-10-05</td>\n",
       "      <td>144.075</td>\n",
       "      <td>147.3800</td>\n",
       "      <td>143.010</td>\n",
       "      <td>146.40</td>\n",
       "      <td>83933253.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001604</td>\n",
       "      <td>-0.118751</td>\n",
       "      <td>10.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0.002053</td>\n",
       "      <td>0.2855</td>\n",
       "      <td>-0.017888</td>\n",
       "      <td>37.8328</td>\n",
       "      <td>-0.002018</td>\n",
       "      <td>-0.002018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>33613</td>\n",
       "      <td>33614</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2022-10-06 04:00:00</td>\n",
       "      <td>2022-10-06</td>\n",
       "      <td>145.810</td>\n",
       "      <td>147.5400</td>\n",
       "      <td>145.220</td>\n",
       "      <td>145.43</td>\n",
       "      <td>72586982.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005023</td>\n",
       "      <td>-0.110901</td>\n",
       "      <td>10.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>-0.006626</td>\n",
       "      <td>0.3052</td>\n",
       "      <td>0.069002</td>\n",
       "      <td>37.4452</td>\n",
       "      <td>-0.010245</td>\n",
       "      <td>-0.010245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows √ó 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index     id symbol           timestamp       date     open      high  \\\n",
       "0    33494  33495   AAPL 2022-04-18 04:00:00 2022-04-18  163.920  166.5984   \n",
       "1    33495  33496   AAPL 2022-04-19 04:00:00 2022-04-19  165.020  167.8200   \n",
       "2    33496  33497   AAPL 2022-04-20 04:00:00 2022-04-20  168.760  168.8800   \n",
       "3    33497  33498   AAPL 2022-04-21 04:00:00 2022-04-21  168.910  171.5300   \n",
       "4    33498  33499   AAPL 2022-04-22 04:00:00 2022-04-22  166.460  167.8699   \n",
       "..     ...    ...    ...                 ...        ...      ...       ...   \n",
       "115  33609  33610   AAPL 2022-09-30 04:00:00 2022-09-30  141.280  143.1000   \n",
       "116  33610  33611   AAPL 2022-10-03 04:00:00 2022-10-03  138.210  143.0700   \n",
       "117  33611  33612   AAPL 2022-10-04 04:00:00 2022-10-04  145.030  146.2200   \n",
       "118  33612  33613   AAPL 2022-10-05 04:00:00 2022-10-05  144.075  147.3800   \n",
       "119  33613  33614   AAPL 2022-10-06 04:00:00 2022-10-06  145.810  147.5400   \n",
       "\n",
       "         low   close       volume  ...  vwap_change  trade_count_change  \\\n",
       "0    163.570  165.07   74493604.0  ...    -0.013575           -0.033606   \n",
       "1    163.910  167.40   75240221.0  ...     0.010325           -0.049385   \n",
       "2    166.100  167.23   73954306.0  ...     0.004275            0.085275   \n",
       "3    165.910  166.42   93153701.0  ...     0.008196            0.263759   \n",
       "4    161.500  161.79   93535037.0  ...    -0.027863           -0.033611   \n",
       "..       ...     ...          ...  ...          ...                 ...   \n",
       "115  138.000  138.20  141390692.0  ...    -0.018747           -0.117879   \n",
       "116  137.685  142.45  124534891.0  ...     0.008126           -0.109068   \n",
       "117  144.260  146.10   96785630.0  ...     0.030161           -0.180357   \n",
       "118  143.010  146.40   83933253.0  ...    -0.001604           -0.118751   \n",
       "119  145.220  145.43   72586982.0  ...     0.005023           -0.110901   \n",
       "\n",
       "     sector_id  industry_id  return_1d     vix  vix_norm    sp500  sp500_norm  \\\n",
       "0         10.0      unknown  -0.001331  0.2217 -0.023348  43.9169   -0.000205   \n",
       "1         10.0      unknown   0.014115  0.2137 -0.036085  44.6221    0.016058   \n",
       "2         10.0      unknown  -0.001016  0.2032 -0.049134  44.5945   -0.000619   \n",
       "3         10.0      unknown  -0.004844  0.2268  0.116142  43.9366   -0.014753   \n",
       "4         10.0      unknown  -0.027821  0.2821  0.243827  42.7178   -0.027740   \n",
       "..         ...          ...        ...     ...       ...      ...         ...   \n",
       "115       10.0      unknown  -0.030039  0.3162 -0.006910  35.8562   -0.015067   \n",
       "116       10.0      unknown   0.030753  0.3010 -0.048071  36.7843    0.025884   \n",
       "117       10.0      unknown   0.025623  0.2907 -0.034219  37.9093    0.030584   \n",
       "118       10.0      unknown   0.002053  0.2855 -0.017888  37.8328   -0.002018   \n",
       "119       10.0      unknown  -0.006626  0.3052  0.069002  37.4452   -0.010245   \n",
       "\n",
       "     market_return_1d  \n",
       "0           -0.000205  \n",
       "1            0.016058  \n",
       "2           -0.000619  \n",
       "3           -0.014753  \n",
       "4           -0.027740  \n",
       "..                ...  \n",
       "115         -0.015067  \n",
       "116          0.025884  \n",
       "117          0.030584  \n",
       "118         -0.002018  \n",
       "119         -0.010245  \n",
       "\n",
       "[120 rows x 35 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ep = OHLCV_DF[OHLCV_DF['symbol']==\"AAPL\"].iloc[71:71+120].copy()\n",
    "train_ep.reset_index()\n",
    "MARKET_FEATURES = ['volume','close']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "  'mean_return': returns.mean(),\n",
    "            'std_return': returns.std(),\n",
    "            'skew': skew(returns),\n",
    "            'kurtosis': kurtosis(returns),\n",
    "            'entropy': entropy(np.histogram(returns, bins=10, density=True)[0] + 1e-8),\n",
    "            'volatility': returns.std(),\n",
    "            'drawdown': (values / np.maximum.accumulate(values)).min() - 1,\n",
    "            'median_return':np.median(returns),\n",
    "\"\"\"\n",
    "def extract_episode_features( df_ep: pd.DataFrame, config={\"lags\":[5]}) -> dict:\n",
    "    returns = df_ep['close'].pct_change().dropna()\n",
    "    values = df_ep['close'].values\n",
    "\n",
    "    feature_dict = {\n",
    "            'mean_return': returns.mean(),\n",
    "            'median_return':np.median(returns),\n",
    "            'std_return': returns.std(),\n",
    "            'skew': skew(returns),\n",
    "            'kurtosis': kurtosis(returns),\n",
    "            'entropy': entropy(np.histogram(returns, bins=10, density=True)[0] + 1e-8),\n",
    "            'volatility': returns.std(),\n",
    "            'drawdown': (values / np.maximum.accumulate(values)).min() - 1,\n",
    "        }\n",
    "\n",
    "    try:\n",
    "        adf_result = adfuller(returns)\n",
    "        feature_dict['adf_pvalue'] = adf_result[1]\n",
    "    except Exception:\n",
    "        feature_dict['adf_pvalue'] = 1.0\n",
    "\n",
    "    try:\n",
    "        for lag in range(1, config['lags'] + 1):\n",
    "            df_ep[f'return_lag_{lag}'] = df_ep['close'].pct_change().shift(lag)\n",
    "        df_lagged = df_ep.dropna()\n",
    "        if len(df_lagged) < config['min_samples']:\n",
    "            raise Exception(\"Insufficient data\")\n",
    "        X = df_lagged[[f'return_lag_{i}' for i in range(1, config['lags'] + 1)]].values\n",
    "        y = df_lagged['close'].pct_change().dropna().values[-len(X):]\n",
    "\n",
    "        model = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "        model.fit(X, y > 0)\n",
    "        residuals = y - model.predict_proba(X)[:, 1]\n",
    "\n",
    "        feature_dict.update({\n",
    "                'resid_std': residuals.std(),\n",
    "                'resid_skew': skew(residuals),\n",
    "                'resid_kurtosis': kurtosis(residuals),\n",
    "                'ljung_pval': acorr_ljungbox(residuals, lags=[1], return_df=True).iloc[0]['lb_pvalue'],\n",
    "                'resid_acf1': pd.Series(residuals).autocorr(lag=1)\n",
    "        })\n",
    "    except Exception:\n",
    "        feature_dict.update({\n",
    "            'resid_std': np.nan,\n",
    "            'resid_skew': np.nan,\n",
    "            'resid_kurtosis': np.nan,\n",
    "            'ljung_pval': np.nan,\n",
    "            'resid_acf1': np.nan\n",
    "        })\n",
    "\n",
    "    return feature_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a769a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536bfeb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dad449",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f67f509",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIENCE_NAME = \"stock_universe_predictability_selection__MetaFeatures__MetaRlLabeling\"\n",
    "FEATURES_PATH = f\"../data/cache/features_{EXPERIENCE_NAME}.pkl\"\n",
    "TARGETS_PATH = f\"../data/cache/targets_{EXPERIENCE_NAME}.pkl\"\n",
    "META_PATH = f\"../data/cache/meta_{EXPERIENCE_NAME}.pkl\"\n",
    "RL_LABELS_PATH = \"../data/cache/meta_rl_labels_stock_universe_predictability_selection__MetaFeatures__MetaRlLabeling__6293649262173480064.pkl\"\n",
    "\n",
    "excluded_tickers=['CEG', 'GEHC', 'GEV', 'KVUE', 'SOLV']\n",
    "excluded_tickers.sort()\n",
    "#tickers = TOP2_STOCK_BY_SECTOR\n",
    "\n",
    "config={\n",
    "    \"regressor\":\"RandomForestRegressor\",\n",
    "    \"n_estimators\": 200,\n",
    "    \"random_state\":314,\n",
    "    \"transaction_cost\":0\n",
    "}\n",
    "run_settings={\n",
    "    \"excluded_tickers\": excluded_tickers,\n",
    "    \"min_samples\": 10,\n",
    "    \"cv_folds\": 3,\n",
    "    \"lags\": 5,\n",
    "    \"start_date\":\"2022-01-01\",\n",
    "    \"end_date\":\"2025-01-01\",\n",
    "    \"seed\":314,\n",
    "    \"episode_length\":18,\n",
    "    \"noise_feature_cols\": [\"return_1d\", \"volume\"]  ,\n",
    "\n",
    "    \"train_steps\": 300,\n",
    "    \"min_ep_len\" : 18\n",
    "}\n",
    "\n",
    "# Config section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6b26536",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import joblib\n",
    "import hashlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from typing import Optional\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from scipy.stats import skew, kurtosis, entropy\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "\n",
    "class MetaTransferabilityPredictor:\n",
    "    def __init__(self, raw_df: pd.DataFrame, benchmark_path: str, result_path: str, cache_path: str, config: dict):\n",
    "        self.df = raw_df.copy()\n",
    "        self.benchmark_path = benchmark_path\n",
    "        self.result_path = result_path\n",
    "        self.cache_path = cache_path\n",
    "        self.config = config\n",
    "\n",
    "        self.scaler = RobustScaler()\n",
    "        self.model = None\n",
    "        self.meta_df = pd.DataFrame()\n",
    "\n",
    "    def _extract_episode_features(self, df_ep: pd.DataFrame) -> dict:\n",
    "        returns = df_ep['close'].pct_change().dropna()\n",
    "        values = df_ep['close'].values\n",
    "\n",
    "        feature_dict = {\n",
    "            'mean_return': returns.mean(),\n",
    "            'std_return': returns.std(),\n",
    "            'skew': skew(returns),\n",
    "            'kurtosis': kurtosis(returns),\n",
    "            'entropy': entropy(np.histogram(returns, bins=10, density=True)[0] + 1e-8),\n",
    "            'volatility': returns.std(),\n",
    "            'drawdown': (values / np.maximum.accumulate(values)).min() - 1,\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            adf_result = adfuller(returns)\n",
    "            feature_dict['adf_pvalue'] = adf_result[1]\n",
    "        except Exception:\n",
    "            feature_dict['adf_pvalue'] = 1.0\n",
    "\n",
    "        try:\n",
    "            for lag in range(1, self.config['lags'] + 1):\n",
    "                df_ep[f'return_lag_{lag}'] = df_ep['close'].pct_change().shift(lag)\n",
    "            df_lagged = df_ep.dropna()\n",
    "            if len(df_lagged) < self.config['min_samples']:\n",
    "                raise Exception(\"Insufficient data\")\n",
    "            X = df_lagged[[f'return_lag_{i}' for i in range(1, self.config['lags'] + 1)]].values\n",
    "            y = df_lagged['close'].pct_change().dropna().values[-len(X):]\n",
    "\n",
    "            model = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "            model.fit(X, y > 0)\n",
    "            residuals = y - model.predict_proba(X)[:, 1]\n",
    "\n",
    "            feature_dict.update({\n",
    "                'resid_std': residuals.std(),\n",
    "                'resid_skew': skew(residuals),\n",
    "                'resid_kurtosis': kurtosis(residuals),\n",
    "                'ljung_pval': acorr_ljungbox(residuals, lags=[1], return_df=True).iloc[0]['lb_pvalue'],\n",
    "                'resid_acf1': pd.Series(residuals).autocorr(lag=1)\n",
    "            })\n",
    "        except Exception:\n",
    "            feature_dict.update({\n",
    "                'resid_std': np.nan,\n",
    "                'resid_skew': np.nan,\n",
    "                'resid_kurtosis': np.nan,\n",
    "                'ljung_pval': np.nan,\n",
    "                'resid_acf1': np.nan\n",
    "            })\n",
    "\n",
    "        return feature_dict\n",
    "\n",
    "    def extract_features_and_labels(self):\n",
    "        with open(self.benchmark_path) as f:\n",
    "            benchmarks = json.load(f)\n",
    "\n",
    "        ticker = self.config['ticker']\n",
    "        df_ticker = self.df[self.df['symbol'] == ticker].reset_index(drop=True)\n",
    "\n",
    "        meta_records = []\n",
    "        for start_idx in tqdm(benchmarks, desc=\"Processing benchmark episodes\"):\n",
    "            test_idx = start_idx + self.config['episode_steps']\n",
    "            if test_idx + self.config['episode_steps'] >= len(df_ticker):\n",
    "                continue\n",
    "\n",
    "            train_df = df_ticker.iloc[start_idx:start_idx + self.config['episode_steps']]\n",
    "            test_df = df_ticker.iloc[test_idx:test_idx + self.config['episode_steps']]\n",
    "\n",
    "            train_feats = self._extract_episode_features(train_df)\n",
    "            test_feats = self._extract_episode_features(test_df)\n",
    "\n",
    "            hash_id = hashlib.sha256(f\"{ticker}_{start_idx}\".encode()).hexdigest()\n",
    "\n",
    "            train_reward = train_df['close'].pct_change().sum()\n",
    "            test_reward = test_df['close'].pct_change().sum()\n",
    "            rand_train = np.random.choice([-1, 1], size=len(train_df)).sum()\n",
    "            rand_test = np.random.choice([-1, 1], size=len(test_df)).sum()\n",
    "\n",
    "            advantage_train = train_reward - rand_train\n",
    "            advantage_test = test_reward - rand_test\n",
    "            transfer_delta = test_reward - train_reward\n",
    "\n",
    "            record = {\n",
    "                'config_hash': hash_id,\n",
    "                'train_idx': start_idx,\n",
    "                'test_idx': test_idx,\n",
    "                'ticker': ticker,\n",
    "                'advantage_train': advantage_train,\n",
    "                'advantage_test': advantage_test,\n",
    "                'transfer_delta': transfer_delta,\n",
    "                'label': int(transfer_delta > 0),\n",
    "                **{f\"train_{k}\": v for k, v in train_feats.items()},\n",
    "                **{f\"test_{k}\": v for k, v in test_feats.items()}\n",
    "            }\n",
    "            meta_records.append(record)\n",
    "\n",
    "        self.meta_df = pd.DataFrame(meta_records)\n",
    "        self.meta_df.to_pickle(self.cache_path)\n",
    "        print(\"[INFO] Feature and label dataset created and cached.\")\n",
    "\n",
    "    def train_classifier(self):\n",
    "        feature_cols = [c for c in self.meta_df.columns if c not in ['label', 'config_hash', 'ticker', 'train_idx', 'test_idx']]\n",
    "        X = self.meta_df[feature_cols].fillna(0)\n",
    "        y = self.meta_df['label']\n",
    "        X_scaled = self.scaler.fit_transform(X)\n",
    "\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            X_scaled, y, test_size=0.2, random_state=self.config['seed'], stratify=y\n",
    "        )\n",
    "\n",
    "        self.model = RandomForestClassifier(n_estimators=100, random_state=self.config['seed'], class_weight='balanced')\n",
    "        self.model.fit(self.X_train, self.y_train)\n",
    "\n",
    "    def evaluate_model(self):\n",
    "        y_pred = self.model.predict(self.X_test)\n",
    "        print(\"\\n[Classification Report]\")\n",
    "        print(classification_report(self.y_test, y_pred))\n",
    "        cm = confusion_matrix(self.y_test, y_pred)\n",
    "        ConfusionMatrixDisplay(cm).plot(cmap=plt.cm.Blues)\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.show()\n",
    "\n",
    "    def predict(self, new_df: pd.DataFrame):\n",
    "        X_scaled = self.scaler.transform(new_df)\n",
    "        return self.model.predict(X_scaled)\n",
    "\n",
    "    def feature_importance(self):\n",
    "        importances = self.model.feature_importances_\n",
    "        feature_cols = [c for c in self.meta_df.columns if c not in ['label', 'config_hash', 'ticker', 'train_idx', 'test_idx']]\n",
    "        sorted_idx = np.argsort(importances)[::-1]\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.bar(range(len(importances)), importances[sorted_idx])\n",
    "        plt.xticks(range(len(importances)), [feature_cols[i] for i in sorted_idx], rotation=90)\n",
    "        plt.title(\"Meta-Feature Importances\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bcee021",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "MetaTransferabilityPredictor.__init__() missing 1 required positional argument: 'config'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m predictor \u001b[38;5;241m=\u001b[39m MetaTransferabilityPredictor(OHLCV_DF, config, run_settings, EXPERIENCE_NAME)\n",
      "\u001b[1;31mTypeError\u001b[0m: MetaTransferabilityPredictor.__init__() missing 1 required positional argument: 'config'"
     ]
    }
   ],
   "source": [
    "predictor = MetaTransferabilityPredictor(OHLCV_DF, config, run_settings, EXPERIENCE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd04917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data and extract meta-features\n",
    "predictor.prepare_data()\n",
    "predictor.extract_or_load_features()\n",
    "\n",
    "# Train classifier using cached RL labels\n",
    "predictor.train()\n",
    "\n",
    "# Evaluate the trained classifier\n",
    "predictor.evaluate()\n",
    "\n",
    "# Plot feature importance\n",
    "predictor.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcba31b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm = TradingEnvironmentBenchmark()\n",
    "bm.result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b8f011",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba9bc14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
