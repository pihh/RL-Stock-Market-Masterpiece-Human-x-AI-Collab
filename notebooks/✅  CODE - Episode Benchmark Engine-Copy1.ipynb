{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dbdf015",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francisco SÃ¡\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\arrays\\masked.py:61: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e1d6324",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import gymnasium as gym\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy.stats import skew, kurtosis, entropy\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "\n",
    "from src.utils.system import boot\n",
    "from src.defaults import RANDOM_SEEDS, TOP2_STOCK_BY_SECTOR\n",
    "from tracker import OHLCV_DF, EpisodeTracker, EnvironmentTracker, AgentTracker\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1adf8276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration ======================\n",
    "excluded_tickers = sorted(['CEG', 'GEHC', 'GEV', 'KVUE', 'SOLV'])\n",
    "\n",
    "config = {\n",
    "    \"regressor\": \"RandomForestRegressor\",\n",
    "    \"n_estimators\": 300,\n",
    "    \"random_state\": 314,\n",
    "    \"transaction_cost\": 0\n",
    "}\n",
    "\n",
    "run_settings = {\n",
    "    \"excluded_tickers\": excluded_tickers,\n",
    "    \"min_samples\": 10,\n",
    "    \"cv_folds\": 3,\n",
    "    \"lags\": 5,\n",
    "    \"start_date\": \"2023-12-31\",\n",
    "    \"end_date\": \"2025-05-01\",\n",
    "    \"seed\": 314,\n",
    "    \"episode_length\": 50,\n",
    "    \"noise_feature_cols\": [\"return_1d\", \"volume\"],\n",
    "    \"train_steps\": 50_000,\n",
    "    \"lookback\": 0,\n",
    "    \n",
    "}\n",
    "\n",
    "# System Boot =======================\n",
    "DEVICE = boot()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7d55ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Prepare Data ================\n",
    "ohlcv_df = OHLCV_DF.copy()\n",
    "\n",
    "\n",
    "# Filter Tickers ======================\n",
    "tickers = ohlcv_df['symbol'].unique()\n",
    "tickers = tickers[~np.isin(tickers, excluded_tickers)]\n",
    "tickers = [\"AAPL\"]  # Force test with AAPL\n",
    "#tickers = TOP2_STOCK_BY_SECTOR\n",
    "# Load and prepare trackers\n",
    "ep_tracker    = EpisodeTracker()\n",
    "env_tracker   = EnvironmentTracker()\n",
    "agent_tracker = AgentTracker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "503db8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ep = ep_tracker.findEpisode(\"2025-01-01\",\"AAPL\",120,\"both\")\n",
    "train_df = ep['train']['df']\n",
    "\n",
    "env = env_tracker.findEnvironment(\n",
    "    \"v4\",\n",
    "    {\"lookback\":0,\n",
    "     #\"scaling_strategy\":\"power\",\n",
    "     \"n_timesteps\":120,\n",
    "     \"market_features\":[ \"close\", \"price_change\", \"volume_change\"]},\n",
    "    ticker=\"AAPL\",\n",
    "    start_idx=ep['train']['df_start_iloc']\n",
    ")\n",
    "agent = agent_tracker.findAgent('PPO','MlpPolicy',{})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aee9c107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x1881585cd50>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ep['train']\n",
    "model = agent[\"model\"].boot(env['environment'])\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff7b50f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 119      |\n",
      "|    ep_rew_mean     | -0.293   |\n",
      "| time/              |          |\n",
      "|    fps             | 368      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 119          |\n",
      "|    ep_rew_mean          | -0.227       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 375          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039481735 |\n",
      "|    clip_fraction        | 0.00503      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.69        |\n",
      "|    explained_variance   | -0.107       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.146        |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00425     |\n",
      "|    value_loss           | 0.253        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 119         |\n",
      "|    ep_rew_mean          | -0.0435     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 344         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004291957 |\n",
      "|    clip_fraction        | 0.00679     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.688      |\n",
      "|    explained_variance   | 0.169       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0454     |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00449    |\n",
      "|    value_loss           | 0.221       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 119         |\n",
      "|    ep_rew_mean          | 0.179       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 353         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 23          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008619598 |\n",
      "|    clip_fraction        | 0.0177      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.684      |\n",
      "|    explained_variance   | 0.14        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0335     |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00589    |\n",
      "|    value_loss           | 0.206       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 119          |\n",
      "|    ep_rew_mean          | 0.386        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 353          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 28           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033814711 |\n",
      "|    clip_fraction        | 0.0268       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.679       |\n",
      "|    explained_variance   | 0.103        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.68e-05     |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00903     |\n",
      "|    value_loss           | 0.169        |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x18822e54a90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=10_000)\n",
    "#env['environment'].reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c1da71f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'env_id': 13,\n",
       " 'id': 13,\n",
       " 'version': 'v2',\n",
       " 'config': {'lookback': 0,\n",
       "  'market_features': ['close', 'price_change', 'volume_change'],\n",
       "  'n_timesteps': 120,\n",
       "  'seed': 314,\n",
       "  'ticker': 'AAPL',\n",
       "  'start_idx': 631},\n",
       " 'environment': <environments.PositionTradingEnvV2 at 0x18813f28890>}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0966ec8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31284606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions ====================\n",
    "import numpy as np\n",
    "\n",
    "def compute_returns_curve(curve):\n",
    "    returns = np.diff(curve) / curve[:-1]\n",
    "    return returns\n",
    "\n",
    "def sharpe_ratio(returns, risk_free_rate=0.0):\n",
    "    excess = returns - risk_free_rate\n",
    "    return np.mean(excess) / (np.std(excess) + 1e-8)\n",
    "\n",
    "def sortino_ratio(returns, risk_free_rate=0.0):\n",
    "    returns = np.array(returns)\n",
    "    excess = returns - risk_free_rate\n",
    "    downside = excess[excess < 0]\n",
    "    \n",
    "    # Avoid division by zero: if no downside, assume very small downside deviation\n",
    "    if len(downside) == 0:\n",
    "        downside_std = 1e-8\n",
    "    else:\n",
    "        downside_std = np.std(downside)\n",
    "    \n",
    "    return np.mean(excess) / downside_std\n",
    "\n",
    "\n",
    "def calmar_ratio(returns_curve):\n",
    "    total_return = returns_curve[-1] / returns_curve[0] - 1\n",
    "    drawdown = np.maximum.accumulate(returns_curve) - returns_curve\n",
    "    max_drawdown = np.max(drawdown) / returns_curve[0]\n",
    "    return total_return / (max_drawdown + 1e-8)\n",
    "\n",
    "def central_tendency_difference (mean,median,std):\n",
    "    return abs(mean-median)/(abs(std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eacd598e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import hashlib\n",
    "from collections import defaultdict\n",
    "STORAGE_PATH = \"data/experiments/episode_benchmark_engine/runs.csv\"\n",
    "\n",
    "\n",
    "EXCLUDED_TICKERS = sorted([\"CEG\", \"GEHC\", \"GEV\", \"KVUE\", \"SOLV\"])\n",
    "\n",
    "CONFIG = {\n",
    "    \"regressor\": \"RandomForestRegressor\",\n",
    "    \"n_estimators\": 300,\n",
    "    \"random_state\": 314,\n",
    "    \"transaction_cost\": 0,\n",
    "}\n",
    "LOOKBACK = 0\n",
    "EPISODE_LENGTH = 50\n",
    "\n",
    "RUN_SETTINGS = {\n",
    "    \"excluded_tickers\": EXCLUDED_TICKERS,\n",
    "    \"cv_folds\": 3,\n",
    "    \"lags\": 5,\n",
    "    \"seed\": 314,\n",
    "    'total_timesteps':50_000,\n",
    "    \"episode\": {\n",
    "        \"episode_length\": EPISODE_LENGTH,\n",
    "        \"lookback\": LOOKBACK,\n",
    "    },\n",
    "    \"environment\": {\n",
    "        \"market_features\": [\"close\", \"price_change\", \"volume_change\"],\n",
    "        \"version\": \"v2\",\n",
    "        \"lookback\": LOOKBACK,\n",
    "        \"episode_length\": EPISODE_LENGTH,\n",
    "        \"transaction_cost\": 0,\n",
    "    },\n",
    "    \"agent\": {\n",
    "        \"model_class\": \"PPO\",\n",
    "        \"policy_class\": \"MlpPolicy\",\n",
    "        \"config\": {\n",
    "            \"verbose\": 1,\n",
    "            \"ent_coef\":0.1,\n",
    "            \"policy_kwargs\": \n",
    "                {\n",
    "                \n",
    "                    \"net_arch\": [64, 64]\n",
    "                    }\n",
    "                },\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "class EpisodeBenchmark:\n",
    "    def __init__(\n",
    "        self,\n",
    "        tickers=[\"AAPL\"],\n",
    "        config=CONFIG,\n",
    "        run_settings=RUN_SETTINGS,\n",
    "        start_date=\"2024-01-01\",\n",
    "    ):\n",
    "        self.ohlcv_df = OHLCV_DF.copy()\n",
    "        self.tickers = tickers  # Force test with AAPL\n",
    "        self.start_date = start_date\n",
    "\n",
    "        self.config = CONFIG\n",
    "        self.run_settings = RUN_SETTINGS\n",
    "        self.run_settings['environment']['market_features'].sort()\n",
    "        self.ep_tracker = EpisodeTracker()\n",
    "        self.env_tracker = EnvironmentTracker()\n",
    "        self.agent_tracker = AgentTracker()\n",
    "        \n",
    "        self.boot()\n",
    "        \n",
    "    def boot(self):\n",
    "        if os.path.exists(STORAGE_PATH):\n",
    "            self.completed_runs_df = pd.read_csv(STORAGE_PATH)\n",
    "\n",
    "            # Fix: use self.completed_runs_df, not df\n",
    "            self.completed_hashes = set(self.completed_runs_df[\"run_hash\"].unique())\n",
    "            self.seen_seeds = defaultdict(set)\n",
    "            for _, row in self.completed_runs_df.iterrows():\n",
    "                self.seen_seeds[row[\"run_hash\"]].add(row[\"seed\"])\n",
    "        else:\n",
    "            self.completed_runs_df = pd.DataFrame()\n",
    "            self.completed_hashes = set()\n",
    "            self.seen_seeds = defaultdict(set)\n",
    "\n",
    "    def compute_run_hash(self, agent_id, train_episode_id,train_environment_id):\n",
    "        market_features =self.run_settings['environment']['market_features']\n",
    "        market_features.sort()\n",
    "        payload = {\n",
    "            \"agent_id\": agent_id,\n",
    "            \"episode_id\": train_episode_id,\n",
    "            \"environment_id\":train_environment_id,\n",
    "            \"timesteps\": self.run_settings['total_timesteps'],\n",
    "            \"lookback\":self.run_settings['episode']['lookback'],\n",
    "            \"episode_length\":self.run_settings['episode']['episode_length'],\n",
    "            \"market_features\":json.dumps(market_features)\n",
    "        }\n",
    "        return hashlib.md5(json.dumps(payload, sort_keys=True).encode()).hexdigest()\n",
    "    \n",
    "    def extract_agent_diagnostics(self,env, model, mode=\"train\"):\n",
    "        \"\"\"\n",
    "        Runs agent through environment and extracts residual diagnostics\n",
    "        from reward trajectory, wallet progression, and optionally oracle and market.\n",
    "        \"\"\"\n",
    "        rewards = []\n",
    "        residuals_oracle = []\n",
    "        obs = env.reset()[0]\n",
    "        done = False\n",
    "\n",
    "        oracle_progress = []\n",
    "        while not done:\n",
    "            action, _ = model.predict(obs, deterministic=True)\n",
    "            obs, reward, done, _, info = env.step(action)\n",
    "            rewards.append(reward)\n",
    "\n",
    "            # Oracle fallback\n",
    "            oracle_score = info.get(\"oracle_score\", None)\n",
    "            if oracle_score is not None:\n",
    "                oracle_progress.append(oracle_score)\n",
    "                residuals_oracle.append(oracle_score - reward)\n",
    "            else:\n",
    "                oracle_progress.append(abs(reward))\n",
    "\n",
    "        # Agent vs Oracle residuals\n",
    "        if residuals_oracle:\n",
    "            r_oracle = np.array(residuals_oracle)\n",
    "        else:\n",
    "            smoothed = pd.Series(rewards).rolling(window=5, min_periods=1).mean()\n",
    "            r_oracle = np.array(rewards) - smoothed.values\n",
    "\n",
    "        # Agent vs Market residuals\n",
    "        agent_returns = np.array(env.wallet_progress)\n",
    "        market_returns = np.array(env.market_progress)\n",
    "        r_market = agent_returns - market_returns\n",
    "\n",
    "        # Daily returns\n",
    "        returns = pd.Series(agent_returns).pct_change().dropna().values\n",
    "        market_pct_returns = pd.Series(market_returns).pct_change().dropna().values\n",
    "\n",
    "        diagnostics = {\n",
    "            f\"{mode}_total_reward\": env.total_reward,\n",
    "            f\"{mode}_wallet\":env.wallet,\n",
    "            f\"{mode}_market\":env.market_progress[-1],\n",
    "\n",
    "            # Residuals vs Oracle\n",
    "            f\"{mode}_resid_oracle_std\": np.std(r_oracle),\n",
    "            f\"{mode}_resid_oracle_skew\": skew(r_oracle),\n",
    "            f\"{mode}_resid_oracle_kurtosis\": kurtosis(r_oracle),\n",
    "            f\"{mode}_resid_oracle_acf1\": pd.Series(r_oracle).autocorr(lag=1),\n",
    "            f\"{mode}_resid_oracle_mean\": np.mean(r_oracle),\n",
    "            f\"{mode}_resid_oracle_median\": np.median(r_oracle),\n",
    "            f\"{mode}_resid_oracle_max\": np.max(r_oracle),\n",
    "            f\"{mode}_resid_oracle_min\": np.min(r_oracle),\n",
    "            f\"{mode}_ljung_oracle_pval\": (\n",
    "                acorr_ljungbox(r_oracle, lags=[min(10, len(r_oracle) - 1)], return_df=True).iloc[0]['lb_pvalue']\n",
    "                if len(r_oracle) > 10 else np.nan\n",
    "            ),\n",
    "\n",
    "            # Residuals vs Market\n",
    "            f\"{mode}_resid_market_std\": np.std(r_market),\n",
    "            f\"{mode}_resid_market_skew\": skew(r_market),\n",
    "            f\"{mode}_resid_market_kurtosis\": kurtosis(r_market),\n",
    "            f\"{mode}_resid_market_acf1\": pd.Series(r_market).autocorr(lag=1),\n",
    "            f\"{mode}_resid_market_mean\": np.mean(r_market),\n",
    "            f\"{mode}_resid_market_median\": np.median(r_market),\n",
    "            f\"{mode}_resid_market_max\": np.max(r_market),\n",
    "            f\"{mode}_resid_market_min\": np.min(r_market),\n",
    "            f\"{mode}_ljung_market_pval\": (\n",
    "                acorr_ljungbox(r_market, lags=[min(10, len(r_market) - 1)], return_df=True).iloc[0]['lb_pvalue']\n",
    "                if len(r_market) > 10 else np.nan\n",
    "            ),\n",
    "\n",
    "            # Financial performance\n",
    "            f\"{mode}_sharpe\": sharpe_ratio(returns),\n",
    "            f\"{mode}_sortino\": sortino_ratio(returns),\n",
    "            f\"{mode}_calmar\": calmar_ratio(agent_returns),\n",
    "            f\"{mode}_market_sharpe\": sharpe_ratio(market_pct_returns),\n",
    "            f\"{mode}_market_sortino\": sortino_ratio(market_pct_returns),\n",
    "            f\"{mode}_market_calmar\": calmar_ratio(market_returns),\n",
    "        }\n",
    "\n",
    "        return diagnostics\n",
    "\n",
    "\n",
    "    def run(self, tickers=None):\n",
    "        # Configurations =============================\n",
    "        config = self.config\n",
    "        run_settings = self.run_settings\n",
    "\n",
    "        # Feature Extraction Loop ====================\n",
    "        features, targets, metadata, runs = [], [], [], []\n",
    "        ohlcv_df = self.ohlcv_df.copy()\n",
    "\n",
    "        if tickers == None:\n",
    "            tickers = self.tickers\n",
    "        \n",
    "        seed = 314\n",
    "        boot(seed)\n",
    "        \n",
    "        for symbol in tqdm(tickers):\n",
    "            df = ohlcv_df[ohlcv_df[\"symbol\"] == symbol].sort_values(\"date\").copy()\n",
    "            df = df[df[\"date\"] > self.start_date]\n",
    "            df = df.iloc[: -self.run_settings[\"episode\"][\"episode_length\"]]\n",
    "            months = df[\"month\"].unique()\n",
    "            \n",
    "            for i  in range(len(months)):\n",
    "                try:\n",
    "\n",
    "                    target_date = str(months[i]) + \"-01\"\n",
    "                    \n",
    "                    episodes = self.ep_tracker.findEpisode(\n",
    "                        target_date,\n",
    "                        symbol,\n",
    "                        episode_length=self.run_settings[\"episode\"][\"episode_length\"],\n",
    "                        lookback=self.run_settings[\"episode\"][\"lookback\"],\n",
    "                        mode=\"both\",\n",
    "                    )\n",
    "\n",
    "                    train_episode = episodes[\"train\"]\n",
    "                    test_episode = episodes[\"test\"]\n",
    "\n",
    "                    env_tracker = EnvironmentTracker()\n",
    "\n",
    "                    train_env_config = {\n",
    "                        \"ticker\": symbol,\n",
    "                        \"n_timesteps\": self.run_settings[\"episode\"][\"episode_length\"],\n",
    "                        \"lookback\": self.run_settings[\"episode\"][\"lookback\"],\n",
    "                        \"market_features\":self.run_settings['environment']['market_features'],\n",
    "                        \"seed\": seed,\n",
    "                        \"start_idx\": train_episode[\"df_start_iloc\"],  # type: ignore\n",
    "                    }\n",
    "                    test_env_config = train_env_config.copy()\n",
    "                    test_env_config[\"start_idx\"] = test_episode[\"df_start_iloc\"] # type: ignore\n",
    "\n",
    "                    env_info = env_tracker.findEnvironment(\n",
    "                        version=\"v2\", config=train_env_config\n",
    "                    )\n",
    "                    \n",
    "                    train_env = env_info[\"environment\"]\n",
    "                    #train_config[\"start_idx\"] = test_episode[\"start_idx\"]\n",
    "                    \n",
    "                    test_env = env_tracker.findEnvironment(\n",
    "                        version=\"v2\", config=test_env_config\n",
    "                    )\n",
    "                   \n",
    "                    test_env = test_env[\"environment\"]\n",
    "\n",
    "                    tracker = AgentTracker()\n",
    "                    \n",
    "                    agent = tracker.findAgent(\n",
    "                        **self.run_settings['agent']\n",
    "                   \n",
    "                    )\n",
    "                    \n",
    "                    run_hash = self.compute_run_hash(\n",
    "                        agent_id=agent[\"id\"],\n",
    "                        train_episode_id=train_episode[\"id\"],\n",
    "                        train_environment_id=env_info['id']\n",
    "                    )\n",
    "                    if run_hash in self.completed_hashes and seed in self.seen_seeds[run_hash]:\n",
    "                        continue  # Skip\n",
    "                        \n",
    "                    _model = agent[\"model\"].boot(train_env)\n",
    "                    _model.learn(total_timesteps=self.run_settings['total_timesteps'])\n",
    "                    \n",
    "                    # diagnostics \n",
    "                     \n",
    "                    train_diagnostics =self.extract_agent_diagnostics(train_env,_model,mode=\"train\")\n",
    "                    test_diagnostics =self.extract_agent_diagnostics(test_env,_model,mode=\"test\")\n",
    "                    full_diagnostics = {\n",
    "                        **train_diagnostics,\n",
    "                        **test_diagnostics\n",
    "                    }\n",
    "                    #ddf.append(full_diagnostics)\n",
    "                    results =  {\n",
    "                        'run_hash':run_hash,\n",
    "                        'seed':seed,\n",
    "                        'target_date':target_date,\n",
    "                            \"agent\":self.run_settings['agent']['model_class'],\n",
    "                            \"policy\":self.run_settings['agent']['policy_class'],\n",
    "                            \"env_version\":env_info['version'],\n",
    "                            \"train_episode_id\": train_episode[\"id\"],\n",
    "                            \"test_episode_id\":  test_episode[\"id\"],\n",
    "                            \"total_timesteps\": self.run_settings['total_timesteps'],\n",
    "                            \"ticker\": symbol,\n",
    "                            \"target_date\": target_date,\n",
    "                            \"environment_id\": env_info[\"id\"],\n",
    "                            \"agent_id\": agent[\"id\"],\n",
    "                            \"episode_length\":self.run_settings['episode']['episode_length'],\n",
    "                            \"lookback\":self.run_settings['episode']['lookback'],\n",
    "                            \"market_features\":json.dumps(self.run_settings['environment']['market_features']),\n",
    "                            **full_diagnostics\n",
    "                        }\n",
    "                    if run_hash in self.completed_hashes and seed in self.seen_seeds[run_hash]:\n",
    "                        print(f\"Skipping already completed run {run_hash} with seed {seed}\")\n",
    "                    else:\n",
    "                        self.completed_runs_df = pd.concat([self.completed_runs_df, pd.DataFrame([results])], ignore_index=True)\n",
    "                        self.completed_hashes.add(run_hash)\n",
    "                        self.seen_seeds[run_hash].add(seed)\n",
    "                        self.completed_runs_df.to_csv(STORAGE_PATH,index=False)\n",
    "\n",
    "                    runs.append(\n",
    "                        {\n",
    "                            \"agent\":self.run_settings['agent']['model_class'],\n",
    "                            \"policy\":self.run_settings['agent']['policy_class'],\n",
    "                            \"env_version\":\"v2\",\n",
    "                     \n",
    "                            \"train_episode_id\": train_episode[\"id\"],\n",
    "                            \"test_episode_id\":  test_episode[\"id\"],\n",
    "                            \"total_timesteps\": self.run_settings['total_timesteps'],\n",
    "                            \"ticker\": symbol,\n",
    "                            \"target_date\": target_date,\n",
    "                            \"environment_id\": env_info[\"id\"],\n",
    "                            \"agent_id\": agent[\"id\"],\n",
    "                            \"model\": _model,\n",
    "                            \"train_env\": train_env,\n",
    "                            \"test_env\": test_env,\n",
    "                            **full_diagnostics\n",
    "                        }\n",
    "                    )\n",
    "               \n",
    "                    print('next')\n",
    "                except Exception as e:\n",
    "                    print(f\"Skipping {symbol} {months[i]} due to error: {e}\")\n",
    "             \n",
    "        return runs    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e6ed33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eb = EpisodeBenchmark(tickers=TOP2_STOCK_BY_SECTOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a3a43f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_total_reward': -0.2112629259249607,\n",
       " 'train_wallet': 1,\n",
       " 'train_market': 1.123126949949466,\n",
       " 'train_resid_oracle_std': 0.024695197241272563,\n",
       " 'train_resid_oracle_skew': 1.3407164336676156,\n",
       " 'train_resid_oracle_kurtosis': 8.731594161080057,\n",
       " 'train_resid_oracle_acf1': 0.04875954464630813,\n",
       " 'train_resid_oracle_mean': 0.00045379600177894815,\n",
       " 'train_resid_oracle_median': -0.0012578296121428774,\n",
       " 'train_resid_oracle_max': 0.13934752896326452,\n",
       " 'train_resid_oracle_min': -0.09039298601881147,\n",
       " 'train_ljung_oracle_pval': 0.023079967734685555,\n",
       " 'train_resid_market_std': 0.04563653121163207,\n",
       " 'train_resid_market_skew': -0.9359093868439381,\n",
       " 'train_resid_market_kurtosis': 0.7607640259387449,\n",
       " 'train_resid_market_acf1': 0.9613263481148321,\n",
       " 'train_resid_market_mean': -0.00804295880148433,\n",
       " 'train_resid_market_median': 0.0008788504635935945,\n",
       " 'train_resid_market_max': 0.08937909214747108,\n",
       " 'train_resid_market_min': -0.1381992354000967,\n",
       " 'train_ljung_market_pval': 1.6997133151070983e-120,\n",
       " 'train_sharpe': 0.0,\n",
       " 'train_sortino': 0.0,\n",
       " 'train_calmar': 0.0,\n",
       " 'train_market_sharpe': 0.08434086382473578,\n",
       " 'train_market_sortino': 0.10215646954792426,\n",
       " 'train_market_calmar': 1.0155852732451096}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#runs = eb.run()\n",
    "eb.extract_agent_diagnostics(env['environment'],model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b3b2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "---------------------------------\n",
    "| rollout/           |          |\n",
    "|    ep_len_mean     | 119      |\n",
    "|    ep_rew_mean     | -0.293   |\n",
    "| time/              |          |\n",
    "|    fps             | 368      |\n",
    "|    iterations      | 1        |\n",
    "|    time_elapsed    | 5        |\n",
    "|    total_timesteps | 2048     |\n",
    "---------------------------------\n",
    "------------------------------------------\n",
    "| rollout/                |              |\n",
    "|    ep_len_mean          | 119          |\n",
    "|    ep_rew_mean          | -0.227       |\n",
    "| time/                   |              |\n",
    "|    fps                  | 375          |\n",
    "|    iterations           | 2            |\n",
    "|    time_elapsed         | 10           |\n",
    "|    total_timesteps      | 4096         |\n",
    "| train/                  |              |\n",
    "|    approx_kl            | 0.0039481735 |\n",
    "|    clip_fraction        | 0.00503      |\n",
    "|    clip_range           | 0.2          |\n",
    "|    entropy_loss         | -0.69        |\n",
    "|    explained_variance   | -0.107       |\n",
    "|    learning_rate        | 0.0003       |\n",
    "|    loss                 | 0.146        |\n",
    "|    n_updates            | 10           |\n",
    "|    policy_gradient_loss | -0.00425     |\n",
    "|    value_loss           | 0.253        |\n",
    "------------------------------------------\n",
    "-----------------------------------------\n",
    "| rollout/                |             |\n",
    "|    ep_len_mean          | 119         |\n",
    "|    ep_rew_mean          | -0.0435     |\n",
    "| time/                   |             |\n",
    "|    fps                  | 344         |\n",
    "|    iterations           | 3           |\n",
    "|    time_elapsed         | 17          |\n",
    "|    total_timesteps      | 6144        |\n",
    "| train/                  |             |\n",
    "|    approx_kl            | 0.004291957 |\n",
    "|    clip_fraction        | 0.00679     |\n",
    "|    clip_range           | 0.2         |\n",
    "|    entropy_loss         | -0.688      |\n",
    "|    explained_variance   | 0.169       |\n",
    "|    learning_rate        | 0.0003      |\n",
    "|    loss                 | -0.0454     |\n",
    "|    n_updates            | 20          |\n",
    "|    policy_gradient_loss | -0.00449    |\n",
    "|    value_loss           | 0.221       |\n",
    "-----------------------------------------\n",
    "-----------------------------------------\n",
    "| rollout/                |             |\n",
    "|    ep_len_mean          | 119         |\n",
    "|    ep_rew_mean          | 0.179       |\n",
    "| time/                   |             |\n",
    "|    fps                  | 353         |\n",
    "|    iterations           | 4           |\n",
    "|    time_elapsed         | 23          |\n",
    "|    total_timesteps      | 8192        |\n",
    "| train/                  |             |\n",
    "|    approx_kl            | 0.008619598 |\n",
    "|    clip_fraction        | 0.0177      |\n",
    "|    clip_range           | 0.2         |\n",
    "|    entropy_loss         | -0.684      |\n",
    "|    explained_variance   | 0.14        |\n",
    "|    learning_rate        | 0.0003      |\n",
    "|    loss                 | -0.0335     |\n",
    "|    n_updates            | 30          |\n",
    "|    policy_gradient_loss | -0.00589    |\n",
    "|    value_loss           | 0.206       |\n",
    "-----------------------------------------\n",
    "------------------------------------------\n",
    "| rollout/                |              |\n",
    "|    ep_len_mean          | 119          |\n",
    "|    ep_rew_mean          | 0.386        |\n",
    "| time/                   |              |\n",
    "|    fps                  | 353          |\n",
    "|    iterations           | 5            |\n",
    "|    time_elapsed         | 28           |\n",
    "|    total_timesteps      | 10240        |\n",
    "| train/                  |              |\n",
    "|    approx_kl            | 0.0033814711 |\n",
    "|    clip_fraction        | 0.0268       |\n",
    "|    clip_range           | 0.2          |\n",
    "|    entropy_loss         | -0.679       |\n",
    "|    explained_variance   | 0.103        |\n",
    "|    learning_rate        | 0.0003       |\n",
    "|    loss                 | 9.68e-05     |\n",
    "|    n_updates            | 40           |\n",
    "|    policy_gradient_loss | -0.00903     |\n",
    "|    value_loss           | 0.169        |\n",
    "------------------------------------------\n",
    "<stable_baselines3.ppo.ppo.PPO at 0x18822e54a90>\n",
    "\n",
    "{'train_total_reward': -0.2112629259249607,\n",
    " 'train_wallet': 1,\n",
    " 'train_market': 1.123126949949466,\n",
    " 'train_resid_oracle_std': 0.024695197241272563,\n",
    " 'train_resid_oracle_skew': 1.3407164336676156,\n",
    " 'train_resid_oracle_kurtosis': 8.731594161080057,\n",
    " 'train_resid_oracle_acf1': 0.04875954464630813,\n",
    " 'train_resid_oracle_mean': 0.00045379600177894815,\n",
    " 'train_resid_oracle_median': -0.0012578296121428774,\n",
    " 'train_resid_oracle_max': 0.13934752896326452,\n",
    " 'train_resid_oracle_min': -0.09039298601881147,\n",
    " 'train_ljung_oracle_pval': 0.023079967734685555,\n",
    " 'train_resid_market_std': 0.04563653121163207,\n",
    " 'train_resid_market_skew': -0.9359093868439381,\n",
    " 'train_resid_market_kurtosis': 0.7607640259387449,\n",
    " 'train_resid_market_acf1': 0.9613263481148321,\n",
    " 'train_resid_market_mean': -0.00804295880148433,\n",
    " 'train_resid_market_median': 0.0008788504635935945,\n",
    " 'train_resid_market_max': 0.08937909214747108,\n",
    " 'train_resid_market_min': -0.1381992354000967,\n",
    " 'train_ljung_market_pval': 1.6997133151070983e-120,\n",
    " 'train_sharpe': 0.0,\n",
    " 'train_sortino': 0.0,\n",
    " 'train_calmar': 0.0,\n",
    " 'train_market_sharpe': 0.08434086382473578,\n",
    " 'train_market_sortino': 0.10215646954792426,\n",
    " 'train_market_calmar': 1.0155852732451096}\n",
    "\n",
    "# V4 ============================================\n",
    "---------------------------------\n",
    "| rollout/           |          |\n",
    "|    ep_len_mean     | 119      |\n",
    "|    ep_rew_mean     | -0.293   |\n",
    "| time/              |          |\n",
    "|    fps             | 368      |\n",
    "|    iterations      | 1        |\n",
    "|    time_elapsed    | 5        |\n",
    "|    total_timesteps | 2048     |\n",
    "---------------------------------\n",
    "------------------------------------------\n",
    "| rollout/                |              |\n",
    "|    ep_len_mean          | 119          |\n",
    "|    ep_rew_mean          | -0.227       |\n",
    "| time/                   |              |\n",
    "|    fps                  | 375          |\n",
    "|    iterations           | 2            |\n",
    "|    time_elapsed         | 10           |\n",
    "|    total_timesteps      | 4096         |\n",
    "| train/                  |              |\n",
    "|    approx_kl            | 0.0039481735 |\n",
    "|    clip_fraction        | 0.00503      |\n",
    "|    clip_range           | 0.2          |\n",
    "|    entropy_loss         | -0.69        |\n",
    "|    explained_variance   | -0.107       |\n",
    "|    learning_rate        | 0.0003       |\n",
    "|    loss                 | 0.146        |\n",
    "|    n_updates            | 10           |\n",
    "|    policy_gradient_loss | -0.00425     |\n",
    "|    value_loss           | 0.253        |\n",
    "------------------------------------------\n",
    "-----------------------------------------\n",
    "| rollout/                |             |\n",
    "|    ep_len_mean          | 119         |\n",
    "|    ep_rew_mean          | -0.0435     |\n",
    "| time/                   |             |\n",
    "|    fps                  | 344         |\n",
    "|    iterations           | 3           |\n",
    "|    time_elapsed         | 17          |\n",
    "|    total_timesteps      | 6144        |\n",
    "| train/                  |             |\n",
    "|    approx_kl            | 0.004291957 |\n",
    "|    clip_fraction        | 0.00679     |\n",
    "|    clip_range           | 0.2         |\n",
    "|    entropy_loss         | -0.688      |\n",
    "|    explained_variance   | 0.169       |\n",
    "|    learning_rate        | 0.0003      |\n",
    "|    loss                 | -0.0454     |\n",
    "|    n_updates            | 20          |\n",
    "|    policy_gradient_loss | -0.00449    |\n",
    "|    value_loss           | 0.221       |\n",
    "-----------------------------------------\n",
    "-----------------------------------------\n",
    "| rollout/                |             |\n",
    "|    ep_len_mean          | 119         |\n",
    "|    ep_rew_mean          | 0.179       |\n",
    "| time/                   |             |\n",
    "|    fps                  | 353         |\n",
    "|    iterations           | 4           |\n",
    "|    time_elapsed         | 23          |\n",
    "|    total_timesteps      | 8192        |\n",
    "| train/                  |             |\n",
    "|    approx_kl            | 0.008619598 |\n",
    "|    clip_fraction        | 0.0177      |\n",
    "|    clip_range           | 0.2         |\n",
    "|    entropy_loss         | -0.684      |\n",
    "|    explained_variance   | 0.14        |\n",
    "|    learning_rate        | 0.0003      |\n",
    "|    loss                 | -0.0335     |\n",
    "|    n_updates            | 30          |\n",
    "|    policy_gradient_loss | -0.00589    |\n",
    "|    value_loss           | 0.206       |\n",
    "-----------------------------------------\n",
    "------------------------------------------\n",
    "| rollout/                |              |\n",
    "|    ep_len_mean          | 119          |\n",
    "|    ep_rew_mean          | 0.386        |\n",
    "| time/                   |              |\n",
    "|    fps                  | 353          |\n",
    "|    iterations           | 5            |\n",
    "|    time_elapsed         | 28           |\n",
    "|    total_timesteps      | 10240        |\n",
    "| train/                  |              |\n",
    "|    approx_kl            | 0.0033814711 |\n",
    "|    clip_fraction        | 0.0268       |\n",
    "|    clip_range           | 0.2          |\n",
    "|    entropy_loss         | -0.679       |\n",
    "|    explained_variance   | 0.103        |\n",
    "|    learning_rate        | 0.0003       |\n",
    "|    loss                 | 9.68e-05     |\n",
    "|    n_updates            | 40           |\n",
    "|    policy_gradient_loss | -0.00903     |\n",
    "|    value_loss           | 0.169        |\n",
    "------------------------------------------\n",
    "\n",
    "{'train_total_reward': 1.8404246654035108,\n",
    " 'train_wallet': 1.2311124381229703,\n",
    " 'train_market': 1.2610675191320353,\n",
    " 'train_resid_oracle_std': 0.1649787826127421,\n",
    " 'train_resid_oracle_skew': 7.100542170671588,\n",
    " 'train_resid_oracle_kurtosis': 71.28572593394061,\n",
    " 'train_resid_oracle_acf1': -0.03614584193924006,\n",
    " 'train_resid_oracle_mean': -6.761922913547766e-05,\n",
    " 'train_resid_oracle_median': -0.0005808469933746441,\n",
    " 'train_resid_oracle_max': 1.5933017925434414,\n",
    " 'train_resid_oracle_min': -0.4090312514457644,\n",
    " 'train_ljung_oracle_pval': 0.43397976725966475,\n",
    " 'train_resid_market_std': 0.004207810947213421,\n",
    " 'train_resid_market_skew': 3.914946935632663,\n",
    " 'train_resid_market_kurtosis': 19.557611931096172,\n",
    " 'train_resid_market_acf1': 0.6085714183637173,\n",
    " 'train_resid_market_mean': -0.004342682837053663,\n",
    " 'train_resid_market_median': -0.006046241177076084,\n",
    " 'train_resid_market_max': 0.022354143814353078,\n",
    " 'train_resid_market_min': -0.006476324087659302,\n",
    " 'train_ljung_market_pval': 4.222512971005281e-58,\n",
    " 'train_sharpe': 0.09010650230498658,\n",
    " 'train_sortino': 0.32005405023559785,\n",
    " 'train_calmar': 1.8007265566029227,\n",
    " 'train_market_sharpe': 0.09126171812151522,\n",
    " 'train_market_sortino': 0.32781071367581516,\n",
    " 'train_market_calmar': 1.8345812189354533}\n",
    "<stable_baselines3.ppo.ppo.PPO at 0x18822e54a90>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca454ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "xxxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a57726e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pddf= pd.DataFrame(runs)\n",
    "pddf['train_episode_id'],pddf['test_episode_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b60975",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [col for col in pddf.columns if col.startswith('test_') and col != 'test_total_reward']\n",
    "pddf_cleaned = pddf.drop(columns=cols_to_drop)\n",
    "\n",
    "# Now you can compute correlation\n",
    "correlations = pddf_cleaned.corr(numeric_only=True)['test_total_reward'].sort_values(ascending=False)\n",
    "correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fbd473",
   "metadata": {},
   "outputs": [],
   "source": [
    "pddf[['train_wallet','test_wallet','train_market','test_market','test_total_reward',\"train_total_reward\",\n",
    "\"train_sortino\"                  ,\n",
    "\"train_calmar\"                   ,\n",
    "\"train_resid_market_acf1\"        ,\n",
    "\"train_resid_oracle_kurtosis\"    ,\n",
    "\"train_sharpe\"                   ,\n",
    "\"train_resid_oracle_max\"         ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74ab044",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppdf['train_episode_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353abf31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
