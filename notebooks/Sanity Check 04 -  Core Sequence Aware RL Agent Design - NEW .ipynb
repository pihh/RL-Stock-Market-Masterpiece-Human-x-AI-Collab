{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33beca1f",
   "metadata": {},
   "source": [
    "#  Core Sequence-Aware Agent Design v2\n",
    "\n",
    "This experiment explores a transformer-based recurrent PPO agent for financial trading. The environment is sequence-aware and includes both regime-based augmentation and per-episode reward normalization. The agent is evaluated across top 2 stocks in each sector using structured episode sequences to assess learning generalization.\n",
    "\n",
    "---\n",
    "\n",
    "##  Experiment Configuration\n",
    "\n",
    "| Parameter               | Value                         |\n",
    "|-------------------------|-------------------------------|\n",
    "| Agent                   | Recurrent PPO + Transformer   |\n",
    "| Env Wrapper             | RegimeAugmentingWrapper + PerEpisodeRewardNormalizer |\n",
    "| Episode Length          | 100                           |\n",
    "| Episodes                | 20                            |\n",
    "| Eval Episodes           | 3 per iteration               |\n",
    "| Steps per Update        | 800                           |\n",
    "| Batch Size              | 100                           |\n",
    "| Total Timesteps         | 20,000                        |\n",
    "| Learning Rate           | 0.0003                        |\n",
    "| Entropy Coefficient     | 0.005                         |\n",
    "| Value Function Coeff    | 0.5                           |\n",
    "| Max Gradient Norm       | 0.5                           |\n",
    "| Normalize Advantage     | True                          |\n",
    "| Optimizer               | Adam                          |\n",
    "| Transformer d_model     | 64                            |\n",
    "| Heads                  | 4                             |\n",
    "| Layers                 | 2                             |\n",
    "\n",
    "---\n",
    "\n",
    "## Environment Setup\n",
    "\n",
    "- **Train Set:** 2023-01-01 → 2023-07-01\n",
    "- **Test Set:** 2023-07-01 → 2024-01-01\n",
    "- **Assets:** Top 2 stocks by sector\n",
    "- **Sequence Split:** 80% train / 20% eval sequences\n",
    "\n",
    "---\n",
    "\n",
    "##  Agent Architecture\n",
    "\n",
    "- **Feature Extractor:** Transformer encoder with causal mask and learnable positional encoding.\n",
    "- **Policy Class:** Custom `TransformerPolicy` extending `RecurrentActorCriticPolicy`.\n",
    "- **Reward Normalization:** Online normalization within episodes.\n",
    "- **Regime Augmentation:** Appends one-hot encoded market regime to each timestep.\n",
    "\n",
    "---\n",
    "\n",
    "## Training Summary (Selected Stats)\n",
    "\n",
    "| Timesteps | Ep Rew Mean | Explained Variance | Value Loss | Policy Grad Loss |\n",
    "|-----------|-------------|--------------------|------------|------------------|\n",
    "|  8000     | 3.21        | 0.15               | 4.68       | -0.00277         |\n",
    "| 14400     | 2.90        | 0.645              | 1.71       |  0.00163         |\n",
    "| 20000     | **3.79**    | **0.751**          | 1.59       | -0.00012         |\n",
    "\n",
    "---\n",
    "\n",
    "## Evaluation Snapshots\n",
    "\n",
    "| Timestep | Mean Reward | Std Dev | Eval Length |\n",
    "|----------|-------------|---------|-------------|\n",
    "| 5000     | -8.17       | ±8.72   | 102         |\n",
    "| 10000    | -4.43       | ±7.59   | 102         |\n",
    "| 15000    | -6.17       | ±4.92   | 102         |\n",
    "| 20000    | **0.24**    | ±2.86   | 102         |\n",
    "\n",
    "---\n",
    "\n",
    "## Statistical Significance\n",
    "\n",
    "### Paired t-test and Mann-Whitney U-test\n",
    "\n",
    "| Metric       | t-test p-value | Mann-Whitney p-value |\n",
    "|--------------|----------------|-----------------------|\n",
    "| `total_reward` | 0.0300         | 0.0075                |\n",
    "| `calmar`       | 0.0132         | 0.0075                |\n",
    "\n",
    "✅ Both `total_reward` and `calmar ratio` show **statistically significant** improvements compared to the baseline.  \n",
    "Especially, Calmar implies **more stable and risk-adjusted returns**.\n",
    "\n",
    "> Note: `sharpe`, `sortino`, and `final_wealth` were skipped due to empty values in the evaluation logs. Ensure metrics are logged and valid across all test episodes to include them.\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. **Fix missing metrics** (`sharpe`, `sortino`, etc.) in the logging pipeline.\n",
    "2. **Plot distribution comparisons** (boxplots, histograms) for rewards and risk-adjusted returns.\n",
    "3. **Run ablation**:\n",
    "   - Without regime augmentation\n",
    "   - Without reward normalization\n",
    "   - With simpler agents (e.g., MLP or LSTM)\n",
    "4. **Test in unseen market conditions** or during volatility spikes to check robustness.\n",
    "\n",
    "---\n",
    "\n",
    "_Logged using `ExperimentTracker` — Run Hash: `${experiment_tracker.run_hash}`_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cab993d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP ===================================\n",
    "import jupyter\n",
    "import warnings\n",
    "\n",
    "from src.utils.system import boot, Notify\n",
    "\n",
    "boot()\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "# PACKAGES ================================\n",
    "import os\n",
    "import torch\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import  RobustScaler\n",
    "\n",
    "# FRAMEWORK STUFF =========================\n",
    "from src.defaults import TOP2_STOCK_BY_SECTOR, FEATURE_COLS,EPISODE_LENGTH\n",
    "from src.data.feature_pipeline import load_base_dataframe\n",
    "from src.experiments.experiment_tracker import ExperimentTracker\n",
    "from src.env.base_timeseries_trading_env import BaseSequenceAwareTradingEnv,SequenceAwareAlphaTradingEnv,SequenceAwareBaselineTradingAgent,SequenceAwareCalmarTradingEnv,SequenceAwareCumulativeTradingEnv,SequenceAwareDrawdownTradingEnv,SequenceAwareHybridTradingEnv,SequenceAwareHybridTradingEnv,SequenceAwareSharpeTradingEnv,SequenceAwareSortinoTradingEnv\n",
    "\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from stable_baselines3.common.policies import ActorCriticPolicy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9067d8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "\n",
    "\n",
    "from src.env.step_rewards import reward_sharpe,reward_sortino,reward_drawdown,reward_alpha,reward_cumulative,reward_calmar,reward_hybrid\n",
    "\n",
    "class BaseSequenceAwareTradingEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    Flexible RL Trading Env with windowed sequence obs (Transformer/LSTM/MLP-ready).\n",
    "    - Set `return_sequences=True` for (window_length, obs_dim) obs (for transformers).\n",
    "    - Set `return_sequences=False` for flat obs (classic RL, SB3 LSTM/MLP).\n",
    "    \"\"\"\n",
    "    metadata = {\"render_modes\": [\"human\"]}\n",
    "\n",
    "    def __init__(\n",
    "        self, df, feature_cols=None, reward_fn=None, internal_features=None,\n",
    "        episode_length=100, transaction_cost=0.0001, seed=314, window_length=10, return_sequences=True):\n",
    "        super().__init__()\n",
    "        self.df = df.copy()\n",
    "        self.feature_cols = feature_cols or []\n",
    "        self.internal_features = internal_features or [\n",
    "            \"position\", \"holding_period\", \"cumulative_reward\", \"pct_time\",\n",
    "            \"drawdown\", \"rel_perf\", \"unrealized_pnl\", \"entry_price\", \"time_in_position\"\n",
    "        ]\n",
    "        self.obs_dim = len(self.feature_cols) + len(self.internal_features)\n",
    "        self.episode_length = episode_length +2\n",
    "        self.window_length = max(1, window_length)\n",
    "        self.return_sequences = return_sequences  # True: (window, obs_dim), False: flat\n",
    "        self.transaction_cost = transaction_cost\n",
    "        self.seed = seed\n",
    "        self.action_counts = {0: 0, 1: 0, 2: 0}  # Hold, Buy, Sell\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "        counts = df['symbol'].value_counts()\n",
    "        eligible = counts[counts >= episode_length].index\n",
    "        self.stocks = df[df['symbol'].isin(eligible)]['symbol'].unique()\n",
    "        self.episode_df = df.copy()\n",
    "        self.reward_fn = reward_fn or self.default_reward_fn\n",
    "\n",
    "        # Set observation space\n",
    "        if self.return_sequences:\n",
    "            self.observation_space = spaces.Box(\n",
    "                low=-np.inf, high=np.inf,\n",
    "                shape=(self.window_length, self.obs_dim), dtype=np.float32\n",
    "            )\n",
    "        else:\n",
    "            self.observation_space = spaces.Box(\n",
    "                low=-np.inf, high=np.inf,\n",
    "                shape=(self.window_length * self.obs_dim,), dtype=np.float32\n",
    "            )\n",
    "        self.action_space = spaces.Discrete(3)  # Hold, Buy, Sell\n",
    "\n",
    "    \n",
    "    def get_current_regime(self):\n",
    "        \"\"\"\n",
    "        Detects current regime based on recent return volatility and trend.\n",
    "        Returns:\n",
    "            0 = Bull, 1 = Bear, 2 = Sideways\n",
    "        \"\"\"\n",
    "        if self.current_step < self.window_length:\n",
    "            return 2  # Not enough data, assume sideways\n",
    "\n",
    "        # Use recent price changes to detect regime\n",
    "        returns = self.episode_df['return_1d'].iloc[self.current_step - self.window_length:self.current_step].values\n",
    "        mean_return = returns.mean()\n",
    "        std_return = returns.std()\n",
    "\n",
    "        # Thresholds can be tuned\n",
    "        if mean_return > 0.001 and std_return < 0.01:\n",
    "            return 0  # Bull\n",
    "        elif mean_return < -0.001 and std_return < 0.01:\n",
    "            return 1  # Bear\n",
    "        else:\n",
    "            return 2  # Sideways\n",
    "        \n",
    "    def default_reward_fn(self, position, price_change, **kwargs):\n",
    "        return position * price_change\n",
    "\n",
    "    def set_episode_sequence(self, sequence):\n",
    "        self.episode_sequence = sequence\n",
    "        self.episode_counter = 0\n",
    "\n",
    "    def generate_episode_sequences_v1(self, train_steps=10000):\n",
    "        dataset_length = len(self.df)\n",
    "        episodes = int(train_steps / self.episode_length) + 1\n",
    "        episode_sequences = []\n",
    "        ticker = self.df['symbol'].unique()[0]\n",
    "        min_start = 0\n",
    "        max_start = dataset_length - self.episode_length - 2\n",
    "        for i in range(episodes):\n",
    "            episode_sequences.append((ticker, np.random.randint(0, max_start)))\n",
    "        np.random.shuffle(episode_sequences)\n",
    "        return episode_sequences\n",
    "\n",
    "    def generate_episode_sequences(self, train_steps=10000):\n",
    "        episodes = int(train_steps / self.episode_length) + 1\n",
    "        episode_sequences = []\n",
    "        for _ in range(episodes):\n",
    "            ticker = np.random.choice(self.stocks)\n",
    "            stock_df = self.df[self.df['symbol'] == ticker].reset_index(drop=True)\n",
    "            max_start = len(stock_df) - self.episode_length - 2\n",
    "            if max_start <= 0:\n",
    "                continue  # skip if not enough data\n",
    "            start = np.random.randint(0, max_start)\n",
    "            episode_sequences.append((ticker, start))\n",
    "        np.random.shuffle(episode_sequences)\n",
    "        return episode_sequences\n",
    "\n",
    "    def reset(self, seed=None, options=None, start_index=None):\n",
    "        self.entry_step = None\n",
    "        self.unrealized_pnl = 0\n",
    "        self.relative_perf = 0\n",
    "        self.drawdown = 0\n",
    "        self.time_in_position = 0\n",
    "        self.action_counts = {0: 0, 1: 0, 2: 0}  # Hold, Buy, Sell\n",
    "        if self.seed is not None:\n",
    "            np.random.seed(self.seed)\n",
    "            \n",
    "            \n",
    "        symbol, start_idx = self.episode_sequence[self.episode_counter]\n",
    "        #print(symbol,start_idx,self.df['symbol'].unique())\n",
    "        symbol_df = self.df[self.df['symbol'] == symbol].reset_index(drop=True)\n",
    "        #print(len(symbol_df))\n",
    "        \n",
    "        if start_idx + self.episode_length > len(symbol_df):\n",
    "            print(f\"[WARN] Episode too short for {symbol} at {start_idx}, skipping...\")\n",
    "            self.episode_counter = (self.episode_counter + 1) % len(self.episode_sequence)\n",
    "            return self.reset()  # tenta o próximo episódio\n",
    "\n",
    "        # ✅ Extração segura\n",
    "        #self.episode_df = symbol_df.iloc[start_idx : start_idx + self.episode_length].copy()\n",
    "        end = start_idx + self.episode_length + 1\n",
    "        if end > len(symbol_df):\n",
    "            print(f\"[WARN] Not enough data for {symbol} from {start_idx}, skipping.\")\n",
    "            self.episode_counter = (self.episode_counter + 1) % len(self.episode_sequence)\n",
    "            return self.reset()\n",
    "        self.episode_df = symbol_df.iloc[start_idx:end].copy()\n",
    "        \n",
    "\n",
    "        # Move to next episode (with wrap-around)\n",
    "        self.episode_counter = (self.episode_counter + 1) % len(self.episode_sequence)\n",
    "        \"\"\"\n",
    "        for _ in range(10):  # Try up to 10 times to get a valid episode\n",
    "            stock = self.stocks[0]\n",
    "            if hasattr(self, \"episode_sequence\"):\n",
    "                if self.episode_counter >= len(self.episode_sequence):\n",
    "                    self.episode_counter = 0\n",
    "                _, start = self.episode_sequence[self.episode_counter]\n",
    "                self.episode_counter += 1\n",
    "            else:\n",
    "                stock = np.random.choice(self.stocks)\n",
    "                stock_df = self.df[self.df['symbol'] == stock].reset_index(drop=True)\n",
    "                max_start = len(stock_df) - self.episode_length\n",
    "                if max_start <= 0:\n",
    "                    continue  # Try another stock\n",
    "                start = np.random.randint(0, max_start + 1)\n",
    "\n",
    "            self.stock = stock\n",
    "            stock_df = self.df[self.df['symbol'] == self.stock].reset_index(drop=True)\n",
    "            self.episode_df = stock_df.iloc[int(start):int(start) + int(self.episode_length + 2)].reset_index(drop=True)\n",
    "\n",
    "            if len(self.episode_df) >= self.window_length:\n",
    "                break\n",
    "        else:\n",
    "            raise RuntimeError(\"Failed to sample a valid episode with sufficient data.\")\n",
    "        \"\"\"\n",
    "        self.current_step = 0\n",
    "        self.entry_price = None\n",
    "        self.position = 0\n",
    "        self.holding_period = 0\n",
    "        self.cumulative_reward = 0\n",
    "        self.returns_history = []\n",
    "        self.reward_history = []\n",
    "        self.episode_pct_changes = self.episode_df['return_1d'].values\n",
    "        self.max_possible_reward = np.sum(np.abs(self.episode_pct_changes))\n",
    "        self.current_wealth = 1.0\n",
    "        self.peak_wealth = 1.0\n",
    "\n",
    "        return self._get_obs(), {}\n",
    "\n",
    "    def _get_obs(self):\n",
    "        # Returns a rolling window of observations (2D or flattened)\n",
    "        obs_list = []\n",
    "        #for i in range(self.current_step - self.window_length + 1, self.current_step + 1):\n",
    "        #    idx = max(i, 0)  # pad with earliest available step\n",
    "        #    features = self.episode_df.iloc[idx][self.feature_cols].values.astype(np.float32)\n",
    "        for i in range(self.current_step - self.window_length + 1, self.current_step + 1):\n",
    "            if 0 <= i < len(self.episode_df):\n",
    "                features = self.episode_df.iloc[i][self.feature_cols].values.astype(np.float32)\n",
    "            else:\n",
    "                features = np.zeros(len(self.feature_cols), dtype=np.float32)  # zero padding\n",
    "            internal_state = {\n",
    "                \"position\": self.position,\n",
    "                \"holding_period\": self.holding_period,\n",
    "                \"cumulative_reward\": self.cumulative_reward,\n",
    "                \"pct_time\": self.current_step / self.episode_length,\n",
    "                \"drawdown\": self.drawdown,\n",
    "                \"rel_perf\": self.relative_perf,\n",
    "                \"unrealized_pnl\": self.unrealized_pnl,\n",
    "                \"entry_price\": self.entry_price if self.entry_price is not None else 0.0,\n",
    "                \"time_in_position\": self.time_in_position,\n",
    "            }\n",
    "            internal = np.array([internal_state[name] for name in self.internal_features], dtype=np.float32)\n",
    "            obs = np.concatenate([features, internal])\n",
    "            obs_list.append(obs)\n",
    "        obs_window = np.stack(obs_list)  # shape: (window_length, obs_dim)\n",
    "        if self.return_sequences:\n",
    "            return obs_window  # shape: (window_length, obs_dim)\n",
    "        else:\n",
    "            return obs_window.flatten()  # shape: (window_length * obs_dim,)\n",
    "        \n",
    "    \n",
    "\n",
    "    def step(self, action):\n",
    "        #print(self.current_step,self.episode_length,len(self.episode_df))\n",
    "        done = self.current_step >= self.episode_length - 1\n",
    "        current_row = self.episode_df.iloc[self.current_step]\n",
    "\n",
    "        # Protege contra acesso fora dos limites\n",
    "        if self.current_step + 1 < len(self.episode_df):\n",
    "            next_row = self.episode_df.iloc[self.current_step + 1]\n",
    "        else:\n",
    "            next_row = current_row.copy()  # fallback seguro\n",
    "\n",
    "        price_change = next_row['return_1d']\n",
    "        prev_position = self.position\n",
    "        reward = 0\n",
    "        cost = 0\n",
    "\n",
    "        self.action_counts[action] += 1\n",
    "\n",
    "        if action == 1:  # Buy\n",
    "            if self.position != 1:\n",
    "                if self.position != 0:\n",
    "                    cost = self.transaction_cost\n",
    "                self.position = 1\n",
    "                self.holding_period = 0\n",
    "                self.entry_price = current_row['close']\n",
    "                self.entry_step = self.current_step\n",
    "\n",
    "        elif action == 2:  # Sell\n",
    "            if self.position != -1:\n",
    "                if self.position != 0:\n",
    "                    cost = self.transaction_cost\n",
    "                self.position = -1\n",
    "                self.holding_period = 0\n",
    "                self.entry_price = current_row['close']\n",
    "                self.entry_step = self.current_step\n",
    "\n",
    "        if self.position != 0:\n",
    "            self.holding_period += 1\n",
    "\n",
    "        step_return = self.position * price_change\n",
    "        self.returns_history.append(step_return)\n",
    "        self.current_wealth *= (1 + step_return)\n",
    "        if self.current_wealth > self.peak_wealth:\n",
    "            self.peak_wealth = self.current_wealth\n",
    "        self.drawdown = 1 - self.current_wealth / self.peak_wealth\n",
    "\n",
    "        if self.position != 0 and self.entry_price is not None:\n",
    "            current_price = next_row['close']\n",
    "            self.unrealized_pnl = (current_price - self.entry_price) * self.position / self.entry_price\n",
    "            self.time_in_position = self.current_step - self.entry_step\n",
    "        else:\n",
    "            self.unrealized_pnl = 0\n",
    "            self.time_in_position = 0\n",
    "\n",
    "        if 'market_return_1d' in self.episode_df.columns:\n",
    "            self.relative_perf = price_change - next_row['market_return_1d']\n",
    "        else:\n",
    "            self.relative_perf = 0\n",
    "\n",
    "        reward = self.reward_fn(\n",
    "            position=self.position,\n",
    "            price_change=price_change,\n",
    "            prev_position=prev_position,\n",
    "            env=self\n",
    "        )\n",
    "        reward -= cost\n",
    "        self.reward_history.append(reward)\n",
    "        self.cumulative_reward += reward\n",
    "\n",
    "        self.current_step += 1\n",
    "        obs = self._get_obs()\n",
    "        info = {}\n",
    "        info[\"regime\"] = self.get_current_regime()\n",
    "\n",
    "        # Calcula métricas no final do episódio\n",
    "        if done:\n",
    "            returns = np.array(self.returns_history)\n",
    "            mean = np.median(returns) if len(returns) > 0 else np.nan\n",
    "            std = returns.std() if len(returns) > 1 else np.nan\n",
    "            downside = returns[returns < 0]\n",
    "            downside_std = downside.std() if len(downside) > 1 else np.nan\n",
    "\n",
    "            sharpe = mean / std if (std is not None and std > 0 and not np.isnan(std)) else np.nan\n",
    "            sortino = mean / downside_std if (downside_std is not None and downside_std > 0 and not np.isnan(downside_std)) else np.nan\n",
    "\n",
    "            wealth_curve = np.cumprod(1 + returns) if len(returns) > 0 else np.array([])\n",
    "            peak_wealth = np.maximum.accumulate(wealth_curve) if len(wealth_curve) > 0 else np.array([])\n",
    "            drawdowns = (wealth_curve - peak_wealth) / (peak_wealth + 1e-8) if len(wealth_curve) > 0 else np.array([])\n",
    "            max_drawdown = np.abs(drawdowns.min()) if len(drawdowns) > 0 else np.nan\n",
    "            calmar = ((wealth_curve[-1] - 1) / max_drawdown) if (len(wealth_curve) > 0 and max_drawdown and not np.isnan(max_drawdown) and max_drawdown > 0) else np.nan\n",
    "            cum_return = wealth_curve[-1] - 1 if len(wealth_curve) > 0 else np.nan\n",
    "            final_wealth = wealth_curve[-1] if len(wealth_curve) > 0 else np.nan\n",
    "\n",
    "            # Trade-level metrics\n",
    "            trades = []\n",
    "            trade_profits = []\n",
    "            prev = 0\n",
    "            for i, ret in enumerate(returns):\n",
    "                if prev == 0 and ret != 0:\n",
    "                    entry_idx = i\n",
    "                    entry_dir = np.sign(ret)\n",
    "                elif prev != 0 and (ret == 0 or np.sign(ret) != np.sign(prev)):\n",
    "                    if 'entry_idx' in locals():\n",
    "                        trade = returns[entry_idx:i+1]\n",
    "                        trade_profits.append(np.sum(trade))\n",
    "                        del entry_idx\n",
    "                prev = ret\n",
    "            win_rate = np.median(np.array(trade_profits) > 0) if trade_profits else np.nan\n",
    "\n",
    "            if 'market_return_1d' in self.episode_df.columns:\n",
    "                market_returns = self.episode_df['market_return_1d'].values[1:self.episode_length]\n",
    "                market_wealth_curve = np.cumprod(1 + market_returns) if len(market_returns) > 0 else np.array([])\n",
    "                market_cum_return = market_wealth_curve[-1] - 1 if len(market_wealth_curve) > 0 else np.nan\n",
    "                alpha = cum_return - market_cum_return if cum_return is not None and not np.isnan(cum_return) and market_cum_return is not None and not np.isnan(market_cum_return) else np.nan\n",
    "            else:\n",
    "                alpha = np.nan\n",
    "\n",
    "            info.update({\n",
    "                \"episode_sharpe\": sharpe,\n",
    "                \"episode_sortino\": sortino,\n",
    "                \"episode_total_reward\": np.sum(self.reward_history) if len(self.reward_history) > 0 else np.nan,\n",
    "                \"cumulative_return\": cum_return,\n",
    "                \"calmar\": calmar,\n",
    "                \"max_drawdown\": max_drawdown,\n",
    "                \"win_rate\": win_rate,\n",
    "                \"alpha\": alpha,\n",
    "                \"returns\": returns,\n",
    "                \"market_returns\": market_returns if 'market_returns' in locals() else [],\n",
    "                \"downside\": downside,\n",
    "                \"regime\": self.get_current_regime(),\n",
    "                \"final_wealth\": final_wealth,\n",
    "                \"action_hold_count\": self.action_counts[0],\n",
    "                \"action_buy_count\": self.action_counts[1],\n",
    "                \"action_sell_count\": self.action_counts[2]\n",
    "            })\n",
    "\n",
    "        return obs, reward, done, False, info\n",
    "\n",
    "    def render(self):\n",
    "        print(f\"Step: {self.current_step} | Pos: {self.position} | Hold: {self.holding_period} | CumRew: {self.cumulative_reward:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "class SequenceAwareSharpeTradingEnv(BaseSequenceAwareTradingEnv):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, reward_fn=reward_sharpe, **kwargs)\n",
    "\n",
    "class SequenceAwareSortinoTradingEnv(BaseSequenceAwareTradingEnv):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, reward_fn=reward_sortino, **kwargs)\n",
    "\n",
    "class SequenceAwareAlphaTradingEnv(BaseSequenceAwareTradingEnv):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, reward_fn=reward_alpha, **kwargs)\n",
    "\n",
    "class SequenceAwareDrawdownTradingEnv(BaseSequenceAwareTradingEnv):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, reward_fn=reward_drawdown, **kwargs)\n",
    "\n",
    "class SequenceAwareCumulativeTradingEnv(BaseSequenceAwareTradingEnv):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, reward_fn=reward_cumulative, **kwargs)\n",
    "\n",
    "class SequenceAwareCalmarTradingEnv(BaseSequenceAwareTradingEnv):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, reward_fn=reward_calmar, **kwargs)\n",
    "\n",
    "class SequenceAwareHybridTradingEnv(BaseSequenceAwareTradingEnv):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, reward_fn=reward_hybrid, **kwargs)\n",
    "\n",
    "class SequenceAwareBaselineTradingAgent:\n",
    "    def __init__(self,df,feature_cols=[],\n",
    "            episode_length=100, seed=314,set_episode_sequence=[]):\n",
    "    \n",
    "        self.env = BaseSequenceAwareTradingEnv(df, feature_cols=feature_cols,\n",
    "            episode_length=episode_length, seed=seed)\n",
    "        self.env.set_episode_sequence(set_episode_sequence)\n",
    "        \n",
    "    def predict(self,obs,*args,**kwargs):\n",
    "        #print(self.env.stocks,'xxxxxxxxxxx')\n",
    "        return self.env.action_space.sample(),{}\n",
    "    \n",
    "    def set_episode_sequence(self,seq):\n",
    "        \n",
    "        pass\n",
    "\n",
    "    \n",
    "    \n",
    "# Regime Augmentation Wrapper ===========================\n",
    "class RegimeAugmentingWrapper(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        self.regime_dim = 3  # One-hot: bull, bear, sideways\n",
    "        obs_shape = self.observation_space.shape\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            low=-np.inf, high=np.inf,\n",
    "            shape=(obs_shape[0], obs_shape[1] + self.regime_dim),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "\n",
    "    def observation(self, obs):\n",
    "        regime = self.env.get_current_regime()  # should return 0, 1, or 2\n",
    "        one_hot = np.zeros(self.regime_dim)\n",
    "        one_hot[regime] = 1.0\n",
    "        one_hot = np.repeat(one_hot[None, :], obs.shape[0], axis=0)\n",
    "        return np.concatenate([obs, one_hot], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "550c1d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-8377624099423380081\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ========== CONFIG ==========\n",
    "EXPERIENCE_NAME = \"core_sequence_aware_agent_design_v2\"\n",
    "RESULTS_PATH = f\"data/experiments/{EXPERIENCE_NAME}_barebones_results.csv\"\n",
    "N_EPISODES = 20\n",
    "N_SEEDS = 3\n",
    "N_EVAL_EPISODES = 3\n",
    "\n",
    "WINDOW_LENGTH = 10  \n",
    "TOTAL_TIMESTEPS = EPISODE_LENGTH * 150\n",
    "N_STEPS = EPISODE_LENGTH * 2\n",
    "\n",
    "TRANSACTION_COST = 0\n",
    "\n",
    "CONFIG = {\n",
    "    \"batch_size\": EPISODE_LENGTH,\n",
    "    \"n_steps\": 800,\n",
    "    \"total_timesteps\": TOTAL_TIMESTEPS,\n",
    "    \"project_name\":EXPERIENCE_NAME,\n",
    "    \"environment\": \"SequenceAwareCumulativeTradingEnv\"\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Load data ==================================\n",
    "ohlcv_df = load_base_dataframe()\n",
    "\n",
    "# Experiment tracker ========================= \n",
    "experiment_tracker = ExperimentTracker(EXPERIENCE_NAME)\n",
    "experiment_tracker.set_hash(CONFIG)\n",
    "\n",
    "# Files ======================================\n",
    "checkpoint_path = \"data/checkpoint\" \n",
    "checkpoint_name = \"-8377624099423380081\"#experiment_tracker.run_hash\n",
    "checkpoint_preffix = f\"{checkpoint_name}--checkpoint\"\n",
    "checkpoint_best_model=f\"{checkpoint_path}/{checkpoint_name}--best_model\"\n",
    "log_path=\"data/logs\"\n",
    "save_path= f\"{checkpoint_path}/{checkpoint_name}--final\"\n",
    "print(checkpoint_name)\n",
    "#data/checkpoint/-8377624099423380081--final\n",
    "#data/checkpoint/-3848392742194634112--best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7102f671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800 100\n"
     ]
    }
   ],
   "source": [
    "EPISODE_LENGTH = 100\n",
    "MAX_LENGTH = 200\n",
    "SAVE_FREQ=10000\n",
    "EVAL_FREQ=5000\n",
    "TOTAL_TIMESTEPS=1_200_000\n",
    "#TOTAL_TIMESTEPS=1000\n",
    "EPISODES_PER_UPDATE = 8          # ~how many episodes before PPO updates\n",
    "EPISODES_PER_BATCH = 1           # number of full episodes per batch\n",
    "\n",
    "# === Auto-derive PPO settings ===\n",
    "N_STEPS = EPISODE_LENGTH * EPISODES_PER_UPDATE\n",
    "BATCH_SIZE = EPISODE_LENGTH * EPISODES_PER_BATCH\n",
    "\n",
    "ENV_CLASS = SequenceAwareCumulativeTradingEnv\n",
    "\n",
    "n = Notify(experiment_tracker.project)\n",
    "n.info('START')\n",
    "print(N_STEPS,BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49e51121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 1961 different episodes accross the top 2 stocks for each sector\n",
      "Testing on 22 different episodes accross the top 2 stocks for each sector\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 102      |\n",
      "|    ep_rew_mean     | 10.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 130      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 800      |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 4.02        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 36          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 44          |\n",
      "|    total_timesteps      | 1600        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008689321 |\n",
      "|    clip_fraction        | 0.0406      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.000169    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.74        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00197    |\n",
      "|    value_loss           | 7.57        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 4.63        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 86          |\n",
      "|    total_timesteps      | 2400        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013494816 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.0561      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.22        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    value_loss           | 7.36        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 3.61        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 25          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 125         |\n",
      "|    total_timesteps      | 3200        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012913847 |\n",
      "|    clip_fraction        | 0.0459      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.0792      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.14        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0018     |\n",
      "|    value_loss           | 7           |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 2.59        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 24          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 163         |\n",
      "|    total_timesteps      | 4000        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011778145 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.0746      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.32        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0098     |\n",
      "|    value_loss           | 5.26        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 2.69        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 23          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 201         |\n",
      "|    total_timesteps      | 4800        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008499797 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.999      |\n",
      "|    explained_variance   | -0.0266     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.3         |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00853    |\n",
      "|    value_loss           | 7.02        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=5000, episode_reward=-6.12 +/- 4.80\n",
      "Episode length: 102.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 102         |\n",
      "|    mean_reward          | -6.12       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 5000        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013199283 |\n",
      "|    clip_fraction        | 0.0468      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.929      |\n",
      "|    explained_variance   | -0.00122    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.4         |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.000313   |\n",
      "|    value_loss           | 9.23        |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 102      |\n",
      "|    ep_rew_mean     | 3        |\n",
      "| time/              |          |\n",
      "|    fps             | 22       |\n",
      "|    iterations      | 7        |\n",
      "|    time_elapsed    | 247      |\n",
      "|    total_timesteps | 5600     |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 102          |\n",
      "|    ep_rew_mean          | 2.47         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 22           |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 284          |\n",
      "|    total_timesteps      | 6400         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046049524 |\n",
      "|    clip_fraction        | 0.0721       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.861       |\n",
      "|    explained_variance   | 0.00843      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.64         |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.0043      |\n",
      "|    value_loss           | 6.47         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 1.87        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 21          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 329         |\n",
      "|    total_timesteps      | 7200        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005759397 |\n",
      "|    clip_fraction        | 0.0264      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.857      |\n",
      "|    explained_variance   | 0.0644      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.28        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00125    |\n",
      "|    value_loss           | 4.77        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 1.58        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 21          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 376         |\n",
      "|    total_timesteps      | 8000        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005345338 |\n",
      "|    clip_fraction        | 0.00712     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.867      |\n",
      "|    explained_variance   | -0.00672    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.5         |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.000929   |\n",
      "|    value_loss           | 6.53        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 102          |\n",
      "|    ep_rew_mean          | 1.36         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 20           |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 422          |\n",
      "|    total_timesteps      | 8800         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0112262815 |\n",
      "|    clip_fraction        | 0.0854       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.933       |\n",
      "|    explained_variance   | 0.0497       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.836        |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.00379     |\n",
      "|    value_loss           | 3.66         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 1.16        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 471         |\n",
      "|    total_timesteps      | 9600        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025309598 |\n",
      "|    clip_fraction        | 0.0442      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.906      |\n",
      "|    explained_variance   | 0.118       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.5         |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00342    |\n",
      "|    value_loss           | 4.74        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=5.54 +/- 5.90\n",
      "Episode length: 102.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 102         |\n",
      "|    mean_reward          | 5.54        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 10000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015733771 |\n",
      "|    clip_fraction        | 0.023       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.834      |\n",
      "|    explained_variance   | 0.107       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.14        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00365    |\n",
      "|    value_loss           | 7.68        |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 102      |\n",
      "|    ep_rew_mean     | 0.811    |\n",
      "| time/              |          |\n",
      "|    fps             | 20       |\n",
      "|    iterations      | 13       |\n",
      "|    time_elapsed    | 516      |\n",
      "|    total_timesteps | 10400    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 0.553       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 556         |\n",
      "|    total_timesteps      | 11200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016949331 |\n",
      "|    clip_fraction        | 0.0496      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.785      |\n",
      "|    explained_variance   | -0.202      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.69        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | 0.00937     |\n",
      "|    value_loss           | 4.77        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 0.404       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 615         |\n",
      "|    total_timesteps      | 12000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018225886 |\n",
      "|    clip_fraction        | 0.0444      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.766      |\n",
      "|    explained_variance   | 0.0226      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.22        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00216    |\n",
      "|    value_loss           | 4.18        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 0.101       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 667         |\n",
      "|    total_timesteps      | 12800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019670397 |\n",
      "|    clip_fraction        | 0.0642      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.778      |\n",
      "|    explained_variance   | -0.0415     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.929       |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | 0.0112      |\n",
      "|    value_loss           | 6.09        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 102        |\n",
      "|    ep_rew_mean          | 0.0336     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 18         |\n",
      "|    iterations           | 17         |\n",
      "|    time_elapsed         | 716        |\n",
      "|    total_timesteps      | 13600      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03528353 |\n",
      "|    clip_fraction        | 0.0442     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.785     |\n",
      "|    explained_variance   | 0.0293     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.83       |\n",
      "|    n_updates            | 160        |\n",
      "|    policy_gradient_loss | 0.00695    |\n",
      "|    value_loss           | 4.47       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 0.512       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 760         |\n",
      "|    total_timesteps      | 14400       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003924586 |\n",
      "|    clip_fraction        | 0.0146      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.798      |\n",
      "|    explained_variance   | -0.0269     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.62        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | 0.000665    |\n",
      "|    value_loss           | 2.81        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=15000, episode_reward=4.31 +/- 9.31\n",
      "Episode length: 102.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 102        |\n",
      "|    mean_reward          | 4.31       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 15000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00915872 |\n",
      "|    clip_fraction        | 0.0461     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.806     |\n",
      "|    explained_variance   | -0.033     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.89       |\n",
      "|    n_updates            | 180        |\n",
      "|    policy_gradient_loss | 0.00245    |\n",
      "|    value_loss           | 10.6       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 102      |\n",
      "|    ep_rew_mean     | 0.733    |\n",
      "| time/              |          |\n",
      "|    fps             | 18       |\n",
      "|    iterations      | 19       |\n",
      "|    time_elapsed    | 812      |\n",
      "|    total_timesteps | 15200    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 1.43        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 855         |\n",
      "|    total_timesteps      | 16000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008025272 |\n",
      "|    clip_fraction        | 0.0545      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.887      |\n",
      "|    explained_variance   | 0.00924     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.21        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.00187    |\n",
      "|    value_loss           | 6.44        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 1.75        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 900         |\n",
      "|    total_timesteps      | 16800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014848726 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.88       |\n",
      "|    explained_variance   | 0.000484    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.09        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.00397    |\n",
      "|    value_loss           | 7.76        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 102        |\n",
      "|    ep_rew_mean          | 1.26       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 18         |\n",
      "|    iterations           | 22         |\n",
      "|    time_elapsed         | 948        |\n",
      "|    total_timesteps      | 17600      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04320553 |\n",
      "|    clip_fraction        | 0.0831     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.805     |\n",
      "|    explained_variance   | 0.00394    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 4.31       |\n",
      "|    n_updates            | 210        |\n",
      "|    policy_gradient_loss | -0.0009    |\n",
      "|    value_loss           | 7.22       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 102        |\n",
      "|    ep_rew_mean          | 1.44       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 18         |\n",
      "|    iterations           | 23         |\n",
      "|    time_elapsed         | 998        |\n",
      "|    total_timesteps      | 18400      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01505216 |\n",
      "|    clip_fraction        | 0.0392     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.789     |\n",
      "|    explained_variance   | -0.00543   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.27       |\n",
      "|    n_updates            | 220        |\n",
      "|    policy_gradient_loss | 0.000948   |\n",
      "|    value_loss           | 7.32       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 102        |\n",
      "|    ep_rew_mean          | 1.54       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 18         |\n",
      "|    iterations           | 24         |\n",
      "|    time_elapsed         | 1045       |\n",
      "|    total_timesteps      | 19200      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01626652 |\n",
      "|    clip_fraction        | 0.0436     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.698     |\n",
      "|    explained_variance   | -0.0263    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.6        |\n",
      "|    n_updates            | 230        |\n",
      "|    policy_gradient_loss | -0.000907  |\n",
      "|    value_loss           | 6          |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=-1.67 +/- 10.97\n",
      "Episode length: 102.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 102         |\n",
      "|    mean_reward          | -1.67       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 20000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003096817 |\n",
      "|    clip_fraction        | 0.0222      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.625      |\n",
      "|    explained_variance   | -0.0195     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.92        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | 0.000494    |\n",
      "|    value_loss           | 7.13        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 102      |\n",
      "|    ep_rew_mean     | 2.11     |\n",
      "| time/              |          |\n",
      "|    fps             | 18       |\n",
      "|    iterations      | 25       |\n",
      "|    time_elapsed    | 1090     |\n",
      "|    total_timesteps | 20000    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 102        |\n",
      "|    ep_rew_mean          | 2.46       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 18         |\n",
      "|    iterations           | 26         |\n",
      "|    time_elapsed         | 1136       |\n",
      "|    total_timesteps      | 20800      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06838205 |\n",
      "|    clip_fraction        | 0.0469     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.578     |\n",
      "|    explained_variance   | 0.0132     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.58       |\n",
      "|    n_updates            | 250        |\n",
      "|    policy_gradient_loss | 0.00818    |\n",
      "|    value_loss           | 7.09       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 2.86        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 1180        |\n",
      "|    total_timesteps      | 21600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015136119 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.576      |\n",
      "|    explained_variance   | 0.0161      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.3         |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.00575    |\n",
      "|    value_loss           | 6.98        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 3.16        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 1225        |\n",
      "|    total_timesteps      | 22400       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023152202 |\n",
      "|    clip_fraction        | 0.0516      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.653      |\n",
      "|    explained_variance   | 0.0145      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.59        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | 0.000915    |\n",
      "|    value_loss           | 5.75        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 102        |\n",
      "|    ep_rew_mean          | 3.04       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 18         |\n",
      "|    iterations           | 29         |\n",
      "|    time_elapsed         | 1271       |\n",
      "|    total_timesteps      | 23200      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12309171 |\n",
      "|    clip_fraction        | 0.0996     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.689     |\n",
      "|    explained_variance   | -0.106     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.21       |\n",
      "|    n_updates            | 280        |\n",
      "|    policy_gradient_loss | 0.0238     |\n",
      "|    value_loss           | 4.92       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 3.37        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 1316        |\n",
      "|    total_timesteps      | 24000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025562687 |\n",
      "|    clip_fraction        | 0.0983      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.685      |\n",
      "|    explained_variance   | -0.168      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.12        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.000949   |\n",
      "|    value_loss           | 5.62        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 2.91        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 1357        |\n",
      "|    total_timesteps      | 24800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019257916 |\n",
      "|    clip_fraction        | 0.0384      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.659      |\n",
      "|    explained_variance   | -0.0784     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.51        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0012     |\n",
      "|    value_loss           | 7.73        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=25000, episode_reward=-9.31 +/- 7.57\n",
      "Episode length: 102.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 102        |\n",
      "|    mean_reward          | -9.31      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 25000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00946239 |\n",
      "|    clip_fraction        | 0.0529     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.701     |\n",
      "|    explained_variance   | 0.0306     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.09       |\n",
      "|    n_updates            | 310        |\n",
      "|    policy_gradient_loss | -0.00155   |\n",
      "|    value_loss           | 5.12       |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 102      |\n",
      "|    ep_rew_mean     | 2.58     |\n",
      "| time/              |          |\n",
      "|    fps             | 18       |\n",
      "|    iterations      | 32       |\n",
      "|    time_elapsed    | 1402     |\n",
      "|    total_timesteps | 25600    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 1.8         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 1448        |\n",
      "|    total_timesteps      | 26400       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012360521 |\n",
      "|    clip_fraction        | 0.0226      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.741      |\n",
      "|    explained_variance   | -0.0211     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.49        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0029     |\n",
      "|    value_loss           | 7.23        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 102          |\n",
      "|    ep_rew_mean          | 2.32         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 18           |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 1502         |\n",
      "|    total_timesteps      | 27200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075347004 |\n",
      "|    clip_fraction        | 0.0519       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.726       |\n",
      "|    explained_variance   | 0.00736      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.47         |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -0.00648     |\n",
      "|    value_loss           | 6.2          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 3           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 1564        |\n",
      "|    total_timesteps      | 28000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016656954 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.73       |\n",
      "|    explained_variance   | 0.062       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.6         |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.00254    |\n",
      "|    value_loss           | 4.99        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 3.49        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 1618        |\n",
      "|    total_timesteps      | 28800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009127669 |\n",
      "|    clip_fraction        | 0.0231      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.736      |\n",
      "|    explained_variance   | -0.0722     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.08        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -1.92e-05   |\n",
      "|    value_loss           | 4.65        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 102        |\n",
      "|    ep_rew_mean          | 3.41       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 17         |\n",
      "|    iterations           | 37         |\n",
      "|    time_elapsed         | 1681       |\n",
      "|    total_timesteps      | 29600      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02988961 |\n",
      "|    clip_fraction        | 0.0917     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.624     |\n",
      "|    explained_variance   | 0.183      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.82       |\n",
      "|    n_updates            | 360        |\n",
      "|    policy_gradient_loss | 0.000824   |\n",
      "|    value_loss           | 6.68       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=30000, episode_reward=0.86 +/- 6.37\n",
      "Episode length: 102.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 102          |\n",
      "|    mean_reward          | 0.858        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 30000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076282956 |\n",
      "|    clip_fraction        | 0.0194       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.636       |\n",
      "|    explained_variance   | 0.0547       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.67         |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | 0.000414     |\n",
      "|    value_loss           | 8.35         |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 102      |\n",
      "|    ep_rew_mean     | 3.57     |\n",
      "| time/              |          |\n",
      "|    fps             | 17       |\n",
      "|    iterations      | 38       |\n",
      "|    time_elapsed    | 1744     |\n",
      "|    total_timesteps | 30400    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 3.12        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 1806        |\n",
      "|    total_timesteps      | 31200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011097543 |\n",
      "|    clip_fraction        | 0.0631      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.63       |\n",
      "|    explained_variance   | 0.151       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.56        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.00492    |\n",
      "|    value_loss           | 6.4         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 102        |\n",
      "|    ep_rew_mean          | 2.87       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 17         |\n",
      "|    iterations           | 40         |\n",
      "|    time_elapsed         | 1860       |\n",
      "|    total_timesteps      | 32000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01177554 |\n",
      "|    clip_fraction        | 0.0546     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.657     |\n",
      "|    explained_variance   | 0.209      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 4.06       |\n",
      "|    n_updates            | 390        |\n",
      "|    policy_gradient_loss | -0.00558   |\n",
      "|    value_loss           | 6.72       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 3.3         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 1920        |\n",
      "|    total_timesteps      | 32800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022469265 |\n",
      "|    clip_fraction        | 0.0961      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.629      |\n",
      "|    explained_variance   | 0.26        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.28        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | 0.00217     |\n",
      "|    value_loss           | 4.22        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 102          |\n",
      "|    ep_rew_mean          | 3.64         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 16           |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 1979         |\n",
      "|    total_timesteps      | 33600        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011650699 |\n",
      "|    clip_fraction        | 0.018        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.631       |\n",
      "|    explained_variance   | 0.188        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.75         |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.00252     |\n",
      "|    value_loss           | 7.48         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 102        |\n",
      "|    ep_rew_mean          | 3.76       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 16         |\n",
      "|    iterations           | 43         |\n",
      "|    time_elapsed         | 2039       |\n",
      "|    total_timesteps      | 34400      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01522783 |\n",
      "|    clip_fraction        | 0.0736     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.614     |\n",
      "|    explained_variance   | 0.127      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.21       |\n",
      "|    n_updates            | 420        |\n",
      "|    policy_gradient_loss | 0.00226    |\n",
      "|    value_loss           | 4.43       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=35000, episode_reward=1.43 +/- 8.74\n",
      "Episode length: 102.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 102          |\n",
      "|    mean_reward          | 1.43         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 35000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035666153 |\n",
      "|    clip_fraction        | 0.034        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.626       |\n",
      "|    explained_variance   | 0.116        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.27         |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.00019     |\n",
      "|    value_loss           | 5.3          |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 102      |\n",
      "|    ep_rew_mean     | 4.08     |\n",
      "| time/              |          |\n",
      "|    fps             | 16       |\n",
      "|    iterations      | 44       |\n",
      "|    time_elapsed    | 2097     |\n",
      "|    total_timesteps | 35200    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 4.61        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 2153        |\n",
      "|    total_timesteps      | 36000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009219706 |\n",
      "|    clip_fraction        | 0.072       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.66       |\n",
      "|    explained_variance   | 0.202       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.63        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.00264    |\n",
      "|    value_loss           | 6.55        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 5.04        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 2206        |\n",
      "|    total_timesteps      | 36800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010069566 |\n",
      "|    clip_fraction        | 0.0609      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.742      |\n",
      "|    explained_variance   | 0.142       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.29        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.00588    |\n",
      "|    value_loss           | 4.77        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 4.76        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 2270        |\n",
      "|    total_timesteps      | 37600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020699216 |\n",
      "|    clip_fraction        | 0.0857      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.763      |\n",
      "|    explained_variance   | 0.218       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.92        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.00127    |\n",
      "|    value_loss           | 7.35        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 4.98        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 2335        |\n",
      "|    total_timesteps      | 38400       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015870756 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.782      |\n",
      "|    explained_variance   | 0.217       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.15        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.00301    |\n",
      "|    value_loss           | 5.25        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 102        |\n",
      "|    ep_rew_mean          | 4.89       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 16         |\n",
      "|    iterations           | 49         |\n",
      "|    time_elapsed         | 2397       |\n",
      "|    total_timesteps      | 39200      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02324978 |\n",
      "|    clip_fraction        | 0.0826     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.805     |\n",
      "|    explained_variance   | 0.125      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.78       |\n",
      "|    n_updates            | 480        |\n",
      "|    policy_gradient_loss | 0.00179    |\n",
      "|    value_loss           | 7.88       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=11.09 +/- 10.66\n",
      "Episode length: 102.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 102         |\n",
      "|    mean_reward          | 11.1        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 40000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015143386 |\n",
      "|    clip_fraction        | 0.0717      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.796      |\n",
      "|    explained_variance   | 0.19        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.88        |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.00423    |\n",
      "|    value_loss           | 6.8         |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 102      |\n",
      "|    ep_rew_mean     | 4.98     |\n",
      "| time/              |          |\n",
      "|    fps             | 16       |\n",
      "|    iterations      | 50       |\n",
      "|    time_elapsed    | 2458     |\n",
      "|    total_timesteps | 40000    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 102          |\n",
      "|    ep_rew_mean          | 4.97         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 16           |\n",
      "|    iterations           | 51           |\n",
      "|    time_elapsed         | 2506         |\n",
      "|    total_timesteps      | 40800        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070573026 |\n",
      "|    clip_fraction        | 0.0577       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.773       |\n",
      "|    explained_variance   | 0.212        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.11         |\n",
      "|    n_updates            | 500          |\n",
      "|    policy_gradient_loss | -0.00162     |\n",
      "|    value_loss           | 4.17         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 5.32        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 2552        |\n",
      "|    total_timesteps      | 41600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015031983 |\n",
      "|    clip_fraction        | 0.0364      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.787      |\n",
      "|    explained_variance   | 0.411       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.01        |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | 0.00164     |\n",
      "|    value_loss           | 4.39        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 5.79        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 2604        |\n",
      "|    total_timesteps      | 42400       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021989217 |\n",
      "|    clip_fraction        | 0.0484      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.81       |\n",
      "|    explained_variance   | -0.039      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.39        |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.00136    |\n",
      "|    value_loss           | 7.58        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 102        |\n",
      "|    ep_rew_mean          | 5.34       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 16         |\n",
      "|    iterations           | 54         |\n",
      "|    time_elapsed         | 2661       |\n",
      "|    total_timesteps      | 43200      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20017818 |\n",
      "|    clip_fraction        | 0.152      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.815     |\n",
      "|    explained_variance   | 0.0804     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.24       |\n",
      "|    n_updates            | 530        |\n",
      "|    policy_gradient_loss | 0.021      |\n",
      "|    value_loss           | 7.16       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 102        |\n",
      "|    ep_rew_mean          | 4.97       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 16         |\n",
      "|    iterations           | 55         |\n",
      "|    time_elapsed         | 2716       |\n",
      "|    total_timesteps      | 44000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10264529 |\n",
      "|    clip_fraction        | 0.156      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.793     |\n",
      "|    explained_variance   | -0.0178    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.579      |\n",
      "|    n_updates            | 540        |\n",
      "|    policy_gradient_loss | 0.0226     |\n",
      "|    value_loss           | 4.09       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 102          |\n",
      "|    ep_rew_mean          | 4.9          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 16           |\n",
      "|    iterations           | 56           |\n",
      "|    time_elapsed         | 2765         |\n",
      "|    total_timesteps      | 44800        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0113336705 |\n",
      "|    clip_fraction        | 0.0391       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.824       |\n",
      "|    explained_variance   | -0.0562      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.73         |\n",
      "|    n_updates            | 550          |\n",
      "|    policy_gradient_loss | -0.00109     |\n",
      "|    value_loss           | 6.37         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=45000, episode_reward=6.88 +/- 8.12\n",
      "Episode length: 102.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 102          |\n",
      "|    mean_reward          | 6.88         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 45000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0141584575 |\n",
      "|    clip_fraction        | 0.0807       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.803       |\n",
      "|    explained_variance   | 0.016        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.42         |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | 0.00754      |\n",
      "|    value_loss           | 6.22         |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 102      |\n",
      "|    ep_rew_mean     | 4.89     |\n",
      "| time/              |          |\n",
      "|    fps             | 16       |\n",
      "|    iterations      | 57       |\n",
      "|    time_elapsed    | 2814     |\n",
      "|    total_timesteps | 45600    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 4.51        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 2860        |\n",
      "|    total_timesteps      | 46400       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032041878 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.815      |\n",
      "|    explained_variance   | -0.00659    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.62        |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.00359    |\n",
      "|    value_loss           | 8.2         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 4.36        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 59          |\n",
      "|    time_elapsed         | 2904        |\n",
      "|    total_timesteps      | 47200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012348259 |\n",
      "|    clip_fraction        | 0.058       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.828      |\n",
      "|    explained_variance   | 0.112       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.98        |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | 0.00349     |\n",
      "|    value_loss           | 6.74        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 4.4         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 2945        |\n",
      "|    total_timesteps      | 48000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018289521 |\n",
      "|    clip_fraction        | 0.0825      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.813      |\n",
      "|    explained_variance   | 0.224       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.79        |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | 0.00196     |\n",
      "|    value_loss           | 5.01        |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 102      |\n",
      "|    ep_rew_mean          | 5.01     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 16       |\n",
      "|    iterations           | 61       |\n",
      "|    time_elapsed         | 3018     |\n",
      "|    total_timesteps      | 48800    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.053354 |\n",
      "|    clip_fraction        | 0.166    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -0.818   |\n",
      "|    explained_variance   | -0.163   |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 2.33     |\n",
      "|    n_updates            | 600      |\n",
      "|    policy_gradient_loss | 0.0192   |\n",
      "|    value_loss           | 7.1      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 102        |\n",
      "|    ep_rew_mean          | 4.79       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 16         |\n",
      "|    iterations           | 62         |\n",
      "|    time_elapsed         | 3079       |\n",
      "|    total_timesteps      | 49600      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03497811 |\n",
      "|    clip_fraction        | 0.218      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.908     |\n",
      "|    explained_variance   | 0.0211     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.37       |\n",
      "|    n_updates            | 610        |\n",
      "|    policy_gradient_loss | 0.024      |\n",
      "|    value_loss           | 7.73       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=-2.01 +/- 9.41\n",
      "Episode length: 102.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 102         |\n",
      "|    mean_reward          | -2.01       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 50000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017370086 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.939      |\n",
      "|    explained_variance   | -0.0623     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.97        |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | 0.00634     |\n",
      "|    value_loss           | 7.37        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 102      |\n",
      "|    ep_rew_mean     | 4.43     |\n",
      "| time/              |          |\n",
      "|    fps             | 16       |\n",
      "|    iterations      | 63       |\n",
      "|    time_elapsed    | 3142     |\n",
      "|    total_timesteps | 50400    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 5.09        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 3182        |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011092639 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.93       |\n",
      "|    explained_variance   | 0.161       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.36        |\n",
      "|    n_updates            | 630         |\n",
      "|    policy_gradient_loss | -0.00135    |\n",
      "|    value_loss           | 6.38        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 4.46        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 3221        |\n",
      "|    total_timesteps      | 52000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.058186907 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.902      |\n",
      "|    explained_variance   | -0.0851     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.72        |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | 0.00928     |\n",
      "|    value_loss           | 6.54        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 4.45        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 3265        |\n",
      "|    total_timesteps      | 52800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019853028 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.903      |\n",
      "|    explained_variance   | 0.0315      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.71        |\n",
      "|    n_updates            | 650         |\n",
      "|    policy_gradient_loss | 0.0127      |\n",
      "|    value_loss           | 7.13        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 4.7         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 3312        |\n",
      "|    total_timesteps      | 53600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.049407586 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.91       |\n",
      "|    explained_variance   | 0.0219      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.5         |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | 0.00897     |\n",
      "|    value_loss           | 6.29        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 4.51        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 3356        |\n",
      "|    total_timesteps      | 54400       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017989835 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.9        |\n",
      "|    explained_variance   | 0.0633      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.17        |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | -0.0032     |\n",
      "|    value_loss           | 5.05        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=55000, episode_reward=1.58 +/- 4.76\n",
      "Episode length: 102.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 102         |\n",
      "|    mean_reward          | 1.58        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 55000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019395785 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.906      |\n",
      "|    explained_variance   | 0.184       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.77        |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | 0.00552     |\n",
      "|    value_loss           | 5.13        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 102      |\n",
      "|    ep_rew_mean     | 5.15     |\n",
      "| time/              |          |\n",
      "|    fps             | 16       |\n",
      "|    iterations      | 69       |\n",
      "|    time_elapsed    | 3400     |\n",
      "|    total_timesteps | 55200    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 102        |\n",
      "|    ep_rew_mean          | 5.11       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 16         |\n",
      "|    iterations           | 70         |\n",
      "|    time_elapsed         | 3436       |\n",
      "|    total_timesteps      | 56000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03994017 |\n",
      "|    clip_fraction        | 0.211      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.878     |\n",
      "|    explained_variance   | 0.46       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.95       |\n",
      "|    n_updates            | 690        |\n",
      "|    policy_gradient_loss | 0.0078     |\n",
      "|    value_loss           | 4.84       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 5.75        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 3474        |\n",
      "|    total_timesteps      | 56800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017549014 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.852      |\n",
      "|    explained_variance   | 0.0341      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.877       |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | -0.00303    |\n",
      "|    value_loss           | 7.02        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 5.48        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 3517        |\n",
      "|    total_timesteps      | 57600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028360922 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.854      |\n",
      "|    explained_variance   | 0.179       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.49        |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | -0.00759    |\n",
      "|    value_loss           | 6.91        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 5.73        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 3563        |\n",
      "|    total_timesteps      | 58400       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011412945 |\n",
      "|    clip_fraction        | 0.0835      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.84       |\n",
      "|    explained_variance   | 0.193       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.12        |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | -0.00771    |\n",
      "|    value_loss           | 6.74        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 5.61        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 3609        |\n",
      "|    total_timesteps      | 59200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024190176 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.88       |\n",
      "|    explained_variance   | 0.286       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.904       |\n",
      "|    n_updates            | 730         |\n",
      "|    policy_gradient_loss | 0.00316     |\n",
      "|    value_loss           | 4.04        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=16.03 +/- 7.02\n",
      "Episode length: 102.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 102        |\n",
      "|    mean_reward          | 16         |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 60000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05539142 |\n",
      "|    clip_fraction        | 0.132      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.832     |\n",
      "|    explained_variance   | 0.0764     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.86       |\n",
      "|    n_updates            | 740        |\n",
      "|    policy_gradient_loss | -0.00635   |\n",
      "|    value_loss           | 5.29       |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 102      |\n",
      "|    ep_rew_mean     | 6.01     |\n",
      "| time/              |          |\n",
      "|    fps             | 16       |\n",
      "|    iterations      | 75       |\n",
      "|    time_elapsed    | 3655     |\n",
      "|    total_timesteps | 60000    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 5.64        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 3692        |\n",
      "|    total_timesteps      | 60800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023633946 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.857      |\n",
      "|    explained_variance   | 0.233       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.1         |\n",
      "|    n_updates            | 750         |\n",
      "|    policy_gradient_loss | -0.00287    |\n",
      "|    value_loss           | 7.13        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 5.86        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 3730        |\n",
      "|    total_timesteps      | 61600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025332054 |\n",
      "|    clip_fraction        | 0.0984      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.874      |\n",
      "|    explained_variance   | 0.16        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.55        |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | 0.00754     |\n",
      "|    value_loss           | 7.05        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 6.46        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 3768        |\n",
      "|    total_timesteps      | 62400       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023832517 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.899      |\n",
      "|    explained_variance   | -0.218      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.62        |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | -0.0057     |\n",
      "|    value_loss           | 6.94        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 102          |\n",
      "|    ep_rew_mean          | 6.44         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 16           |\n",
      "|    iterations           | 79           |\n",
      "|    time_elapsed         | 3813         |\n",
      "|    total_timesteps      | 63200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077594537 |\n",
      "|    clip_fraction        | 0.0794       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.888       |\n",
      "|    explained_variance   | 0.224        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.13         |\n",
      "|    n_updates            | 780          |\n",
      "|    policy_gradient_loss | 0.004        |\n",
      "|    value_loss           | 6.03         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 102          |\n",
      "|    ep_rew_mean          | 6.31         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 16           |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 3859         |\n",
      "|    total_timesteps      | 64000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0129124895 |\n",
      "|    clip_fraction        | 0.142        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.872       |\n",
      "|    explained_variance   | 0.141        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.91         |\n",
      "|    n_updates            | 790          |\n",
      "|    policy_gradient_loss | -0.00737     |\n",
      "|    value_loss           | 7.77         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 5.96        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 3902        |\n",
      "|    total_timesteps      | 64800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017728515 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.884      |\n",
      "|    explained_variance   | -0.38       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.761       |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | 0.00774     |\n",
      "|    value_loss           | 5.83        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=65000, episode_reward=8.28 +/- 8.26\n",
      "Episode length: 102.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 102         |\n",
      "|    mean_reward          | 8.28        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 65000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028934225 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.909      |\n",
      "|    explained_variance   | -0.0556     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.77        |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | 0.00915     |\n",
      "|    value_loss           | 5.35        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 102      |\n",
      "|    ep_rew_mean     | 5.56     |\n",
      "| time/              |          |\n",
      "|    fps             | 16       |\n",
      "|    iterations      | 82       |\n",
      "|    time_elapsed    | 3946     |\n",
      "|    total_timesteps | 65600    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 5.61        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 3983        |\n",
      "|    total_timesteps      | 66400       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011268463 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.869      |\n",
      "|    explained_variance   | 0.0248      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.56        |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | 0.000545    |\n",
      "|    value_loss           | 6.13        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 5.53        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 4020        |\n",
      "|    total_timesteps      | 67200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028797127 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.899      |\n",
      "|    explained_variance   | 0.0228      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.44        |\n",
      "|    n_updates            | 830         |\n",
      "|    policy_gradient_loss | -0.00161    |\n",
      "|    value_loss           | 6.03        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 5.77        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 4064        |\n",
      "|    total_timesteps      | 68000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047228888 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.916      |\n",
      "|    explained_variance   | 0.09        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.49        |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | 0.00434     |\n",
      "|    value_loss           | 6.43        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 5.48        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 86          |\n",
      "|    time_elapsed         | 4110        |\n",
      "|    total_timesteps      | 68800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017687678 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.928      |\n",
      "|    explained_variance   | 0.0512      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.4         |\n",
      "|    n_updates            | 850         |\n",
      "|    policy_gradient_loss | -0.00285    |\n",
      "|    value_loss           | 6.5         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 102        |\n",
      "|    ep_rew_mean          | 5.7        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 16         |\n",
      "|    iterations           | 87         |\n",
      "|    time_elapsed         | 4155       |\n",
      "|    total_timesteps      | 69600      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01680946 |\n",
      "|    clip_fraction        | 0.156      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.898     |\n",
      "|    explained_variance   | 0.279      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.03       |\n",
      "|    n_updates            | 860        |\n",
      "|    policy_gradient_loss | -0.00259   |\n",
      "|    value_loss           | 4.75       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=-3.26 +/- 11.55\n",
      "Episode length: 102.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 102         |\n",
      "|    mean_reward          | -3.26       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 70000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025257898 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.892      |\n",
      "|    explained_variance   | 0.221       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.83        |\n",
      "|    n_updates            | 870         |\n",
      "|    policy_gradient_loss | 0.0207      |\n",
      "|    value_loss           | 6.11        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 102      |\n",
      "|    ep_rew_mean     | 6.12     |\n",
      "| time/              |          |\n",
      "|    fps             | 16       |\n",
      "|    iterations      | 88       |\n",
      "|    time_elapsed    | 4199     |\n",
      "|    total_timesteps | 70400    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 102        |\n",
      "|    ep_rew_mean          | 5.56       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 16         |\n",
      "|    iterations           | 89         |\n",
      "|    time_elapsed         | 4236       |\n",
      "|    total_timesteps      | 71200      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03961028 |\n",
      "|    clip_fraction        | 0.273      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.878     |\n",
      "|    explained_variance   | 0.113      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.56       |\n",
      "|    n_updates            | 880        |\n",
      "|    policy_gradient_loss | 0.00771    |\n",
      "|    value_loss           | 7.4        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 6.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 4275        |\n",
      "|    total_timesteps      | 72000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014908919 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.806      |\n",
      "|    explained_variance   | 0.241       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.75        |\n",
      "|    n_updates            | 890         |\n",
      "|    policy_gradient_loss | -6.2e-05    |\n",
      "|    value_loss           | 5.91        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 4.88        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 4315        |\n",
      "|    total_timesteps      | 72800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030188853 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.848      |\n",
      "|    explained_variance   | 0.283       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.98        |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | 0.000145    |\n",
      "|    value_loss           | 7.25        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 4.69        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 4360        |\n",
      "|    total_timesteps      | 73600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010614616 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.858      |\n",
      "|    explained_variance   | 0.193       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.83        |\n",
      "|    n_updates            | 910         |\n",
      "|    policy_gradient_loss | 0.00178     |\n",
      "|    value_loss           | 9.25        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 5.01        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 4405        |\n",
      "|    total_timesteps      | 74400       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028468404 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.906      |\n",
      "|    explained_variance   | 0.419       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.79        |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | 0.000586    |\n",
      "|    value_loss           | 6.73        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=75000, episode_reward=8.25 +/- 8.63\n",
      "Episode length: 102.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 102         |\n",
      "|    mean_reward          | 8.25        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 75000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010866037 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.832      |\n",
      "|    explained_variance   | 0.127       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.4         |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | 0.000158    |\n",
      "|    value_loss           | 6.72        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 102      |\n",
      "|    ep_rew_mean     | 5.71     |\n",
      "| time/              |          |\n",
      "|    fps             | 16       |\n",
      "|    iterations      | 94       |\n",
      "|    time_elapsed    | 4452     |\n",
      "|    total_timesteps | 75200    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 5.92        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 4491        |\n",
      "|    total_timesteps      | 76000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015151119 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.789      |\n",
      "|    explained_variance   | -0.0513     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.7         |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | -0.00352    |\n",
      "|    value_loss           | 5.6         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 5.54        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 4528        |\n",
      "|    total_timesteps      | 76800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019179951 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.789      |\n",
      "|    explained_variance   | 0.138       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.75        |\n",
      "|    n_updates            | 950         |\n",
      "|    policy_gradient_loss | 0.00194     |\n",
      "|    value_loss           | 6.57        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 5.19        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 4567        |\n",
      "|    total_timesteps      | 77600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011407757 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.829      |\n",
      "|    explained_variance   | 0.273       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.88        |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.0024     |\n",
      "|    value_loss           | 5.59        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 5.59        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 4610        |\n",
      "|    total_timesteps      | 78400       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010026907 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.765      |\n",
      "|    explained_variance   | 0.196       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.34        |\n",
      "|    n_updates            | 970         |\n",
      "|    policy_gradient_loss | -0.00563    |\n",
      "|    value_loss           | 5.25        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 5.21        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 4658        |\n",
      "|    total_timesteps      | 79200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015286145 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.735      |\n",
      "|    explained_variance   | 0.168       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.55        |\n",
      "|    n_updates            | 980         |\n",
      "|    policy_gradient_loss | -0.000438   |\n",
      "|    value_loss           | 6.7         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=7.42 +/- 11.67\n",
      "Episode length: 102.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 102         |\n",
      "|    mean_reward          | 7.42        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 80000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010392288 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.711      |\n",
      "|    explained_variance   | 0.528       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.24        |\n",
      "|    n_updates            | 990         |\n",
      "|    policy_gradient_loss | -0.00352    |\n",
      "|    value_loss           | 5.11        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 102      |\n",
      "|    ep_rew_mean     | 5.03     |\n",
      "| time/              |          |\n",
      "|    fps             | 17       |\n",
      "|    iterations      | 100      |\n",
      "|    time_elapsed    | 4705     |\n",
      "|    total_timesteps | 80000    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 4.96        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 101         |\n",
      "|    time_elapsed         | 4745        |\n",
      "|    total_timesteps      | 80800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014368098 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.724      |\n",
      "|    explained_variance   | 0.352       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.25        |\n",
      "|    n_updates            | 1000        |\n",
      "|    policy_gradient_loss | 0.00106     |\n",
      "|    value_loss           | 6.72        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 102        |\n",
      "|    ep_rew_mean          | 4.51       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 17         |\n",
      "|    iterations           | 102        |\n",
      "|    time_elapsed         | 4783       |\n",
      "|    total_timesteps      | 81600      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02615529 |\n",
      "|    clip_fraction        | 0.197      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.781     |\n",
      "|    explained_variance   | 0.0904     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.74       |\n",
      "|    n_updates            | 1010       |\n",
      "|    policy_gradient_loss | 0.00105    |\n",
      "|    value_loss           | 4.49       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 4.68        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 103         |\n",
      "|    time_elapsed         | 4819        |\n",
      "|    total_timesteps      | 82400       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025510529 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.798      |\n",
      "|    explained_variance   | 0.476       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.96        |\n",
      "|    n_updates            | 1020        |\n",
      "|    policy_gradient_loss | 0.00725     |\n",
      "|    value_loss           | 6.59        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 5.77        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 104         |\n",
      "|    time_elapsed         | 4861        |\n",
      "|    total_timesteps      | 83200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015775286 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.804      |\n",
      "|    explained_variance   | 0.0623      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.27        |\n",
      "|    n_updates            | 1030        |\n",
      "|    policy_gradient_loss | 0.00385     |\n",
      "|    value_loss           | 7.04        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 5.95        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 105         |\n",
      "|    time_elapsed         | 4907        |\n",
      "|    total_timesteps      | 84000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014786465 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.744      |\n",
      "|    explained_variance   | 0.299       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.2         |\n",
      "|    n_updates            | 1040        |\n",
      "|    policy_gradient_loss | -0.00417    |\n",
      "|    value_loss           | 4.7         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 6.03        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 106         |\n",
      "|    time_elapsed         | 4952        |\n",
      "|    total_timesteps      | 84800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011389149 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.753      |\n",
      "|    explained_variance   | 0.1         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.39        |\n",
      "|    n_updates            | 1050        |\n",
      "|    policy_gradient_loss | -7.05e-05   |\n",
      "|    value_loss           | 4.89        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=85000, episode_reward=-2.14 +/- 9.54\n",
      "Episode length: 102.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 102         |\n",
      "|    mean_reward          | -2.14       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 85000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016585145 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.752      |\n",
      "|    explained_variance   | 0.121       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.94        |\n",
      "|    n_updates            | 1060        |\n",
      "|    policy_gradient_loss | -0.00614    |\n",
      "|    value_loss           | 3.81        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 102      |\n",
      "|    ep_rew_mean     | 5.35     |\n",
      "| time/              |          |\n",
      "|    fps             | 17       |\n",
      "|    iterations      | 107      |\n",
      "|    time_elapsed    | 4997     |\n",
      "|    total_timesteps | 85600    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 102        |\n",
      "|    ep_rew_mean          | 4.48       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 17         |\n",
      "|    iterations           | 108        |\n",
      "|    time_elapsed         | 5034       |\n",
      "|    total_timesteps      | 86400      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02677637 |\n",
      "|    clip_fraction        | 0.163      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.737     |\n",
      "|    explained_variance   | -0.053     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.17       |\n",
      "|    n_updates            | 1070       |\n",
      "|    policy_gradient_loss | 0.00526    |\n",
      "|    value_loss           | 3.3        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 4.73        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 109         |\n",
      "|    time_elapsed         | 5072        |\n",
      "|    total_timesteps      | 87200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014069792 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.657      |\n",
      "|    explained_variance   | 0.434       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.2         |\n",
      "|    n_updates            | 1080        |\n",
      "|    policy_gradient_loss | -0.00148    |\n",
      "|    value_loss           | 5.66        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 4.29        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 110         |\n",
      "|    time_elapsed         | 5112        |\n",
      "|    total_timesteps      | 88000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014562755 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.673      |\n",
      "|    explained_variance   | 0.305       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.69        |\n",
      "|    n_updates            | 1090        |\n",
      "|    policy_gradient_loss | -0.004      |\n",
      "|    value_loss           | 5.25        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 4.49        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 111         |\n",
      "|    time_elapsed         | 5156        |\n",
      "|    total_timesteps      | 88800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024316914 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.713      |\n",
      "|    explained_variance   | 0.0787      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.43        |\n",
      "|    n_updates            | 1100        |\n",
      "|    policy_gradient_loss | 0.000726    |\n",
      "|    value_loss           | 5.74        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 4.19        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 112         |\n",
      "|    time_elapsed         | 5208        |\n",
      "|    total_timesteps      | 89600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043970063 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.793      |\n",
      "|    explained_variance   | -0.153      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.66        |\n",
      "|    n_updates            | 1110        |\n",
      "|    policy_gradient_loss | 0.00187     |\n",
      "|    value_loss           | 4.86        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=90000, episode_reward=4.22 +/- 10.41\n",
      "Episode length: 102.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 102         |\n",
      "|    mean_reward          | 4.22        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 90000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.055291057 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.617      |\n",
      "|    explained_variance   | -0.0337     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.64        |\n",
      "|    n_updates            | 1120        |\n",
      "|    policy_gradient_loss | 0.0122      |\n",
      "|    value_loss           | 6.23        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 102      |\n",
      "|    ep_rew_mean     | 4.42     |\n",
      "| time/              |          |\n",
      "|    fps             | 17       |\n",
      "|    iterations      | 113      |\n",
      "|    time_elapsed    | 5260     |\n",
      "|    total_timesteps | 90400    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 3.94        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 114         |\n",
      "|    time_elapsed         | 5312        |\n",
      "|    total_timesteps      | 91200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022187632 |\n",
      "|    clip_fraction        | 0.0968      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.549      |\n",
      "|    explained_variance   | 0.355       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.3         |\n",
      "|    n_updates            | 1130        |\n",
      "|    policy_gradient_loss | 0.0035      |\n",
      "|    value_loss           | 3.87        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 3.72        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 115         |\n",
      "|    time_elapsed         | 5371        |\n",
      "|    total_timesteps      | 92000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010557058 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.454      |\n",
      "|    explained_variance   | 0.428       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.23        |\n",
      "|    n_updates            | 1140        |\n",
      "|    policy_gradient_loss | -0.000832   |\n",
      "|    value_loss           | 5.67        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 3.41        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 116         |\n",
      "|    time_elapsed         | 5418        |\n",
      "|    total_timesteps      | 92800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009861295 |\n",
      "|    clip_fraction        | 0.0705      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.485      |\n",
      "|    explained_variance   | 0.292       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.31        |\n",
      "|    n_updates            | 1150        |\n",
      "|    policy_gradient_loss | -0.00103    |\n",
      "|    value_loss           | 4.86        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 2.33        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 117         |\n",
      "|    time_elapsed         | 5470        |\n",
      "|    total_timesteps      | 93600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013059932 |\n",
      "|    clip_fraction        | 0.091       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.516      |\n",
      "|    explained_variance   | 0.417       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.62        |\n",
      "|    n_updates            | 1160        |\n",
      "|    policy_gradient_loss | 0.00228     |\n",
      "|    value_loss           | 4.61        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 102        |\n",
      "|    ep_rew_mean          | 1.95       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 17         |\n",
      "|    iterations           | 118        |\n",
      "|    time_elapsed         | 5520       |\n",
      "|    total_timesteps      | 94400      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02211016 |\n",
      "|    clip_fraction        | 0.126      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.475     |\n",
      "|    explained_variance   | 0.085      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.866      |\n",
      "|    n_updates            | 1170       |\n",
      "|    policy_gradient_loss | 0.00334    |\n",
      "|    value_loss           | 4.95       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=95000, episode_reward=5.65 +/- 9.96\n",
      "Episode length: 102.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 102         |\n",
      "|    mean_reward          | 5.65        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 95000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024600022 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.444      |\n",
      "|    explained_variance   | 0.0512      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.606       |\n",
      "|    n_updates            | 1180        |\n",
      "|    policy_gradient_loss | 0.00198     |\n",
      "|    value_loss           | 3.03        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 102      |\n",
      "|    ep_rew_mean     | 1.43     |\n",
      "| time/              |          |\n",
      "|    fps             | 17       |\n",
      "|    iterations      | 119      |\n",
      "|    time_elapsed    | 5574     |\n",
      "|    total_timesteps | 95200    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 1.14        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 120         |\n",
      "|    time_elapsed         | 5616        |\n",
      "|    total_timesteps      | 96000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026873853 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.566      |\n",
      "|    explained_variance   | 0.297       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.41        |\n",
      "|    n_updates            | 1190        |\n",
      "|    policy_gradient_loss | 0.00362     |\n",
      "|    value_loss           | 6.14        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 0.879       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 121         |\n",
      "|    time_elapsed         | 5657        |\n",
      "|    total_timesteps      | 96800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017564774 |\n",
      "|    clip_fraction        | 0.0785      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.586      |\n",
      "|    explained_variance   | 0.131       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.779       |\n",
      "|    n_updates            | 1200        |\n",
      "|    policy_gradient_loss | -0.0076     |\n",
      "|    value_loss           | 5.12        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 102        |\n",
      "|    ep_rew_mean          | 1.19       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 17         |\n",
      "|    iterations           | 122        |\n",
      "|    time_elapsed         | 5698       |\n",
      "|    total_timesteps      | 97600      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02876772 |\n",
      "|    clip_fraction        | 0.127      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.586     |\n",
      "|    explained_variance   | 0.585      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.789      |\n",
      "|    n_updates            | 1210       |\n",
      "|    policy_gradient_loss | 0.0123     |\n",
      "|    value_loss           | 4.09       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 1.09        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 123         |\n",
      "|    time_elapsed         | 5743        |\n",
      "|    total_timesteps      | 98400       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013844337 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.619      |\n",
      "|    explained_variance   | 0.326       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.36        |\n",
      "|    n_updates            | 1220        |\n",
      "|    policy_gradient_loss | 0.00208     |\n",
      "|    value_loss           | 4.44        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 0.463       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 124         |\n",
      "|    time_elapsed         | 5792        |\n",
      "|    total_timesteps      | 99200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021795254 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.774      |\n",
      "|    explained_variance   | 0.45        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.36        |\n",
      "|    n_updates            | 1230        |\n",
      "|    policy_gradient_loss | 0.00271     |\n",
      "|    value_loss           | 4.88        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=5.01 +/- 8.33\n",
      "Episode length: 102.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 102         |\n",
      "|    mean_reward          | 5.01        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 100000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011719811 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.684      |\n",
      "|    explained_variance   | 0.503       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.79        |\n",
      "|    n_updates            | 1240        |\n",
      "|    policy_gradient_loss | -0.00376    |\n",
      "|    value_loss           | 3.33        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 102      |\n",
      "|    ep_rew_mean     | 0.614    |\n",
      "| time/              |          |\n",
      "|    fps             | 17       |\n",
      "|    iterations      | 125      |\n",
      "|    time_elapsed    | 5846     |\n",
      "|    total_timesteps | 100000   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 0.675       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 126         |\n",
      "|    time_elapsed         | 5892        |\n",
      "|    total_timesteps      | 100800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012374277 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.692      |\n",
      "|    explained_variance   | 0.341       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.18        |\n",
      "|    n_updates            | 1250        |\n",
      "|    policy_gradient_loss | -0.00286    |\n",
      "|    value_loss           | 5.74        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 102        |\n",
      "|    ep_rew_mean          | 1.25       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 17         |\n",
      "|    iterations           | 127        |\n",
      "|    time_elapsed         | 5933       |\n",
      "|    total_timesteps      | 101600     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02064193 |\n",
      "|    clip_fraction        | 0.112      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.748     |\n",
      "|    explained_variance   | 0.405      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.82       |\n",
      "|    n_updates            | 1260       |\n",
      "|    policy_gradient_loss | -0.00995   |\n",
      "|    value_loss           | 5.53       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 1.42        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 128         |\n",
      "|    time_elapsed         | 5974        |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010341525 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.825      |\n",
      "|    explained_variance   | 0.493       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.962       |\n",
      "|    n_updates            | 1270        |\n",
      "|    policy_gradient_loss | -0.00207    |\n",
      "|    value_loss           | 5.1         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 102        |\n",
      "|    ep_rew_mean          | 0.415      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 17         |\n",
      "|    iterations           | 129        |\n",
      "|    time_elapsed         | 6014       |\n",
      "|    total_timesteps      | 103200     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01273405 |\n",
      "|    clip_fraction        | 0.105      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.798     |\n",
      "|    explained_variance   | 0.555      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.12       |\n",
      "|    n_updates            | 1280       |\n",
      "|    policy_gradient_loss | -0.00663   |\n",
      "|    value_loss           | 3.85       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 0.889       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 130         |\n",
      "|    time_elapsed         | 6062        |\n",
      "|    total_timesteps      | 104000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017668858 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.778      |\n",
      "|    explained_variance   | 0.0375      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.74        |\n",
      "|    n_updates            | 1290        |\n",
      "|    policy_gradient_loss | -0.00603    |\n",
      "|    value_loss           | 4.42        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 102        |\n",
      "|    ep_rew_mean          | 1          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 17         |\n",
      "|    iterations           | 131        |\n",
      "|    time_elapsed         | 6111       |\n",
      "|    total_timesteps      | 104800     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06824727 |\n",
      "|    clip_fraction        | 0.171      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.762     |\n",
      "|    explained_variance   | 0.114      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.88       |\n",
      "|    n_updates            | 1300       |\n",
      "|    policy_gradient_loss | -0.0034    |\n",
      "|    value_loss           | 3.33       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=105000, episode_reward=-6.23 +/- 6.55\n",
      "Episode length: 102.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 102         |\n",
      "|    mean_reward          | -6.23       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 105000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.054532934 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.794      |\n",
      "|    explained_variance   | 0.0281      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.18        |\n",
      "|    n_updates            | 1310        |\n",
      "|    policy_gradient_loss | -0.00102    |\n",
      "|    value_loss           | 5.47        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 102      |\n",
      "|    ep_rew_mean     | 1.22     |\n",
      "| time/              |          |\n",
      "|    fps             | 17       |\n",
      "|    iterations      | 132      |\n",
      "|    time_elapsed    | 6161     |\n",
      "|    total_timesteps | 105600   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 1.63        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 133         |\n",
      "|    time_elapsed         | 6204        |\n",
      "|    total_timesteps      | 106400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019658638 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.776      |\n",
      "|    explained_variance   | -0.0502     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.864       |\n",
      "|    n_updates            | 1320        |\n",
      "|    policy_gradient_loss | 0.00295     |\n",
      "|    value_loss           | 4.62        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 2           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 134         |\n",
      "|    time_elapsed         | 6244        |\n",
      "|    total_timesteps      | 107200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008415506 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.811      |\n",
      "|    explained_variance   | -0.191      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.37        |\n",
      "|    n_updates            | 1330        |\n",
      "|    policy_gradient_loss | -0.0037     |\n",
      "|    value_loss           | 4.82        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 102        |\n",
      "|    ep_rew_mean          | 1.23       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 17         |\n",
      "|    iterations           | 135        |\n",
      "|    time_elapsed         | 6285       |\n",
      "|    total_timesteps      | 108000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02431532 |\n",
      "|    clip_fraction        | 0.164      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.758     |\n",
      "|    explained_variance   | 0.0421     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.27       |\n",
      "|    n_updates            | 1340       |\n",
      "|    policy_gradient_loss | 0.00602    |\n",
      "|    value_loss           | 4.04       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 1.3         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 136         |\n",
      "|    time_elapsed         | 6332        |\n",
      "|    total_timesteps      | 108800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036619812 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.811      |\n",
      "|    explained_variance   | 0.429       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.66        |\n",
      "|    n_updates            | 1350        |\n",
      "|    policy_gradient_loss | 0.00478     |\n",
      "|    value_loss           | 3.75        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 1.36        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 137         |\n",
      "|    time_elapsed         | 6383        |\n",
      "|    total_timesteps      | 109600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021972714 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.804      |\n",
      "|    explained_variance   | 0.52        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.891       |\n",
      "|    n_updates            | 1360        |\n",
      "|    policy_gradient_loss | 6.95e-07    |\n",
      "|    value_loss           | 4.13        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=110000, episode_reward=0.90 +/- 4.02\n",
      "Episode length: 102.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 102          |\n",
      "|    mean_reward          | 0.902        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 110000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0088012805 |\n",
      "|    clip_fraction        | 0.11         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.824       |\n",
      "|    explained_variance   | 0.592        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.1          |\n",
      "|    n_updates            | 1370         |\n",
      "|    policy_gradient_loss | -0.00261     |\n",
      "|    value_loss           | 4.04         |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 102      |\n",
      "|    ep_rew_mean     | 1.62     |\n",
      "| time/              |          |\n",
      "|    fps             | 17       |\n",
      "|    iterations      | 138      |\n",
      "|    time_elapsed    | 6436     |\n",
      "|    total_timesteps | 110400   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 102        |\n",
      "|    ep_rew_mean          | 1.27       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 17         |\n",
      "|    iterations           | 139        |\n",
      "|    time_elapsed         | 6479       |\n",
      "|    total_timesteps      | 111200     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04418919 |\n",
      "|    clip_fraction        | 0.173      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.838     |\n",
      "|    explained_variance   | 0.627      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.895      |\n",
      "|    n_updates            | 1380       |\n",
      "|    policy_gradient_loss | -0.00328   |\n",
      "|    value_loss           | 5.4        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 102        |\n",
      "|    ep_rew_mean          | 0.968      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 17         |\n",
      "|    iterations           | 140        |\n",
      "|    time_elapsed         | 6521       |\n",
      "|    total_timesteps      | 112000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03482443 |\n",
      "|    clip_fraction        | 0.194      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.827     |\n",
      "|    explained_variance   | 0.546      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.987      |\n",
      "|    n_updates            | 1390       |\n",
      "|    policy_gradient_loss | 0.000713   |\n",
      "|    value_loss           | 4.15       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 1.14        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 141         |\n",
      "|    time_elapsed         | 6561        |\n",
      "|    total_timesteps      | 112800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.051925834 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.792      |\n",
      "|    explained_variance   | 0.596       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.727       |\n",
      "|    n_updates            | 1400        |\n",
      "|    policy_gradient_loss | 0.0067      |\n",
      "|    value_loss           | 5.16        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 1.77        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 142         |\n",
      "|    time_elapsed         | 6604        |\n",
      "|    total_timesteps      | 113600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016870348 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.796      |\n",
      "|    explained_variance   | 0.476       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.15        |\n",
      "|    n_updates            | 1410        |\n",
      "|    policy_gradient_loss | 0.00731     |\n",
      "|    value_loss           | 3.63        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 1.16        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 143         |\n",
      "|    time_elapsed         | 6654        |\n",
      "|    total_timesteps      | 114400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020897161 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.779      |\n",
      "|    explained_variance   | 0.267       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.98        |\n",
      "|    n_updates            | 1420        |\n",
      "|    policy_gradient_loss | 0.000703    |\n",
      "|    value_loss           | 4.43        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=115000, episode_reward=7.98 +/- 3.85\n",
      "Episode length: 102.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 102         |\n",
      "|    mean_reward          | 7.98        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 115000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021911774 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.781      |\n",
      "|    explained_variance   | 0.587       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.78        |\n",
      "|    n_updates            | 1430        |\n",
      "|    policy_gradient_loss | -0.00154    |\n",
      "|    value_loss           | 5.28        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 102      |\n",
      "|    ep_rew_mean     | 1.52     |\n",
      "| time/              |          |\n",
      "|    fps             | 17       |\n",
      "|    iterations      | 144      |\n",
      "|    time_elapsed    | 6713     |\n",
      "|    total_timesteps | 115200   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 0.498       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 145         |\n",
      "|    time_elapsed         | 6764        |\n",
      "|    total_timesteps      | 116000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008928966 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.793      |\n",
      "|    explained_variance   | 0.394       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.89        |\n",
      "|    n_updates            | 1440        |\n",
      "|    policy_gradient_loss | 0.00189     |\n",
      "|    value_loss           | 4.89        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 102        |\n",
      "|    ep_rew_mean          | -0.134     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 17         |\n",
      "|    iterations           | 146        |\n",
      "|    time_elapsed         | 6809       |\n",
      "|    total_timesteps      | 116800     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02069928 |\n",
      "|    clip_fraction        | 0.176      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.781     |\n",
      "|    explained_variance   | 0.539      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.22       |\n",
      "|    n_updates            | 1450       |\n",
      "|    policy_gradient_loss | -0.00541   |\n",
      "|    value_loss           | 3.73       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | -0.288      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 147         |\n",
      "|    time_elapsed         | 6858        |\n",
      "|    total_timesteps      | 117600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016923025 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.785      |\n",
      "|    explained_variance   | 0.307       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.35        |\n",
      "|    n_updates            | 1460        |\n",
      "|    policy_gradient_loss | 0.00327     |\n",
      "|    value_loss           | 3.76        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 102        |\n",
      "|    ep_rew_mean          | 0.414      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 17         |\n",
      "|    iterations           | 148        |\n",
      "|    time_elapsed         | 6912       |\n",
      "|    total_timesteps      | 118400     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07535203 |\n",
      "|    clip_fraction        | 0.359      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.883     |\n",
      "|    explained_variance   | 0.00297    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.24       |\n",
      "|    n_updates            | 1470       |\n",
      "|    policy_gradient_loss | 0.0299     |\n",
      "|    value_loss           | 5.53       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | -0.023      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 149         |\n",
      "|    time_elapsed         | 6979        |\n",
      "|    total_timesteps      | 119200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020280156 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.876      |\n",
      "|    explained_variance   | 0.124       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.97        |\n",
      "|    n_updates            | 1480        |\n",
      "|    policy_gradient_loss | 0.00631     |\n",
      "|    value_loss           | 5.8         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=120000, episode_reward=-4.26 +/- 6.52\n",
      "Episode length: 102.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 102         |\n",
      "|    mean_reward          | -4.26       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 120000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014942654 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.901      |\n",
      "|    explained_variance   | 0.00622     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.26        |\n",
      "|    n_updates            | 1490        |\n",
      "|    policy_gradient_loss | -0.00253    |\n",
      "|    value_loss           | 5.1         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 102      |\n",
      "|    ep_rew_mean     | -0.144   |\n",
      "| time/              |          |\n",
      "|    fps             | 17       |\n",
      "|    iterations      | 150      |\n",
      "|    time_elapsed    | 7044     |\n",
      "|    total_timesteps | 120000   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | -0.302      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 151         |\n",
      "|    time_elapsed         | 7098        |\n",
      "|    total_timesteps      | 120800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024346054 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.906      |\n",
      "|    explained_variance   | 0.161       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.04        |\n",
      "|    n_updates            | 1500        |\n",
      "|    policy_gradient_loss | -0.00584    |\n",
      "|    value_loss           | 4.56        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 102        |\n",
      "|    ep_rew_mean          | 0.297      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 17         |\n",
      "|    iterations           | 152        |\n",
      "|    time_elapsed         | 7145       |\n",
      "|    total_timesteps      | 121600     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01963078 |\n",
      "|    clip_fraction        | 0.301      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.937     |\n",
      "|    explained_variance   | -0.0466    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.19       |\n",
      "|    n_updates            | 1510       |\n",
      "|    policy_gradient_loss | 0.0106     |\n",
      "|    value_loss           | 4.82       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 0.412       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 153         |\n",
      "|    time_elapsed         | 7188        |\n",
      "|    total_timesteps      | 122400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017189974 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.99       |\n",
      "|    explained_variance   | -0.569      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.6         |\n",
      "|    n_updates            | 1520        |\n",
      "|    policy_gradient_loss | -0.00961    |\n",
      "|    value_loss           | 3.82        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 0.686       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 154         |\n",
      "|    time_elapsed         | 7230        |\n",
      "|    total_timesteps      | 123200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025715463 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.974      |\n",
      "|    explained_variance   | 0.152       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.07        |\n",
      "|    n_updates            | 1530        |\n",
      "|    policy_gradient_loss | -0.00265    |\n",
      "|    value_loss           | 3.5         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 0.747       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 155         |\n",
      "|    time_elapsed         | 7292        |\n",
      "|    total_timesteps      | 124000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012455602 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.931      |\n",
      "|    explained_variance   | -0.244      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.5         |\n",
      "|    n_updates            | 1540        |\n",
      "|    policy_gradient_loss | -0.0023     |\n",
      "|    value_loss           | 4.42        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 0.673       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 156         |\n",
      "|    time_elapsed         | 7353        |\n",
      "|    total_timesteps      | 124800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017073952 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.968      |\n",
      "|    explained_variance   | -0.0764     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.1         |\n",
      "|    n_updates            | 1550        |\n",
      "|    policy_gradient_loss | -0.00197    |\n",
      "|    value_loss           | 7.09        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=125000, episode_reward=4.06 +/- 8.78\n",
      "Episode length: 102.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 102         |\n",
      "|    mean_reward          | 4.06        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 125000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008723056 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.997      |\n",
      "|    explained_variance   | -0.121      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.68        |\n",
      "|    n_updates            | 1560        |\n",
      "|    policy_gradient_loss | 0.0075      |\n",
      "|    value_loss           | 5.15        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 102      |\n",
      "|    ep_rew_mean     | 0.542    |\n",
      "| time/              |          |\n",
      "|    fps             | 16       |\n",
      "|    iterations      | 157      |\n",
      "|    time_elapsed    | 7418     |\n",
      "|    total_timesteps | 125600   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 1.23        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 158         |\n",
      "|    time_elapsed         | 7473        |\n",
      "|    total_timesteps      | 126400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013663536 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.972      |\n",
      "|    explained_variance   | 0.305       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.09        |\n",
      "|    n_updates            | 1570        |\n",
      "|    policy_gradient_loss | -0.00416    |\n",
      "|    value_loss           | 6.34        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 1.5         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 159         |\n",
      "|    time_elapsed         | 7523        |\n",
      "|    total_timesteps      | 127200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020668246 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.98       |\n",
      "|    explained_variance   | 0.174       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.41        |\n",
      "|    n_updates            | 1580        |\n",
      "|    policy_gradient_loss | -0.00683    |\n",
      "|    value_loss           | 6.09        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 1.33        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 160         |\n",
      "|    time_elapsed         | 7577        |\n",
      "|    total_timesteps      | 128000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009756598 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | 0.0477      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.94        |\n",
      "|    n_updates            | 1590        |\n",
      "|    policy_gradient_loss | -0.00288    |\n",
      "|    value_loss           | 4.17        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 102        |\n",
      "|    ep_rew_mean          | 1.55       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 16         |\n",
      "|    iterations           | 161        |\n",
      "|    time_elapsed         | 7635       |\n",
      "|    total_timesteps      | 128800     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01820767 |\n",
      "|    clip_fraction        | 0.192      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.992     |\n",
      "|    explained_variance   | 0.131      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.94       |\n",
      "|    n_updates            | 1600       |\n",
      "|    policy_gradient_loss | -0.00217   |\n",
      "|    value_loss           | 6.72       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 1.33        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 162         |\n",
      "|    time_elapsed         | 7705        |\n",
      "|    total_timesteps      | 129600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010739461 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.999      |\n",
      "|    explained_variance   | 0.371       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.8         |\n",
      "|    n_updates            | 1610        |\n",
      "|    policy_gradient_loss | -0.00284    |\n",
      "|    value_loss           | 6.59        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=130000, episode_reward=0.27 +/- 8.20\n",
      "Episode length: 102.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 102         |\n",
      "|    mean_reward          | 0.271       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 130000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016558932 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.999      |\n",
      "|    explained_variance   | -0.0191     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.8         |\n",
      "|    n_updates            | 1620        |\n",
      "|    policy_gradient_loss | -0.00421    |\n",
      "|    value_loss           | 4.47        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 102      |\n",
      "|    ep_rew_mean     | 1.34     |\n",
      "| time/              |          |\n",
      "|    fps             | 16       |\n",
      "|    iterations      | 163      |\n",
      "|    time_elapsed    | 7771     |\n",
      "|    total_timesteps | 130400   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 0.644       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 164         |\n",
      "|    time_elapsed         | 7823        |\n",
      "|    total_timesteps      | 131200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012728903 |\n",
      "|    clip_fraction        | 0.0966      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | 0.0777      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.48        |\n",
      "|    n_updates            | 1630        |\n",
      "|    policy_gradient_loss | -0.00739    |\n",
      "|    value_loss           | 7.86        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 0.588       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 165         |\n",
      "|    time_elapsed         | 7875        |\n",
      "|    total_timesteps      | 132000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015380247 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.977      |\n",
      "|    explained_variance   | -0.135      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.54        |\n",
      "|    n_updates            | 1640        |\n",
      "|    policy_gradient_loss | -0.00232    |\n",
      "|    value_loss           | 6.08        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 102        |\n",
      "|    ep_rew_mean          | 0.793      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 16         |\n",
      "|    iterations           | 166        |\n",
      "|    time_elapsed         | 7921       |\n",
      "|    total_timesteps      | 132800     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02274371 |\n",
      "|    clip_fraction        | 0.203      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.952     |\n",
      "|    explained_variance   | -0.104     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.47       |\n",
      "|    n_updates            | 1650       |\n",
      "|    policy_gradient_loss | -0.00294   |\n",
      "|    value_loss           | 4.87       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 0.849       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 167         |\n",
      "|    time_elapsed         | 7968        |\n",
      "|    total_timesteps      | 133600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018505499 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.984      |\n",
      "|    explained_variance   | -0.0938     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.43        |\n",
      "|    n_updates            | 1660        |\n",
      "|    policy_gradient_loss | -0.000704   |\n",
      "|    value_loss           | 6.02        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 1.04        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 168         |\n",
      "|    time_elapsed         | 8025        |\n",
      "|    total_timesteps      | 134400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010689936 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | 0.206       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.91        |\n",
      "|    n_updates            | 1670        |\n",
      "|    policy_gradient_loss | -0.00471    |\n",
      "|    value_loss           | 6.45        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=135000, episode_reward=7.42 +/- 11.90\n",
      "Episode length: 102.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 102        |\n",
      "|    mean_reward          | 7.42       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 135000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02142318 |\n",
      "|    clip_fraction        | 0.158      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.04      |\n",
      "|    explained_variance   | 0.15       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.64       |\n",
      "|    n_updates            | 1680       |\n",
      "|    policy_gradient_loss | -0.00528   |\n",
      "|    value_loss           | 4          |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 102      |\n",
      "|    ep_rew_mean     | 1.27     |\n",
      "| time/              |          |\n",
      "|    fps             | 16       |\n",
      "|    iterations      | 169      |\n",
      "|    time_elapsed    | 8089     |\n",
      "|    total_timesteps | 135200   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 1.6         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 170         |\n",
      "|    time_elapsed         | 8149        |\n",
      "|    total_timesteps      | 136000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020889198 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.97       |\n",
      "|    explained_variance   | 0.463       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.66        |\n",
      "|    n_updates            | 1690        |\n",
      "|    policy_gradient_loss | -0.00744    |\n",
      "|    value_loss           | 4.17        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 102          |\n",
      "|    ep_rew_mean          | 1.5          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 16           |\n",
      "|    iterations           | 171          |\n",
      "|    time_elapsed         | 8214         |\n",
      "|    total_timesteps      | 136800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0143045075 |\n",
      "|    clip_fraction        | 0.159        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | 0.449        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.95         |\n",
      "|    n_updates            | 1700         |\n",
      "|    policy_gradient_loss | -0.0055      |\n",
      "|    value_loss           | 5.12         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 1.4         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 172         |\n",
      "|    time_elapsed         | 8264        |\n",
      "|    total_timesteps      | 137600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022789553 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.993      |\n",
      "|    explained_variance   | 0.0105      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.85        |\n",
      "|    n_updates            | 1710        |\n",
      "|    policy_gradient_loss | -0.00501    |\n",
      "|    value_loss           | 4.5         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 102        |\n",
      "|    ep_rew_mean          | 1.3        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 16         |\n",
      "|    iterations           | 173        |\n",
      "|    time_elapsed         | 8305       |\n",
      "|    total_timesteps      | 138400     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01645425 |\n",
      "|    clip_fraction        | 0.191      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.989     |\n",
      "|    explained_variance   | -0.0795    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.9        |\n",
      "|    n_updates            | 1720       |\n",
      "|    policy_gradient_loss | -0.00782   |\n",
      "|    value_loss           | 6.83       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 1.25        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 174         |\n",
      "|    time_elapsed         | 8353        |\n",
      "|    total_timesteps      | 139200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015775176 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.974      |\n",
      "|    explained_variance   | -0.275      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.05        |\n",
      "|    n_updates            | 1730        |\n",
      "|    policy_gradient_loss | -0.00853    |\n",
      "|    value_loss           | 5.08        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=140000, episode_reward=3.27 +/- 4.75\n",
      "Episode length: 102.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 102         |\n",
      "|    mean_reward          | 3.27        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 140000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017292332 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.94       |\n",
      "|    explained_variance   | 0.125       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.378       |\n",
      "|    n_updates            | 1740        |\n",
      "|    policy_gradient_loss | -0.00623    |\n",
      "|    value_loss           | 4.32        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 102      |\n",
      "|    ep_rew_mean     | 1.42     |\n",
      "| time/              |          |\n",
      "|    fps             | 16       |\n",
      "|    iterations      | 175      |\n",
      "|    time_elapsed    | 8422     |\n",
      "|    total_timesteps | 140000   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 1.39        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 176         |\n",
      "|    time_elapsed         | 8499        |\n",
      "|    total_timesteps      | 140800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019577507 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | -0.173      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.58        |\n",
      "|    n_updates            | 1750        |\n",
      "|    policy_gradient_loss | -0.00399    |\n",
      "|    value_loss           | 7.76        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 1.74        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 177         |\n",
      "|    time_elapsed         | 8565        |\n",
      "|    total_timesteps      | 141600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010915589 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.97       |\n",
      "|    explained_variance   | -0.0655     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.22        |\n",
      "|    n_updates            | 1760        |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    value_loss           | 4.58        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 1.21        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 178         |\n",
      "|    time_elapsed         | 8629        |\n",
      "|    total_timesteps      | 142400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008913084 |\n",
      "|    clip_fraction        | 0.0539      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.991      |\n",
      "|    explained_variance   | 0.152       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.07        |\n",
      "|    n_updates            | 1770        |\n",
      "|    policy_gradient_loss | -0.00764    |\n",
      "|    value_loss           | 3.2         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 1.49        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 179         |\n",
      "|    time_elapsed         | 8684        |\n",
      "|    total_timesteps      | 143200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008966228 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.98       |\n",
      "|    explained_variance   | 0.193       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.01        |\n",
      "|    n_updates            | 1780        |\n",
      "|    policy_gradient_loss | -0.0096     |\n",
      "|    value_loss           | 5.27        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 2.15        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 180         |\n",
      "|    time_elapsed         | 8731        |\n",
      "|    total_timesteps      | 144000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018001448 |\n",
      "|    clip_fraction        | 0.0921      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.984      |\n",
      "|    explained_variance   | 0.152       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.5         |\n",
      "|    n_updates            | 1790        |\n",
      "|    policy_gradient_loss | -0.00454    |\n",
      "|    value_loss           | 5.24        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 1.67        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 181         |\n",
      "|    time_elapsed         | 8786        |\n",
      "|    total_timesteps      | 144800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012091659 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.962      |\n",
      "|    explained_variance   | -0.146      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.59        |\n",
      "|    n_updates            | 1800        |\n",
      "|    policy_gradient_loss | -0.0017     |\n",
      "|    value_loss           | 6.62        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=145000, episode_reward=2.58 +/- 13.31\n",
      "Episode length: 102.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 102         |\n",
      "|    mean_reward          | 2.58        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 145000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018028505 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.994      |\n",
      "|    explained_variance   | -0.204      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.99        |\n",
      "|    n_updates            | 1810        |\n",
      "|    policy_gradient_loss | -0.0074     |\n",
      "|    value_loss           | 6.83        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 102      |\n",
      "|    ep_rew_mean     | 1.17     |\n",
      "| time/              |          |\n",
      "|    fps             | 16       |\n",
      "|    iterations      | 182      |\n",
      "|    time_elapsed    | 8857     |\n",
      "|    total_timesteps | 145600   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 102          |\n",
      "|    ep_rew_mean          | 1.27         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 16           |\n",
      "|    iterations           | 183          |\n",
      "|    time_elapsed         | 8913         |\n",
      "|    total_timesteps      | 146400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0110592395 |\n",
      "|    clip_fraction        | 0.151        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.924       |\n",
      "|    explained_variance   | -0.0497      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.37         |\n",
      "|    n_updates            | 1820         |\n",
      "|    policy_gradient_loss | -0.0067      |\n",
      "|    value_loss           | 4.44         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 1.87        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 184         |\n",
      "|    time_elapsed         | 8958        |\n",
      "|    total_timesteps      | 147200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009600694 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.976      |\n",
      "|    explained_variance   | 0.0241      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.14        |\n",
      "|    n_updates            | 1830        |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    value_loss           | 5.2         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 2.54        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 185         |\n",
      "|    time_elapsed         | 9002        |\n",
      "|    total_timesteps      | 148000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011111409 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.982      |\n",
      "|    explained_variance   | 0.144       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.58        |\n",
      "|    n_updates            | 1840        |\n",
      "|    policy_gradient_loss | -0.0031     |\n",
      "|    value_loss           | 8.15        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 3.16        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 186         |\n",
      "|    time_elapsed         | 9042        |\n",
      "|    total_timesteps      | 148800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016674338 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.997      |\n",
      "|    explained_variance   | 0.0971      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.21        |\n",
      "|    n_updates            | 1850        |\n",
      "|    policy_gradient_loss | 0.00123     |\n",
      "|    value_loss           | 3.46        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 3.22        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 187         |\n",
      "|    time_elapsed         | 9096        |\n",
      "|    total_timesteps      | 149600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014626464 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.972      |\n",
      "|    explained_variance   | 0.119       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.32        |\n",
      "|    n_updates            | 1860        |\n",
      "|    policy_gradient_loss | -0.00668    |\n",
      "|    value_loss           | 4.09        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=150000, episode_reward=-3.79 +/- 11.59\n",
      "Episode length: 102.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 102         |\n",
      "|    mean_reward          | -3.79       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 150000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020614829 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.946      |\n",
      "|    explained_variance   | 0.157       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.06        |\n",
      "|    n_updates            | 1870        |\n",
      "|    policy_gradient_loss | -0.00433    |\n",
      "|    value_loss           | 6.18        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 102      |\n",
      "|    ep_rew_mean     | 3.14     |\n",
      "| time/              |          |\n",
      "|    fps             | 16       |\n",
      "|    iterations      | 188      |\n",
      "|    time_elapsed    | 9167     |\n",
      "|    total_timesteps | 150400   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 3.02        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 189         |\n",
      "|    time_elapsed         | 9240        |\n",
      "|    total_timesteps      | 151200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010234365 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.974      |\n",
      "|    explained_variance   | 0.385       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.916       |\n",
      "|    n_updates            | 1880        |\n",
      "|    policy_gradient_loss | -0.00413    |\n",
      "|    value_loss           | 5.66        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 102        |\n",
      "|    ep_rew_mean          | 3.15       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 16         |\n",
      "|    iterations           | 190        |\n",
      "|    time_elapsed         | 9311       |\n",
      "|    total_timesteps      | 152000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02085993 |\n",
      "|    clip_fraction        | 0.235      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.949     |\n",
      "|    explained_variance   | 0.421      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.12       |\n",
      "|    n_updates            | 1890       |\n",
      "|    policy_gradient_loss | -0.00175   |\n",
      "|    value_loss           | 6.1        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 3.62        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 191         |\n",
      "|    time_elapsed         | 9366        |\n",
      "|    total_timesteps      | 152800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021713713 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.872      |\n",
      "|    explained_variance   | 0.492       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.5         |\n",
      "|    n_updates            | 1900        |\n",
      "|    policy_gradient_loss | -0.00115    |\n",
      "|    value_loss           | 5.52        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 102        |\n",
      "|    ep_rew_mean          | 2.59       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 16         |\n",
      "|    iterations           | 192        |\n",
      "|    time_elapsed         | 9422       |\n",
      "|    total_timesteps      | 153600     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01741167 |\n",
      "|    clip_fraction        | 0.165      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.824     |\n",
      "|    explained_variance   | 0.399      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.06       |\n",
      "|    n_updates            | 1910       |\n",
      "|    policy_gradient_loss | -0.00502   |\n",
      "|    value_loss           | 4.85       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 102        |\n",
      "|    ep_rew_mean          | 2.33       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 16         |\n",
      "|    iterations           | 193        |\n",
      "|    time_elapsed         | 9481       |\n",
      "|    total_timesteps      | 154400     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01811613 |\n",
      "|    clip_fraction        | 0.282      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.89      |\n",
      "|    explained_variance   | -0.0761    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.667      |\n",
      "|    n_updates            | 1920       |\n",
      "|    policy_gradient_loss | -0.000326  |\n",
      "|    value_loss           | 5.88       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=155000, episode_reward=-0.20 +/- 5.47\n",
      "Episode length: 102.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 102          |\n",
      "|    mean_reward          | -0.197       |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 155000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0142233595 |\n",
      "|    clip_fraction        | 0.145        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.723       |\n",
      "|    explained_variance   | 0.0591       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.72         |\n",
      "|    n_updates            | 1930         |\n",
      "|    policy_gradient_loss | -0.00257     |\n",
      "|    value_loss           | 5.56         |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 102      |\n",
      "|    ep_rew_mean     | 2.42     |\n",
      "| time/              |          |\n",
      "|    fps             | 16       |\n",
      "|    iterations      | 194      |\n",
      "|    time_elapsed    | 9543     |\n",
      "|    total_timesteps | 155200   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 102        |\n",
      "|    ep_rew_mean          | 2.84       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 16         |\n",
      "|    iterations           | 195        |\n",
      "|    time_elapsed         | 9611       |\n",
      "|    total_timesteps      | 156000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02253966 |\n",
      "|    clip_fraction        | 0.176      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.774     |\n",
      "|    explained_variance   | -0.31      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.13       |\n",
      "|    n_updates            | 1940       |\n",
      "|    policy_gradient_loss | -0.00517   |\n",
      "|    value_loss           | 3.34       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 2.01        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 196         |\n",
      "|    time_elapsed         | 9664        |\n",
      "|    total_timesteps      | 156800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012361422 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.775      |\n",
      "|    explained_variance   | 0.00818     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.16        |\n",
      "|    n_updates            | 1950        |\n",
      "|    policy_gradient_loss | -0.00191    |\n",
      "|    value_loss           | 4.3         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 102        |\n",
      "|    ep_rew_mean          | 2.26       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 16         |\n",
      "|    iterations           | 197        |\n",
      "|    time_elapsed         | 9720       |\n",
      "|    total_timesteps      | 157600     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03152161 |\n",
      "|    clip_fraction        | 0.168      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.856     |\n",
      "|    explained_variance   | -0.115     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.862      |\n",
      "|    n_updates            | 1960       |\n",
      "|    policy_gradient_loss | -0.00632   |\n",
      "|    value_loss           | 3.57       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 2.35        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 198         |\n",
      "|    time_elapsed         | 9770        |\n",
      "|    total_timesteps      | 158400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021868138 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.885      |\n",
      "|    explained_variance   | 0.135       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.559       |\n",
      "|    n_updates            | 1970        |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    value_loss           | 3.46        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 102        |\n",
      "|    ep_rew_mean          | 1.91       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 16         |\n",
      "|    iterations           | 199        |\n",
      "|    time_elapsed         | 9816       |\n",
      "|    total_timesteps      | 159200     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01773344 |\n",
      "|    clip_fraction        | 0.218      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.832     |\n",
      "|    explained_variance   | 0.322      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.14       |\n",
      "|    n_updates            | 1980       |\n",
      "|    policy_gradient_loss | 5.65e-05   |\n",
      "|    value_loss           | 4.3        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=3.11 +/- 10.28\n",
      "Episode length: 102.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 102         |\n",
      "|    mean_reward          | 3.11        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 160000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028181165 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.746      |\n",
      "|    explained_variance   | 0.382       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.3         |\n",
      "|    n_updates            | 1990        |\n",
      "|    policy_gradient_loss | -0.00573    |\n",
      "|    value_loss           | 4.53        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 102      |\n",
      "|    ep_rew_mean     | 1.7      |\n",
      "| time/              |          |\n",
      "|    fps             | 16       |\n",
      "|    iterations      | 200      |\n",
      "|    time_elapsed    | 9869     |\n",
      "|    total_timesteps | 160000   |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 1.39        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 201         |\n",
      "|    time_elapsed         | 9923        |\n",
      "|    total_timesteps      | 160800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023877809 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.887      |\n",
      "|    explained_variance   | 0.17        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.43        |\n",
      "|    n_updates            | 2000        |\n",
      "|    policy_gradient_loss | 0.00681     |\n",
      "|    value_loss           | 5.4         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 1.58        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 202         |\n",
      "|    time_elapsed         | 9976        |\n",
      "|    total_timesteps      | 161600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014316533 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.781      |\n",
      "|    explained_variance   | -0.0795     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.926       |\n",
      "|    n_updates            | 2010        |\n",
      "|    policy_gradient_loss | -0.00752    |\n",
      "|    value_loss           | 4.87        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 1.23        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 203         |\n",
      "|    time_elapsed         | 10033       |\n",
      "|    total_timesteps      | 162400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014902836 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.806      |\n",
      "|    explained_variance   | -0.152      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.524       |\n",
      "|    n_updates            | 2020        |\n",
      "|    policy_gradient_loss | -0.00286    |\n",
      "|    value_loss           | 3.32        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 102        |\n",
      "|    ep_rew_mean          | 1.22       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 16         |\n",
      "|    iterations           | 204        |\n",
      "|    time_elapsed         | 10089      |\n",
      "|    total_timesteps      | 163200     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03249106 |\n",
      "|    clip_fraction        | 0.23       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.887     |\n",
      "|    explained_variance   | 0.198      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.74       |\n",
      "|    n_updates            | 2030       |\n",
      "|    policy_gradient_loss | -0.0095    |\n",
      "|    value_loss           | 4.11       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 102        |\n",
      "|    ep_rew_mean          | 1.24       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 16         |\n",
      "|    iterations           | 205        |\n",
      "|    time_elapsed         | 10130      |\n",
      "|    total_timesteps      | 164000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01209814 |\n",
      "|    clip_fraction        | 0.16       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.846     |\n",
      "|    explained_variance   | -0.0917    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.732      |\n",
      "|    n_updates            | 2040       |\n",
      "|    policy_gradient_loss | -0.00612   |\n",
      "|    value_loss           | 3.62       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 1.27        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 206         |\n",
      "|    time_elapsed         | 10190       |\n",
      "|    total_timesteps      | 164800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021863356 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.848      |\n",
      "|    explained_variance   | 0.365       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.33        |\n",
      "|    n_updates            | 2050        |\n",
      "|    policy_gradient_loss | -0.00697    |\n",
      "|    value_loss           | 3.4         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=165000, episode_reward=2.84 +/- 15.03\n",
      "Episode length: 102.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 102         |\n",
      "|    mean_reward          | 2.84        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 165000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013677533 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.861      |\n",
      "|    explained_variance   | 0.472       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.59        |\n",
      "|    n_updates            | 2060        |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    value_loss           | 5.42        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 102      |\n",
      "|    ep_rew_mean     | 1.66     |\n",
      "| time/              |          |\n",
      "|    fps             | 16       |\n",
      "|    iterations      | 207      |\n",
      "|    time_elapsed    | 10263    |\n",
      "|    total_timesteps | 165600   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 102        |\n",
      "|    ep_rew_mean          | 0.877      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 16         |\n",
      "|    iterations           | 208        |\n",
      "|    time_elapsed         | 10329      |\n",
      "|    total_timesteps      | 166400     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03051185 |\n",
      "|    clip_fraction        | 0.216      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.845     |\n",
      "|    explained_variance   | 0.295      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.735      |\n",
      "|    n_updates            | 2070       |\n",
      "|    policy_gradient_loss | -0.0156    |\n",
      "|    value_loss           | 4.04       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 102        |\n",
      "|    ep_rew_mean          | 1.6        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 16         |\n",
      "|    iterations           | 209        |\n",
      "|    time_elapsed         | 10383      |\n",
      "|    total_timesteps      | 167200     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01402339 |\n",
      "|    clip_fraction        | 0.143      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.833     |\n",
      "|    explained_variance   | 0.35       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.46       |\n",
      "|    n_updates            | 2080       |\n",
      "|    policy_gradient_loss | 0.00503    |\n",
      "|    value_loss           | 7.47       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 102        |\n",
      "|    ep_rew_mean          | 1.1        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 16         |\n",
      "|    iterations           | 210        |\n",
      "|    time_elapsed         | 10434      |\n",
      "|    total_timesteps      | 168000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02148908 |\n",
      "|    clip_fraction        | 0.114      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.746     |\n",
      "|    explained_variance   | 0.379      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.05       |\n",
      "|    n_updates            | 2090       |\n",
      "|    policy_gradient_loss | -0.00401   |\n",
      "|    value_loss           | 4.45       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 1.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 211         |\n",
      "|    time_elapsed         | 10482       |\n",
      "|    total_timesteps      | 168800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021506997 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.793      |\n",
      "|    explained_variance   | 0.319       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.15        |\n",
      "|    n_updates            | 2100        |\n",
      "|    policy_gradient_loss | 0.000953    |\n",
      "|    value_loss           | 3.99        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 1.36        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 212         |\n",
      "|    time_elapsed         | 10567       |\n",
      "|    total_timesteps      | 169600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016039914 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.827      |\n",
      "|    explained_variance   | 0.221       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.45        |\n",
      "|    n_updates            | 2110        |\n",
      "|    policy_gradient_loss | -0.00336    |\n",
      "|    value_loss           | 5.97        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=170000, episode_reward=7.03 +/- 8.01\n",
      "Episode length: 102.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 102         |\n",
      "|    mean_reward          | 7.03        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 170000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034069054 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.805      |\n",
      "|    explained_variance   | 0.0396      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.21        |\n",
      "|    n_updates            | 2120        |\n",
      "|    policy_gradient_loss | -0.00674    |\n",
      "|    value_loss           | 5.94        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 102      |\n",
      "|    ep_rew_mean     | 1.75     |\n",
      "| time/              |          |\n",
      "|    fps             | 15       |\n",
      "|    iterations      | 213      |\n",
      "|    time_elapsed    | 10695    |\n",
      "|    total_timesteps | 170400   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 102        |\n",
      "|    ep_rew_mean          | 2.3        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 15         |\n",
      "|    iterations           | 214        |\n",
      "|    time_elapsed         | 10807      |\n",
      "|    total_timesteps      | 171200     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02794272 |\n",
      "|    clip_fraction        | 0.245      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.774     |\n",
      "|    explained_variance   | 0.263      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.632      |\n",
      "|    n_updates            | 2130       |\n",
      "|    policy_gradient_loss | 0.0012     |\n",
      "|    value_loss           | 5.07       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 2.28        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 215         |\n",
      "|    time_elapsed         | 10915       |\n",
      "|    total_timesteps      | 172000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023594487 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.663      |\n",
      "|    explained_variance   | 0.331       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.73        |\n",
      "|    n_updates            | 2140        |\n",
      "|    policy_gradient_loss | -0.0026     |\n",
      "|    value_loss           | 3.52        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 2.29        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 216         |\n",
      "|    time_elapsed         | 10987       |\n",
      "|    total_timesteps      | 172800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013233874 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.701      |\n",
      "|    explained_variance   | 0.614       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.21        |\n",
      "|    n_updates            | 2150        |\n",
      "|    policy_gradient_loss | -0.00593    |\n",
      "|    value_loss           | 3.61        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 2.05        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 217         |\n",
      "|    time_elapsed         | 11036       |\n",
      "|    total_timesteps      | 173600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016957527 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.637      |\n",
      "|    explained_variance   | -0.0315     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.676       |\n",
      "|    n_updates            | 2160        |\n",
      "|    policy_gradient_loss | -0.00589    |\n",
      "|    value_loss           | 4.93        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 2.36        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 218         |\n",
      "|    time_elapsed         | 11084       |\n",
      "|    total_timesteps      | 174400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015396412 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.764      |\n",
      "|    explained_variance   | -0.296      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.79        |\n",
      "|    n_updates            | 2170        |\n",
      "|    policy_gradient_loss | -0.005      |\n",
      "|    value_loss           | 3.62        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=175000, episode_reward=3.42 +/- 3.46\n",
      "Episode length: 102.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 102          |\n",
      "|    mean_reward          | 3.42         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 175000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0143870935 |\n",
      "|    clip_fraction        | 0.116        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.519       |\n",
      "|    explained_variance   | 0.148        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.572        |\n",
      "|    n_updates            | 2180         |\n",
      "|    policy_gradient_loss | -0.00943     |\n",
      "|    value_loss           | 3.39         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 102      |\n",
      "|    ep_rew_mean     | 2.8      |\n",
      "| time/              |          |\n",
      "|    fps             | 15       |\n",
      "|    iterations      | 219      |\n",
      "|    time_elapsed    | 11143    |\n",
      "|    total_timesteps | 175200   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 2.98        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 220         |\n",
      "|    time_elapsed         | 11199       |\n",
      "|    total_timesteps      | 176000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014170994 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.653      |\n",
      "|    explained_variance   | 0.387       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.34        |\n",
      "|    n_updates            | 2190        |\n",
      "|    policy_gradient_loss | -0.00139    |\n",
      "|    value_loss           | 3.86        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 102        |\n",
      "|    ep_rew_mean          | 2.82       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 15         |\n",
      "|    iterations           | 221        |\n",
      "|    time_elapsed         | 11280      |\n",
      "|    total_timesteps      | 176800     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02220766 |\n",
      "|    clip_fraction        | 0.258      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.814     |\n",
      "|    explained_variance   | -0.164     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.25       |\n",
      "|    n_updates            | 2200       |\n",
      "|    policy_gradient_loss | -0.00215   |\n",
      "|    value_loss           | 3.48       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 2.62        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 222         |\n",
      "|    time_elapsed         | 11356       |\n",
      "|    total_timesteps      | 177600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024167985 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.732      |\n",
      "|    explained_variance   | 0.121       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.574       |\n",
      "|    n_updates            | 2210        |\n",
      "|    policy_gradient_loss | -0.0062     |\n",
      "|    value_loss           | 3.39        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 3           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 223         |\n",
      "|    time_elapsed         | 11422       |\n",
      "|    total_timesteps      | 178400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015499976 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.728      |\n",
      "|    explained_variance   | 0.287       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.604       |\n",
      "|    n_updates            | 2220        |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    value_loss           | 2.53        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 102        |\n",
      "|    ep_rew_mean          | 3.37       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 15         |\n",
      "|    iterations           | 224        |\n",
      "|    time_elapsed         | 11479      |\n",
      "|    total_timesteps      | 179200     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02378181 |\n",
      "|    clip_fraction        | 0.199      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.676     |\n",
      "|    explained_variance   | 0.131      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.534      |\n",
      "|    n_updates            | 2230       |\n",
      "|    policy_gradient_loss | -0.0028    |\n",
      "|    value_loss           | 3.92       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=180000, episode_reward=4.06 +/- 6.21\n",
      "Episode length: 102.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 102         |\n",
      "|    mean_reward          | 4.06        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 180000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018261423 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.682      |\n",
      "|    explained_variance   | 0.00937     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.11        |\n",
      "|    n_updates            | 2240        |\n",
      "|    policy_gradient_loss | -0.00874    |\n",
      "|    value_loss           | 3.67        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 102      |\n",
      "|    ep_rew_mean     | 2.6      |\n",
      "| time/              |          |\n",
      "|    fps             | 15       |\n",
      "|    iterations      | 225      |\n",
      "|    time_elapsed    | 11536    |\n",
      "|    total_timesteps | 180000   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 2.69        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 226         |\n",
      "|    time_elapsed         | 11603       |\n",
      "|    total_timesteps      | 180800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019704508 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.645      |\n",
      "|    explained_variance   | 0.298       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.2         |\n",
      "|    n_updates            | 2250        |\n",
      "|    policy_gradient_loss | -0.00263    |\n",
      "|    value_loss           | 4.47        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 2.96        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 227         |\n",
      "|    time_elapsed         | 11673       |\n",
      "|    total_timesteps      | 181600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035243228 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.729      |\n",
      "|    explained_variance   | -0.286      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.94        |\n",
      "|    n_updates            | 2260        |\n",
      "|    policy_gradient_loss | 0.000526    |\n",
      "|    value_loss           | 4.76        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 3.65        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 228         |\n",
      "|    time_elapsed         | 11731       |\n",
      "|    total_timesteps      | 182400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024802027 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.89       |\n",
      "|    explained_variance   | 0.115       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.757       |\n",
      "|    n_updates            | 2270        |\n",
      "|    policy_gradient_loss | -0.00487    |\n",
      "|    value_loss           | 5.08        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 102        |\n",
      "|    ep_rew_mean          | 3.81       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 15         |\n",
      "|    iterations           | 229        |\n",
      "|    time_elapsed         | 11774      |\n",
      "|    total_timesteps      | 183200     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04027981 |\n",
      "|    clip_fraction        | 0.143      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.649     |\n",
      "|    explained_variance   | 0.293      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.691      |\n",
      "|    n_updates            | 2280       |\n",
      "|    policy_gradient_loss | -0.000479  |\n",
      "|    value_loss           | 4.79       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 102        |\n",
      "|    ep_rew_mean          | 4.45       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 15         |\n",
      "|    iterations           | 230        |\n",
      "|    time_elapsed         | 11816      |\n",
      "|    total_timesteps      | 184000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04337953 |\n",
      "|    clip_fraction        | 0.203      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.713     |\n",
      "|    explained_variance   | 0.333      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.951      |\n",
      "|    n_updates            | 2290       |\n",
      "|    policy_gradient_loss | 0.00536    |\n",
      "|    value_loss           | 2.76       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 4.62        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 231         |\n",
      "|    time_elapsed         | 11862       |\n",
      "|    total_timesteps      | 184800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019462865 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.697      |\n",
      "|    explained_variance   | 0.109       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.31        |\n",
      "|    n_updates            | 2300        |\n",
      "|    policy_gradient_loss | -6.11e-05   |\n",
      "|    value_loss           | 4.62        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=185000, episode_reward=6.48 +/- 11.24\n",
      "Episode length: 102.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 102         |\n",
      "|    mean_reward          | 6.48        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 185000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020782597 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.626      |\n",
      "|    explained_variance   | 0.124       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.37        |\n",
      "|    n_updates            | 2310        |\n",
      "|    policy_gradient_loss | -0.00874    |\n",
      "|    value_loss           | 5.09        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 102      |\n",
      "|    ep_rew_mean     | 4.14     |\n",
      "| time/              |          |\n",
      "|    fps             | 15       |\n",
      "|    iterations      | 232      |\n",
      "|    time_elapsed    | 11925    |\n",
      "|    total_timesteps | 185600   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 4.52        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 233         |\n",
      "|    time_elapsed         | 11991       |\n",
      "|    total_timesteps      | 186400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024084006 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.583      |\n",
      "|    explained_variance   | 0.241       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.59        |\n",
      "|    n_updates            | 2320        |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    value_loss           | 4.26        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 4.83        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 234         |\n",
      "|    time_elapsed         | 12046       |\n",
      "|    total_timesteps      | 187200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026009474 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.673      |\n",
      "|    explained_variance   | 0.281       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.09        |\n",
      "|    n_updates            | 2330        |\n",
      "|    policy_gradient_loss | -0.000101   |\n",
      "|    value_loss           | 4.78        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 5.32        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 235         |\n",
      "|    time_elapsed         | 12099       |\n",
      "|    total_timesteps      | 188000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028910149 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.646      |\n",
      "|    explained_variance   | 0.0945      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.16        |\n",
      "|    n_updates            | 2340        |\n",
      "|    policy_gradient_loss | -0.00431    |\n",
      "|    value_loss           | 5.04        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 4.96        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 236         |\n",
      "|    time_elapsed         | 12149       |\n",
      "|    total_timesteps      | 188800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021459851 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.498      |\n",
      "|    explained_variance   | 0.432       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.56        |\n",
      "|    n_updates            | 2350        |\n",
      "|    policy_gradient_loss | 0.00437     |\n",
      "|    value_loss           | 3.92        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 5.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 237         |\n",
      "|    time_elapsed         | 12193       |\n",
      "|    total_timesteps      | 189600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022858977 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.575      |\n",
      "|    explained_variance   | 0.263       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.09        |\n",
      "|    n_updates            | 2360        |\n",
      "|    policy_gradient_loss | -0.00693    |\n",
      "|    value_loss           | 4.42        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=190000, episode_reward=6.25 +/- 9.67\n",
      "Episode length: 102.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 102         |\n",
      "|    mean_reward          | 6.25        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 190000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034742463 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.55       |\n",
      "|    explained_variance   | 0.399       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.696       |\n",
      "|    n_updates            | 2370        |\n",
      "|    policy_gradient_loss | 0.013       |\n",
      "|    value_loss           | 5.14        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 102      |\n",
      "|    ep_rew_mean     | 5.47     |\n",
      "| time/              |          |\n",
      "|    fps             | 15       |\n",
      "|    iterations      | 238      |\n",
      "|    time_elapsed    | 12252    |\n",
      "|    total_timesteps | 190400   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 102       |\n",
      "|    ep_rew_mean          | 6.01      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 15        |\n",
      "|    iterations           | 239       |\n",
      "|    time_elapsed         | 12331     |\n",
      "|    total_timesteps      | 191200    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0615447 |\n",
      "|    clip_fraction        | 0.229     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.621    |\n",
      "|    explained_variance   | 0.312     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.83      |\n",
      "|    n_updates            | 2380      |\n",
      "|    policy_gradient_loss | 0.00266   |\n",
      "|    value_loss           | 5.08      |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 102          |\n",
      "|    ep_rew_mean          | 5.64         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 15           |\n",
      "|    iterations           | 240          |\n",
      "|    time_elapsed         | 12402        |\n",
      "|    total_timesteps      | 192000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0122150965 |\n",
      "|    clip_fraction        | 0.121        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.614       |\n",
      "|    explained_variance   | 0.239        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.973        |\n",
      "|    n_updates            | 2390         |\n",
      "|    policy_gradient_loss | -0.0057      |\n",
      "|    value_loss           | 5.37         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 5.31        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 241         |\n",
      "|    time_elapsed         | 12468       |\n",
      "|    total_timesteps      | 192800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016155977 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.614      |\n",
      "|    explained_variance   | 0.249       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.06        |\n",
      "|    n_updates            | 2400        |\n",
      "|    policy_gradient_loss | -0.00358    |\n",
      "|    value_loss           | 4.36        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 102        |\n",
      "|    ep_rew_mean          | 5.75       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 15         |\n",
      "|    iterations           | 242        |\n",
      "|    time_elapsed         | 12528      |\n",
      "|    total_timesteps      | 193600     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03325835 |\n",
      "|    clip_fraction        | 0.239      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.65      |\n",
      "|    explained_variance   | 0.311      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.76       |\n",
      "|    n_updates            | 2410       |\n",
      "|    policy_gradient_loss | -0.00821   |\n",
      "|    value_loss           | 3.16       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 5.92        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 243         |\n",
      "|    time_elapsed         | 12610       |\n",
      "|    total_timesteps      | 194400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025490249 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.689      |\n",
      "|    explained_variance   | 0.452       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.891       |\n",
      "|    n_updates            | 2420        |\n",
      "|    policy_gradient_loss | -0.00511    |\n",
      "|    value_loss           | 4.49        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=195000, episode_reward=-1.31 +/- 13.74\n",
      "Episode length: 102.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 102         |\n",
      "|    mean_reward          | -1.31       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 195000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020239484 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.598      |\n",
      "|    explained_variance   | 0.423       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.494       |\n",
      "|    n_updates            | 2430        |\n",
      "|    policy_gradient_loss | -0.00738    |\n",
      "|    value_loss           | 3.61        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 102      |\n",
      "|    ep_rew_mean     | 5.42     |\n",
      "| time/              |          |\n",
      "|    fps             | 15       |\n",
      "|    iterations      | 244      |\n",
      "|    time_elapsed    | 12690    |\n",
      "|    total_timesteps | 195200   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 5.54        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 245         |\n",
      "|    time_elapsed         | 12771       |\n",
      "|    total_timesteps      | 196000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023354799 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.681      |\n",
      "|    explained_variance   | -0.0111     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.7         |\n",
      "|    n_updates            | 2440        |\n",
      "|    policy_gradient_loss | -0.00686    |\n",
      "|    value_loss           | 4.43        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 5.7         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 246         |\n",
      "|    time_elapsed         | 12877       |\n",
      "|    total_timesteps      | 196800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031053644 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.64       |\n",
      "|    explained_variance   | 0.143       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.982       |\n",
      "|    n_updates            | 2450        |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    value_loss           | 2.08        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 5.59        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 247         |\n",
      "|    time_elapsed         | 12955       |\n",
      "|    total_timesteps      | 197600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020979183 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.628      |\n",
      "|    explained_variance   | 0.343       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.969       |\n",
      "|    n_updates            | 2460        |\n",
      "|    policy_gradient_loss | -0.00117    |\n",
      "|    value_loss           | 2.97        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 5.25        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 248         |\n",
      "|    time_elapsed         | 13017       |\n",
      "|    total_timesteps      | 198400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026051521 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.621      |\n",
      "|    explained_variance   | 0.228       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.779       |\n",
      "|    n_updates            | 2470        |\n",
      "|    policy_gradient_loss | -0.00515    |\n",
      "|    value_loss           | 2.24        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 5.13        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 249         |\n",
      "|    time_elapsed         | 13103       |\n",
      "|    total_timesteps      | 199200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013951119 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.7        |\n",
      "|    explained_variance   | 0.043       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.778       |\n",
      "|    n_updates            | 2480        |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    value_loss           | 3.25        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=200000, episode_reward=1.36 +/- 12.38\n",
      "Episode length: 102.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 102         |\n",
      "|    mean_reward          | 1.36        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 200000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028266672 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.679      |\n",
      "|    explained_variance   | 0.222       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.5         |\n",
      "|    n_updates            | 2490        |\n",
      "|    policy_gradient_loss | -0.0071     |\n",
      "|    value_loss           | 3.92        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 102      |\n",
      "|    ep_rew_mean     | 5.01     |\n",
      "| time/              |          |\n",
      "|    fps             | 15       |\n",
      "|    iterations      | 250      |\n",
      "|    time_elapsed    | 13195    |\n",
      "|    total_timesteps | 200000   |\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from sb3_contrib import RecurrentPPO\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from stable_baselines3.common.policies import ActorCriticPolicy\n",
    "from stable_baselines3.common.callbacks import EvalCallback, CheckpointCallback\n",
    "from sb3_contrib.common.recurrent.policies import RecurrentActorCriticPolicy\n",
    "\n",
    "# Causal Mask Function ============================\n",
    "def generate_causal_mask(seq_len):\n",
    "    return torch.triu(torch.ones((seq_len, seq_len), dtype=torch.bool), diagonal=1)\n",
    "\n",
    "# Transformer Feature Extractor ===================\n",
    "class TransformerFeatureExtractor(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space, d_model=64, n_heads=4, n_layers=2, max_len=MAX_LENGTH):\n",
    "        super().__init__(observation_space, features_dim=d_model)\n",
    "        self.d_model = d_model\n",
    "        input_dim = observation_space.shape[-1]\n",
    "\n",
    "        self.input_proj = nn.Linear(input_dim, d_model)\n",
    "        self.positional_encoding = nn.Parameter(torch.randn(max_len, d_model))\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=n_heads, batch_first=True)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n",
    "\n",
    "    def forward_v1(self, obs):\n",
    "        # obs shape: (batch, seq_len, input_dim)\n",
    "        x = self.input_proj(obs)\n",
    "        seq_len = x.size(1)\n",
    "        x = x + self.positional_encoding[:seq_len]\n",
    "        causal_mask = generate_causal_mask(seq_len).to(x.device)\n",
    "        x = self.transformer(x, mask=causal_mask)\n",
    "        return x[:, -1]  # return the last token output\n",
    "    \n",
    "    def forward(self, obs):\n",
    "        # obs shape: (batch, seq_len, input_dim)\n",
    "        #print(\">>> [Transformer] Input shape:\", obs.shape)\n",
    "\n",
    "        x = self.input_proj(obs)\n",
    "        seq_len = x.size(1)\n",
    "        x = x + self.positional_encoding[:seq_len]\n",
    "\n",
    "        causal_mask = generate_causal_mask(seq_len).to(x.device)\n",
    "        x = self.transformer(x, mask=causal_mask)\n",
    "\n",
    "        pooled_output = x[:, -1]\n",
    "        #print(\">>> [Transformer] Pooled output mean/std:\", pooled_output.mean().item(), pooled_output.std().item())\n",
    "\n",
    "        return pooled_output\n",
    "\n",
    "# Transformer Policy ===================================\n",
    "class TransformerPolicy(RecurrentActorCriticPolicy):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs,\n",
    "                         features_extractor_class=TransformerFeatureExtractor,\n",
    "                         features_extractor_kwargs=dict(\n",
    "                             d_model=64, n_heads=4, n_layers=2, max_len=32\n",
    "                         ))\n",
    "        #self._build(self.lr_schedule)\n",
    "\n",
    "# Regime Augmentation Wrapper ===========================\n",
    "class RegimeAugmentingWrapper(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        self.regime_dim = 3  # One-hot: bull, bear, sideways\n",
    "        obs_shape = self.observation_space.shape\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            low=-np.inf, high=np.inf,\n",
    "            shape=(obs_shape[0], obs_shape[1] + self.regime_dim),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "\n",
    "    def observation(self, obs):\n",
    "        regime = self.env.get_current_regime()  # 0,1,2 -> bull,bear,sideways\n",
    "        one_hot = np.zeros(self.regime_dim)\n",
    "        one_hot[regime] = 1.0\n",
    "        one_hot = np.repeat(one_hot[None, :], obs.shape[0], axis=0)\n",
    "        return np.concatenate([obs, one_hot], axis=-1)\n",
    "\n",
    "class PerEpisodeRewardNormalizer(gym.Wrapper):\n",
    "    def reset(self, **kwargs):\n",
    "        self.episode_rewards = []\n",
    "        return self.env.reset(**kwargs)\n",
    "\n",
    "    def step(self, action):\n",
    "        obs, reward, done, truncated, info = self.env.step(action)\n",
    "        self.episode_rewards.append(reward)\n",
    "        mean = np.mean(self.episode_rewards)\n",
    "        std = np.std(self.episode_rewards) + 1e-8\n",
    "        norm_reward = (reward - mean) / std\n",
    "        return obs, norm_reward, done, truncated, info\n",
    "# Training =============================================================\n",
    "train_df = ohlcv_df[(ohlcv_df['date']>=\"2023-01-01\") & (ohlcv_df['date']<\"2023-07-01\")]\n",
    "test_df = ohlcv_df[(ohlcv_df['date']>=\"2023-07-01\") & (ohlcv_df['date']<\"2024-01-01\")]\n",
    "train_df = train_df[train_df['symbol'].isin(TOP2_STOCK_BY_SECTOR)]\n",
    "test_df = test_df[test_df['symbol'].isin(TOP2_STOCK_BY_SECTOR)]\n",
    "\n",
    "train_env =ENV_CLASS(train_df, episode_length=EPISODE_LENGTH, feature_cols=FEATURE_COLS)\n",
    "test_env =ENV_CLASS(test_df, episode_length=EPISODE_LENGTH, feature_cols=FEATURE_COLS)\n",
    "# Train on few episodes to prove a point only\n",
    "train_seq = train_env.generate_episode_sequences(TOTAL_TIMESTEPS)\n",
    "_test_seq = test_env.generate_episode_sequences(int(TOTAL_TIMESTEPS))\n",
    "episodes = _test_seq\n",
    "unique_episodes = {}\n",
    "for ticker, start in episodes:\n",
    "    if ticker not in unique_episodes:\n",
    "        unique_episodes[ticker] = start\n",
    "# Convert back to a list of tuples\n",
    "test_seq = [(ticker, start) for ticker, start in unique_episodes.items()]\n",
    "\n",
    "print(f\"Training on {len(train_seq)} different episodes accross the top 2 stocks for each sector\")\n",
    "print(f\"Testing on {len(test_seq)} different episodes accross the top 2 stocks for each sector\")\n",
    "def train_agent():\n",
    "    \n",
    "    \n",
    "    \n",
    "    train_env =ENV_CLASS(train_df, episode_length=EPISODE_LENGTH, feature_cols=FEATURE_COLS)\n",
    "    eval_env =ENV_CLASS(test_df, episode_length=EPISODE_LENGTH, feature_cols=FEATURE_COLS)\n",
    "    train_env.set_episode_sequence(train_seq)\n",
    "    eval_env.set_episode_sequence(test_seq)\n",
    "    \n",
    "    train_env = PerEpisodeRewardNormalizer(RegimeAugmentingWrapper(train_env))\n",
    "    eval_env = PerEpisodeRewardNormalizer(RegimeAugmentingWrapper(eval_env))\n",
    "    checkpoint_callback = CheckpointCallback(\n",
    "        save_freq=SAVE_FREQ, save_path=checkpoint_path, name_prefix=checkpoint_preffix\n",
    "    )\n",
    "\n",
    "    eval_callback = EvalCallback(\n",
    "        eval_env, best_model_save_path=checkpoint_best_model,\n",
    "        log_path=log_path, eval_freq=EVAL_FREQ, deterministic=True\n",
    "    )\n",
    "\n",
    "    model = RecurrentPPO(\n",
    "        policy=TransformerPolicy,\n",
    "        env=train_env,\n",
    "        verbose=1,\n",
    "        #tensorboard_log=\"./tensorboard_logs\",\n",
    "        n_steps=N_STEPS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        learning_rate=3e-4,\n",
    "        gamma=0.99,\n",
    "        gae_lambda=0.95,\n",
    "        ent_coef=0.005,\n",
    "        vf_coef=0.5,\n",
    "        max_grad_norm=0.5,\n",
    "        normalize_advantage=True,\n",
    "        policy_kwargs=dict(share_features_extractor=True)\n",
    "    )\n",
    "\n",
    "    model.learn(total_timesteps=TOTAL_TIMESTEPS, callback=[checkpoint_callback, eval_callback])\n",
    "    model.save(save_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_agent()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38331a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = Notify(experiment_tracker.project)\n",
    "n.info('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abba2ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarketVersusWalletHistoryTracker:\n",
    "    def __init__(self, initial_wallet=1.0):\n",
    "        self.wallet_value = initial_wallet\n",
    "        self.prev_wallet_value = initial_wallet\n",
    "        self.wallet_locked = False\n",
    "        self.buy_price = None\n",
    "        self.market_entry_price = None\n",
    "        self.last_price = None\n",
    "        self.has_opened_position = False  # NEW: ensure proper update after first buy\n",
    "\n",
    "        self.wallet_history = []\n",
    "        self.market_history = []\n",
    "        self.price_history = []\n",
    "        self.action_history = []\n",
    "\n",
    "    def reset(self, initial_price):\n",
    "        self.__init__(initial_wallet=1.0)\n",
    "        self.market_entry_price = initial_price\n",
    "        self.last_price = initial_price\n",
    "        self.wallet_history.append(self.wallet_value)\n",
    "        self.market_history.append(1.0)\n",
    "        self.price_history.append(initial_price)\n",
    "        self.action_history.append(0)\n",
    "\n",
    "    def step(self, action, current_price):\n",
    "        self.price_history.append(current_price)\n",
    "        agent_action = 0\n",
    "\n",
    "        # === 1. Update market benchmark ===\n",
    "        market_perf = current_price / self.market_entry_price\n",
    "        self.market_history.append(market_perf)\n",
    "\n",
    "        # === 2. Update wallet value ===\n",
    "        if self.wallet_locked and self.has_opened_position:\n",
    "            self.wallet_value *= current_price / self.last_price\n",
    "\n",
    "        self.wallet_history.append(self.wallet_value)\n",
    "        self.prev_wallet_value = self.wallet_value\n",
    "        self.last_price = current_price  # must be set after wallet update!\n",
    "\n",
    "        # === 3. Process Action ===\n",
    "        if action == 1 and not self.wallet_locked:\n",
    "            self.buy_price = current_price\n",
    "            self.wallet_locked = True\n",
    "            self.has_opened_position = True\n",
    "            agent_action = 1\n",
    "\n",
    "        elif action == 2 and self.wallet_locked:\n",
    "            self.wallet_locked = False\n",
    "            self.buy_price = None\n",
    "            self.has_opened_position = False\n",
    "            agent_action = 2\n",
    "\n",
    "        self.action_history.append(agent_action)\n",
    "\n",
    "    def export(self):\n",
    "        return {\n",
    "            \"wallet_history\": self.wallet_history,\n",
    "            \"market_history\": self.market_history,\n",
    "            \"market_price_history\": self.price_history,\n",
    "            \"performed_action_history\": self.action_history\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88c1c622",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Agent: 100%|██████████| 22/22 [00:18<00:00,  1.18it/s]\n",
      "Evaluating Agent: 100%|██████████| 22/22 [00:13<00:00,  1.58it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABjUAAAPeCAYAAABEOJjvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAADRrklEQVR4nOzdd5xdZZ0/8M/N1IQkdFLoTQTpUqRIEQEDokYUBRGQuhQREEEWlQArJUiRDi5VBAQhLCwGyFJ/VCmCBURRmksiQoAEyEymnN8f2RkzJIFMSe6c5P1+vXgx99xTvve5z72TOZ9znqdSFEURAAAAAACAfm5AtQsAAAAAAACYG0INAAAAAACgFIQaAAAAAABAKQg1AAAAAACAUhBqAAAAAAAApSDUAAAAAAAASkGoAQAAAAAAlIJQAwAAAAAAKAWhBgAAAAAAUApCDQBgoXXuueemUqlk7bXXrnYps3XhhRfmyiuvnOv1V1pppVQqlc7/Bg8enE033TRXX311n9d29913Z6ONNsoiiyySSqWSW265pc+PsbCZMmVKfvzjH2ejjTbK0KFD09DQkJVWWin77rtvnnrqqWqXN8/dd999qVQque+++6pdyhy9/fbbWWqppXL99dd3LhszZkyXz11dXV1WWGGFHHDAAZk0aVLVat1nn32y0korVe3481t/fR/6o1NOOaVb39kzt2ulUsmiiy6abbbZJrfffnuX9brzO6ilpSUXXXRRNttssyy66KIZOHBg1lxzzXz/+9/Pm2++Ocv6W221VY444ojuvlQAYAEl1AAAFlqXX355kuSPf/xjHnvssSpXM6vuhhpJssUWW+SRRx7JI488kiuvvDKVSiV77713Lrrooj6rqyiK7Lbbbqmrq8utt96aRx55JFtvvXWf7X9h9Ne//jUbbLBBTjvttGy77ba57rrrctddd+XEE0/MP/7xj3zyk5/MO++8U+0y56kNN9wwjzzySDbccMNqlzJHJ554YkaOHJmvfe1rszx3xx135JFHHsn48ePz9a9/PZdffnm22267tLS0VKHShZf34aN1N9RIkq985St55JFH8tBDD+WCCy7IpEmTsssuu8wSbMzN76D3338/22+/fb797W9ngw02yHXXXZdf//rX+eY3v5lLL700G2ywQZ5//vku+z355JNz4YUXzrIcAFg41Va7AACAanjiiSfyzDPPZOedd87tt9+eyy67LJtuumm1y+q1xRZbLJ/61Kc6H3/2s5/NiiuumLPOOisHH3xwr/bd0tKSSqWSf/zjH5k8eXJGjx6d7bbbrrclJ0mmTZuWxsbGVCqVPtlfmbS1tWX06NF544038sgjj3S5c2jrrbfO3nvvnfHjx6eurq6KVc47Hf1q6NChXfpufzN58uRccsklOfvss2fbTz/5yU9mqaWWSjLjc/fGG2/kiiuuyIMPPphtt912fpe70Crb+zBt2rQMHDhwluUdn4va2v7xJ/uwYcM6P5+bb755Nttss6y22mo555xzsvPOO3euNze/g4488sjcf//9uf7667sEhNtuu22+8pWvZJNNNsmuu+6aZ555JjU1NUlmfBeuscYaOfPMM3PppZfOj5cMAPRj7tQAABZKl112WZLktNNOy+abb57rr78+77///izr/f3vf89XvvKVDBkyJIsttli+8Y1v5PHHH0+lUpnlLoonnngiX/jCF7LEEkuksbExG2ywQW644YYu63RcuXrvvffm4IMPzlJLLZUll1wyX/7yl/Paa691rrfSSivlj3/8Y+6///7OoTx6MpTMYostljXWWCMvv/xy57K//OUv2WOPPbLMMsukoaEha665Zi644IIu23UMBfTzn/883/3ud7PsssumoaEhe+65Z5ZbbrkkybHHHjtLXQ8++GC22267DBkyJIMGDcrmm28+y5W8HW1w1113Zd99983SSy+dQYMGpbm5Odtss03WXnvtPPLII9l8880zcODArLTSSrniiiuSJLfffns23HDDDBo0KOuss07uuOOOLvt+4YUX8q1vfSurr756Bg0alGWXXTa77LJLfv/738/29V133XU5/vjjM3LkyAwdOjSf/exnZ3sl8B133JHtttsuiy66aAYNGpQ111wzp556apd15ub9n51bbrklv//973PcccfNcSi0UaNGZdCgQT1q53vuuScHHHBAllxyyQwdOjR77bVX3nvvvUyaNCm77bZbFltssYwYMSJHH310l6vZX3rppVQqlYwdOzY//vGPs8IKK6SxsTEbbbRR7r777l61+wf71QsvvDDb4af+9re/5etf/3pGjhyZhoaGDBs2LNttt12efvrpznXa29szduzYfPzjH09DQ0OWWWaZ7LXXXvn73//e5dgdfevxxx/Ppz/96QwaNCirrLJKTjvttLS3t3/k+3TllVemtbV1tndpzM5GG22UJPnHP/7Rueyf//xnDjnkkKy11loZPHhwlllmmXzmM5/J//t//6/Lth1t/5Of/CRnnXVWVl555QwePDibbbZZHn300dnWtsYaa3R+nuc05NzkyZNzyCGHZNlll019fX1WWWWVHH/88Wlubu6yXqVSyWGHHZYrrrgia6yxRgYOHJiNNtoojz76aIqiyBlnnNFZ02c+85m88MILH9oWt9xySyqVyiz9JkkuuuiiVCqV/O53v0syd+95d8zufUiS//mf/8l2222XoUOHZtCgQdliiy1mW9+f/vSn7L777hk2bFgaGhqywgorZK+99upss45hrz6o4/P30ksvdS5baaWV8vnPfz4333xzNthggzQ2NubEE0/80M/F3NbaUccf//jH7L777ll00UUzbNiw7Lvvvl3u8qpUKnnvvfdy1VVXdf5u2WabbbrdrquuumqWXnrpLr9bZueDv4MmTZqUyy+/PDvuuONsP0sf+9jHcuyxx+aPf/zjLHeTfPOb38y1116bqVOndrteAGDBItQAABY606ZNy3XXXZeNN944a6+9dvbdd99MnTo1N954Y5f13nvvvWy77ba59957c/rpp+eGG27IsGHDZnsi5t57780WW2yRt99+OxdffHH+67/+K+uvv36+9rWvzXYIqf333z91dXW59tprM3bs2Nx3333Zc889O58fN25cVllllWywwQadQ3mMGzeu26+1paUlL7/8cpZeeukkybPPPpuNN944f/jDH3LmmWfmv//7v7Pzzjvn8MMPz4knnjjL9scdd1xeeeWVXHzxxbntttsyduzY3HzzzUmSb3/7213quv/++/OZz3wm77zzTi677LJcd911GTJkSHbZZZf88pe/nGXf++67b+rq6vLzn/88v/rVrzrvRJg0aVK+9a1vZf/9989//dd/ZZ111sm+++6bk046Kccdd1yOOeaY3HTTTRk8eHC+9KUvdQmDXnvttSy55JI57bTTcscdd+SCCy5IbW1tNt1009mGFf/+7/+el19+Of/5n/+ZSy+9NH/5y1+yyy67pK2trXOdyy67LDvttFPa29s72+Hwww/vctK8u+//zO66664kyZe+9KUPXa9Dd9t5//33z6KLLprrr78+P/jBD3LttdfmgAMOyM4775z11lsvv/rVr7L33nvnzDPPzHnnnTfL9ueff37uuOOOnHPOObnmmmsyYMCAjBo1Ko888kjnOt1t9w/2q2WWWWa2r3WnnXbKk08+mbFjx2bChAm56KKLssEGG+Ttt9/uXOfggw/Osccem+233z633nprTj755Nxxxx3ZfPPN88Ybb3TZ36RJk/KNb3wje+65Z2699daMGjUqxx13XK655pqPbPfbb789G2ywQRZbbLGPXDdJXnzxxSQzTtJ2mDx5cpLkhBNOyO23354rrrgiq6yySrbZZpvZziVywQUXZMKECTnnnHPyi1/8Iu+991522mmnLiepr7zyynzrW9/KmmuumZtuuik/+MEPcvLJJ+eee+7psq+mpqZsu+22ufrqq3PUUUfl9ttvz5577pmxY8fmy1/+8izH/u///u/853/+Z0477bRcd911mTp1anbeeed897vfzUMPPZTzzz8/l156aZ599tnsuuuuKYpijm3x+c9/Pssss0xnODmzK6+8MhtuuGHWXXfdJHP3nnfH7N6Ha665JjvssEOGDh2aq666KjfccEOWWGKJ7Ljjjl3CgmeeeSYbb7xxHn300Zx00kkZP358Tj311DQ3N2f69Ok9quepp57K9773vRx++OG54447suuuu3Y+N7vPxdzW2mHXXXfNxz72sdx00035/ve/n2uvvTZHHnlk5/OPPPJIBg4cmJ122qnzd8uFF17Y7dfx1ltv5c033+z83TInH/wddO+996a1tfVDv+86npswYUKX5dtss03ee++9fj3vDgAwnxQAAAuZq6++ukhSXHzxxUVRFMXUqVOLwYMHF5/+9Ke7rHfBBRcUSYrx48d3WX7QQQcVSYorrriic9nHP/7xYoMNNihaWlq6rPv5z3++GDFiRNHW1lYURVFcccUVRZLikEMO6bLe2LFjiyTFxIkTO5d94hOfKLbeeuu5fl0rrrhisdNOOxUtLS1FS0tL8eKLLxZ77713kaT43ve+VxRFUey4447FcsstV7zzzjtdtj3ssMOKxsbGYvLkyUVRFMW9995bJCm22mqrWY7z4osvFkmKM844o8vyT33qU8UyyyxTTJ06tXNZa2trsfbaaxfLLbdc0d7e3qUN9tprr1n2vfXWWxdJiieeeKJz2ZtvvlnU1NQUAwcOLP73f/+3c/nTTz9dJCnOPffcObZJa2trMX369GL11VcvjjzyyM7lHa9vp5126rL+DTfcUCQpHnnkkaIoZvSNoUOHFltuuWVn/bMzt+//7Hzuc58rkhRNTU1zXGdm3W3nb3/72122/9KXvlQkKc4666wuy9dff/1iww037Hzc8T6PHDmymDZtWufyKVOmFEsssUTx2c9+do41flS7z65fdTx37733FkVRFG+88UaRpDjnnHPmeJznnntutp+nxx57rEhS/Pu//3vnso6+9dhjj3VZd6211ip23HHHOR6jw6BBg4p/+7d/m2X5CSecUCQpJk2aVLS0tBRvvfVWccMNNxSLLLJIsfvuu3/oPltbW4uWlpZiu+22K0aPHt25vKPt11lnnaK1tbVz+W9+85siSXHdddcVRVEUbW1txciRI4sNN9ywS/986aWXirq6umLFFVfsXHbxxRcXSYobbrihSw2nn356kaS46667OpclKYYPH168++67nctuueWWIkmx/vrrdznWOeecUyQpfve7333oaz3qqKOKgQMHFm+//XbnsmeffbZIUpx33nlFUczdez4nc/s+vPfee8USSyxR7LLLLl22b2trK9Zbb71ik0026Vz2mc98plhsscWK119//SOP+0Edn78XX3yxc9mKK65Y1NTUFM8//3yXdef0uehOrR11jB07tsu6hxxySNHY2NjlPVtkkUWKvffee46v6YM6PmMtLS3F9OnTi+eee64YNWpUkaS44IILury+j/oddNpppxVJijvuuGOOx5s2bVqRpBg1alSX5dOnTy8qlUpx7LHHznXtAMCCyZ0aAMBC57LLLsvAgQPz9a9/PUkyePDgfPWrX83/+3//L3/5y18617v//vszZMiQfO5zn+uy/e67797l8QsvvJA//elP+cY3vpEkaW1t7fxvp512ysSJE2e5Wv0LX/hCl8cdVyl/1FAeH+XXv/516urqUldXl5VXXjk33HBDvv3tb+c//uM/0tTUlLvvvjujR4/OoEGDZqmzqalplqFtZr6K+MO89957eeyxx/KVr3wlgwcP7lxeU1OTb37zm/n73/8+SxvMad8jRozIJz/5yc7HSyyxRJZZZpmsv/76GTlyZOfyNddcM0nXNmttbc0pp5yStdZaK/X19amtrU19fX3+8pe/5LnnnpvlWB/1Pjz88MOZMmVKDjnkkDnO99GT97+netLOn//857s87mi3mcfB71g+u/735S9/OY2NjZ2PO+4KeeCBBzrvaOluu89Nv1piiSWy6qqr5owzzshZZ52V3/72t7MME3XvvfcmSfbZZ58uyzfZZJOsueaas1zJPnz48GyyySZdlq277rof+bl7++238/7778/xjpKOfdfV1WXxxRfPbrvtlk9+8pO56qqrZlnv4osvzoYbbpjGxsbU1tamrq4ud99992zbaeedd+6cU6Cj1uRf/fP555/Pa6+9lj322KNL/1xxxRWz+eabd9nXPffck0UWWSRf+cpXuizvaLsPttW2226bRRZZpPNxR78ZNWpUl2PN7nM4O/vuu2+mTZvW5W6iK664Ig0NDdljjz2SzN17/lE+6n14+OGHM3ny5Oy9995dPqvt7e353Oc+l8cffzzvvfde3n///dx///3ZbbfdPvJuhO5Yd911u9w1MrMPfi7mttaZze47rampKa+//nqv6r7wwgtTV1eX+vr6rLnmmnn44Ydz0kkn5ZBDDumy3of9DuquD37n1tXVZbHFFsv//u//9uq1AADlJ9QAABYqL7zwQh544IHsvPPOKYoib7/9dt5+++3OE32XX35557pvvvlmhg0bNss+PrisY6z2o48+uvNkTsd/HSd8PjgMzpJLLtnlcUNDQ5IZQ2P1xpZbbpnHH388TzzxRJ599tm8/fbbOffcc1NfX58333wzra2tOe+882apc6eddpptnSNGjJir47711lspimK263cEEW+++eZc7XuJJZaYZVl9ff0sy+vr65PMGFanw1FHHZUf/vCH+dKXvpTbbrstjz32WB5//PGst956s23bj3of/vnPfyZJ5zwis9OT939mK6ywQpJ/DZPzYXrSznNqt9ktn7ktOwwfPny2y6ZPn5533303SffbfW76VcccDDvuuGPGjh2bDTfcMEsvvXQOP/zwzjH1O17rnNrjg23xwfc7mfGef9TnruP5mcOdD/qf//mfPP7447nzzjuz66675oEHHsi3v/3tLut0TJa86aab5qabbsqjjz6axx9/PJ/73Od61D87Xt+c3qOZvfnmmxk+fPgsJ4qXWWaZ1NbW9qrfJJlt35nZJz7xiWy88cadQ1C1tbXlmmuuyRe/+MXOfc7Ne/5RPup96Pi8fuUrX5nl83r66aenKIpMnjw5b731Vtra2j70s98TH9b3P/jc3NY6s3n1u2W33Xbr/N3y/PPP580338wPf/jDWdb7sN9Bydx933U8t/zyy8/yXGNjY69fCwBQfrXVLgAAYH66/PLLUxRFfvWrX+VXv/rVLM9fddVV+Y//+I/U1NRkySWXzG9+85tZ1pk0aVKXx0sttVSSGeOhz25s+iRZY401+qD6j7booot2Toz7QYsvvnjnFf2HHnrobNdZeeWVuzye090Js9v3gAEDMnHixFme65jzoqOdurvv7rjmmmuy11575ZRTTumy/I033pjruRBm1nGF9gcnnZ5Zb9//HXfcMZdeemluueWWfP/73//QenrSzr31wf7esay+vr7zbpHutvvcvvcrrrhiLrvssiTJn//859xwww0ZM2ZMpk+fnosvvrjzBO7EiRNnOfn82muv9VlbdBzngyeQZ7beeut1Hm/77bfvfF/322+/bLzxxklmtNM222yTiy66qMu2PZ34uKOuOb1HH1z3scceS1EUXdr/9ddfT2tra5/3m9n51re+lUMOOSTPPfdc/va3v2XixIn51re+1WWdj3rPP8pHvQ8dz5133nn51Kc+Ndt9DBs2LG1tbampqfnQz37yr6Crubm5M0BI5hxkfljf/+Bzc1vr/LD00kvP8XfLzD7sd1Ay4w6g2tra3HLLLfm3f/u32a7TMUH49ttvP8tzb7311nzpqwBA/+ZODQBgodHW1parrroqq666au69995Z/vvud7+biRMnZvz48UmSrbfeOlOnTu183OH666/v8niNNdbI6quvnmeeeSYbbbTRbP8bMmRIt+udmyvIu2PQoEHZdttt89vf/jbrrrvubOuc3ZXsc2ORRRbJpptumptvvrlLze3t7bnmmmuy3HLLzXHIlb5UqVS6nFhMZkzw3NPhSjbffPMsuuiiufjii+c4EXJv3/8vfvGLWWeddXLqqafmD3/4w2zXufPOO/P+++9XpZ1vvvnmLlfhT506Nbfddls+/elPdw6N1NftPjsf+9jH8oMf/CDrrLNOnnrqqSTJZz7zmSSZZaLvxx9/PM8991y22267Pjl2fX19Vllllfz1r3+dq/UrlUouuOCC1NTU5Ac/+EGX5R9sp9/97nddJl3vjjXWWCMjRozIdddd16V/vvzyy3n44Ye7rLvddtvl3Xff7Txh3OHqq6/ufH5e23333dPY2Jgrr7wyV155ZZZddtnssMMOc1x/du95d8zufdhiiy2y2GKL5dlnn53j57W+vj4DBw7M1ltvnRtvvPFD77RaaaWVksx4H2d22223dbveD5rbWrurr3+3dMfw4cOz77775s477+wyFFmHP//5zzn99NPziU98YpbJxF977bU0NTVlrbXWmk/VAgD9lTs1AICFxvjx4/Paa6/l9NNPzzbbbDPL82uvvXbOP//8XHbZZfn85z+fvffeO2effXb23HPP/Md//EdWW221jB8/PnfeeWeSZMCAf10fcskll2TUqFHZcccds88++2TZZZfN5MmT89xzz+Wpp57KjTfe2O1611lnnVx//fX55S9/mVVWWSWNjY1ZZ511evz6k+SnP/1pttxyy3z605/OwQcfnJVWWilTp07NCy+8kNtuuy333HNPj/d96qmnZvvtt8+2226bo48+OvX19bnwwgvzhz/8Idddd908uTPjgz7/+c/nyiuvzMc//vGsu+66efLJJ3PGGWf0eAiZwYMH58wzz8z++++fz372sznggAMybNiwvPDCC3nmmWdy/vnnJ+nd+19TU5Nx48Zlhx12yGabbZaDDz64cz6Dl19+Ob/61a9y22235a233koy/9u5pqYm22+/fY466qi0t7fn9NNPz5QpU3LiiSd2rtPX7Z7MOEl82GGH5atf/WpWX3311NfX55577snvfve7zjta1lhjjRx44IE577zzMmDAgIwaNSovvfRSfvjDH2b55ZfPkUce2evX32GbbbaZJeD8MKuvvnoOPPDAXHjhhXnwwQez5ZZb5vOf/3xOPvnknHDCCdl6663z/PPP56STTsrKK6+c1tbWbtc0YMCAnHzyydl///0zevToHHDAAXn77bczZsyYWYaf2muvvXLBBRdk7733zksvvZR11lknDz74YE455ZTstNNO+exnP9vt43fXYostltGjR+fKK6/M22+/naOPPrrL9+jcvOfdNbv34bzzzsvee++dyZMn5ytf+UqWWWaZ/POf/8wzzzyTf/7zn5130px11lnZcssts+mmm+b73/9+VltttfzjH//IrbfemksuuSRDhgzJTjvtlCWWWCL77bdfTjrppNTW1ubKK6/Mq6++2uv2Gjx48FzX2h3rrLNO7rvvvtx2220ZMWJEhgwZMt/uJkxmtOvzzz+fPffcMw888EB22WWXNDQ05NFHH81PfvKTDBkyJDfddFOX+WSSdM75tO222863WgGA/kmoAQAsNC677LLU19fPMtxJh6WWWiqjR4/Or371q/zjH//IsGHDcs899+SII47IMccck0qlkh122CEXXnhhdtpppy7D6my77bb5zW9+kx//+Mc54ogj8tZbb2XJJZfMWmutld12261H9Z544omZOHFiDjjggEydOjUrrrhiXnrppR7tq8Naa62Vp556KieffHJ+8IMf5PXXX89iiy2W1VdfvXNejZ7aeuutc8899+SEE07IPvvsk/b29qy33nq59dZbZ5msel756U9/mrq6upx66ql59913s+GGG+bmm2/ucrV8d+23334ZOXJkTj/99Oy///4piiIrrbRS9t577851evv+r7rqqnnqqady3nnnZdy4cbnooovS3NycESNGZKuttsqDDz6YRRddNMn8b+fDDjssTU1NOfzww/P666/nE5/4RG6//fZsscUWnevMi3YfPnx4Vl111Vx44YV59dVXU6lUssoqq+TMM8/sMkfCRRddlFVXXTWXXXZZLrjggiy66KL53Oc+l1NPPbXHdx7Nzje+8Y1cfvnlefzxxzuHk/ooJ5xwQq6++ur86Ec/yj333JPjjz8+77//fi677LKMHTs2a621Vi6++OKMGzcu9913X4/q2m+//ZIkp59+er785S9npZVWyr//+7/n/vvv77LPxsbG3HvvvTn++ONzxhln5J///GeWXXbZHH300TnhhBN6dOye+Na3vpXrrrsuyawTvM/te95dH3wf9txzz6ywwgoZO3ZsDjrooEydOjXLLLNM1l9//S41rbfeevnNb36TE044Iccdd1ymTp2a4cOH5zOf+UznHRJDhw7NHXfckSOOOCJ77rlnFltssey///4ZNWpU9t9//x7X3GFua+2On/70pzn00EPz9a9/Pe+//3623nrrHve/nlhkkUUyYcKE/OxnP8vVV1+dq6++Oi0tLVlppZWy//7755hjjpntZ/eWW27JOuus0+twHwAov0oxp/voAQCYrVNOOSU/+MEP8sorr/T5JLLQX7z00ktZeeWVc8YZZ+Too4+udjn9wrrrrpstttiiR1fHAz03ZcqUjBw5MmeffXYOOOCAapcDAFSZOzUAAD5Ex/BCH//4x9PS0pJ77rkn5557bvbcc0+BBixkxo4dm9GjR+f444/3+Yf56Oyzz84KK6wwxzstAYCFi1ADAOBDDBo0KGeffXZeeumlNDc3Z4UVVsixxx7bq2F1gHL63Oc+lzPOOCMvvviiUAPmo6FDh+bKK69Mba1TGACA4acAAAAAAICSGFDtAgAAAAAAAOaGUAMAAAAAACgFoQYAAAAAAFAKZtn6gPb29rz22msZMmRIKpVKtcsBAAAAAIAFXlEUmTp1akaOHJkBA+Z8P4ZQ4wNee+21LL/88tUuAwAAAAAAFjqvvvpqlltuuTk+L9T4gCFDhiSZ0XBDhw6tcjXl19LSkrvuuis77LBD6urqql0OdKF/0l/pm/Rn+if9mf5Jf6Z/0p/pn/Rn+if9mf7Zt6ZMmZLll1++8xz9nAg1PqBjyKmhQ4cKNfpAS0tLBg0alKFDh/pg0+/on/RX+ib9mf5Jf6Z/0p/pn/Rn+if9mf5Jf6Z/zhsfNS2EicIBAAAAAIBSEGoAAAAAAAClINQAAAAAAABKwZwaAAAAAAB8pPb29kyfPr3aZfQbLS0tqa2tTVNTU9ra2qpdTr9XV1eXmpqaXu9HqAEAAAAAwIeaPn16XnzxxbS3t1e7lH6jKIoMHz48r7766kdObs0Miy22WIYPH96r9hJqAAAAAAAwR0VRZOLEiampqcnyyy+fAQPMapDMuHPl3XffzeDBg7XJRyiKIu+//35ef/31JMmIESN6vC+hBgAAAAAAc9Ta2pr3338/I0eOzKBBg6pdTr/RMRxXY2OjUGMuDBw4MEny+uuvZ5lllunxUFRaGgAAAACAOeqYL6K+vr7KlVB2HaFYS0tLj/ch1AAAAAAA4COZN4Le6os+JNQAAAAAAABKQagBAAAAAACUglADAAAAAACqrFKp5JZbbql2Gf2eUAMAAAAAACgFoQYAAAAAAAutO+64I1tuuWUWW2yxLLnkkvn85z+fv/71r53PP/zww1l//fXT2NiYjTbaKLfccksqlUqefvrpznWeffbZ7LTTThk8eHCGDRuWb37zm3njjTc6n99mm21y+OGH55hjjskSSyyR4cOHZ8yYMZ3Pr7TSSkmS0aNHp1KpdD5mVkINAAAAAAAWWu+9916OOuqoPP7447n77rszYMCAjB49Ou3t7Zk6dWp22WWXrLPOOnnqqady8skn59hjj+2y/cSJE7P11ltn/fXXzxNPPJE77rgj//jHP7Lbbrt1We+qq67KIossksceeyxjx47NSSedlAkTJiRJHn/88STJFVdckYkTJ3Y+Zla11S4AAAAAAACqZdddd+3y+LLLLssyyyyTZ599Ng8++GAqlUp+9rOfpbGxMWuttVb+93//NwcccEDn+hdffHE23HDDnHLKKZ3LLr/88iy//PL585//nI997GNJknXXXTcnnHBCkmT11VfP+eefn7vvvjvbb799ll566STJYostluHDh8/rl1xq7tQAAAAAAGCh9de//jV77LFHVllllQwdOjQrr7xykuSVV17J888/n3XXXTeNjY2d62+yySZdtn/yySdz7733ZvDgwZ3/ffzjH+/cd4d11123y3YjRozI66+/Pq9e1gLLnRoAAAAAACy0dtlllyy//PL52c9+lpEjR6a9vT1rr712pk+fnqIoUqlUuqxfFEWXx+3t7dlll11y+umnz7LvESNGdP5cV1fX5blKpZL29vY+fCULB6EGAAAAAAALpTfffDPPPfdcLrnkknz6059Okjz44IOdz3/84x/PL37xizQ3N6ehoSFJ8sQTT3TZx4Ybbpibb745K620Umpre37Kva6uLm1tbT3efmFh+CkAAAAAABZKiy++eJZccslceumleeGFF3LPPffkqKOO6nx+jz32SHt7ew488MA899xzufPOO/OTn/wkSTrv4DjkkEMyefLk7L777vnNb36Tv/3tb7nrrruy7777diukWGmllXL33Xdn0qRJeeutt/r2hS5AhBoAAAAAACyUBgwYkOuvvz5PPvlk1l577Rx55JE544wzOp8fOnRobrvttjz99NNZf/31c/zxx+dHP/pRknTOszFy5Mg89NBDaWtry4477pi111473/nOd7LoootmwIC5PwV/5plnZsKECVl++eWzwQYb9O0LXYAYfgoAAAAAgIXWZz/72Tz77LNdls08b8bmm2+eZ555pvPxL37xi9TV1WWFFVZIS0tLkmT11VfPzTffPMdj3HfffbMsu+WWW7o83mWXXbLLLrv04BUsXIQaAAAAAAAwB1dffXVWWWWVLLvssnnmmWdy7LHHZrfddsvAgQM7Qw3mH6EGAAAAAADMwaRJk/KjH/0okyZNyogRI/LVr341P/7xj6td1kJLqAEAAAAAAHNwzDHH5JhjjplleXt7exWqwUThAAAAAABAKQg1AAAAAACAUhBqAAAAAAAApSDUAAAAAAAASkGoAQAAAAAAlIJQAwAAAAAAKIXaahcAAAAAAED5tLW1pSiK+Xa8SqWSmpqa+XY8+iehBgAAAAAA3dLW1pYvf+WreeetyfPtmIsuvkRu/tWNgo2ZvPTSS1l55ZXz29/+Nuuvv361y5kvhBr9UFEUaWpq6tX2zc3NSZKGhoZUKpUe76uxsbFX2wMAAAAAC56iKPLOW5MzdcO9ksp8mOWgaE+eurpXd4ZMnz499fX1fVjUR2tra0ulUsmAAV3bqBq1LCiEGv1QU1NTRo0aVe0ykiTjx4/PwIEDq10GAAAAAHOptxfMduxjQbhoVlvMB5UByYD5EGq0d3+TbbbZJmuvvXbq6+tz9dVX5xOf+EQuuuiiHH300XnggQeyyCKLZIcddsjZZ5+dpZZaasZh2ttzxhln5Gc/+1leffXVDBs2LAcddFCOP/743Hfffdl2223z1ltvZbHFFkuS/P73v89WW22VF198MSuttFKuvPLKHHHEEbnmmmtyzDHH5M9//nP+8pe/ZNttt83++++fF154IePGjcuXvvSlXHXVVXn44Yfz/e9/P48//niWWmqpjB49OqeeemoWWWSRJMlKK62UAw88MC+88EJuvPHGLL744vnBD36QAw88MEmy8sorJ0k22GCDJMnWW2+d++6770PbZZ999snbb7+dDTbYIBdccEGampqy++6757zzzusMWjraLkmuueaa1NTU5OCDD87JJ5/c2YffeuutfOc738ltt92W5ubmbL311jn33HOz+uqrd//N6gahBgAAAAAsQPrTBbNJdS+a1RZcddVVOfjgg/PQQw9l8uTJ2XrrrXPAAQfkrLPOyrRp03Lsscdmt912yz333JMkOe644/Kzn/0sZ599drbccstMnDgxf/rTn7p1zPfffz+nnnpq/vM//zNLLrlklllmmSTJGWeckR/+8If5wQ9+kGRGILLjjjvm5JNPzmWXXZZ//vOfOeyww3LYYYfliiuu6NzfmWeemZNPPjn//u//nl/96lc5+OCDs9VWW+XjH/94fvOb32STTTbJ//zP/+QTn/jEXN/9cffdd6exsTH33ntvXnrppXzrW9/KUkstlR//+Mdd2m6//fbLY489lieeeCIHHnhgVlxxxRxwwAFJZoQjf/nLX3Lrrbdm6NChOfbYY7PTTjvl2WefTV1dXbfarDuEGv1QY2Njxo8f3+Ptm5qaMnr06CTJuHHj0tjY2KtaAAAAAADKaLXVVsvYsWOTJD/60Y+y4YYb5pRTTul8/vLLL8/yyy+fP//5zxkxYkR++tOf5vzzz8/ee++dJFl11VWz5ZZbduuYLS0tufDCC7Peeut1Wf6Zz3wmRx99dOfjvfbaK3vssUeOOOKIJMnqq6+ec889N1tvvXUuuuiiznOzO+20Uw455JAkybHHHpuzzz479913Xz7+8Y9n6aWXTpIsueSSGT58+FzXWF9fn8svvzyDBg3KJz7xiZx00kn53ve+l5NPPrlzqKzll18+Z599diqVStZYY438/ve/z9lnn50DDjigM8x46KGHsvnmmydJfvGLX2T55ZfPLbfckq9+9avdarPuEGr0Q5VKpc8S28bGRukvAAAAwEKktxfMJgvORbPago022qjz5yeffDL33ntvBg8ePMt6f/3rX/P222+nubk52223Xa+OWV9fn3XXXfdDa+mo54UXXsgvfvGLzmVFUaS9vT0vvvhi1lxzzSTpsq9KpZLhw4fn9ddf71WN6623XgYNGtT5eLPNNsu7776bV199NSuuuGKS5FOf+lSX4dI222yznHnmmWlra8tzzz2X2trabLrppp3PL7nkklljjTXy3HPP9aq2jyLUAAAAAIAFSF9eMJuU+6JZbUHH3BTJjPkydtlll5x++umzrDdixIj87W9/+9B9ddzBMPNk5S0tLbOsN3DgwNnOnTJzLR31HHTQQTn88MNnWXeFFVbo/PmDQzlVKpW0t/dgkpG5MLdzvsxpwvaiKOb5vDFCDQAAAAAAFngbbrhhbrrppqy00kqprZ311Pjqq6+egQMH5u67787+++8/y/MdQz1NnDgxiy++eJIZ82L0pp4//vGPWW211Xq8j445NNra2rq13TPPPJNp06Z1hnSPPvpoBg8enOWWW65znUcffbTLNo8++mhWX3311NTUZK211kpra2see+yxzuGn3nzzzfz5z3/uvMNkXpkP09IDAAAAAEB1HXrooZk8eXJ23333/OY3v8nf/va33HXXXdl3333T1taWxsbGHHvssTnmmGNy9dVX569//WseffTRXHbZZUlmzM+x/PLLZ8yYMfnzn/+c22+/PRdccEGP6zn22GPzyCOP5NBDD83TTz/dOU/Ft7/97bnexzLLLJOBAwfmjjvuyD/+8Y+88847c7Xd9OnTs99+++XZZ5/N+PHjc8IJJ+Swww7rvBslSV599dUcddRRef7553PdddflvPPOy3e+850kMwKgL37xiznggAPy4IMP5plnnsmee+6ZZZddNl/84he71xDdJNQAAAAAAKBnivakfT78V/R+uKWRI0fmoYceSltbW3bcccesvfba+c53vpNFF12082T+D3/4w3z3u9/Nj370o6y55pr52te+1jl/RV1dXa677rr86U9/ynrrrZczzjgjxx9/fI/rWXfddXP//ffnL3/5Sz796U9ngw02yA9/+MOMGDFirvdRW1ubc889N5dccklGjhw514HCdtttl9VXXz1bbbVVdtttt+yyyy4ZM2ZMl3X22muvTJs2LZtsskkOPfTQfPvb386BBx7Y+fwVV1yRT37yk/n85z+fzTbbLEVR5Ne//vUsw2X1NcNPAQAAAADQLZVKJYsuvkTy1NXz7ZiLLr5Et+ZruO+++2ZZtvrqq+fmm2+e4zYDBgzI8ccfP8ewYosttsjvfve7JDPmxJgyZUra2to6Q5F99tkn++yzzyzbvfTSS7Pd38Ybb5y77rprjvXMbrunn366y+P9999/tsNlfZQTTzwxJ5544hyfr6uryznnnJOLLrpots8vvvjiufrq+ff+dxBqAAAAAADQLTU1Nbn5VzfOccLoeaFSqaSmpma+HY/+SagBAAAAAEC3CRj6p8GDB8/xufHjx8/HSuYNoQYAAAAAACwgPjg81cyWXXbZfPrTn/7Ifcxu6K7+QqgBAAAAAAALiNVWW63aJcxTA6pdAAAAAAAAwNwoTahx6qmnZuONN86QIUOyzDLL5Etf+lKef/75LusURZExY8Zk5MiRGThwYLbZZpv88Y9/rFLFAAAAAABAXypNqHH//ffn0EMPzaOPPpoJEyaktbU1O+ywQ957773OdcaOHZuzzjor559/fh5//PEMHz4822+/faZOnVrFygEAAAAAgL5Qmjk17rjjji6Pr7jiiiyzzDJ58skns9VWW6Uoipxzzjk5/vjj8+UvfzlJctVVV2XYsGG59tprc9BBB1WjbAAAAAAAoI+UJtT4oHfeeSdJssQSSyRJXnzxxUyaNCk77LBD5zoNDQ3Zeuut8/DDDws1SqooijQ1NfVq++bm5iQz+kOlUulVPY2Njb3eBwAAAAAAPVPKUKMoihx11FHZcssts/baaydJJk2alCQZNmxYl3WHDRuWl19+eY77am5u7jzpnSRTpkxJkrS0tKSlpaWvS58vZq67paUltbXVe5s7aulpW06bNi1f+MIX+rKkXrn11lszcODAapdBH+lt/4R5Rd+kP9M/6c/0T/oz/ZP+TP9kdvrL+aX+0D/7S1tUU0tLS4qiSHt7e9rb2zuXt7W1pSiK+VZHpVJJTU3NfDveR+l47UVRZO+9987bb7+dcePGVbmq/q29vT1FUaSlpWWW93JuP+el/AQedthh+d3vfpcHH3xwluc+eBV9URQfemX9qaeemhNPPHGW5XfddVcGDRrU+2KrYOY3/6677kpdXV0Vq5lhwoQJPdquv/2Dqr+0J32rp/0T5jV9k/5M/6Q/0z/pz/RP+jP9k5n1t/NL1eyf/a0tqqG2tjbDhw/Pu+++m+nTpyeZEWgcuN+38ubbU+ZbHUsuNjSXXnZFvwo2kmTq1KlpaWlJa2tr50XzzN706dMzbdq0PPDAA2ltbe3y3Pvvvz9X+yhdqPHtb387t956ax544IEst9xyncuHDx+eZMYdGyNGjOhc/vrrr89y98bMjjvuuBx11FGdj6dMmZLll18+O+ywQ4YOHToPXsG8N23atJx//vlJkh122KGqdxa0tLRkwoQJ2X777Xv0hV8URZchxbqrqakpu+22W5LkhhtuSGNjY4/3lRh+akHT2/4J84q+SX+mf9Kf6Z/0Z/on/Zn+yez0l/NL/aF/9pe2qKampqa8+uqrGTx4cOf5tdbW1rz59pT8bOs3UzMfTpe1FckB9ydDhgzp8d0y06dPT319fZ/VVBRFpk6dmiFDhqSuri61tbWlPac8vzQ1NWXgwIHZaqutZjlXO7eBUGlCjaIo8u1vfzvjxo3Lfffdl5VXXrnL8yuvvHKGDx+eCRMmZIMNNkgyo5Pef//9Of300+e434aGhjQ0NMyyvK6urrS/yGdOuPrL6+hNHb35opn5mEOGDFkof+nw0frL5wQ+SN+kP9M/6c/0T/oz/ZP+TP9kZv3t/FI1a+hvbVENbW1tqVQqGTBgQAYMGJAknf+vqSS1A+ZDEf836tXMNXyUbbbZJmuvvXbq6+tz9dVX5xOf+ES++MUv5oorrsjf/va3LLHEEtlll10yduzYDB48OEly5ZVX5ogjjsgvf/nLHHHEEXn11Vez5ZZb5oorrui8mL6trS3f+973cvnll2fAgAHZb7/9kqSzjZIZ0x5873vfy/XXX58pU6Zko402ytlnn52NN944SXLfffdl2223zR133JHvf//7+dOf/pTNNtss119/fZ588skcddRR+d///d/svPPOueyyy0o7qtAHDRgwIJVKZbafpbn9bM2P7tYnDj300FxzzTW59tprM2TIkEyaNCmTJk3KtGnTkszoMEcccUROOeWUjBs3Ln/4wx+yzz77ZNCgQdljjz2qXD0AAAAAAPPbVVddldra2jz00EO55JJLMmDAgJx77rn5wx/+kKuuuir33HNPjjnmmC7bvP/++/nJT36Sn//853nggQfyyiuv5Oijj+58/swzz8zll1+en/3sZxk/fnwmT548y1waxxxzTG666aZcddVVeeqpp7Laaqtlxx13zOTJk7usN2bMmJx//vl5+OGH8+qrr2a33XbLOeeck2uvvTa33357JkyYkPPOO2/eNVAJleZOjYsuuijJjHRtZldccUX22WefJDM6yrRp03LIIYfkrbfeyqabbpq77rorQ4YMmc/VAgAAAABQbauttlrGjh3b+fjjH/94588rr7xyTj755Bx88MG58MILO5e3tLTk4osvzqqrrppkxhzPJ510Uufz55xzTo477rjsuuuumTJlSi666KLcddddnc+/9957ueiii3LllVdm1KhRSZKf/exnmTBhQi677LJ873vf61z3P/7jP7LFFlskSfbbb78cd9xx+etf/5pVVlklSfKVr3wl9957b4499ti+bJZSK02o0TGT/IepVCoZM2ZMxowZM+8LAgAAAACgX9too426PL733ntzyimn5Nlnn82UKVPS2tqapqamvPfee1lkkUWSJIMGDeoMNJJkxIgRef3115Mk77zzTiZOnJjNNtus8/na2tpstNFGneew//rXv6alpaUzrEhmDK20ySab5LnnnutSz7rrrtv587BhwzJo0KDOQKNj2W9+85veNsMCpTTDTwEAAAAAQHd0BBVJ8vLLL2ennXbK2muvnZtuuilPPvlkLrjggiQz7s7o8MG5HSqVylxddN+hY91KpTLL8g8um/lYHXNNfPDY7e3tc33shYFQAwAAAACABd4TTzyR1tbWnHnmmfnUpz6Vj33sY3nttde6tY9FF100I0aMyKOPPtq5rLW1NU8++WTn49VWWy319fV58MEHO5e1tLTkiSeeyJprrtn7F7KQK83wUwAAAAAA0FOrrrpqWltbc95552WXXXbJQw89lIsvvrjb+/nOd76T0047LauuumqWX375/OxnP8vbb7/d+fwiiyySgw8+ON/73veyxBJLZIUVVsjYsWPz/vvvZ7/99uvDV7RwEmoAAAAAANAjbUWS+TA6Utvcj/40R+uvv37OOuusnH766TnuuOOy1VZb5dRTT81ee+3Vrf1897vfzcSJE7PvvvumUqlk3333zejRo/POO+90rnPaaaelvb093/zmNzN16tRstNFGufPOO7P44ov3/oUs5IQaAAAAAAB0S6VSyVJLLJoD7p9/x1xqiUVnmZPiw9x3332zLDvyyCNz5JFHdln2zW9+s/PnffbZJ/vss0+X57/0pS91mVOjtrY255xzTs4666xMmTIlQ4cOzYABXWd6aGxszLnnnptzzz13trVts802s8zTMbtjjxkzJmPGjJnDK1w4CTUAAAAAAOiWmpqa/PLGm7s1gXZvVSqV1NTUzLfj0T8JNQAAAAAA6DYBA9Uw4KNXAQAAAAAAqD6hBgAAAAAAUApCDQAAAAAAoBSEGgAAAAAAfKT5OSk4C6b29vZe78NE4QAAAAAAzFFdXV0qlUr++c9/Zumll06lUql2Sf1Ce3t7pk+fnqampgwY4P6BD1MURaZPn55//vOfGTBgQOrr63u8L6EGAAAAAABzVFNTk+WWWy5///vf89JLL1W7nH6jKIpMmzYtAwcOFPTMpUGDBmWFFVboVQgk1AAAAAAA4EMNHjw4q6++elpaWqpdSr/R0tKSBx54IFtttVXq6uqqXU6/V1NTk9ra2l4HQEINAAAAAAA+Uk1NTWpqaqpdRr9RU1OT1tbWNDY2CjXmIwN9AQAAAAAApSDUAAAAAAAASkGoAQAAAAAAlIJQAwAAAAAAKAWhBgAAAAAAUApCDQAAAAAAoBSEGgAAAAAAQCkINQAAAAAAgFIQagAAAAAAAKUg1AAAAAAAAEpBqAEAAAAAAJSCUAMAAAAAACgFoQYAAAAAAFAKQg0AAAAAAKAUhBoAAAAAAEApCDUAAAAAAIBSEGoAAAAAAAClINQAAAAAAABKQagBAAAAAACUglADAAAAAAAoBaEGAAAAAABQCkINAAAAAACgFIQaAAAAAABAKQg1AAAAAACAUhBqAAAAAAAApSDUAAAAAAAASkGoAQAAAAAAlIJQAwAAAAAAKAWhBgAAAAAAUApCDQAAAAAAoBSEGgAAAAAAQCkINQAAAAAAgFIQagAAAAAAAKUg1AAAAAAAAEpBqAEAAAAAAJSCUAMAAAAAACgFoQYAAAAAAFAKQg0AAAAAAKAUhBoAAAAAAEApCDUAAAAAAIBSEGoAAAAAAAClINQAAAAAAABKQagBAAAAAACUglADAAAAAAAoBaEGAAAAAABQCkINAAAAAACgFIQaAAAAAABAKdRWuwAAAAAA4F+KokhTU1NVa5j5+NWspaWlpbOG1tbWqtTQX9qiQ2NjYyqVSrXLgKoRagAAAABAP9LU1JRRo0ZVu4xOo0ePrtqx6+vrc+ihh2bXXXfN9OnTq1ZHh2q2RYfx48dn4MCB1S4DqsbwUwAAAAAAQCm4UwMAAAAA+ql31989xYAqnMIriqT9/4Z7GlCbzOfhjirtrRn89HVdlp2/5eQ01BTztY5kRlNMb5/xc/2A+d4USZLmtkoOe3CJ+X9g6IeEGgAAAADQTxUDapOauiodvb5Kx01mF1001BRpqJnvpSRJGqtz2JnM/zAH+ivDTwEAAAAAAKUg1AAAAAAAAEpBqAEAAAAAAJSCUAMAAAAAACgFoQYAAAAAAFAKQg0AAAAAAKAUhBoAAAAAAEApCDUAAAAAAIBSEGoAAAAAAAClINQAAAAAAABKQagBAAAAAACUglADAAAAAAAoBaEGAAAAAABQCkINAAAAAACgFIQaAAAAAABAKQg1AAAAAACAUhBqAAAAAAAApSDUAAAAAAAASkGoAQAAAAAAlIJQAwAAAAAAKAWhBgAAAAAAUApCDQAAAAAAoBSEGgAAAAAAQCkINQAAAAAAgFIQagAAAAAAAKUg1AAAAAAAAEpBqAEAAAAAAJSCUAMAAAAAACgFoQYAAAAAAFAKQg0AAAAAAKAUhBoAAAAAAEApCDUAAAAAAIBSEGoAAAAAAAClINQAAAAAAABKQagBAAAAAACUglADAAAAAAAoBaEGAAAAAABQCkINAAAAAACgFIQaAAAAAABAKQg1AAAAAACAUhBqAAAAAAAApVBb7QJYcBVFkaampiRJU1NTWltb53sNHcf/4M/V0tjYmEqlUu0yAAAAAABKSajBPNPU1JRdd901hx56aHbddddMnz69qvWMHj26qsdPkvHjx2fgwIHVLgMAAAAAoJQMPwUAAAAAAJSCOzWYL37yqbcysDL/h38qimR6+4yf6wck1Rj5qbmtksMeXGL+HxgAAAAAYAEj1GC+qK8p0lClqSQaq3PYmRTVLgAAAAAAYIFg+CkAAAAAAKAUhBoAAAAAAEApCDUAAAAAAIBSEGoAAAAAAAClINQAAAAAAABKQagBAAAAAACUglADAAAAAAAoBaEGAAAAAABQCkINAAAAAACgFIQaAAAAAABAKQg1AAAAAACAUhBqAAAAAAAApSDUAAAAAAAASkGoAQAAAAAAlIJQAwAAAAAAKAWhBgAAAAAAUApCDQAAAAAAoBSEGgAAAAAAQCkINQAAAAAAgFIQagAAAAAAAKUg1AAAAAAAAEpBqAEAAAAAAJSCUAMAAAAAACgFoQYAAAAAAFAKQg0AAAAAAKAUhBoAAAAAAEApCDUAAAAAAIBSEGoAAAAAAAClINQAAAAAAABKQagBAAAAAACUglADAAAAAAAohdpqF7CgKYoiTU1NVa1h5uNXs5ZqtwMAAAAAAAsWoUYfa2pqyqhRo6pdRqfRo0dX9fj19fVVPT4AAAAAAAsOw08BAAAAAACl4E6Neejd9XdPMaAKTVwUSXvrjJ8H1CaVynwvodLemsFPXzffjwsAAAAAwIJLqDEPFQNqk5q6Kh29usM+FVU9OgAAAAAACyKhBgAAAAD0I0Ux0+WibS3VK6Sa/u91t7e3Z/r06SmKIs1tVa6pimZ+7V36ByyEhBoAAAAA0I80Nzd3/jzkmeurWEn1tba25oILLkiSHPbgklWupn9obm7OoEGDql0GVI2JwgEAAAAAgFJwpwYAAAAA9CMNDQ2dP09d7+tVnLO1itpaMuSZ61NbW5uDDjool156ac7edFIaaqpdWHU0t/3rTpWZ+wcsjIQaAAAAANCPVCqVfz2oqVs4Q43/M2DAgNTX16dSqaShJgttqDGzLv0DFkKGnwIAAAAAAEqhVKHGAw88kF122SUjR45MpVLJLbfc0uX5oigyZsyYjBw5MgMHDsw222yTP/7xj9UpFgAAAAAA6FOlCjXee++9rLfeejn//PNn+/zYsWNz1lln5fzzz8/jjz+e4cOHZ/vtt8/UqVPnc6UAAAAAAEBfK9WcGqNGjcqoUaNm+1xRFDnnnHNy/PHH58tf/nKS5KqrrsqwYcNy7bXX5qCDDpqfpQIAAAAAAH2sVKHGh3nxxRczadKk7LDDDp3LGhoasvXWW+fhhx+eY6jR3Nyc5ubmzsdTpkxJkrS0tKSlpaXbdbS2tqa+vj5JUl9TSRbayYsqqa+vT13djIms2gbUp20hncOorUhnn2htbe1Rv2Le6HgvvCf0N/om/Zn+SX+mf9Kf6Z/0Z/pn/+P8UvLBc0t1dXVpG9CQtlKNO9N3nF/qn3x/9q25bcdKURTFPK5lnqhUKhk3bly+9KUvJUkefvjhbLHFFvnf//3fjBw5snO9Aw88MC+//HLuvPPO2e5nzJgxOfHEE2dZfu2112bQoEHzpHYAAAAAAOBf3n///eyxxx555513MnTo0Dmut8DcqdGhUul6O0BRFLMsm9lxxx2Xo446qvPxlClTsvzyy2eHHXb40Iabk6ampuy6665JkqnrfT2pWeCaeO60tWbIM9enrq4uBx54YFb73ekZVJle7aqqorktOfyhJZIkN910UxobG6tcER1aWloyYcKEbL/99p1XfkB/oG/Sn+mf9Gf6J/2Z/kl/pn/2P84vZZZzS5deemnO3OQfaVgo71pxfqm/8v3ZtzpGUfooC8w34vDhw5MkkyZNyogRIzqXv/766xk2bNgct2toaEhDQ8Msy+vq6nrUEVtbWzN9+oyT99PbSnkTTN9oKzrbIUlq2qenptL8IRssuGra09kWtbW1vuD6oZ5+3mFe0zfpz/RP+jP9k/5M/6Q/0z/7D+eXMsu5pZaWltS0N6dmIR3e3Pml/s33Z9+Y2zZcYEahW3nllTN8+PBMmDChc9n06dNz//33Z/PNN69iZQAAAAAAQF8o1Z0a7777bl544YXOxy+++GKefvrpLLHEEllhhRVyxBFH5JRTTsnqq6+e1VdfPaecckoGDRqUPfbYo4pVAwAAAAAAfaFUocYTTzyRbbfdtvNxx1wYe++9d6688socc8wxmTZtWg455JC89dZb2XTTTXPXXXdlyJAh1SoZAAAAAADoI6UKNbbZZpsUxZzHEaxUKhkzZkzGjBkz/4oCAAAAAADmiwVmTg0AAAAAAGDBJtQAAAAAAABKQagBAAAAAACUglADAAAAAAAoBaEGAAAAAABQCkINAAAAAACgFIQaAAAAAABAKQg1AAAAAACAUhBqAAAAAAAApSDUAAAAAAAASkGoAQAAAAAAlIJQAwAAAAAAKAWhBgAAAAAAUApCDQAAAAAAoBSEGgAAAAAAQCkINQAAAAAAgFIQagAAAAAAAKUg1AAAAAAAAEpBqAEAAAAAAJSCUAMAAAAAACgFoQYAAAAAAFAKQg0AAAAAAKAUhBoAAAAAAEApCDUAAAAAAIBSEGoAAAAAAAClINQAAAAAAABKQagBAAAAAACUglADAAAAAAAoBaEGAAAAAABQCkINAAAAAACgFIQaAAAAAABAKQg1AAAAAACAUhBqAAAAAAAApSDUAAAAAAAASkGoAQAAAAAAlIJQAwAAAAAAKAWhBgAAAAAAUApCDQAAAAAAoBSEGgAAAAAAQCkINQAAAAAAgFIQagAAAAAAAKUg1AAAAAAAAEpBqAEAAAAAAJSCUAMAAAAAACgFoQYAAAAAAFAKQg0AAAAAAKAUhBoAAAAAAEApCDUAAAAAAIBSEGoAAAAAAAClINQAAAAAAABKQagBAAAAAACUglADAAAAAAAoBaEGAAAAAABQCkINAAAAAACgFIQaAAAAAABAKdRWu4AFTVEU/3rQ1lK9Qqrt/157URRd2wQAAAAAAHpIqNHHmpubO38e8sz1Vaykf2hpaUlra2u1ywAAAAAAYAFg+CkAAAAAAKAU3KnRxxoaGjp/nrre15OauipWU0VtLRnyzPWpra1NURRpbktqKtUuqjqa2/71s6G4AAAAAAB6TqjRxyqVmc7c19QtvKHG/2ltbc0FF1yQZPD//bdwa25uzqBBg6pdBgAAAABAKRl+CgAAAAAAKAV3ajBP1dXV5aCDDsrqvzstgyrNH73BAqi5LTnswSWTdB2eDAAAAACA7hFqME9VKpXU1dWloSZpWEjn1JhZl+HJAAAAAADoFsNPAQAAAAAApSDUAAAAAAAASkGoAQAAAAAAlIJQAwAAAAAAKAWhBgAAAAAAUApCDQAAAAAAoBSEGgAAAAAAQCnUVrsAAAAAAGD2Ku2tKapx4KJI2ltn/DygNqlU5uvhKx3HnklzWyWpQmsURTK9fcbP9QPme1Mk6XjtQCLUAAAAAIB+a/DT11W7hH7jsAeXqHYJQD9g+CkAAAAAAKAU3KkBAAAAAP1IY2Njxo8fX9UampqaMnr06CTJuHHj0tjYWJU6Wlpacu+99+amm25KbW11TmX2l7boUO3jQ7UJNQAAAACgH6lUKhk4cGC1y+jU2NhYtXo6gozGxsbU1dVVpYaZVbMtgBkMPwUAAAAAAJSCUAMAAAAAACgFoQYAAAAAAFAKQg0AAAAAAKAUTBQOADCPFUWRpqamXu+jubk5SdLQ0JBKpdLjfTU2NvZqewAAAKgWoQYAwDzW1NSUUaNGVbuMTuPHj8/AgQOrXQYAAAB0m+GnAAAAAACAUnCnBgDAPNbY2Jjx48f3ah9NTU0ZPXp0kmTcuHFpbGzsVT0AAABQRkINAIB5rFKp9OlwT42NjYaPAgAAYKFk+CkAAAAAAKAUhBoAAAAAAEApCDUAAAAAAIBSEGoAAAAAAAClINQAAAAAAABKQagBAAAAAACUglADAAAAAAAoBaEGAAAAAABQCkINAAAAAACgFIQaAAAAAABAKQg1AAAAAACAUhBqAAAAAAAApSDUAAAAAAAASkGoAQAAAAAAlIJQAwAAAAAAKAWhBgAAAAAAUApCDQAAAAAAoBSEGgAAAAAAQCkINQAAAAAAgFIQagAAAAAAAKUg1AAAAAAAAEpBqAEAAAAAAJSCUAMAAAAAACgFoQYAAAAAAFAKQg0AAAAAAKAUhBoAAAAAAEApCDUAAAAAAIBSEGoAAAAAAAClINQAAAAAAABKQagBAAAAAACUglADAAAAAAAoBaEGAAAAAABQCkINAAAAAACgFIQaAAAAAABAKQg1AAAAAACAUhBqAAAAAAAApSDUAAAAAAAASkGoAQAAAAAAlEJttQsAAGDhUhRFmpqaerV9c3NzkqShoSGVSqXH+2psbOzV9gAAAMxfQg0AAOarpqamjBo1qtplJEnGjx+fgQMHVrsMAAAA5pJQAwDgI/T2zoK+MPPxq1lLa2trkhltAgAALHz68s7r/qA3d3+3tLQkmfE3WsffSt2xILVFh/lxN7xQAwDgI/SnOwuSZPTo0VU7dn19fQ499NA0Nzenvr6+R/tobGzM+PHje1xDU1NTZxuMGzcujY2NPd5Xb7YFAICFUX/7+6iaOv4+2nXXXTN9+vRql9MvzI+74YUaAADMV5VKpc/+kdvY2Gj4KAAAgIWIUAMAoBveXX/3FAOq8E+ookja/+925gG1SRUmt660t2aJZ2+a78cFAAD6px79fTTz3zb9QQ/+vqq0t2bw09d1WXb+lpPTUNO9YXqLIpne3q1N5qn6AT37U7O5rZLDHlyi7wuaA6EGAEA3FANqk5q6Kh29Z8M99RWzaAAAADPr+d9H1f3bprdm97dRQ02Rhpru72vBGBB3/v61OGC+Hg0AAAAAAKCHhBoAAAAAAEApCDUAAAAAAIBSEGoAAAAAAAClYKJwoFuKokhTU1Ovtm9ubk6SNDQ0pFKp9HhfjY2NvdoeAAAAACgXoQbQLU1NTRk1alS1y0iSjB8/PgMHDqx2GQAAAADAfGL4KQAAAAAAoBTcqQF0S2NjY8aPH9/j7ZuamjJ69Ogkybhx49LY2NirWqqpPw3FlRiOCwAAAIAFn1ADFiK9PQnf3/T2tbS2tvb6+P1lKK7EcFwAAAAALPiEGrAQ6W8n4Tvu2KiW+vr6HHrooVWtAQAAAACYe0INWIgURVHtEvqVoig6717pyV0bRVFk3LhxPT5+U1NTdt999yTJdddd1+vhtIqiyLRp03q8fdmHr+qLO5H6ckiwaren4dEAAACABZFQAxYiHScomaGlpSXTpk3Ll7/85bS0tFS1lo5wo5p+/etfZ9CgQVU7fsdJ+J6eiJ82bVr22GOPPq6q56699toeDwfW0tKS999/P2+99Vbq6up6tI8FqT0aGxuFIgAAAP1El4tm26p7PqVq/u91t7e3Z/r06TMuDGyrck1VNPNrnx8XVQs1gIXaJZdcUu0S+o3m5uaqhhr9bXi03uqLQGFB6p+9bQ9zxgAAAPQPM180O+SZ66tYSfW1trbmggsuSJIc9uCSVa6mf5gf55cGzNO9A/1KQ0NDtUsAAAAAAOgxd2rAQmTgwIEZP358VWtoamrqnCB83LhxvZ5HoqemTZuWr33taznooINyySWXVH34qf6g2qFXY2Njxo8f3+Php2aeA6Kn+nIeid5s39LSkrvvvjvbbbddj4ef6m179PWcGr3ZR8fwUwAAAFTfzOcPpq739aSmZ3+3llpbS4Y8c31qa2tz0EEH5dJLL83Zm05KQ021C6uO5rZ/3akyP84vCTVgIVKpVHo9fEtfTMbcV3ozxn5jY2Nuvvnm3HPPPbn55ptTW9v9r8PenDSeOHFiDj300C7jDFYqlVxwwQUZMWJEj/bZFxNbV1NH/zTE0IxQY9CgQVl88cV7HGrAvNbU1NSj786+Ovbsfq4Wc74AALAw6fJv35q6hTPU+D8DBgxIfX19KpVKGmqy0IYaM5sffxsJNYBu6ct5Dzru2Oip3oyxX6lUOk/iNzY29ujE8bRp03r9GmZWFEUOOeSQHm9vzgFgfvrGN76R6dOnV7uMPv0e7infvwAAAPOPOTUAAAAAAIBScKcG88X0tkpqqjAqQ1Ek09tn/Fw/IKnGyBDNbQvWcBQd8x70VF+O01/t4ZJ62hYvv/xy/u3f/m2Oz1988cVZccUVe1QPwPx0/paT01BTfPSKfay//H4/7MEl5v+BAVjgPPzww/npT3+a73znO9l8882rXQ4A9HtCDeaLox9dvF8MUUHv9cW8HIMGDeqjaqqrp22xxhprZJ111snvf//7WZ5bd911s8YaaxibHSiFhpqiamPGVj/Gnf9hDgALnqamppx11ll54403ctZZZ2XDDTd0sRIAfATDTwHMZ5VKJccee+wswcWAAQNmuxwAAFgw/eIXv8ibb76ZJHnzzTdz7bXXVrkiAOj/3KnBfHHTTTeltnb+d7empqbOCUTHjRtX9Steqn18+o/lllsuX//613Pdddd1Lvv617+eZZddtopVAQD0L0VRpKmpqdf76MvhT12AQofe9s/XXnst1157bYqi6NzfL37xi2y99dYZOXJkt/enfwKwsBBqMF80Njamrq6u6jX0dtgk6Et77713br/99kyZMiVDhw7NXnvtVe2SgDnoONmQJGlrqV4h1dbWkqIo0tLS0rVNAOaRpqamjBo1qtpldBo/fry/Keg0L/pnW1tb9ttvvx5tq38CsLAQagBUSWNjY77//e93TgroTh7ovzqu8E2SIc9cX8VKqq8lyfnnn1/1ixXoO66EBwAAykSoAVBFm2++eTbffPNqlwHQbUVRpLmt2lVUz8yvvex3rbgSnnmpt6FZURQZN25cr2poamrK7rvvniS57rrrenUhSVEUmTZtWo+2bW1t7dxHT48tgOxfGhsbM378+B5tWxRFfvjDH+a3v/1t2tvbO5cPGDAgG2ywQU4++eRut281L5LSPwGYnxbIUOPCCy/MGWeckYkTJ+YTn/hEzjnnnHz605+udlkAQEk1NDR0/jx1va8nNQvpXQptLVn8j79Ka2trWltbc9iDS1a7on6hubk5gwYNqnYZ9AEn5fpefwvNOsKNaqivr8+hhx6a5ubm1NfXd3v7/taWC0IA2Ref+Z6qVCo55JBDcuCBB852eU8++715Lb0N3fRPAOanBS7U+OUvf5kjjjgiF154YbbYYotccsklGTVqVJ599tmssMIK1S4PACihLicWauoW3lAjKf0J1gWRK+H/xUk5yqCpqSm1td3/U7xaJ9/npC/qqXZw198+80nv5tTojd6GbgAwPy1wocZZZ52V/fbbL/vvv3+S5Jxzzsmdd96Ziy66KKeeemqVqwMAKL/DDjssl1xySc7edFIaaqpdTXU0t6XzTpWZ7+SphmnTpmWnnXaqag0zq+aV8HV1dTnooIPy9ttvZ8iQId3e3knjvjdzwPTuOl9NMaAKXxpFkvYZgVcG1CZVaI5Ke1sW/9MtaWlpyR577JGWlpb5X0QfGz16dK/3Ue3gruzDB/aloijS0tKSadOm9Sh0W5AC8g7V/v4EYM4WqFBj+vTpefLJJ/P973+/y/IddtghDz/8cJWqAgBYcFQqldTV1aVSqaShJgttqDGzap/wmHki+4VdS0tLzj///Fx88cWdd22UWV+cNP71r39d1eHRZu6fg39/Y9Xq6A9akpx//vk9OmG8oKp2qOD781/62/dnNQPyDtX+/uytvhhebebte7uvaoZE2mLeqrS3ptvf5kXxrwsO+oMBtUk335PKbOpvbqsk3WyNokimt3/0evNL/YBuN0WSjtc+/yxQ/5p644030tbWlmHDhnVZPmzYsEyaNGm22zQ3N3f5h8yUKVOSzPiF3pOrZ1pbWztv1ayvqSQL7R/6ldTX16eubsbwHNW6Emnm47a0tPgDgi46+seCcKUcCxZ9s//x+71DpfN3e11dXdoGNKRtQJVLqpK2Ip19orW1taqf1/5w8qm/0Sb/8t5773V+bqvBezErbfIv+mf/o03+pdr9s7emTZuWL3zhC322v94G7bfeemuP78zq7d9HC1Jb9Bcz/320xLM3dXv7jrvD+ouOi7a6baZzn3V1dTnqN8O7vYsFpi2SdIxe2Ju/j+Z2u0pR7Usj+tBrr72WZZddNg8//HA222yzzuU//vGP8/Of/zx/+tOfZtlmzJgxOfHEE2dZfu2115Y6kWeGjqtNkhlDZZT5HyQALNyKoug80VBbW7tAXd1F78zcN6qxfTLj31yXX355kmTfffft1b+5etO/W1pacskll/T42Auiav8buC/6V2/N3C8OOuigqrWH/jkr/VP/7M+q3T97a+bzIf1BNdtTW/Q/3pN/0RZdvf/++9ljjz3yzjvvZOjQoXNcb4EKNaZPn55Bgwblxhtv7JKafuc738nTTz+d+++/f5ZtZnenxvLLL5833njjQxtuTpqamrLrrrsmSaau9/WkZiG9M6CtNUOeuT51dXU58MADs/3221flAzFzGr8gJOH0rZaWlkyYMKFq/RPmRN/sf2b+/V4tM1/B05urZ3qr43f7pZdemjM3+cdCO/xUc1ty+ENLJEluuummXo373VtFUfRqCJWmpqZ89atf7cOKeufGG2/scXtOnTo1Dz/8cC6//PIeXR3WF38aFUWRtra2JElNTU2vP6u93f6mm26q6r+BfX/+S21tbfbdd98e98++0N8Ccv1T/5xZe3t75/dnR03V7KPV7p+91RdDLs38b4yGhoZevR+9GXKpt38fLUht0V/09t+fvd2+r/XmPW1pacn/+3//L1tttVWP5yRaUNqiL/YxZcqULLXUUh8ZaixQZ9zr6+vzyU9+MhMmTOgSakyYMCFf/OIXZ7tNQ0PDbCd3rKur69EXZWtra6ZPn54kmd62wORF3ddWdLZD0vP27K2Zr7qpVg30f/oG/ZW+2X/M/Pu9P+gPtye3tLSkpr05NeX+e6zHatrT2Sdqa2ur/lntuP2/J/rb8JyDBw/u8UmkhoaG1NXV5Ze//GWPXldTU1OfzGPRYeaTcz0xbty4Xgdm1T5xUltbm//6r/+q2vGTru/rDTfcULUQ8t13383DDz9c9SHrOlT7DoWk+v/W6W3/7IsTUTNPjn311Vf3qn/29qTcvffem+uvv77HJ4172xZXX31152TjlUolo0ePzh577NGjffXFSblqf3/2hd78+6A/6s13xoLWFv2BNp2h43f64MGDq/43wYJgbtuwf/0F0weOOuqofPOb38xGG22UzTbbLJdeemleeeWV/Nu//Vu1SwMASqqxsTHjx4+vag0zn5TrixOdPdVxUo4FR1/0776+erGnOo7b2Ni4QPxR2djYWOqrhJMZ70lvXkNfXF3bl3pzkrOmZsatbTfddFO/CN16q69Ct2rqbf+cNm1an74nvZ0ce/z48T1+PR19cuDAgT36/uzrtiiKIjfeeGNuvPHGHm3fm7YAoP9b4EKNr33ta3nzzTdz0kknZeLEiVl77bXz61//OiuuuGK1SwMASqq3Jz36WjVPdM58ZW9zWyXJ/L8ztSiS6e0zfq4fkFTjIsoZr33B0Ff9e0GYj25BCngWFE1NTRk1alSf7a+3J117c6JU6AYA0DcWuFAjSQ455JAccsgh1S4DAGCBdtiDS1S7BOhTAh76M6Fb/+M96XrsnrbFK6+8koMOOmiOz19yySVZYYUVul0PAAuuBTLUAAAAoPycNP4XoVv/4z35l960xcc+9rFsvPHGeeqpp7rMRVRTU5NPfvKT+djHPlb6uS0A6FtCDQAA5lpDQ0OSno8J3xf6y/wiHap9fFiQOWkMC75KpZLvfOc72XvvvWe7XKABwAcJNQAAmGv9bUx4Y7oDQPktt9xy2WOPPXLNNdekKIpUKpXsscceWXbZZatdGgD9kFADAGAeK4oiTU1NvdrHzNv3dl+NjY2uegQA+pVvfOMbGT9+fN54440stdRS2WOPPapdEgD9lFADAGAea2pqyqhRo/psfx1DL/XU+PHj3d0AAPQrjY2NOeqoo/LTn/403/nOdwzvCMAcCTUAAAAAqLrNN988m2++ebXLAKCfE2oAAMxjjY2NGT9+fK/2URRFmpubk8yYrLs3w0e58hEAAICyEmrMQ5X21hTVOHBRJO2tM34eUJtUYczsSsfxAYBUKpU+Ge5p0KBBfVBN9fV2jhHziwAAACy8hBrz0OCnr6t2CQAA/U5fzjFifhEAAICFy4CebvjCCy/kzjvvzLRp05LMuOIOAAAAAABgXun2nRpvvvlmvva1r+Wee+5JpVLJX/7yl6yyyirZf//9s9hii+XMM8+cF3WWRl+Mmd1bTU1NnVctjhs3rqrjZre2tuaee+6p2vEBgP6nt/9eMr8IAADAwqvbocaRRx6Z2travPLKK1lzzTU7l3/ta1/LkUceudCHGn01ZnZfaWxsrGo9LS0tVTs2ANA/9cW/lxaU+UUAAADonm6HGnfddVfuvPPOLLfccl2Wr7766nn55Zf7rDAAAAAAAICZdXtOjffee2+2V8a98cYbaWho6JOiAAAAAAAAPqjbocZWW22Vq6++uvNxpVJJe3t7zjjjjGy77bZ9WhwAAAAAAECHbg8/dcYZZ2SbbbbJE088kenTp+eYY47JH//4x0yePDkPPfTQvKgRAAAAAACg+3dqrLXWWvnd736XTTbZJNtvv33ee++9fPnLX85vf/vbrLrqqvOiRgAAAAAAgO7fqZEkw4cPz4knntjXtQAAAAAAAMxRt0ONBx544EOf32qrrXpcDAAAAAAAwJx0O9TYZpttZllWqVQ6f25ra+tVQQAAAAAAALPT7Tk13nrrrS7/vf7667njjjuy8cYb56677poXNQIAAAAAAHT/To1FF110lmXbb799GhoacuSRR+bJJ5/sk8IAAAAAAABm1u07NeZk6aWXzvPPP99XuwMAAAAAAOii23dq/O53v+vyuCiKTJw4MaeddlrWW2+9PisMAAAAAABgZt0ONdZff/1UKpUURdFl+ac+9alcfvnlfVYYAAAAAADAzLodarz44otdHg8YMCBLL710Ghsb+6woAAAAAACAD+p2qLHiiivOizoAAAAAAAA+1FyFGueee+5c7/Dwww/vcTEAAAAAAABzMlehxtlnnz1XO6tUKkINAAAAAABgnpirUOOD82gAAAAAAADMbwOqXQAAAAAAAMDc6PZE4Uny97//PbfeemteeeWVTJ8+vctzZ511Vp8UBgAAAAAAMLNuhxp33313vvCFL2TllVfO888/n7XXXjsvvfRSiqLIhhtuOC9qBAAAAAAA6P7wU8cdd1y++93v5g9/+EMaGxtz00035dVXX83WW2+dr371q/OiRgAAAAAAgO6HGs8991z23nvvJEltbW2mTZuWwYMH56STTsrpp5/e5wUCAAAAAAAkPQg1FllkkTQ3NydJRo4cmb/+9a+dz73xxht9VxkAAAAAAMBMuj2nxqc+9ak89NBDWWuttbLzzjvnu9/9bn7/+9/n5ptvzqc+9al5USMAAAAAAED3Q42zzjor7777bpJkzJgxeffdd/PLX/4yq622Ws4+++w+LxAAAAAAACDpQahx8sknZ88990xRFBk0aFAuvPDCeVEXAAAAAABAF92eU+PNN9/MzjvvnOWWWy7f/e538/TTT8+DsgAAAAAAALrqdqhx6623ZtKkSTnhhBPy5JNP5pOf/GTWWmutnHLKKXnppZfmQYkAAAAAAAA9CDWSZLHFFsuBBx6Y++67Ly+//HK+9a1v5ec//3lWW221vq4PAAAAAAAgSQ9DjQ4tLS154okn8thjj+Wll17KsGHD+qouAAAAAACALnoUatx777054IADMmzYsOy9994ZMmRIbrvttrz66qt9XR8AAAAAAECSpLa7Gyy33HJ58803s+OOO+aSSy7JLrvsksbGxnlRGwAAAAAAQKduhxo/+tGP8tWvfjWLL774vKgHAAAAAABgtrodahx44IHzog4AAAAAAIAP1auJwgEAAAAAAOYXoQYAAAAAAFAKQg0AAAAAAKAUhBoAAAAAAEApCDUAAAAAAIBSEGoAAAAAAAClINQAAAAAAABKQagBAAAAAACUglADAAAAAAAoBaEGAAAAAABQCkINAAAAAACgFIQaAAAAAABAKQg1AAAAAACAUhBqAAAAAAAApSDUAAAAAAAASkGoAQAAAAAAlIJQAwAAAAAAKAWhBgAAAAAAUApCDQAAAAAAoBSEGgAAAAAAQCkINQAAAAAAgFIQagAAAAAAAKUg1AAAAAAAAEpBqAEAAAAAAJSCUAMAAAAAACgFoQYAAAAAAFAKQg0AAAAAAKAUhBoAAAAAAEApCDUAAAAAAIBSEGoAAAAAAAClINQAAAAAAABKQagBAAAAAACUglADAAAAAAAoBaEGAAAAAABQCkINAAAAAACgFIQaAAAAAABAKQg1AAAAAACAUhBqAAAAAAAApSDUAAAAAAAASkGoAQAAAAAAlIJQAwAAAAAAKAWhBgAAAAAAUApCDQAAAAAAoBSEGgAAAAAAQCkINQAAAAAAgFIQagAAAAAAAKUg1AAAAAAAAEpBqAEAAAAAAJSCUAMAAAAAACgFoQYAAAAAAFAKQg0AAAAAAKAUhBoAAAAAAEApCDUAAAAAAIBSEGoAAAAAAAClINQAAAAAAABKQagBAAAAAACUglADAAAAAAAoBaEGAAAAAABQCkINAAAAAACgFIQaAAAAAABAKQg1AAAAAACAUhBqAAAAAAAApSDUAAAAAAAASkGoAQAAAAAAlIJQAwAAAAAAKAWhBgAAAAAAUApCDQAAAAAAoBSEGgAAAAAAQCkINQAAAAAAgFIQagAAAAAAAKUg1AAAAAAAAEpBqAEAAAAAAJSCUAMAAAAAACgFoQYAAAAAAFAKQg0AAAAAAKAUhBoAAAAAAEApCDUAAAAAAIBSEGoAAAAAAAClINQAAAAAAABKQagBAAAAAACUglADAAAAAAAoBaEGAAAAAABQCkINAAAAAACgFIQaAAAAAABAKQg1AAAAAACAUhBqAAAAAAAApSDUAAAAAAAASkGoAQAAAAAAlIJQAwAAAAAAKAWhBgAAAAAAUApCDQAAAAAAoBSEGgAAAAAAQCkINQAAAAAAgFIQagAAAAAAAKUg1AAAAAAAAEpBqAEAAAAAAJSCUAMAAAAAACgFoQYAAAAAAFAKQg0AAAAAAKAUhBoAAAAAAEApCDUAAAAAAIBSEGoAAAAAAAClINQAAAAAAABKQagBAAAAAACUglADAAAAAAAoBaEGAAAAAABQCkINAAAAAACgFIQaAAAAAABAKZQm1Pjxj3+czTffPIMGDcpiiy0223VeeeWV7LLLLllkkUWy1FJL5fDDD8/06dPnb6EAAAAAAMA8UVvtAubW9OnT89WvfjWbbbZZLrvsslmeb2try84775yll146Dz74YN58883svffeKYoi5513XhUqBgAAAAAA+lJpQo0TTzwxSXLllVfO9vm77rorzz77bF599dWMHDkySXLmmWdmn332yY9//OMMHTp0fpUKAAAAAADMA6UJNT7KI488krXXXrsz0EiSHXfcMc3NzXnyySez7bbbzna75ubmNDc3dz6eMmVKkqSlpSUtLS3ztuh5ZOa6W1paUltbvbe5o5ZqtWV/agv6n2r3T5gTfZP+TP+kP9M/6c/0T/oz/ZP+TP+kP9M/+9bctuMCc4Z30qRJGTZsWJdliy++eOrr6zNp0qQ5bnfqqad23gUys7vuuiuDBg3q8zrnh5nf/Lvuuit1dXVVrGaGCRMmVOW4/bEt6H+q1T/ho+ib9Gf6J/2Z/kl/pn/Sn+mf9Gf6J/2Z/tk33n///blar6qhxpgxY2YbKMzs8ccfz0YbbTRX+6tUKrMsK4pitss7HHfccTnqqKM6H0+ZMiXLL798dthhh9IOWTVt2rScf/75SZIddtghAwcOrFotLS0tmTBhQrbffvuqBAr9qS3of6rdP2FO9E36M/2T/kz/pD/TP+nP9E/6M/2T/kz/7Fsdoyh9lKqGGocddli+/vWvf+g6K6200lzta/jw4Xnssce6LHvrrbfS0tIyyx0cM2toaEhDQ8Msy+vq6krbEVtbWzt/7i+vo1p19Me2oP/RN+iv9E36M/2T/kz/pD/TP+nP9E/6M/2T/kz/7Btz24ZVDTWWWmqpLLXUUn2yr8022yw//vGPM3HixIwYMSLJjOGGGhoa8slPfrJPjgEAAAAAAFRPaebUeOWVVzJ58uS88soraWtry9NPP50kWW211TJ48ODssMMOWWuttfLNb34zZ5xxRiZPnpyjjz46BxxwQGmHkQIAAAAAAP6lNKHGj370o1x11VWdjzfYYIMkyb333pttttkmNTU1uf3223PIIYdkiy22yMCBA7PHHnvkJz/5SbVKBgAAAAAA+lBpQo0rr7wyV1555Yeus8IKK+S///u/509BAAAAAADAfDWg2gUAAAAAAADMDaEGAAAAAABQCkINAAAAAACgFIQaAAAAAABAKQg1AAAAAACAUhBqAAAAAAAApSDUAAAAAAAASkGoAQAAAAAAlIJQAwAAAAAAKAWhBgAAAAAAUApCDQAAAAAAoBSEGgAAAAAAQCkINQAAAAAAgFIQagAAAAAAAKUg1AAAAAAAAEpBqAEAAAAAAJSCUAMAAAAAACgFoQYAAAAAAFAKQg0AAAAAAKAUaqtdAHyYoijS1NTU4+1n3rY3++nQ2NiYSqXS6/0AAAAAANB9Qg36taampowaNapP9jV69Ohe72P8+PEZOHBgH1QDAAAAAEB3GX4KAAAAAAAoBXdq0K81NjZm/PjxPd6+KIo0NzcnSRoaGno9dFRjY2OvtgcAAAAAoOeEGvRrlUql18M9DRo0qI+qAQAAAACgmgw/BQAAAAAAlIJQAwAAAAAAKAWhBgAAAAAAUApCDQAAAAAAoBSEGgAAAAAAQCkINQAAAAAAgFIQagAAAAAAAKUg1AAAAAAAAEpBqAEAAAAAAJSCUAMAAAAAACgFoQYAAAAAAFAKQg0AAAAAAKAUhBoAAAAAAEApCDUAAAAAAIBSEGoAAAAAAAClINQAAAAAAABKQagBAAAAAACUglADAAAAAAAoBaEGAAAAAABQCkINAAAAAACgFIQaAAAAAABAKQg1AAAAAACAUhBqAAAAAAAApSDUAPj/7d13YBTl+vbxa1NI6CVEelNBgdCkIyhFQKQooIBw6L0JoYUqSBEkBELvkV4DSAm99140EpDeixBKCKQ/7x+82V+i6PEIZLPh+/nnsLMz672cm9mZuWaeBwAAAAAAAIBdINQAAAAAAAAAAAB2gVADAAAAAAAAAADYBUINAAAAAAAAAABgFwg1AAAAAAAAAACAXSDUAAAAAAAAAAAAdoFQAwAAAAAAAAAA2AVCDQAAAAAAAAAAYBcINQAAAAAAAAAAgF0g1AAAAAAAAAAAAHaBUAMAAAAAAAAAANgFQg0AAAAAAAAAAGAXCDUAAAAAAAAAAIBdINQAAAAAAAAAAAB2gVADAAAAAAAAAADYBUINAAAAAAAAAABgFwg1AAAAAAAAAACAXSDUAAAAAAAAAAAAdoFQAwAAAAAAAAAA2AVCDQAAAAAAAAAAYBcINQAAAAAAAAAAgF1wsnUB+DNjjMLCwv719nG3fZnPkSRXV1dZLJaX+gwAAAAAAAAAAF4FQo1EKCwsTDVq1Hgln1W3bt2X2n7Dhg1Knjz5K6kFAAAAAAAAAICXwfBTAAAAAAAAAADALvCkRiLk6uqqDRs2/OvtjTEKDw+XJLm4uLzU8FGurq7/elsAAAAAAAAAAF4lQo1EyGKxvPSQTylSpHhF1QAAAAAAAAAAkDgw/BQAAAAAAAAAALALhBoAAAAAAAAAAMAuEGoAAAAAAAAAAAC7QKgBAAAAAAAAAADsAqEGAAAAAAAAAACwC4QaAAAAAAAAAADALhBqAAAAAAAAAAAAu0CoAQAAAAAAAAAA7AKhBgAAAAAAAAAAsAuEGgAAAAAAAAAAwC4QagAAAAAAAAAAALtAqAEAAAAAAAAAAOwCoQYAAAAAAAAAALALhBoAAAAAAAAAAMAuEGoAAAAAAAAAAAC7QKgBAAAAAAAAAADsAqEGAAAAAAAAAACwC4QaAAAAAAAAAADALhBqAAAAAAAAAAAAu0CoAQAAAAAAAAAA7AKhBgAAAAAAAAAAsAuEGgAAAAAAAAAAwC4QagAAAAAAAAAAALtAqAEAAAAAAAAAAOwCoQYAAAAAAAAAALALhBoAAAAAAAAAAMAuEGoAAAAAAAAAAAC7QKgBAAAAAAAAAADsAqEGAAAAAAAAAACwC4QaAAAAAAAAAADALhBqAAAAAAAAAAAAu0CoAQAAAAAAAAAA7AKhBgAAAAAAAAAAsAuEGgAAAAAAAAAAwC4QagAAAAAAAAAAALtAqAEAAAAAAAAAAOwCoQYAAAAAAAAAALALhBoAAAAAAAAAAMAuEGoAAAAAAAAAAAC7QKgBAAAAAAAAAADsAqEGAAAAAAAAAACwC4QaAAAAAAAAAADALhBqAAAAAAAAAAAAu0CoAQAAAAAAAAAA7AKhBgAAAAAAAAAAsAuEGgAAAAAAAAAAwC4QagAAAAAAAAAAALtAqAEAAAAAAAAAAOwCoQYAAAAAAAAAALALhBoAAAAAAAAAAMAuEGoAAAAAAAAAAAC7QKgBAAAAAAAAAADsAqEGAAAAAAAAAACwC4QaAAAAAAAAAADALhBqAAAAAAAAAAAAu0CoAQAAAAAAAAAA7AKhBgAAAAAAAAAAsAuEGgAAAAAAAAAAwC4QagAAAAAAAAAAALtAqJFE7d+/Xw0bNtT+/fttXQoAAAAAAAAAAK8EoUYSFBYWprFjx+rOnTsaO3aswsLCbF0SAAAAAAAAAAAvjVAjCVq4cKHu378vSbp//74WLVpk44oAAAAAAAAAAHh5hBpJzPXr17Vo0SIZYyRJxhgtWrRI169ft3FlAAAAAAAAAAC8HEKNJMQYo/Hjx//l8tigAwAAAAAAAAAAe0SokYRcvXpVR44cUXR0dLzl0dHROnLkiK5evWqjygAAAAAAAAAAeHmEGklIzpw5VbJkSTk6OsZb7ujoqFKlSilnzpw2qgwAAAAAAAAAgJdHqJGEWCwWdevW7S+XWywWG1QFAAAAAAAAAMCrQaiRxGTPnl2NGze2BhgWi0WNGzdWtmzZbFwZAAAAAAAAAAAvh1AjCWrSpInc3NwkSRkzZlTjxo1tXBEAAAAAAAAAAC+PUCMJcnV1VY8ePZQpUyZ5enrK1dXV1iUBAAAAAAAAAPDSnGxdAF6PcuXKqVy5crYuAwAAAAAAAACAV4YnNQAAAAAAAAAAgF0g1AAAAAAAAAAAAHaBUAMAAAAAAAAAANgFQg0AAAAAAAAAAGAXCDUAAAAAAAAAAIBdINQAAAAAAAAAAAB2gVADAAAAAAAAAADYBUINAAAAAAAAAABgFwg1AAAAAAAAAACAXSDUAAAAAAAAAAAAdsEuQo3Lly+rdevWypMnj5InT6533nlHgwcPVkRERLz1rl69qtq1aytlypTKmDGjvvnmmz+tAwAAAAAAAAAA7JOTrQv4J86cOaOYmBhNnz5d7777rgIDA9W2bVuFhoZqzJgxkqTo6GjVrFlT7u7u2rt3r+7fv6/mzZvLGKOJEyfa+BsAAAAAAAAAAICXZRehxqeffqpPP/3U+vrtt9/W2bNnNXXqVGuosXnzZp0+fVrXrl1T1qxZJUk+Pj5q0aKFRowYoTRp0tikdgAAAAAAAAAA8GrYxfBTL/Lo0SNlyJDB+vrAgQPy8PCwBhqSVL16dYWHh+vYsWO2KBEAAAAAAAAAALxCdvGkxh9duHBBEydOlI+Pj3XZ7du3lSlTpnjrpU+fXsmSJdPt27f/8rPCw8MVHh5uff348WNJUmRkpCIjI19x5W+e2L9D/i6RGNGfSKzoTSRm9CcSM/oTiRn9icSM/kRiRn8iMaM/X61/+vdoMcaY11zLXxoyZIi+++67v13nyJEjKlGihPX1zZs39fHHH+vjjz/WrFmzrMvbtWunK1euaNOmTfG2T5YsmebNm6dGjRr9TzUsWrRIKVKk+F++DgAAAAAAAAAA+BeePn2qxo0b69GjR387nYRNQ4179+7p3r17f7tO7ty55erqKul5oFGpUiWVLl1ac+bMkYPD/42e9e2332r16tU6deqUddmDBw+UIUMGbd++XZUqVXrh57/oSY0cOXLo3r17zMPxCkRGRmrLli2qWrWqnJ2dbV0OEA/9icSK3kRiRn8iMaM/kZjRn0jM6E8kZvQnEjP689V6/PixMmbM+F9DDZsOP5UxY0ZlzJjxH61748YNVapUScWLF9ePP/4YL9CQpLJly2rEiBG6deuWsmTJIun55OEuLi4qXrz4X36ui4uLXFxc/rTc2dmZRnyF+PtEYkZ/IrGiN5GY0Z9IzOhPJGb0JxIz+hOJGf2JxIz+fDX+6d+hXcypcfPmTVWsWFE5c+bUmDFj9Pvvv1vfy5w5sySpWrVqKlCggJo2bSpvb28FBwerV69eatu2LU9cAAAAAAAAAACQBNhFqLF582adP39e58+fV/bs2eO9Fzt6lqOjowICAtSpUyd9+OGHSp48uRo3bqwxY8bYomQAAAAAAAAAAPCK2UWo0aJFC7Vo0eK/rpczZ06tW7fu9RcEAAAAAAAAAAASnMN/XwUAAAAAAAAAAMD2CDUAAAAAAAAAAIBdINQAAAAAAAAAAAB2gVADAAAAAAAAAADYBUINAAAAAAAAAABgFwg1AAAAAAAAAACAXSDUAAAAAAAAAAAAdoFQAwAAAAAAAAAA2AVCDQAAAAAAAAAAYBcINQAAAAAAAAAAgF0g1AAAAAAAAAAAAHaBUAMAAAAAAAAAANgFQg0AAAAAAAAAAGAXCDUAAAAAAAAAAIBdINQAAAAAAAAAAAB2gVADAAAAAAAAAADYBUINAAAAAAAAAABgFwg1AAAAAAAAAACAXSDUAAAAAAAAAAAAdoFQAwAAAAAAAAAA2AVCDQAAAAAAAAAAYBcINQAAAAAAAAAAgF0g1AAAAAAAAAAAAHaBUAMAAAAAAAAAANgFQg0AAAAAAAAAAGAXCDUAAAAAAAAAAIBdINQAAAAAAAAAAAB2gVADAAAAAAAAAADYBUINAAAAAAAAAABgFwg1AAAAAAAAAACAXSDUAAAAAAAAAAAAdoFQAwAAAAAAAAAA2AVCDQAAAAAAAAAAYBcINQAAAAAAAAAAgF0g1AAAAAAAAAAAAHaBUAMAAAAAAAAAANgFQg0AAAAAAAAAAGAXCDUAAAAAAAAAAIBdINQAAAAAAAAAAAB2gVADAAAAAAAAAADYBUINAAAAAAAAAABgFwg1AAAAAAAAAACAXSDUAAAAAAAAAAAAdoFQAwAAAAAAAAAA2AVCDQAAAAAAAAAAYBcINQAAAAAAAAAAgF0g1AAAAAAAAAAAAHaBUAMAAAAAAAAAANgFQg0AAAAAAAAAAGAXCDUAAAAAAAAAAIBdINQAAAAAAAAAAAB2gVADAAAAAAAAAADYBUINAAAAAAAAAABgFwg1AAAAAAAAAACAXSDUAAAAAAAAAAAAdoFQAwAAAAAAAAAA2AVCDQAAAAAAAAAAYBcINQAAAAAAAAAAgF0g1AAAAAAAAAAAAHaBUAMAAAAAAAAAANgFQg0AAAAAAAAAAGAXCDUAAAAAAAAAAIBdINQAAAAAAAAAAAB2gVADAAAAAAAAAADYBUINAAAAAAAAAABgFwg1AAAAAAAAAACAXSDUAAAAAAAAAAAAdoFQAwAAAAAAAAAA2AVCDQAAAAAAAAAAYBcINQAAAAAAAAAAgF0g1AAAAAAAAAAAAHaBUCOJ2r9/vxo2bKj9+/fbuhQAAAAAAAAAAF4JQo0kKCwsTGPHjtWdO3c0duxYhYWF2bokAAAAAAAAAABeGqFGErRw4ULdv39fknT//n0tWrTIxhUBAAAAAAAAAPDyCDWSmOvXr2vRokUyxkiSjDFatGiRrl+/buPKAAAAAAAAAAB4OYQaSYgxRuPHj//L5bFBBwAAAAAAAAAA9ohQIwm5evWqjhw5oujo6HjLo6OjdeTIEV29etVGlQEAAAAAAAAA8PIINZKQnDlzqmTJknJ0dIy33NHRUaVKlVLOnDltVBkAAAAAAAAAAC+PUCMJsVgs6tat218ut1gsNqgKAAAAAAAAAIBXg1AjicmePbsaN25sDTAsFosaN26sbNmy2bgyAAAAAAAAAABeDqFGEtSkSRO5ublJkjJmzKjGjRvbuCIAAAAAAAAAAF4eoUYS5Orqqh49eihTpkzy9PSUq6urrUsCAAAAAAAAAOClOdm6ALwe5cqVU7ly5WxdBgAAAAAAAAAArwxPagAAAAAAAAAAALtAqAEAAAAAAAAAAOwCoQYAAAAAAAAAALALhBoAAAAAAAAAAMAuEGoAAAAAAAAAAAC7QKgBAAAAAAAAAADsAqEGAAAAAAAAAACwC4QaAAAAAAAAAADALhBqAAAAAAAAAAAAu0CoAQAAAAAAAAAA7AKhBgAAAAAAAAAAsAuEGgAAAAAAAAAAwC4QagAAAAAAAAAAALtAqAEAAAAAAAAAAOwCoQYAAAAAAAAAALALhBoAAAAAAAAAAMAuEGoAAAAAAAAAAAC7QKgBAAAAAAAAAADsAqEGAAAAAAAAAACwC4QaAAAAAAAAAADALhBqAAAAAAAAAAAAu0CoAQAAAAAAAAAA7AKhBgAAAAAAAAAAsAuEGgAAAAAAAAAAwC4QagAAAAAAAAAAALtAqAEAAAAAAAAAAOwCoQYAAAAAAAAAALALhBoAAAAAAAAAAMAuEGoAAAAAAAAAAAC7QKgBAAAAAAAAAADsgpOtC0hsjDGSpMePH9u4kqQhMjJST58+1ePHj+Xs7GzrcoB46E8kVvQmEjP6E4kZ/YnEjP5EYkZ/IjGjP5GY0Z+vVuw1+dhr9H+FUOMPQkJCJEk5cuSwcSUAAAAAAAAAALxZQkJClDZt2r9832L+W+zxhomJidHNmzeVOnVqWSwWW5dj9x4/fqwcOXLo2rVrSpMmja3LAeKhP5FY0ZtIzOhPJGb0JxIz+hOJGf2JxIz+RGJGf75axhiFhIQoa9ascnD465kzeFLjDxwcHJQ9e3Zbl5HkpEmThn/YSLToTyRW9CYSM/oTiRn9icSM/kRiRn8iMaM/kZjRn6/O3z2hEYuJwgEAAAAAAAAAgF0g1AAAAAAAAAAAAHaBUAOvlYuLiwYPHiwXFxdblwL8Cf2JxIreRGJGfyIxoz+RmNGfSMzoTyRm9CcSM/rTNpgoHAAAAAAAAAAA2AWe1AAAAAAAAAAAAHaBUAMAAAAAAAAAANgFQg0AAAAAAAAAAGAXCDWQJDA1DAAAAAAAAAAkfYQasGsDBw5UZGSkLBYLwQYAAImQMSbeb3R0dLQNqwEAAACkM2fO2LoEAC+BUAN268KFC/L19dUnn3yiqKgogg0AABIhi8Uii8WidevW6c6dO3J0dLR1SQBgNzi/AYBXb9iwYWratKn2799v61IA/EuEGrBbefLk0a5du3Tjxg1VrFiRJzaQaMTExMR7TU/CXvyxdyX6F6/GwYMHVadOHa1du9bWpQCSXry/i8V+D4lBbB9aLJYXLgcSEn2HpCZ//vxyd3fX8OHDtXfvXluXA+BfsBh+nWCHoqOjrXd6Hjx4UHXr1lXp0qW1fPlyOTs7yxjzpxMAICHExMTIweF5Xvzbb78pZcqUcnd3V7JkyWxcGfD3wsLC5OrqKun5k3ApU6ZUhgwZlCxZsnj7XOB/FRQUpP379+vBgwfq1auXrcsB4v1WL168WIGBgUqWLJkKFy6sunXr2rg6QNZzmb1792rTpk1ydHRU7ty51aJFC1uXhjdQ3H3m48ePFRYWprfeesvGVQEvb/PmzZoxY4aePn2qIUOGqFSpUrYuCUlc3P3pH3Ed83/HkxqwO8YY68W1YcOGacKECUqVKpXWrFmjTz/9lKGoYBMTJ07UwYMHrT9Qffv21eeff66CBQuqZ8+e3P2BRKt///4KDw+3BhoDBw5U5cqVVblyZdWrV08PHz6Uo6Mj8yDgX7l8+bKaNGminj17WveP9BJsLbYX+/Tpo169eunGjRs6f/68WrVqpe+//97G1QHPn85YuXKlqlevrhMnTmjz5s3q2rWrvvzyS4WFhUniznkkjLgX4EaMGKGaNWuqWLFiatWqlU6ePGnb4oB/Ie6TmsmSJVOGDBl0+PBh9e/fX4cPH7ZhZUjq4u5P/fz81LFjR3Xo0EGTJ0+W9OcnM/HfEWrA7sT+Qx8zZox8fHzUtm1bLVq0SD/++KPOnTunKlWqEGwgQe3bt09jxozRtGnTFBgYqICAAC1atEje3t4aPHiwjh8/rtGjR2vLli22LhWI5+eff9aPP/6oTz75RMYYbdu2TbNnz5avr6/atm2rhw8fqlixYnrw4AHBBv6VNGnSqH79+kqbNq127NghSfQSEoX169dr6dKlWrFihebMmaPq1asrLCxMWbJksXVpgK5du6ZevXpp5MiRWrdunbZt26YNGzbowIEDat68uSQufiBhxF6AGzRokCZNmqQmTZpo6dKlCggI0KBBg7R161YbVwj8M7HXhmJ7ukePHmrTpo3Spk2rGjVq6PTp0/r222+ZYwOvTdybagYOHCgXFxe5ubmpa9eu6tmzp42rs0+EGrAbfxz7+OjRo2rRooUqVaqkkiVL6j//+Y8WLlyoM2fOqE6dOsyxgQTz4YcfytvbW6dPn9aUKVO0fft2DRgwQLVq1ZKnp6eGDRumsLAwjR8/ngN/JCoFChTQ/PnzFRoaqo8++kgXL17U0KFDVbduXXl6emrKlCnKnDmzPvjgA4IN/CsZMmRQx44d1a1bNwUGBqpLly6SCDZge5cvX5aHh4fKlCmjlStXqlOnTho/frxatmypJ0+e6NChQ7YuEW+wR48eyRijqlWrSpKSJ0+u8uXLa+HChdq4caOWL19u4wrxJtm2bZtWrlyppUuXqkOHDnJyctKjR490/PhxDRw40HrTApCYxQ2Cjxw5omXLlsnPz0/e3t6aP3++JkyYoIiICA0ZMkRHjx61YaVIynbv3q0VK1bI399fvr6+KlGihJIlS6Z8+fLZujS7RKgBu2CMsaaasZOMhoSEKCgoyLqOo6Ojypcvr6ZNm2rjxo0qU6aMoqOjuYsJr1VERIQkqUGDBurXr58OHz6s2bNn6/79+9Z1KleurL59+yoiIkITJ07UunXrbFUuYBUdHS0nJyd9/PHHGjt2rJ4+faoOHTro2bNn1nUKFy6sGTNmKGvWrCpRooTu3bvH3Br4S7E3EZw+fdp6Z/Ht27eVIUMGNWvWTJ07d9auXbv0zTffSHr+u/13kzUDr0Nszzk6Oipz5sxasWKFmjdvLm9vb7Vr106StH37dq1YsUL37t2zZal4g7m5uen+/ft/GgqlaNGiypEjh27evGmjyvAmSpcunbp27aqPPvpImzdvVs2aNTVr1iydPHlSQUFBGjNmjPUcHUhsvv76a82cOTPeMkdHRz158iTeec2XX36ptm3bas+ePRowYIB27tyZwJXiTXDjxg1lzZpV5cqV06pVq9SsWTNNmDBB7du31+PHj7V9+3Zbl2hXCDWQ6MWdLGf48OHq0KGDLl68qCZNmujGjRtavHixdV2LxaK8efOqUaNGKlCggK1KxhsiJCTEOgG4v7+/atSooSFDhihLlizatGlTvDs8KleurH79+unatWvatWuXrUoGJEm3b9+2HsSvX79eFStW1KhRo1S0aFHNnDnTGtZJUqFChTR9+nQ5ODioffv2tioZiVzsb/XKlStVs2ZN9ezZU/369VO9evV07tw5ZcyYUc2bN1fz5s21Z88etWrVSpL+cqI84FX5Y3AW23O5cuXSwoUL9dVXX2n06NHW/dvTp081ZcoUhYSEyM3NLcHrxZsnNhCO26sZMmRQvXr1tHDhQm3bts26PF26dHJzc7OuyxPpeNVedLPB+++/ry+++ELPnj3T2LFj1a1bNzVp0kQZMmTQe++9py1btnAhDonS77//rvLly6tFixbxlidLlkyZMmXSxYsXJf3fvvTrr79W/vz5df78eQUEBCR0uXgDpEqVSunTp5efn5+aNWumMWPGWG+qOXTokBYsWKBr167ZuEr7wZkkEr3YQOP48eMKCgrSggUL9Pbbb6tcuXJ67733NG/ePPn5+Ul6/qMVEBCgggULav78+Qxvgddm+/btevvtt/Xs2TP16tVLPXv2VHBwsGrVqqXhw4crNDRUkyZN0vHjx63bVKpUSbNmzdIPP/xgw8rxptu4caMaN26sU6dOydPTU3Xr1tWdO3dUqVIljR49WpJUsWLFeMGGh4eHNm3apGXLltmqbCRyFotF27ZtU+vWreXl5aWzZ8/Ky8tLBw8eVPXq1XX69Gm5u7urefPmqlu3rs6ePas7d+7YumwkcXGf9F2+fLmmT5+uGTNmKCQkRJ9++qnGjBkjSQoNDdXOnTt14MABffHFF7p9+7YmTpzIMKZ47WID4c2bN6tHjx5q1aqVfv31V7m4uKhTp06KiYnRiBEjNHXqVB04cEA9e/bUL7/8ojp16khiXg28WuHh4dZ95qlTp3T+/HndvXtXKVOmVObMmRUeHq579+4pS5YsslgsioqKUrFixbRr1y7r/hRITNzd3dW5c2c5Oztr6tSp6t+/v6Tn5zblypVTjx49tGfPHuv6d+/e1bvvvqtvv/2Wc3a8lL96Gv2tt97SqVOn1KZNGw0ZMsR6U82zZ880btw4GWOUPXv2hCzVrlkMR+qwAwsWLND06dMVGhqqtWvXKlu2bJKkwMBAjRo1Snv27FF4eLjSpEkjFxcXnThxQk5OTjauGklR7Mnn1atX1aJFC/3yyy+KjIzU8ePH9fbbb1vXW7p0qby9veXh4aFu3bqpWLFi8T4nJiaGO5SRoB4/fqw0adLo/Pnzql27tiIiIhQcHKxdu3apcOHCkp4PSbVjxw716tVLKVOm1I4dO6xPI8WKjo5mCCr8yZMnT9S9e3flzJlT3377rW7duqXSpUurTJky+v3333Xp0iVt3bpV7777ru7duycHBwdlyJDB1mUjCYv7pK+np6fmzp2rLFmyKDQ0VBEREVqwYIEqV66sMWPGaPLkyXr48KHy5cunDBkyaM2aNXJ2dmZ/hwSxadMm1a5dW7Vq1VJQUJBu376tcePGqUWLFjpy5Ihmz56tJUuWKEuWLHJ2dta8efNUtGhRW5eNJKRjx47q0aOH8ubNK0nq16+f5syZI1dXV2XMmFGzZs1SkSJFdPfuXVWpUkVvv/22KleurICAAN2/f19Hjx6VxWJhn4lEKyQkRIMHD9aaNWvUvHlzDRo0SJL0xRdfaM+ePWrZsqUyZ86sgIAARUdHa+fOnXJwcOCcHf9K3GPQ6dOn6+bNm3J1dVXfvn1lsVg0b948tWjRQl27dtWHH36oNGnSyMfHR3fv3tWxY8fk5OQU7zPw1wg1YBd27Nihvn376ueff9bs2bPVuHFj63v37t3TvXv3tGnTJrm5ualRo0ZycnLioAqv3JdffqlcuXLJx8dHkuTl5SVvb29lypRJgYGBcnNzU2RkpJydnSVJy5Yt09ixY+Xu7i4fHx8mf4LN9OrVS2FhYerXr5+yZcum3r17y9fXV6VKlZKvr69KlixpXTc22PDy8lJISIhOnz5NSIx/ZPv27XJxcVHBggVVuXJllSpVStOmTdP8+fPVvHlzpU6dWgcPHlT+/PltXSreIOfOnVOHDh00duxY5c6dWzExMWrbtq127dqlTZs26YMPPtCFCxcUFhamlClTKleuXNY7kNn34XWJvVjx8OFDjRgxQnnz5rUOP9GxY0etWLFCo0aNUsuWLWWxWHTv3j2FhoYqTZo0Sp8+vY2rR1Jy4cIFNWjQQI8ePdL27dv14MED1apVS3PnztWtW7e0Zs0arVu3Tjt37lTJkiV1/PhxtWzZUsmTJ1fatGm1bt06OTs7cwEOid7169c1a9YsLV26VF9//bW+/fZbSdLAgQN1/Phx3b59W7lz59bSpUvl7OxMoIGXNnjwYE2aNEmFCxfWxYsXlSZNGu3evVvp06fX7NmzNW/ePJ08eVKFChWSu7u7li1bxk01/yNCDSQ6f/XjcfjwYXl6eiplypTq1auXqlWrJkkvPIBiJ4DXYfLkyerevbsGDhyowYMHKzAwUHfv3tWoUaMUFBSkvXv3KleuXAoPD5eLi4uk58NdrF+/XrNnz+agCDbTvXt37d27V9WrV1efPn104sQJhYeHq2/fvnrrrbfUr18/VaxY0bp+dHS0tm3bpnnz5mnu3LnsT/Enf3fxYv369Ro1apQWLlyoHDlyaOfOnRo1apSyZs2qvn37EvDitYrbm/PmzdOkSZOUNm1arVq1SilTprS+V6NGDd26dUvHjh370z6OCxl4Hfz9/VW4cGHrPvDYsWP67LPPlC1bNg0bNkw1a9a0rtuxY0f5+/vL29tbn3/+OUEGXqtjx45pwIABOnfunDp37qyYmBj16tVLknTlyhX16dNHa9eu1c6dO1WqVCkFBwfL0dFRadKkIQSGXblx44amT5+uZcuW6euvv9bgwYMlPR+GUpJSpEhBT+Nfi3v8aIxR69at1alTJxUpUkRBQUFq1aqVQkJCtH//frm5uen+/fsKDQ21zrNB7/3vOFpHohJ3J3D27FkdOnRI9+/fV1RUlEqVKqWRI0fq2bNnmjx5srZs2SJJLxzvmAtweB06d+6smTNnaujQoRoyZIg8PDxUuXJlTZ8+XXnz5lX58uV1/fp1a6AxdepU1apVSz/++KP18VUgIcXuG319fVWzZk2tX79eY8aMUf78+VW9enUtWbJEt27d0siRI+ONJztnzhxVq1ZNCxYsYG4i/EnsReN9+/bJ19dX8+fP15MnT6zv37hxQ4cPH7b+Fm/evFlZsmTRxIkTCTTwWsXExFhDi2vXrunq1at68uSJLly4oFSpUslisSgsLEyS1Lt3bwUHB+u333770+cQaOBVMsbo1KlTGjBggFKkSGFdXrx4cZUpU0YnT57UhQsXFBUVZX1v6tSpatSokdq0aaOAgADmdsFrEdtXxYsX1/Dhw1WgQAHrvjH2/Vy5cmn06NGqU6eOqlSpov379ytDhgxKmzatLBaLYmJiuAAHu5EtWza1b99eDRo00NKlSzVs2DBJUsqUKa03Phhj6Gn8z+JeywwMDNShQ4f0+++/K1WqVHJ2dlbhwoW1YMECpUmTRuXLl1dwcLDc3NyUM2dOZciQgd77twyQSMTExFj/3L9/f1OwYEGTMmVKU7lyZTNixAjz7NkzY4wxO3fuNBUqVDB169Y1a9eutVW5eIP5+fkZBwcHM3jwYOuyS5cumcqVK5tMmTKZxYsXm8qVK5sPPvjAREdH265QwJh4PTho0CBTrFgx069fP3Pjxg1jjDFnz541RYoUMZ988okZN26cqV27tkmTJg29i78VEBBgnJ2dTfny5Y3FYjFffPGF2bt3rzHGmMuXL5sKFSqYLFmymOrVq5sUKVKYX375xcYV403SqVMn07VrV3Px4kUzYcIE4+bmZpo1axZvnf3795vs2bPTm0gwDx8+NMYYExgYaH7++Wfr8i+++MJkyJDBbNiwwURGRsbbpmfPnubs2bMJWifeDLHn3nGP9w4cOGBq1Khh3NzczPnz5+Otd+XKFVO1alVTqVKlhC8WeMWuX79uBg8ebNKnT29+/PFHW5eDJKRPnz4mQ4YMpmDBgiZ58uRm27Zt8d4/c+aMKV26tMmQIYN59OiRjapMOhh+ConO8OHDNWnSJM2bN0+lS5dWy5YtdfToUTVo0EDDhg1T8uTJtXv3brVv316ff/65Ro0aZeuSkYSZ/39HcuyuMvYO0B9//FFt2rTRoEGDNGTIEEnSnTt39M033+j06dPKkSOHVq9ezXicsBnzF8MDDRo0SAEBAfr000/VuXNnZcuWTefPn1e3bt0UEhKi5MmTW8dHpnfxVzp06KAiRYqoY8eOOnPmjOrVq6c8efJowIABKleunI4cOaKffvpJT58+Vbt27ZhHAwnm8uXLqlWrlqZOnaoKFSroyZMnmjVrlqZNm6ZChQpp2LBhevz4sYYMGaIHDx5o37597Ofw2hhjFBMTY31y7d69eypUqJA+/fRT9ezZUx4eHpKkWrVq6fDhw5o7d66qVq3KnZp4reIe3z19+lQRERFKly6dJOmXX35R9+7ddfHiRW3dulXvvPOO9Zjyzp07cnd3Z5+JJOHq1avavHmzWrZsyUgf+NfiDn2/YcMG9erVSyNHjlRMTIx8fHx069YtrV27Nt65UGBgoMaNG6cZM2bQey+JUAOJyqlTp9SuXTsNHTpU1atX1/bt21W7dm1VrFhRFy5c0BdffKEhQ4bI1dXVOqEOOwG8LnEP+B8+fKjIyEi5u7tb3/fz81Pbtm01aNAgDR482HoB+cqVK8qZMydjIsJm4vbugwcPFBMTo3Tp0ln3lwMHDtT69ev16aefqkuXLsqaNaseP36s8PBwZcyYkd7Fn8Re0Lh+/bqcnZ01YcIEff755ypVqpQkKSgoSF999ZVy5MihIUOGqHTp0pKYmwAJ6/vvv9f58+fl5OSkKVOmWPdhjx490pw5c/Tdd98pPDxc9erVU4oUKeTr66vkyZMzFxteudh9X0REhJIlSybp+cXiAgUKaMWKFfLy8lKNGjXUqVOneMHGiRMnNGXKFNWsWZPfYLx2Q4cO1YYNG3T37l1Vq1ZNrVq1UsmSJRUYGChPT09duHBB27ZtU548eeJtx287EpMX9eNf3dz1v3wG8Hdu3ryprFmzWl/PmjVLN2/elKOjowYMGCDp+Xl47dq1dffuXa1evfqFN3lxDPpy+FcLm/pjpubh4aGOHTuqTJky2r17txo3bqzx48crICBAWbJk0Zw5c9S5c2eFhYWpaNGijPWO1ybugc3IkSNVo0YNlStXTl988YUuXbqk6OhotWrVSjNnztSIESM0bNgwRUZGSpJy5crFGLOwmbi9O3z4cH355ZfKnz+/+vbta52LaPjw4frss8+0adMmTZkyRTdu3FCaNGnk7u5O7+KFLBaLli9fro8++kiFChWSt7e3Dh06ZH0/f/788vf3161bt9SjRw/t27fPuh2QEKKiohQWFqY5c+bo559/tu4Ho6OjlTZtWrVq1UrffvutChQoIEdHR02fPl3JkyfXs2fPOJnEK+fg4KDr16+rTJkyevbsmTZs2KDKlSvr5MmTatCggUaPHq21a9dqypQpCgwMlCStW7dO77zzjnr37q3w8HAbfwMkRXHPm8eMGWO9QaFz587aunWrvLy8tGbNGnl4eMjb21vvv/++ChYsqJs3b8b7HC7+IrGIe95z9OhR7dixQ7/++qt1/qy/2y7WvXv36Gn8Tz7//HMtXrxY0v9d05w0aZKGDBmi06dPW/e16dOn17p165QpUybVq1dPv/zyy58+i2PQl2STQa+AP5g/f76ZM2eOMcaYsLAwY4wxbdq0Md26dbOOLdupUydTokQJ4+npyVjvSDADBgwwWbJkMVOnTjWHDx82mTJlMtWqVTMHDhyw9qGfn5+xWCzGz8/PxtUC/2fgwIEmY8aMZt68eWbBggWmVKlSpkKFCmbVqlXWdQYNGmSyZ89upk2bZrtCkSjFnefKGGMuXrxo8ufPb7y9vc2iRYtMyZIlTfny5c2KFSvirRcYGGjKli1rrl69mpDl4g30xx41xpjg4GAzduxY4+DgYMaPH29dHvt7/eDBAzN27FhTqFAh06VLlwSrFW+m48ePm8qVK5vs2bMbJycns3z5cmPM//XusmXLTPbs2U3Hjh3jze3C/hOv27Fjx4yPj0+8Y8LLly+batWqmcqVK1vnXdu3b5/x9PQ0UVFRNqoU+GtxjwP69etn8uTJYzw8PEyWLFlMq1atzLFjx/7rdpMnTzatW7e2znkE/BMrV6404eHhxhhj7t+/b11eu3ZtkyFDBrNly5Z4c2Q9ePDA5MuXzzRs2DDBa03qCDVgUzExMSY4ONh8/vnnplmzZtbJwI0xplatWqZRo0bW1w0bNjQLFy584aRmwOuwbds24+HhYXbu3GmMMWb79u0mZcqUxt3d3RQsWNAcPHjQepC/bt26P03uCNjKhg0bTP78+c3BgweNMcbs3r3bODs7m+LFi5ty5cqZtWvXWtedPn06J6uIJ/bmgti+OH78uOnWrZvp1KmT9bc3KCjIVKtWzVStWvVPwUZERETCFow3TtxjwCdPnpiQkBDr68ePH5vhw4cbi8Vipk+f/qdtHj58aMaPH2+yZ89uevTokXBF440R94LZtGnTjMViMW+99Zb5/fffjTHGeiHEmOfBRu7cuc1//vMfc/r06QSvFUmfl5eXuXTpkvX1/v37jcViMY6Ojmb+/PnGmP/7vb927ZpJmzZtvFA4FseKSEzi7mcnTJhgMmfObPbs2WOMMaZHjx4mderUZvfu3X+73fTp003y5MnNsmXLXn/BSBL+eEONr6+vad++vQkKCrIu++ijj0zOnDnNjh074u03Q0JC2I++BjxjhQQX91E/Y4zSp0+vLl26aMWKFVqxYoUkKSIiQkWKFNGlS5f0xRdfqEKFCgoMDFTDhg2tQ6PwiCBet+TJk6tTp076+OOPtWXLFn311VeaPHmyLl68qPv372vgwIHau3evjDHWsY+joqJsXTagnDlzqkmTJipdurTWr1+vunXravr06ZoyZYrOnTunESNGaOHChZKkdu3aMZQfrObNm6cqVaooODhYjo6OevTokXx9fbVw4UKdPn3a+tv7/vvvy9fXVxaLRbNmzdKiRYusn8HQZXid4h4D+vj4qHbt2vrkk0/UqlUrSVLq1KnVo0cPDRs2TB07dtTMmTMlPR8uxRijtGnTqlmzZhowYIA6d+5ss++BpCt22L0dO3bIxcVF3t7eKlOmjEqWLKkLFy4oWbJk1uGlvvrqK40ePVrHjx9X+vTpbVk2kqD79+9r5syZ+vrrr3X9+nVJUpEiReTr62udo1KS9fw6e/bsKlOmjC5fvvynz2KIFCQGZ8+elfS8Z2PPXQ4fPqxvvvlG5cuX16pVqzR79myNHj1aFSpUUHh4uEJCQiTFn2dj+vTp6t27txYsWKCvvvrKNl8GScKqVavk5+dn7c1du3YpV65catGihfbu3Wu9PpQqVSrOuV8H22YqeJNNnDjRjBo1yjx+/NgYY8yIESNMtmzZzKlTp4wxxvz+++9m4MCBpnHjxqZVq1bWOz9JN/E6vOjJn8jISHP9+nXz7NkzU61aNTNo0CBjzPOUvVy5csZisZgmTZokdKlAPC/q3ejoaBMcHGyePn1qPv30UzNs2DDrnSUff/yxyZs3r+nWrVsCVwp74OfnZ0qVKmXq1KljfZw6MDDQtGrVyri7u5spU6bEWz8oKMiULl3a1K1b1/p7DiSEfv36mSxZshhvb2+zfPlykypVKlO/fn1z/fp1Y4wxT58+Nd9//72xWCzmp59+sm4Xuy980fBVwKty5MgRY7FYzIoVK0xYWJg5evSoqVatmsmdO3e8u+a3bt1qIiMjzZMnT2xXLJK0a9eumQIFCphSpUqZa9euGWOMCQ0NNd7e3sZisRhvb2/ruuHh4aZAgQLWcx4gMenataspV66c2bdvn3VZWFiYKVu2rNm6das5cOCASZUqlXVY3YiICDN+/HizZcuWeJ8zbdo0kzZtWuPv75+g9SPpOHHihPXPs2bNMtmyZTM9evQwZ86csS6vVKmSSZYs2V8Og4ZXg1ADNnH79m2TIkUK4+joaIoWLWpOnDhhjh07Zpo0aWJ69+5tvZDyx4t1DO+D1yFunx07dswcO3bMHD161LosODjYeHh4WB/RDgsLM+3btzeXLl0iZINNxe3d06dPm3379pm7d++ap0+fGmOMuXfvnsmbN6+ZNGmSMeZ5Lzdu3NgsXryYIfzwQlFRUWbx4sWmXLlypkaNGubevXvGGGPOnDljmjdvbj788EMzY8aMeNucPXvWXLlyxRbl4g21fv16kz9/futQExs3bjQpU6Y0adKkMeXLl7eOBx8aGmrmzJnD8SMS1KlTp4y/v78ZOHBgvOVHjx411atXNzlz5jQ7d+40/fv3N1myZLEGccDrcu3aNfP++++bkiVLWoONZ8+emdGjRxsHBwdTq1Yt07lzZ1OnTh2TP39+hpFEonT06FFToEAB8/nnn5u9e/dal3fs2NFkypTJuLq6Ws/XjXk+10GlSpXM2LFjrctmzJhhUqdOTaCB/0nc8+aVK1eakiVLmtmzZ1uXzZgx44XBRqdOnbhe9JpZjPn/U7UDr9Efh4uKjIzUhAkT9Ouvvyo0NFRXr15VzZo1dfToUetQF0WKFFFkZKScnZ0lxX9cEHhV4vbVgAED5O/vL2dnZ924cUMtW7ZUr169lClTJhUtWlRubm5q2LCh/P399eDBAx09elQODg6Kjo7mkWwkuLi9279/f/3000969OiRsmbNqmLFiql///5Kly6dmjVrJicnJ3300UfauHGjQkJCtGfPHjk4ODCUH+KJ7amYmBgtWbJEkydPVtq0aTV//ny5ubnp119/lbe3t3777Te1bt1arVu3tnXJeEOtX79ev/32m7p3766NGzeqSZMmGjVqlMqVK6cyZcqoWrVq8vX1VY4cOazbREVFMTQaXrvQ0FC9++67unPnjpo2baq5c+fGe//nn3/W4MGDtW/fPmXIkEELFixQiRIlbFQtkqoXHd9dv35dn3zyiVKnTq1Vq1Ype/bsCgsL09SpUzVgwAB98MEHGj16tEqWLClnZ2f2mUhUIiIilCxZMgUFBenLL79UgQIF1KVLF3388ccKDAxU586ddevWLR05ckSpU6fWvXv31Lx5cz18+FB79+61nqtPmDBBOXLkUN26dW38jWAv4u5PV65cqb1792r27NnKlSuX+vTpo//85z+SpJkzZ2ro0KFq1KiRmjdvLg8PD+tncL3oNbJlooI3z9y5c01wcLAx5vlwFh9++KFZv369OXDggOnfv791SJ8KFSrYuFK8aby9vU3GjBnN/v37jTHPh7WwWCzm0KFDxhhjLl26ZDw8PEypUqVM9erVrXcwcbc7bM3Hx8e89dZbZvv27cYYY5o1a2YyZsxovYNp9erVpkaNGsbDw8PUqFGD3sU/EhUVZRYsWPCnJzYCAwNN69atTf78+c3cuXNtXCXeBC/aV0VFRZnLly+bJ0+emAoVKpihQ4caY4y5c+eOKViwoLFYLKZdu3YJXSpgjDHml19+MYULFzYeHh7xhpqKFR0dbX7++Wdz+/bthC8OSV7cfebmzZvNqlWrzOrVq40xz5/YKFiwoClRooT1iY0nT56YcePGGYvFYiZMmGCMYXQEJC5/HFXBy8vLJE+e3Hz22WfW0RVWrVplypQpY9KmTWuKFy9uihcvbkqWLGk976Gn8bL69u1rMmbMaMaPH2/GjRtn3n//fVOmTBnj5+dnXWfWrFnG0dHRTJw40YaVvlkINZBgrl69agoXLmzSp09vZs+ebZ48eWJWr15tMmTIYC5cuGCioqLM3r17TbZs2Uzp0qW54IYE1bhxYzN16lRjjDHLly836dOnt44d/+zZM2PM83E579+/bx2Hm4Mj2FJMTIwJCwszn3/+uXV4qYCAAJM6dWozffp0Y8zzsZGNeT4Ey4MHD+hdvFBsXwQHB1t7xZjnfTJ//vw/BRunTp0ynTp1euHFOuBViruvCgoKMrdu3bLeHGOMMZcvXzZ58+Y127ZtM8YY8+DBA9OqVSvz66+/8rg/EkTcuVni/jkwMNBkzZrVVK9e3brvBF63uD3Yr18/ky1bNlOsWDHj6upqmjdvbq5du2auXr1qChYs+MKhqJIlS2Z++OEHW5UP/K3evXubbNmymUGDBpn27dub1KlTm6pVq5rjx48bY54PNzV16lQzfvx4s3TpUutxAOc9eFm//fabyZ07t1m1apV12ZUrV0z16tVNkSJFzIIFC6zLV69ezTFoAmL4Kbw2fzWsSb9+/bR9+3alS5dOPXv21IEDB3T79m2NHDlS6dKl0++//y43NzeGRsFrY/4wlNnDhw9VrFgxTZo0SenSpdOnn34qb29vdejQQRERERo4cKBq166tChUqWLehN2ELf+y7iIgIffLJJ5owYYJ+//131atXT2PGjFH79u0VERGhuXPnKl++fKpQoYJ1O3oXccXuDwMCAjRhwgTdvHlT+fPnV7NmzVSrVi1FRUVpyZIlmjp1qtzc3DR79my5u7tbhwEAXodRo0bpk08+sQ7L069fP/n7+ys0NFQ1atRQmzZtVLZsWYWGhipv3rwqV66cmjZtqkmTJunp06fWIfZ43B+vU+z+c+vWrdqwYYPOnTun+vXrq0iRIipatKgCAwNVtWpVFS1aVAsWLJCbm5utS8YbYvTo0fL19dVPP/2kUqVKaeLEierWrZvq1q2r8ePHS5Jq1qyphw8f6ujRo3J3d1dYWJh++OEHTZgwQefPn1f69Olt/C2A/3PixAnVqFFDCxcuVJUqVSRJJ0+eVO3atZUvXz6NHDlSpUqV+tN2HAfgVbh165bKlSunUaNGqWHDhta+un37tooUKaKcOXOqc+fOatGihXUbei9hcFUDr0Xci2YbN27U8uXLNXv2bEnSyJEjNXr0aBUoUEA1a9bUsmXLdOTIEQUFBUmS3N3dCTTwWsUGGkuWLNH9+/eVLl061a9fXyNGjLBeIO7QoYMk6cmTJzp+/LhOnDgR7zPoTdhCbN+tXbtWkpQsWTIlS5ZMX3/9tb788ktNmDBB7du3lyTdv39fS5Ys0fnz5+P1K72LuCwWi9asWaMGDRqoYsWK6tOnj1KkSKGmTZtqxYoVcnJyUqNGjdS5c2dduHBBnTt3VkxMjHW+K+BV27dvnxYvXqwRI0bozJkz2rFjhxYsWKCJEyeqe/fuunPnjvr06aNt27YpZcqUWrx4sQ4fPqyBAwcqMjJSO3futB5HcjKJ18lisWjVqlWqXbu27t27p7CwMI0dO1bdunXT9u3b5eHhoS1btuj06dOqXbu2goODbV0y3gA3b97U6dOnNW7cOJUqVUorV67U4MGDNXDgQG3btk3dunVTVFSUVq9erY8++sgaXri6uqpv3746d+4cgQYSHRcXFzk6OipFihSSns+TVbRoUf3000/au3evfHx8tGXLlj9tx3EA/lcvuu/fwcFBLi4uOnDggKTnv//R0dHKnDmzihcvrrCwMC1ZskSHDx+2bkPvJRBbPiaCpK9Pnz4mT548ply5cubdd981BQsWNMeOHbO+v3PnTlOiRAljsVhMly5dbFgp3jTnz583JUqUMN9//70xxhh/f3+TL18+U6lSJeuj2Hfv3jWfffaZ+fDDD3mEEInG3bt3jcVisfbuzz//bAoWLGgKFy5sjHk+hEBwcLCpUaMGvYv/6ty5c6ZEiRLW4fbu3r1rsmfPbvLnz29SpUplli1bZox5/uj+0qVLGXIKCWLJkiWmSpUqpkGDBqZnz57Wcd6NMWbr1q2mbt26ply5cmbXrl3GGGNCQkLM5cuXGWIPCerWrVumWLFiZvz48dZlW7duNY0bNzaVKlUygYGBxpjnQ/blz5/fXLlyxVal4g3y7Nkzs3LlSvPgwQNz5MgRkzt3bmuP+vj4GIvFYipVqmTu3Llj3YZ9JhKT2N/yuMOpXbhwId7w0JGRkSY6Oto8ffrUFChQwDg4OJj+/fvbpF4kHXGHwD9//ry5ePGidf6r1atXG0dHR+Pt7W1dJzIy0jRp0sSsWLHC5MqVy3h6eiZ4zW86J1uHKki6Zs6cqTlz5mjTpk0qWrSo/P391aBBA927d0/S8wT0448/1qpVq7R9+3Y1btzYxhUjKfvj43+5cuXShx9+qICAALVv317169fXtWvXtGTJEpUrV045cuRQeHi4JOnAgQNydHTkEULYxB/7zt3dXWPHjtWSJUtUqVIllS5dWoMGDVK3bt303nvvKUOGDLJYLAoLC9OhQ4foXfyJ+f9DpkRERChDhgwqW7asGjRooOvXr6tKlSr67LPP1LNnT7Vp00atWrVSZGSkGjdurAYNGti6dCRxkZGRcnZ2VsOGDeXo6Kjp06dr+/bt6t27t3WdKlWqyGKxaNKkSRo4cKD69eunGjVqKFWqVJKePy3s5MQpDl6/iIgI3blzR9myZbMuq1KlimJiYtStWzedPXtWBQsWVOHChXXy5EmG7EOCcHV1Va1ateTs7Kxt27apQIECat68uaTnT/g2adJE9+7dU8aMGa3bsM9EYhF3tI5nz54pRYoUioyM1Ntvv60ePXqoW7duyp49u2rXri3p+THthx9+qHHjxlmHpQL+DWOMtfeGDBmilStXKjIyUo8ePdLQoUP11VdfaeLEiercubP27t2rjBkz6uzZswoODtaCBQu0adMm/frrrzb+Fm8exqDAKxMTExPv9W+//aYOHTqoaNGiWrp0qdq0aaMpU6aoWrVqCg0NtQ4BlD17djVr1kxOTk6KioqyRel4A8Re0F25cqUOHDggJycnjR49Wnfu3FGXLl0kSd27d5evr68GDRqk6tWry9PTU4cOHZKzs7OioqK4KAybiO27JUuW6MGDB5KkOnXqKFWqVFq3bp0sFovq16+vEydOqEmTJqpTp47atm2rI0eO0Lv4ExNnDHgvLy89evRII0aMkJubm8aNG6dChQrJx8dH+fLlU/78+ZU8eXL169dPjx49euHj2MCrEndYs3Xr1qlixYrq2rWrcuXKpYULF+rkyZPWdStXrqyuXbtah0+LiyH28LrE7gNPnjypa9euKVWqVMqUKZNu374t6f/OhapWrao0adJo3bp11m0JNJCQYkOK8+fP6/Hjx9abXTZt2qRatWppw4YN1mH6gMQibqDh4+Ojr7/+WhUrVpSnp6du3LihgQMHqk2bNvr888/VrVs3fffdd6pVq5aOHj2qqlWrWm/kAv6N2OuTw4YN05QpUzRmzBgdPXpUZcqUUZ8+fXTnzh117NhRu3fvVsqUKXXv3j29//771uPTGzduKG/evDb8Bm8oGz4lgiQk7qOBGzduNMYYU716ddOvXz+zd+9ekypVKuujgjExMWbQoEFm0qRJNqkVb66tW7cai8Vi0qRJYyZPnmzCw8PN9u3bjYeHh5k1a9ZfbsfwPbC1zZs3G4vFYipUqGAmTJhg7t69a9auXWtcXFzMkSNH/nI7ehcvsmLFCpM8eXIzdOhQa/9ERkaaSpUqmW7dulnX69y5s5k5c6a5f/++jSrFmyLucWS/fv1M5syZzeTJk40xxixfvtxUrFjRfPHFF+bkyZPxtjt27Fi8oQKA1yW2R1etWmWyZs1qBg4caIwxpkOHDsbd3d0cOHAg3ro1a9Y0w4cPt0mtQKyDBw8aZ2dn4+HhYfLmzWsKFSrEUFNI9Pr162fc3NzMDz/8YNq2bWvKly9vsmbNah3Cb+bMmaZMmTKmQoUKpl69eiYiIsIYE/9YAvin4h5HxsTEmNq1a5sFCxYYY57/5qdPn956TBrba2FhYdZtHjx4YLy8vIy7u7s5ffp0AlYOY4yxGMNtd3g55v/f9SlJ3333nfz8/LR3717t2LFDPj4+OnPmjCZPnqw2bdpIkkJCQvT111+raNGiGj58uC1LRxIXe7dH3B5t3LixLl68qODgYH366afKnDmzbt++rejoaPXt21c5cuSwcdVA/DuVpOd3fnzyyScKDw9Xs2bNtGnTJo0bN06zZ8/WqVOntHnzZqVLl+6FPQ/EdfbsWdWoUUO9e/dWx44d473n5eUlf39/9erVS0FBQfL399e+ffuUJ08eG1WLN82wYcM0YcIErV+/Xvny5VPatGklST/99JOmTp2qFClS6LvvvlPhwoXjbffHfSbwOgQEBOirr77ShAkT9Omnnyp79uySpAYNGmjXrl3q0aOH3N3d9euvv2rWrFk6dOiQ3n//fRtXjTfd8ePHtXLlSqVJk0Y9evSwjo7AkFNIjM6fP6/atWvLx8dHn332maTnI4B0795dv/32mw4cOCB3d3c9ffpUrq6uslgsslgs9DRe2rfffqsUKVJo0qRJ2r59u27evKnatWvL29tbHTp00LNnz/T999+rXbt21mtGV65c0cyZM7Vw4UKtWrVKRYsWte2XeANx9I+XFnvh7Pjx4zp9+rTmz5+vHDlyqGTJknJ3d1eBAgXk5uYm6fnFlEaNGunOnTsaMmSIDavGmyD2Asfp06ety2rVqqVy5crJx8dHOXPm1LFjx+Tn56fly5dr9+7dtioViCe2dwMDA3X37l1ly5ZNU6ZMUfLkyZU7d261bdtWn332ma5fv66LFy9q7ty5io6Otm5HoIG/cvXqVTk5OVlPFKX/G1KlUaNGqlatmry9vbV//34FBAQQaCDBBAcHa/fu3fL19VXJkiX15MkT7dixQ23btlV4eLgqVaqkiIgIdenSRRcuXIi3LYEGXrewsDDNnTtXnp6eatOmjTJkyKBz587Jx8dHrVu3VtmyZbVp0yaNHDlSx44d065duwg0kCh88MEHGj58uPr06UOggUTv0aNHunz5sjJlymRd9u6772r48OFKlSqVtmzZIklycXGRg4ODLBaLjDH0NP5ncYffW7ZsmebMmaNatWrpo48+Urdu3VSzZk2NHz9eHTp0kCQ9fPhQu3bt0q5du6zbZc2aVc2bN9e+ffsINGyEMwC8EvPmzVOvXr105coV5c+fX5KUP39+DRs2TLly5VLXrl2VOXNmNWrUSI8fP9b+/fvl5OTEmId47Q4cOKBChQqpa9euOnz4sBo1aqQLFy5o06ZN6tWrlyZNmqSGDRvq3r17mjt3rq3LBazWr1+v+vXrq2fPnvr1119VqVIl1a1bV7/99ptatWqlgIAA5ciRQ8HBwTpy5AjzZuAfCQ0NVVhYmPV13AP6p0+fqnnz5vrll1+0detWFStWzBYl4g1lsVh0+vRpBQUFaffu3erZs6f69u2rkydPqnv37nJzc1PDhg1VuHBhwjYkOGOMLl26pJCQEAUHB8vLy0tt2rSRj4+P2rdvr48++kgrVqzQgQMHtGbNGi5uINHi4i8Si7jHoOHh4ZKk999/XwUKFNDGjRsVGRkp6fmNCwULFlRYWJguXbokSfHOe7iZC/9G7A0xO3fu1K5du9SzZ095eHioePHiOnXqlKpUqaJWrVpJkh4/fqw2bdrI0dFRX3/9tfUznJ2dlTdvXmXNmtUm3wGEGnhF0qZNq/v37+uXX37RoUOHrMvLli2rqVOnKiAgQGPGjNHkyZO1c+dOJq9Fgilbtqw2bNigX375RX369NHo0aM1Y8YMrV27VvPmzVOWLFk0e/ZsrV27Vhs2bLB1uYDVZ599pr59+yo6OlqlS5fW3LlzlTlzZu3bt09HjhxR2bJlNWLECO3du5dADv9YkSJFdO/ePc2YMUOSrHe5SZK/v78CAgKUPHlypUuXzoZV4k2UPn16DR06VFOmTFHt2rWVK1cujRgxQkeOHFHlypV16NAhNWvWTJMmTWKCWyS45MmTq2vXrpo1a5by5MmjGzduqHXr1rp586bq1KmjgIAApU6dWhkzZlSaNGlsXS4AJGpxh42cMGGCZs+erVu3bsnV1VUlS5ZUQECAVq5caV0/KipK6dKls44AArwKt2/fVps2bTR//nw9e/ZMktStWzc1aNBA165dU7FixdSgQQNVq1ZNN27c0ObNm5mQPpFhTg28MrHpZpYsWeTl5aXy5ctL0gvHdo+OjibQQIKI7b9Lly5p8+bNGjFihHLmzCl3d3dJko+Pj95++23r+vQmEoO4fRgaGqqZM2dqwoQJqlmzppYuXap3331XW7ZsUcqUKV+4DfB3/Pz81KFDB3Xv3l3NmjWTo6Oj5syZoxkzZujAgQMMmQKbunr1qsLDw5U3b15Jzy98VKtWTaVKldL3339v4+rwpjt9+rRu3LihqlWrWi/KdenSRSEhIZoxY4ZcXFxsXSIAJFp/vDbUp08fzZs3T8OGDVPt2rWVOXNmPXnyRP/5z3905coV5c2b1xpy3L9/XydOnOBpI7xSP//8s+rXry93d3dNnDhRxYsXV3R0tAICArRr1y5FRkYqT5486tq1K0P4JUKEGnhpcX+YNm3apMGDBytXrlz65ptv9OGHH9q4OrwJ/tukyHHff/jwoTp27Kg9e/bo5s2b8vf3V7169RKqVOAf+2Nf7969WwEBAVq/fr1+/fVXzZ49Wy1btrRhhbBXMTExWrFihdq3b6+UKVPK1dVVjo6OWrx4MUNOIdF48uSJTp48qR9++EFXrlzR8ePHOYlEonLmzBnNnz9fkydP1t69e+Xh4WHrkgDAbsyYMUODBg3S1q1bVahQIUnPh0JNkSKFIiIiNHPmTK1bt07h4eHKlSuXZsyYIWdnZ27kwiv3888/q3nz5ipRooS6du2qwoULv3A9ei/xIdTAP/Z3/4DjXnzbuHGjvvvuO+tktpUrV07IMvGGuXXrlrJkyRLvEda/ErdPV65cqf3792vUqFFcJEGi9sdQ7sKFC9bHtOldvIybN2/qypUrslgsypMnT7xJGQFbMsZo165d8vHxUWRkpNauXcuFDCQqx44dk4+Pj06ePKnFixerSJEiti4JABKtqlWrqkOHDqpfv7512YABA3Tr1i35+fnp/Pnz2rlzp8aPH68sWbKofv36at++vSQpLCxMrq6uksRd8nhtTpw4oTZt2qh48eLq1q2bChYsaOuS8A8QauC/+vHHH9WgQQOlTJnyby8c//GJjU6dOqlJkyYaOnRoQpaLN8jQoUO1YMECBQQEKG/evP8o2HjROhwcwV7RuwCSqvDwcJ0+fVpFihSRg4MD+zskKs+ePdPRo0eVO3du5ciRw9blAECidf/+fS1evFjt2rVTsmTJrMs7d+6sgIAANW/eXOvXr1f27NmVJ08ePXz4UKdPn9ZPP/2kzJkzW9f/b6MzAC/rxIkTat++vXLlyqXRo0crT548ti4J/wWhBv7W8uXL1bdvX33++ecaPny4UqRI8Y+DjUOHDqlEiRLcUYfXZsWKFZo1a5aePHkiPz+/lwo2gIR06tQpZcmSRW+99Za+++471a5dWx988ME/3p4eBvAmYZ8HAID9Gz16tJydneXp6SlJatiwoe7cuaO6deuqSpUq8vDw0IYNGzR48GAFBARY58EEEsrhw4c1bdo0zZo1i2NPO0Cogb8VFhYmb29vbdiwwTpB4z8JNowx1vcZKgCv0/r16zV+/Hg9efJEc+bM+a/BRtzgLTQ0NN5Ey0BCCAwMVMOGDfXll1/q7t27mj59ugIDA1WgQIG/3e6Pw1ClS5cuAaoFAAAAgJcTGhqqgQMHatq0afLx8VGnTp0kSY8ePVLatGklSREREapbt66SJUumlStX8mQGbCL2vJubahI//t/BX4qJiZGrq6v69OmjTz/9VAcPHlT//v319OlTOTg4KCYm5i+3jf2H/9tvvxFo4LWIzWM/++wzffPNN0qVKpVatGihc+fO/WV/xr0oPGnSJA0aNEhhYWEJWjfg4eGhJk2aaNq0aZo7d662bt2qAgUKKDo6+i+3idu7fn5+6tmzp0JCQhKqZAAAAAD4x/54Pp4yZUp5enqqd+/e8vLy0tSpUyVJadOm1aNHjzR58mTVrVtX165d07Jly6wXlYGEZrFY4t2ojcSL/4fwlxwcHBQdHS0XFxd5eXmpRo0a/zXY+ONF4w8++EBXrlyxRflIomLDjLh3bdSsWVNdunT522Ajbm/OmDFDffr0UenSpa2TjgEJITa4KFCggJydnZUzZ07t3r1bN2/elKOjo1708GRMTIy1d6dPn67OnTurTp06Sp06dYLWDgAAAAD/Tdw73K9evaoLFy5IknLmzClPT0917dpVffr00YwZMyRJLi4uOnv2rNzc3HT8+HE5OzsrKiqKi8qwGZ4Ssg8MP4U/+atHrMLCwjRq1Cht3LhRZcqU+dNQVHEvGk+fPl39+/fXlClT1LBhw4T+Ckii4vbm2bNn5ejoKAcHB7399tuSpDVr1mjy5Ml/GopK+r+nh6ZPn64+ffroxx9/VL169WzzRfDG+eN+9d69e3J0dNSUKVO0fPly1ahRQ998842yZMnyl9vRuwAAAADsxYABA7Rw4UI9ffpUmTNnVu/evVW3bl0ZYzRy5EhNnjxZo0ePVvv27RUdHS0HBwdZLBaGMAfwjzjZugAkLnEvoG3YsEEXLlxQtmzZlD9/fr3//vvy8vKSJG3cuFEDBgzQiBEjlCJFCkVFRcnJ6Xk7xV548/PzU/369W32XZC0xH38b/DgwVqzZo1u376t999/X40aNVL79u1Vp04dSdKUKVPUunVrTZs2Ld48BbFPaPj5+XFRGAkm7n51165dCgsLU0REhGrXrq0BAwbIGKMVK1bIyclJnTt3VubMmdWyZUt1795dRYoUkfR8v+rl5UXvAgAAAEiU4p73LFq0SDNnztSECROUJUsWzZgxQz/88INu3rypbt26ydPTU05OTurYsaPeeust1a1bV9Lz834CDQD/BE9qwCrukxZeXl5asmSJ3N3d5eLiIhcXFw0dOlTly5fXs2fPNHr0aG3evFn58uXTtGnT5OLiIun5hbe+fftq1qxZBBp4LYYMGaIpU6ZowYIFypQpk7y9vbVkyRL98MMP6tmzpyRp3bp1GjJkiEqUKKFp06ZJknx9fTVgwAAtWLDAesAEJKS+ffvK399fadOm1c2bN1WoUCHNmDFDuXPn1tChQ7VmzRq5ubkpPDxcQUFBunHjhpycnDR//ny1a9dOCxYsYL8KAAAAIFFbsWKF7t+/r+joaHXs2NG6vE+fPlq5cqX8/Pz00Ucf6cqVK9q8ebNatmxpvUkWAP4pBqiDVWyg4evrq8WLF2vx4sU6evSoatWqpX379qlTp07atm2bkidPrj59+qhMmTJydnaWs7OzJGnTpk3q2LEjgQZem0OHDmnTpk3y9/dXtWrVdPv2ba1Zs0afffaZBg8eLF9fX0lSrVq15OvrqylTpli3jYiI0MyZMwk0YBOTJk2Sn5+fli5dqmPHjmnIkCHaunWrLl26JEn69ttv1bZtW+XPn1/vvvuuNdAIDQ3VuXPntGLFCvarAAAAABK169evq0WLFurQoYNu3rwpSYqKipIkjR49WpkyZbKet+fKlUtt27aVk5OTdR0A+Kd4UgPxxisMDg5W+/btVbVqVbVr107r1q1TkyZN1LZtW506dUq3bt3S1KlTVaFCBUVERMjZ2dkahjx8+FBnzpxRmTJlbPl1kIQFBwdr8uTJ6t27t/bt26f//Oc/+u6771SvXj3Vr19fe/bs0bfffqshQ4ZYt4k7NBpgK507d1auXLnUp08fLVu2TO3bt9fIkSPVoUMHPXnyRKlSpfrTNpGRkXJ2drb+LwAAAAAkJi+ak3X37t3q1auXoqOjtXv3bqVMmdK6Xo8ePXTp0iWtWrXKRhUDSCoINd5wT58+VYoUKSRJV69eVc6cOfXzzz8rVapUevr0qWrVqqVevXqpS5cuGj9+vDw9PeXu7q7Vq1dbw4u4w1YBr8rfTVjv6uqq1q1bK02aNBo9erScnZ3Vrl07/fLLL8qQIYPWrVsnSfQlbCLuPjE0NFSurq4qVaqUmjdvrhIlSqh69ery9vZWhw4dFB0drQEDBqho0aJq1KiRjSsHAAAAgH8m7jn7nDlzFBQUpIiICJUtW1aZM2dW+/btlT17di1cuFCpUqWSs7OzKlSooPfee09z5861cfUA7B3DT73BNm/erO+++07S87uIa9asqadPn6pw4cJ6++23tWvXLr3//vtq3bq1JClTpkyqU6eOvLy8VLJkSevncOEYr1rcg6Pdu3frp59+0u3btxUZGSlXV1c9ffpUx44dU3R0tJydnRUaGqoHDx7I09NTAQEB9CRsKrb/Bg0apBkzZsjR0VH/+c9/9OOPP6py5coaP368OnToIEl68uSJTp06pQsXLtiyZAAAAAD4n8Ses/fp00d9+/ZVZGSkrl+/rkGDBmnFihWaMWOGzpw5o1KlSql27dpq3ry5QkJCNGvWLEnPbwYDgH+LUOMNtnv3bm3YsEHlypXT0qVL5e/vb31qQ3o+B8Gvv/6q8+fPKyYmRkuWLFGxYsXk6ekpR0dHRUdH27B6JGWxB0e9e/fWl19+qTZt2qhMmTKaNWuW7t+/rxQpUqhevXpauXKlOnTooOrVq+vixYvWOQd4eggJbcaMGQoMDLS+jomJ0aFDh1SgQAFJUsmSJZUsWTIVKVJE77//viTpypUraty4sR48eCAvLy+b1A0AAAAA/9bmzZu1YsUKrVmzRmPHjlWDBg105coVlSlTRhUqVNCiRYuUKVMmBQYGatCgQfr111/l7OysqKgoztkBvBRCjTfY8OHDlTlzZh08eFB169ZVjhw5JD2/GCdJpUuXVv78+VWlShV5eHjot99+04ABA2SxWGSMsc7DAbwqcYOyHTt2aPfu3fL391dQUJBq1KihyZMny8/PTyEhIWrdurXatGmjc+fO6d1339XBgwetYRsHR0hIBw4cUKdOnTR16lSdPXtW0vNg7ebNmwoNDZUklS9fXgMHDlSaNGlUv3595cuXT3Xr1lVwcLD27NkjJycngmIAAAAAduXmzZvKmTOnSpUqJX9/f7Vu3Vq+vr76+uuvFRYWpqioKI0ZM0bOzs7q1auXdTuuJwF4Wcyp8YaKiIhQRESEhgwZoqdPn+rIkSP65JNP1L17d2XKlMm63v79+xUUFKTHjx+ra9eu1gtv/ADhVfrtt9+UL18+6+sFCxbo2LFjcnJykre3t3W5p6enNm/erJYtW6pDhw5KlSpVvInAmRQctuLv76+ePXvqs88+U/fu3fXee++pUKFC8vb2VrVq1WSxWGSxWHT+/HldvHhR58+fV+7cuVW9enU5OjrSuwAAAADsRuzoCNOnT9fOnTvVrFkzNWjQwDp3oCStXr1ahw4dUrdu3XTu3Dk1adJE2bNn1759+2xcPYCkgFDjDfJXEy9L0oABA7RhwwZVr149XrBx4cIFvfPOO9b1CDTwqtWpU0eFCxfW8OHDrT1arVo1bd26VVWrVtW6devk7OxsXd/T01Pbtm3TF198oR49eihdunSSGHIKthEZGWntz02bNqlly5aqVauW2rVrpwEDBsjb21uFCxdWZGSkHBwc5OjoqMePHytNmjTWz2C/CgAAAMAenT59WkWLFlVUVJT8/PzUokULSdKzZ89Ut25dZcuWTbNnz5b0fDSGzp07a9OmTdaRQgDg3yLUeEPEDTT8/Px05MgRubi4qECBAmrXrp0k6dtvv9WGDRtUoUIFtWzZUp6enoqKitLOnTu5YIzXokKFCgoNDdWBAwfk4uKi69evK3v27JKkVq1aacuWLRo6dKgaNmwYb76XVq1aKTIyUvPmzaMvkSgMGjRIzZo1U1BQkLp06aIPP/xQq1atUooUKfT2229LkkJCQhQTE6P69etr1KhRNq4YAAAAAF7e/Pnz1b59e3Xt2lU1atSQMUYjR47UnTt3dPTo0Xg3KT579kzJkye3YbUAkgpCjTdMnz59NGfOHH3yySd69OiRtmzZoq+//lpz586VJA0dOlRr1qzR3bt3lS1bNu3atUvJkiWzcdVIioYMGaKffvpJJ06ckMVi0aJFi/TTTz/J09NTZcuWlSR99dVXCgoKkpeXl7788st4Bz+xQR2BG2whbt8tXbpU7dq10+rVq1WxYkX5+/urS5cueuedd/TJJ5+oQoUKio6O1t27d+Xi4qJ69eox1BQAAACAJCEqKkr+/v7WOTMyZ86srFmzasWKFdZJwTn/AfCqsVdJ4uI+obFv3z7Nnz9f/v7++uijjxQVFaUdO3aoQYMG6tChg6ZNm6Zvv/1W9erV06NHj1SmTBnGesdrExISIkdHR1ksFmvA4eTkpBkzZsjBwUGlS5fW8uXL9eWXX2r06NFycHBQ3bp1rU9sODg4/O2QasDrFBtobNq0SQcPHpSPj48qVqwoSfryyy/l6Oiob775Rg8ePNA777yjPHnyxNue/SoAAACApMDJyUmNGjVSlSpV9PDhQ7m6uip79uyyWCyc9wB4bbgamIQZY6wXfKOiovTgwQMlT55cxYsXl/T8h6dq1aqaOXOmli1bpt27d0uSPDw89OGHH8rR0VHR0dH8AOGVin04rG7dunr27JkKFy6s8ePHa9euXerfv78CAwM1efJkHTp0SNLzCZjz58+v7t27a8+ePfE+i0ADtnTw4EF5eXlp7ty51keqIyMjJT3v77Fjx2rNmjXq37+/Ll++HG9b9qsAAAAAkhJ3d3flzZtXOXLkkMViUUxMDOc9AF4brggmUTt27NCiRYskSR06dFCfPn2UPXt23b17V/v27Yu3bpEiReTi4qInT5786XOYvBavWuwd7uXLl1fOnDkVGBioMmXKKG3atKpXr548PT0VFBQUL9hYtmyZ2rdvr08++cSWpQPxlClTRi1atFC6dOk0a9Ys3blzx/p4tfR8+LThw4crLCxMOXPmtHG1AAAAAJBwuAkRwOvEnBpJjDFGT548Uf369RUREaE0adJo165d2r17t/LkyaOmTZvKyclJPXv2VLly5SRJ9+/fV8WKFTVixAjVqVPHxt8Ab4rg4GA1b95cpUqV0pIlS1S4cGEtXrxYkrRo0SL5+vqqYMGCatWqlSpUqGDdLjo6mrANCe7vhjqbMGGCFixYoMKFC2vkyJFyd3d/4WPWDJcGAAAAAADw8gg1kqjg4GCVK1dOv/32m0aOHCkvLy9J0po1azRu3DgZY1SvXj3lzp1bkyZN0v3793X48GEuFiNBRUdHy8HBQT/++KO8vb1VrFgx6xNGixcvVr9+/dS6dWsNGjTIxpXiTRY3jFi9erXOnDmjzJkzy8PDwzqcn4+Pj1auXKkCBQro+++/l7u7OwEcAAAAAADAa0CokUQ9fPhQTZo00ZMnT+Ti4qKmTZuqadOmkqSNGzcqICBA8+fPV758+eTm5qY1a9bI2dmZi3CwidDQUC1btkyjR4/WBx98oIULF0qStmzZosqVK9OTsBljjHXINC8vLy1atEjvvPOOoqOjFRMTo759+6p27dqSngcbq1ev1ltvvaVZs2YpXbp0NqwcAAAAAAAgaSLUSOJu376t1q1b69mzZ2rZsqU12JCkW7duKXny5EqbNq0sFssLh0sBEkpoaKiWL1+uMWPGKHv27Nq4caP1PcI22NrEiRM1ZswYLVmyRGXLltW4cePUt29f5c6dW8OHD9dXX30lSfruu+9069YtTZkyhaGmAAAAAAAAXgNCjTfApUuX1LVrV0VERKhRo0Zq3ry5KleurA8//FDff/+9JMZ6R+IQGhqqOXPmaN++fVqwYAE9iUQhJCREXbp0UYkSJdS1a1etXbtWTZs2VadOnfTrr78qMDBQ48ePV61atST939Md7FcBAAAAAABePUKNN8SlS5fUq1cvBQUFKTw8XClSpNCxY8eULFkyW5cGxBMWFiYXFxcuCsNmXtR3586dk4ODgyIiIlSrVi1169ZN33zzjebMmaO2bdsqVapUWrp0qapVqyYp/rBVAAAAAAAAeHUYa+gNkSdPHk2aNEnHjh3TnTt31Lx5czk5OTHkFBIdV1dXSc8vChNoIKHFDTQ2btyoR48eqVChQipQoIAkyc/PT9myZVPr1q0lSenTp1ft2rVVpUoVValSxfo5BBoAAAAAAACvB1ez3yBZsmSxDo8iPZ+ngEADiRUXhWELsYFGv379NGHCBGXLlk2XLl3SuHHj1L59ezk5Oen8+fM6fvy4SpcurdmzZ8vDw0OdOnWSxWJh/hcAAAAAAIDXjCvabzAuvAHAc7HDRRljdOXKFe3du1dbt27Ve++9px9//FHffPONQkNDVbp0aZUpU0ZffPGFMmTIoGTJkmnlypXWbdmvAgAAAAAAvF7MqQEAeKPFHXIqODhY9+/fl5+fn4YPH24NKcaPH68ePXrI19dXHh4eevjwoe7cuaM2bdrIycmJJzQAAAAAAAASCKEGAACSBgwYoC1btujs2bPKnTu3li1bpvfee8/6vq+vr7y8vNS7d28NHz7cupxAAwAAAAAAIOEwCy8A4I0UExNj/fOSJUv0448/qmnTpmrVqpXOnz+vWbNm6cqVK9Z1unfvrm+//VY7duxQ3PsBCDQAAAAAAAASDk9qAADeaLt27dKyZctUunRpNWvWTJI0ZcoUjRw5Uk2aNFHHjh2VK1cu6/px599gQnsAAAAAAICExUThAIA31u3bt9W6dWvduXNH+fLlsy7v1KmTjDEaNWqUHB0d1bp1a7399tuSRKABAAAAAABgQww/BQB4Y2XOnFkrV65U1qxZFRAQoF9++cX6XufOndW/f3/98MMP2rx5c7ztCDQAAAAAAABsg+GnAABvvFOnTqlly5YqUaKEunXrpoIFC1rfW7lypT7//HPmzgAAAAAAAEgECDUAAJB04sQJtWnTRsWLF1f37t1VoECBeO9HR0cTbAAAAAAAANgYoQYAAP/fiRMn1L59e+XKlUujR49Wnjx5bF0SAAAAAAAA4mBODQAA/r9ixYpp0qRJSp06tXLlymXrcgAAAAAAAPAHPKkBAMAfGGNksVgUExMjBwfyfwAAAAAAgMSCUAMAgBeIDTYAAAAAAACQeHD7KQAAL0CgAQAAAAAAkPgQagAAAAAAAAAAALtAqAEAAAAAAAAAAOwCoQYAAAAAAAAAALALhBoAAAAAAAAAAMAuEGoAAAAAAAAAAAC7QKgBAAAA4I00ZMgQFS1a1NZlAAAAAPgfWIwxxtZFAAAAAMCrULFiRRUtWlS+vr7/dd0nT54oPDxcbm5ur78wAAAAAK+Ek60LAAAAAICEZIxRdHS0UqVKpVSpUtm6HAAAAAD/A4afAgAAAGATFStWVNeuXdW9e3elT59emTJl0owZMxQaGqqWLVsqderUeuedd7RhwwbrNqdPn9Znn32mVKlSKVOmTGratKnu3bsnSWrRooV27dql8ePHy2KxyGKx6PLly9q5c6csFos2bdqkEiVKyMXFRXv27Hnh8FN+fn4qWLCgXFxclCVLFnXp0iUh/0oAAAAA/BeEGgAAAABsZu7cucqYMaMOHz6srl27qmPHjvrqq69Urlw5HT9+XNWrV1fTpk319OlT3bp1Sx9//LGKFi2qo0ePauPGjbpz544aNGggSRo/frzKli2rtm3b6tatW7p165Zy5Mhh/W/16dNHI0eOVFBQkAoXLvynWqZOnarOnTurXbt2+uWXX7RmzRq9++67CfZ3AQAAAOC/Y04NAAAAADZRsWJFRUdHa8+ePZKk6OhopU2bVvXq1dO8efMkSbdv31aWLFl04MABrV+/XocOHdKmTZusn3H9+nXlyJFDZ8+eVb58+V44p8bOnTtVqVIl/fTTT/r888+ty4cMGaKffvpJJ0+elCRly5ZNLVu21PDhw1//lwcAAADwrzCnBgAAAACbifvEhKOjo9zc3FSoUCHrskyZMkmS7t69q2PHjmnHjh0vnAfjwoULypcv39/+t0qUKPGX7929e1c3b95UlSpV/tevAAAAACABEWoAAAAAsBlnZ+d4ry0WS7xlFotFkhQTE6OYmBjVrl1bP/zww58+J0uWLP/1v5UyZcq/fC958uT/tGQAAAAANkSoAQAAAMAufPDBB1qxYoVy584tJ6cXn8okS5ZM0dHR//Nnp06dWrlz59a2bdtUqVKlly0VAAAAwGvCROEAAAAA7ELnzp0VHBysr7/+WocPH9bFixe1efNmtWrVyhpk5M6dW4cOHdLly5d17949xcTE/OPPHzJkiHx8fDRhwgSdO3dOx48f18SJE1/X1wEAAADwLxBqAAAAALALWbNm1b59+xQdHa3q1avLw8ND3bp1U9q0aeXg8PzUplevXnJ0dFSBAgXk7u6uq1ev/uPPb968uXx9fTVlyhQVLFhQtWrV0rlz517X1wEAAADwL1iMMcbWRQAAAAAAAAAAAPw3PKkBAAAAAAAAAADsAqEGAAAAAAAAAACwC4QaAAAAAAAAAADALhBqAAAAAAAAAAAAu0CoAQAAAAAAAAAA7AKhBgAAAAAAAAAAsAuEGgAAAAAAAAAAwC4QagAAAAAAAAAAALtAqAEAAAAAAAAAAOwCoQYAAAAAAAAAALALhBoAAAAAAAAAAMAuEGoAAAAAAAAAAAC78P8A/wv3zzdhle0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1600x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>t-test p-value</th>\n",
       "      <th>mann-whitney p-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>total_reward</td>\n",
       "      <td>0.652151</td>\n",
       "      <td>0.841858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>final_wealth</td>\n",
       "      <td>0.080242</td>\n",
       "      <td>0.177120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>market_wealth</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>calmar</td>\n",
       "      <td>0.086983</td>\n",
       "      <td>0.209194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sharpe</td>\n",
       "      <td>0.159795</td>\n",
       "      <td>0.169706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sortino</td>\n",
       "      <td>0.178440</td>\n",
       "      <td>0.192667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>alpha</td>\n",
       "      <td>0.085365</td>\n",
       "      <td>0.162527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>episode_id</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>regime</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          metric  t-test p-value  mann-whitney p-value\n",
       "0   total_reward        0.652151              0.841858\n",
       "1   final_wealth        0.080242              0.177120\n",
       "2  market_wealth        1.000000              1.000000\n",
       "3         calmar        0.086983              0.209194\n",
       "4         sharpe        0.159795              0.169706\n",
       "5        sortino        0.178440              0.192667\n",
       "6          alpha        0.085365              0.162527\n",
       "7     episode_id        1.000000              1.000000\n",
       "8         regime        1.000000              1.000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Imports ===\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import ttest_ind, mannwhitneyu\n",
    "\n",
    "from sb3_contrib import RecurrentPPO\n",
    "#from src.env.base_timeseries_trading_env import SequenceAwareCumulativeTradingEnv\n",
    "from src.defaults import TOP2_STOCK_BY_SECTOR, EPISODE_LENGTH\n",
    "from src.data.feature_pipeline import load_base_dataframe\n",
    "#from src.env.base_timeseries_trading_env import RegimeAugmentingWrapper\n",
    "\n",
    "ENV_CLASS=SequenceAwareCumulativeTradingEnv\n",
    "# === Config ===\n",
    "N_EVAL_EPISODES = 5\n",
    "MODEL_PATH = save_path\n",
    "\n",
    "# === Load Data ===\n",
    "ohlcv_df = load_base_dataframe()\n",
    "test_df = ohlcv_df[(ohlcv_df['date'] >= \"2023-07-01\") & (ohlcv_df['date'] < \"2024-01-01\")]\n",
    "test_df = test_df[test_df['symbol'].isin(TOP2_STOCK_BY_SECTOR)]\n",
    "\n",
    "\n",
    "# === Evaluation Logic ===\n",
    "def evaluate_agent(agent, env, n_episodes=22):\n",
    "    episode_metrics = []\n",
    "    episode_infos = []\n",
    "\n",
    "    for _ in tqdm(range(n_episodes), desc=\"Evaluating Agent\"):\n",
    "        obs, _ = env.reset()\n",
    "        done = False\n",
    "        state = None\n",
    "        rewards = []\n",
    "        infos = []\n",
    "\n",
    "        # === Tracker setup ===\n",
    "        tracker = MarketVersusWalletHistoryTracker()\n",
    "        initial_price = env.env.env.episode_df.iloc[0]['close']\n",
    "        tracker.reset(initial_price)\n",
    "\n",
    "        while not done:\n",
    "            action, state = agent.predict(obs, state=state, deterministic=True)\n",
    "            action = int(action)\n",
    "            current_price = env.env.env.episode_df.iloc[env.env.env.current_step]['close']\n",
    "\n",
    "            # Step the wallet tracker\n",
    "            tracker.step(action, current_price)\n",
    "\n",
    "            obs, reward, done, _, info = env.step(action)\n",
    "            rewards.append(reward)\n",
    "            infos.append(info)\n",
    "\n",
    "        # === Episode summary ===\n",
    "        _env = env.env.env\n",
    "        agent_wealth = infos[-1].get(\"final_wealth\", np.nan)\n",
    "        market_wealth = np.prod(1 + _env.episode_df['market_return_1d'].values)\n",
    "        alpha = agent_wealth - market_wealth\n",
    "\n",
    "        metrics = {\n",
    "            \"total_reward\": np.sum(rewards),\n",
    "            \"final_wealth\": agent_wealth,\n",
    "            \"market_wealth\": market_wealth,\n",
    "            \"calmar\": infos[-1].get(\"calmar\", np.nan),\n",
    "            \"sharpe\": infos[-1].get(\"episode_sharpe\", np.nan),\n",
    "            \"sortino\": infos[-1].get(\"episode_sortino\", np.nan),\n",
    "            \"alpha\": alpha,\n",
    "            \"episode_id\": _env.episode_counter,\n",
    "            \"regime\": infos[-1].get(\"regime\", np.nan)\n",
    "        }\n",
    "\n",
    "        tracker_data = tracker.export()\n",
    "        info[\"ticker\"] = _env.episode_df.iloc[0]['symbol']\n",
    "        info[\"wallet_history\"] = tracker_data[\"wallet_history\"]\n",
    "        info[\"market_history\"] = tracker_data[\"market_history\"]\n",
    "        info[\"market_price_history\"] = tracker_data[\"market_price_history\"]\n",
    "        info[\"performed_action_history\"] = tracker_data[\"performed_action_history\"]\n",
    "        episode_infos.append(info)\n",
    "        episode_metrics.append(metrics)\n",
    "\n",
    "    return pd.DataFrame(episode_metrics), episode_infos\n",
    "\n",
    "def evaluate_random_agent( env, n_episodes=22):\n",
    "    episode_metrics = []\n",
    "    episode_infos = []\n",
    "\n",
    "    for _ in tqdm(range(n_episodes), desc=\"Evaluating Agent\"):\n",
    "        obs, _ = env.reset()\n",
    "        done = False\n",
    "        state = None\n",
    "        rewards = []\n",
    "        infos = []\n",
    "\n",
    "        # === Tracker setup ===\n",
    "        tracker = MarketVersusWalletHistoryTracker()\n",
    "        initial_price = env.env.env.episode_df.iloc[0]['close']\n",
    "        tracker.reset(initial_price)\n",
    "        initial_symbol =env.env.env.episode_df.iloc[0]['symbol']\n",
    "        #print(initial_symbol,env.env.env.episode_df.iloc[0]['date'],len(env.env.env.episode_df),env.env.env.episode_counter,env.env.env.episode_sequence)\n",
    "        while not done:\n",
    "            action=  env.action_space.sample()\n",
    "            action = int(action)\n",
    "            current_price = env.env.env.episode_df.iloc[env.env.env.current_step]['close']\n",
    "            current_symbol = env.env.env.episode_df.iloc[env.env.env.current_step]['symbol']\n",
    "            if(current_symbol != initial_symbol):\n",
    "                print('EPISODE SWITCHED', initial_symbol,current_symbol)\n",
    "                initial_symbol = current_symbol\n",
    "            # Step the wallet tracker\n",
    "            tracker.step(action, current_price)\n",
    "\n",
    "            obs, reward, done, _, info = env.step(action)\n",
    "            rewards.append(reward)\n",
    "            infos.append(info)\n",
    "        #print(current_symbol)\n",
    "        # === Episode summary ===\n",
    "        _env = env.env.env\n",
    "        agent_wealth = infos[-1].get(\"final_wealth\", np.nan)\n",
    "        market_wealth = np.prod(1 + _env.episode_df['market_return_1d'].values)\n",
    "        alpha = agent_wealth - market_wealth\n",
    "\n",
    "        metrics = {\n",
    "            \"total_reward\": np.sum(rewards),\n",
    "            \"final_wealth\": agent_wealth,\n",
    "            \"market_wealth\": market_wealth,\n",
    "            \"calmar\": infos[-1].get(\"calmar\", np.nan),\n",
    "            \"sharpe\": infos[-1].get(\"episode_sharpe\", np.nan),\n",
    "            \"sortino\": infos[-1].get(\"episode_sortino\", np.nan),\n",
    "            \"alpha\": alpha,\n",
    "            \"episode_id\": _env.episode_counter,\n",
    "            \"regime\": infos[-1].get(\"regime\", np.nan)\n",
    "        }\n",
    "\n",
    "        tracker_data = tracker.export()\n",
    "        info[\"ticker\"] = _env.episode_df.iloc[0]['symbol']\n",
    "        info[\"wallet_history\"] = tracker_data[\"wallet_history\"]\n",
    "        info[\"market_history\"] = tracker_data[\"market_history\"]\n",
    "        info[\"market_price_history\"] = tracker_data[\"market_price_history\"]\n",
    "        info[\"performed_action_history\"] = tracker_data[\"performed_action_history\"]\n",
    "        episode_infos.append(info)\n",
    "        episode_metrics.append(metrics)\n",
    "\n",
    "    return pd.DataFrame(episode_metrics), episode_infos\n",
    "\n",
    "\n",
    "# === Run Evaluation ===\n",
    "\n",
    "model = RecurrentPPO.load(MODEL_PATH)\n",
    "\n",
    "def make_test_env():\n",
    "    eval_env =ENV_CLASS(test_df, episode_length=EPISODE_LENGTH, feature_cols=FEATURE_COLS)\n",
    "    eval_env.set_episode_sequence(test_seq)\n",
    "    return PerEpisodeRewardNormalizer(RegimeAugmentingWrapper(eval_env)) #RegimeAugmentingWrapper(ENV_CLASS(test_df, episode_length=EPISODE_LENGTH,feature_cols=FEATURE_COLS))\n",
    "\n",
    "\n",
    "ppo_agent_df, ppo_agent_infos = evaluate_agent(model, make_test_env(), n_episodes=22)\n",
    "random_agent_df, random_agent_infos = evaluate_random_agent(make_test_env(), n_episodes=22)\n",
    "\n",
    "ppo_agent_df[\"agent\"] = \"recurrent_ppo\"\n",
    "random_agent_df[\"agent\"] = \"random\"\n",
    "results_df = pd.concat([ppo_agent_df, random_agent_df])\n",
    "\n",
    "\n",
    "# === Plotting ===\n",
    "melted = results_df.melt(id_vars=\"agent\", var_name=\"metric\", value_name=\"value\")\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.boxplot(data=melted, x=\"metric\", y=\"value\", hue=\"agent\")\n",
    "plt.title(\"Agent Performance Comparison (Random vs Recurrent PPO)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# === Statistical Tests ===\n",
    "comparison_results = []\n",
    "\n",
    "for metric in ppo_agent_df.columns[:-1]:  # exclude 'agent'\n",
    "    a = ppo_agent_df[metric].dropna()\n",
    "    b = random_agent_df[metric].dropna()\n",
    "\n",
    "    # Skip if either is empty\n",
    "    if len(a) == 0 or len(b) == 0:\n",
    "        print(f\"Skipping metric {metric}: empty values\")\n",
    "        continue\n",
    "\n",
    "    t_stat, p_val_t = ttest_ind(a, b)\n",
    "    u_stat, p_val_u = mannwhitneyu(a, b, alternative='two-sided')\n",
    "    comparison_results.append({\n",
    "        \"metric\": metric,\n",
    "        \"t-test p-value\": p_val_t,\n",
    "        \"mann-whitney p-value\": p_val_u\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_results)\n",
    "comparison_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "77d6d6f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('LIN', 4),\n",
       " ('SO', 10),\n",
       " ('LLY', 11),\n",
       " ('JPM', 3),\n",
       " ('COST', 2),\n",
       " ('NEE', 2),\n",
       " ('GE', 11),\n",
       " ('UBER', 7),\n",
       " ('AMZN', 0),\n",
       " ('META', 6),\n",
       " ('MSFT', 16),\n",
       " ('XOM', 6),\n",
       " ('V', 20),\n",
       " ('TSLA', 17),\n",
       " ('GOOGL', 4),\n",
       " ('AMT', 7),\n",
       " ('UNH', 16),\n",
       " ('CVX', 5),\n",
       " ('PLD', 5),\n",
       " ('WMT', 2),\n",
       " ('SHW', 6),\n",
       " ('AAPL', 11)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_test_env().env.env.episode_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "407fefa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='market_wealth', ylabel='alpha'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(data=ppo_agent_df, x='market_wealth', y='alpha', hue='regime', alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15d832fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "sns.scatterplot(data=ppo_agent_df, x='market_wealth', y='alpha', hue='agent')\n",
    "plt.axhline(0, linestyle='--', color='red', label='Alpha = 0')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb71e476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='agent', ylabel='alpha_ratio'>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkMAAAGwCAYAAACq12GxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAs5klEQVR4nO3df1iUdb7/8dcIMuAPJgUhLQTdSilUFFaD1tVqw6W0tHOOmmcxt7RsNVPaK2NNM/tB9mutbTWtts2Ouu6p7LTniMWWtSpigZC1umhlgQUamINrCjpzf//w61w7gYbjwMzweT6u676umc/9uW/eA5fO6/p8Pvd92yzLsgQAAGCoDoEuAAAAIJAIQwAAwGiEIQAAYDTCEAAAMBphCAAAGI0wBAAAjEYYAgAARgsPdAHBzu126+uvv1bXrl1ls9kCXQ4AAGgBy7J0+PBh9erVSx06nHnshzD0A77++mslJCQEugwAAOCDqqoqXXjhhWfsQxj6AV27dpV08pcZHR0d4GoAAEBL1NfXKyEhwfM9fiaEoR9wamosOjqaMAQAQIhpyRIXFlADAACjEYYAAIDRCEMAAMBohCEAAGA0whAAADAaYQgAABiNMAQAAIxGGAIAAEYjDAEAAKMRhgAYq6ioSBMmTFBRUVGgSwEQQIQhAEY6duyYnnrqKe3fv19PPfWUjh07FuiSAAQIYQiAkVatWqW6ujpJUl1dnVavXh3gigAECmEIgHH27dun1atXy7IsSZJlWVq9erX27dsX4MoABAJhCIBRLMvS008/fdr2UwEJgDkIQwCMUllZqQ8//FAul8ur3eVy6cMPP1RlZWWAKgMQKIQhAEbp3bu3fvzjHyssLMyrPSwsTEOHDlXv3r0DVBmAQCEMATCKzWbTXXfdddp2m80WgKoABBJhCIBxLrzwQk2aNMkTfGw2myZNmqQLLrggwJUBCATCEAAj/ed//qdiYmIkSbGxsZo0aVKAKwIQKIQhAEaKjIxUbm6u4uPjNWfOHEVGRga6JAABEh7oAgAgUDIzM5WZmRnoMgAEWMiNDC1dulR9+vRRZGSk0tLStGnTphYdt2XLFoWHhys1NbV1CwQAACElpEaG1q5dq9mzZ2vp0qW64oortHz5cmVnZ2vnzp1nvBzW6XRq8uTJuvrqq7V///42rBjwZlkWz8AKEpZlqaGhQZJkt9u5iixIREZG8rdAm7NZIXS71WHDhmnIkCFatmyZpy05OVljx45Vfn7+aY+bOHGiLr74YoWFhemNN95QeXl5i39mfX29HA6HnE6noqOjz6V8QEePHlV2dnagywCCVkFBgaKiogJdBtqBs/n+DplpssbGRpWWliorK8urPSsrS0VFRac97qWXXtJnn32m+++/v0U/p6GhQfX19V4bAABov0Jmmqy2tlYul0vx8fFe7fHx8aqpqWn2mD179ujee+/Vpk2bFB7eso+an5+vBx544JzrBZoTGRmpgoKCQJcBSceOHdO4ceMkSevWreNqsiDB3wGBEDJh6JTvzyVbltXs/LLL5dKkSZP0wAMP6JJLLmnx+fPy8pSbm+t5X19fr4SEBN8LBv6FzWZjCiAIRUZG8ncBDBYyYSg2NlZhYWFNRoEOHDjQZLRIkg4fPqySkhKVlZVp5syZkiS32y3LshQeHq63335bV111VZPj7Ha77HZ763wIAAAQdEJmzVBERITS0tJUWFjo1V5YWNjsfUKio6P18ccfq7y83LNNnz5d/fr1U3l5uYYNG9ZWpQMAgCAWMiNDkpSbm6ucnBylp6crIyNDK1asUGVlpaZPny7p5BTXV199pZUrV6pDhw5KSUnxOj4uLk6RkZFN2gEAgLlCKgxNmDBBdXV1WrRokaqrq5WSkqL169crMTFRklRdXa3KysoAVwkAAEJJSN1nKBC4zxDQPv3rPZ+4tw3Q/rTL+wwBAAC0BsIQAAAwGmEIAAAYjTAEAACMRhgCAABGIwwBAACjEYYAAIDRCEMAAMBohCEAAGA0whAAADAaYQgAABiNMAQAAIxGGAIAAEYjDAEAAKMRhgAAgNEIQwAAwGiEIQAAYDTCEAAAMBphCAAAGI0wBAAAjEYYAgAARiMMAQAAoxGGAACA0QhDAADAaIQhAABgNMIQAAAwGmEIAAAYjTAEAACMRhgCAABGIwwBAACjEYYAAIDRCEMAAMBohCEAAGA0whAAADAaYQgAABiNMAQAAIxGGAIAAEYjDAEAAKMRhgAAgNEIQwAAwGiEIQAAYLSQC0NLly5Vnz59FBkZqbS0NG3atOm0fTdv3qwrrrhCMTExioqKUv/+/fXb3/62DasFAADBLjzQBZyNtWvXavbs2Vq6dKmuuOIKLV++XNnZ2dq5c6d69+7dpH/nzp01c+ZMDRw4UJ07d9bmzZt1++23q3PnzrrtttsC8AkAAECwsVmWZQW6iJYaNmyYhgwZomXLlnnakpOTNXbsWOXn57foHDfeeKM6d+6sV155pUX96+vr5XA45HQ6FR0d7VPdAILP0aNHlZ2dLUkqKChQVFRUgCsC4E9n8/0dMtNkjY2NKi0tVVZWlld7VlaWioqKWnSOsrIyFRUVacSIEaft09DQoPr6eq8NAAC0XyEThmpra+VyuRQfH+/VHh8fr5qamjMee+GFF8putys9PV0zZszQ1KlTT9s3Pz9fDofDsyUkJPilfgAAEJxCJgydYrPZvN5bltWk7fs2bdqkkpISPffcc1qyZInWrFlz2r55eXlyOp2eraqqyi91AwCA4BQyC6hjY2MVFhbWZBTowIEDTUaLvq9Pnz6SpAEDBmj//v1auHChbrrppmb72u122e12/xQNAACCXsiMDEVERCgtLU2FhYVe7YWFhcrMzGzxeSzLUkNDg7/LAwAAISpkRoYkKTc3Vzk5OUpPT1dGRoZWrFihyspKTZ8+XdLJKa6vvvpKK1eulCT9/ve/V+/evdW/f39JJ+879MQTT+jOO+8M2GcAAADBJaTC0IQJE1RXV6dFixapurpaKSkpWr9+vRITEyVJ1dXVqqys9PR3u93Ky8vT3r17FR4erh/96Ed69NFHdfvttwfqIwAAgCATUvcZCgTuMwS0T9xnCGjf2uV9hgAAAFoDYQgAABiNMAQAAIxGGAIAAEYjDAEAAKMRhgAAgNEIQwAAwGiEIQAAYDTCEAAAMBphCAAAGI0wBAAAjEYYAgAARiMMAQAAoxGGAACA0QhDAADAaIQhAABgNMIQAAAwGmEIAAAYjTAEAACMRhgCAABGIwwBAACjEYYAAIDRCEMAAMBohCEAAGA0whAAADAaYQgAABiNMAQAAIxGGAIAAEYjDAEAAKMRhgAAgNEIQwAAwGiEIQAAYDTCEAAAMBphCAAAGI0wBAAAjEYYAgAARiMMAQAAoxGGAACA0QhDAADAaIQhAABgNMIQAAAwWsiFoaVLl6pPnz6KjIxUWlqaNm3adNq+r7/+uq655hr16NFD0dHRysjI0FtvvdWG1QIAgGAXUmFo7dq1mj17tubNm6eysjINHz5c2dnZqqysbLb/3/72N11zzTVav369SktLdeWVV2rMmDEqKytr48oBAECwslmWZQW6iJYaNmyYhgwZomXLlnnakpOTNXbsWOXn57foHJdddpkmTJigBQsWNLu/oaFBDQ0Nnvf19fVKSEiQ0+lUdHT0uX0AAEHj6NGjys7OliQVFBQoKioqwBUB8Kf6+no5HI4WfX+HzMhQY2OjSktLlZWV5dWelZWloqKiFp3D7Xbr8OHD6t69+2n75Ofny+FweLaEhIRzqhsAAAS3kAlDtbW1crlcio+P92qPj49XTU1Ni87x5JNP6siRIxo/fvxp++Tl5cnpdHq2qqqqc6obAAAEt/BAF3C2bDab13vLspq0NWfNmjVauHCh/ud//kdxcXGn7We322W328+5TgAAEBpCJgzFxsYqLCysySjQgQMHmowWfd/atWt166236r//+7/1s5/9rDXLBAAAISZkpskiIiKUlpamwsJCr/bCwkJlZmae9rg1a9ZoypQpWr16ta677rrWLhMAAISYkBkZkqTc3Fzl5OQoPT1dGRkZWrFihSorKzV9+nRJJ9f7fPXVV1q5cqWkk0Fo8uTJevrpp3X55Zd7RpWioqLkcDgC9jkAAEDwCKkwNGHCBNXV1WnRokWqrq5WSkqK1q9fr8TERElSdXW11z2Hli9frhMnTmjGjBmaMWOGp/3mm2/WH//4x7YuHwAABKGQus9QIJzNfQoAhA7uMwS0b+3yPkMAAACtgTAEAACMRhgCAABGIwwBAACjEYYAAIDRCEMAAMBohCEAAGA0whAAADAaYQgAABiNMAQAAIx2zmFo3759+uqrr/xRCwAAQJvzKQy53W4tWrRIDodDiYmJ6t27t8477zw9+OCDcrvd/q4RAACg1fj01Pp58+bpxRdf1KOPPqorrrhClmVpy5YtWrhwoY4dO6aHH37Y33UCAAC0Cp/C0Msvv6wXXnhB119/vadt0KBBuuCCC/SrX/2KMAQAAEKGT9NkBw8eVP/+/Zu09+/fXwcPHjznogAAANqKT2Fo0KBBevbZZ5u0P/vssxo0aNA5FwUAANBWfJome+yxx3Tdddfpr3/9qzIyMmSz2VRUVKSqqiqtX7/e3zUCAAC0Gp9GhkaMGKHdu3dr3LhxOnTokA4ePKgbb7xRFRUVGj58uL9rBAAAaDU+jQxJUq9evVgoDQAAQl6Lw9COHTuUkpKiDh06aMeOHWfsO3DgwHMuDAAAoC20OAylpqaqpqZGcXFxSk1Nlc1mk2VZTfrZbDa5XC6/FgkAANBaWhyG9u7dqx49enheAwAAtActDkOJiYme119++aUyMzMVHu59+IkTJ1RUVOTVFwAAIJj5dDXZlVde2ezNFZ1Op6688spzLgoAAKCt+HQ1mWVZstlsTdrr6urUuXPncy4K/mVZlo4dOxboMoCg8q//Jvj3ATQvMjKy2e/79uaswtCNN94o6eQi6SlTpshut3v2uVwu7dixQ5mZmf6tEOfs2LFjys7ODnQZQNAaN25coEsAglJBQYGioqICXUarO6sw5HA4JJ0caejatavXLygiIkKXX365pk2b5t8KAQAAWtFZhaGXXnpJkpSUlKRf//rXTImFoH+m3iSrg8/32gTaD8uS3CdOvu4QLhkwFQC0hM19Ql3K1wS6jDbl07fi/fff7+860EasDuFSWMdAlwEEiYhAFwAEnaZ3EGz/fB4iePXVV/XnP/9ZlZWVamxs9Nq3ffv2cy4MAACgLfh0af0zzzyjX/7yl4qLi1NZWZmGDh2qmJgYff755yzUBQAAIcWnMLR06VKtWLFCzz77rCIiInTPPfeosLBQs2bNktPp9HeNAAAArcanMFRZWem5hD4qKkqHDx+WJOXk5GjNGrMWXQEAgNDmUxg6//zzVVdXJ+nkYzqKi4slnXxmWXMPbwUAAAhWPoWhq666Sn/5y18kSbfeeqvmzJmja665RhMmTODmZQAAIKT4dDXZihUr5Ha7JUnTp09X9+7dtXnzZo0ZM0bTp0/3a4EAAACt6azD0IkTJ/Twww/rlltuUUJCgiRp/PjxGj9+vN+LAwAAaG1nPU0WHh6uxx9/XC6XqzXqAQAAaFM+rRn62c9+pvfee8/PpQAAALQ9n9YMZWdnKy8vT5988onS0tKaPKPs+uuv90txAAAArc2nMHTHHXdIkp566qkm+2w2W6tOoS1dulSPP/64qqurddlll2nJkiUaPnx4s32rq6t19913q7S0VHv27NGsWbO0ZMmSVqsNAACEHp+mydxu92m31gxCa9eu1ezZszVv3jyVlZVp+PDhys7OVmVlZbP9Gxoa1KNHD82bN0+DBg1qtboAAEDo8ikMtdSAAQNUVVXlt/M99dRTuvXWWzV16lQlJydryZIlSkhI0LJly5rtn5SUpKefflqTJ0+Ww+HwWx0AAKD9aNUw9MUXX+j48eN+OVdjY6NKS0uVlZXl1Z6VlaWioiK//Azp5GhSfX291wYAANqvVg1D/lRbWyuXy6X4+Hiv9vj4eNXU1Pjt5+Tn58vhcHi2U/dSAgAA7VPIhKFTbDab13vLspq0nYu8vDw5nU7P5s9pPgAAEHx8uposEGJjYxUWFtZkFOjAgQNNRovOhd1ul91u99v5AABAcAuZkaGIiAilpaWpsLDQq72wsFCZmZkBqgoAAIS6kBkZkqTc3Fzl5OQoPT1dGRkZWrFihSorKz0Ph83Ly9NXX32llStXeo4pLy+XJP3zn//UN998o/LyckVEROjSSy8NxEcAAABBplXD0PLly/06hTVhwgTV1dVp0aJFqq6uVkpKitavX6/ExERJJ2+y+P17Dg0ePNjzurS0VKtXr1ZiYqK++OILv9UFAABCl82yLMuXA48cOaL3339flZWVamxs9No3a9YsvxQXDOrr6+VwOOR0OhUdHR3ocnxy9OhRZWdnS5IOD8mRwjoGuCIAQNByHVfX7a9IkgoKChQVFRXggnxzNt/fPo0MlZWV6dprr9V3332nI0eOqHv37qqtrVWnTp0UFxfXrsIQAABo33xaQD1nzhyNGTNGBw8eVFRUlIqLi/Xll18qLS1NTzzxhL9rBAAAaDU+haHy8nLdfffdCgsLU1hYmBoaGpSQkKDHHntMv/nNb/xdIwAAQKvxKQx17NjRc6PD+Ph4z6Jlh8Nx2oemAgAABCOf1gwNHjxYJSUluuSSS3TllVdqwYIFqq2t1SuvvKIBAwb4u0YAAIBW49PI0COPPKKePXtKkh588EHFxMTojjvu0IEDB7RixQq/FggAANCafBoZSk9P97zu0aOH1q9f77eCAAAA2lLIPI4DAACgNfgUhvbv36+cnBz16tVL4eHhnqvKTm0AAAChwqdpsilTpqiyslLz589Xz549PVeWAQAAhBqfwtDmzZu1adMmpaam+rkcAACAtuXTNFlCQoJ8fKQZAABAUPEpDC1ZskT33nsvT34HAAAhr8XTZN26dfNaG3TkyBH96Ec/UqdOndSxo/dT0A8ePOi/CgEAAFpRi8PQkiVLWrEMAACAwGhxGLr55ptbsw4AAICA8OlqMklyuVxat26ddu3aJZvNpuTkZN1www0KD/f5lAAAAG3Op+TyySef6IYbblBNTY369esnSdq9e7d69OihN998k4e1AgCAkOHT1WRTp07VZZddpn379mn79u3avn27qqqqNHDgQN12223+rhEAAKDV+DQy9NFHH6mkpETdunXztHXr1k0PP/ywfvzjH/utOAAAgNbm08hQv379tH///ibtBw4c0EUXXXTORQEAALQVn8LQI488olmzZunVV1/Vvn37tG/fPr366quaPXu2Fi9erPr6es8GAAAQzHyaJhs9erQkafz48Z4bMZ56PMeYMWM87202m1wulz/qBAAAaBU+haGNGzf6uw4AAICA8CkMjRgxwt91AAAABESLw9COHTtafNKBAwf6VAwAAEBba3EYSk1Nlc1m86wNOh3WCQEAgFDS4jC0d+/e1qwDAAAgIFochhITE5u07dy5U5WVlWpsbPS02Wy2ZvsicLxG81zHA1cIACD4/cv3xA/NBrUXPi2g/vzzzzVu3Dh9/PHHXlNnpy6zZ5osuDQ0NHhed/3oTwGsBAAQShoaGtSpU6dAl9HqfLrp4l133aU+ffpo//796tSpkz755BP97W9/U3p6ut577z0/lwgAANB6fBoZ2rp1q95991316NFDHTp0UFhYmH7yk58oPz9fs2bNUllZmb/rxDmw2+2e14cHTZTCOgawGgBAUHMd98wi/Ov3R3vmUxhyuVzq0qWLJCk2NlZff/21+vXrp8TERFVUVPi1QJy7U9OXkk4GIcIQAKAFvL4/2jGfwlBKSop27Nihvn37atiwYXrssccUERGhFStWqG/fvv6uEQAAoNX4FIbuu+8+HTlyRJL00EMPafTo0Ro+fLhiYmK0du1avxYIAADQmnwKQ6NGjfK87tu3r3bu3KmDBw+qW7duxgypAQCA9sGnMNSc7t27++tUAAAAbcanS+sBAADaC8IQAAAwGmEIAAAYjTAEAACMFnJhaOnSperTp48iIyOVlpamTZs2nbH/+++/r7S0NEVGRqpv37567rnn2qhSAAAQCkIqDK1du1azZ8/WvHnzVFZWpuHDhys7O1uVlZXN9t+7d6+uvfZaDR8+XGVlZfrNb36jWbNm6bXXXmvjygEAQLAKqTD01FNP6dZbb9XUqVOVnJysJUuWKCEhQcuWLWu2/3PPPafevXtryZIlSk5O1tSpU3XLLbfoiSeeaOPKAQBAsAqZMNTY2KjS0lJlZWV5tWdlZamoqKjZY7Zu3dqk/6hRo1RSUqLjx483e0xDQ4Pq6+u9NgAA0H6FTBiqra2Vy+VSfHy8V3t8fLxqamqaPaampqbZ/idOnFBtbW2zx+Tn58vhcHi2hIQE/3wAAAAQlEImDJ3y/cd9WJZ1xkeANNe/ufZT8vLy5HQ6PVtVVdU5VgwAAIKZ3x7H0dpiY2MVFhbWZBTowIEDTUZ/Tjn//POb7R8eHq6YmJhmj7Hb7bLb7f4pGgAABL2QGRmKiIhQWlqaCgsLvdoLCwuVmZnZ7DEZGRlN+r/99ttKT09Xx44dW61WAAAQOkImDElSbm6uXnjhBf3hD3/Qrl27NGfOHFVWVmr69OmSTk5xTZ482dN/+vTp+vLLL5Wbm6tdu3bpD3/4g1588UX9+te/DtRHAAAAQSZkpskkacKECaqrq9OiRYtUXV2tlJQUrV+/XomJiZKk6upqr3sO9enTR+vXr9ecOXP0+9//Xr169dIzzzyjf/u3fwvURwAAAEHGZp1aUYxm1dfXy+FwyOl0Kjo6OtDl+OTo0aPKzs6WJB0ekiOFMUUIADgN13F13f6KJKmgoEBRUVEBLsg3Z/P9HVLTZAAAAP5GGAIAAEYjDAEAAKMRhgAAgNEIQwAAwGiEIQAAYDTCEAAAMBphCAAAGI0wBAAAjEYYAgAARiMMAQAAoxGGAACA0QhDAADAaIQhAABgNMIQAAAwGmEIAAAYjTAEAACMFh7oAtC2bO4TsgJdBBAMLEtynzj5ukO4ZLMFth4gSNhO/bswCGHIMF3K1wS6BAAAggrTZAAAwGiMDBkgMjJSBQUFgS4DCCrHjh3TuHHjJEnr1q1TZGRkgCsCgo8p/y4IQwaw2WyKiooKdBlA0IqMjOTfCGAwpskAAIDRCEMAAMBohCEAAGA0whAAADAaYQgAABiNMAQAAIxGGAIAAEYjDAEAAKMRhgAAgNEIQwAAwGiEIQAAYDTCEAAAMBphCAAAGI0wBAAAjEYYAgAARiMMAQAAoxGGAACA0QhDAADAaIQhAABgtJAJQ99++61ycnLkcDjkcDiUk5OjQ4cOnfGY119/XaNGjVJsbKxsNpvKy8vbpFYAABA6QiYMTZo0SeXl5dqwYYM2bNig8vJy5eTknPGYI0eO6IorrtCjjz7aRlUCAIBQEx7oAlpi165d2rBhg4qLizVs2DBJ0vPPP6+MjAxVVFSoX79+zR53Kix98cUXLf5ZDQ0Namho8Lyvr6/3vXAAABD0QmJkaOvWrXI4HJ4gJEmXX365HA6HioqK/Pqz8vPzPVNxDodDCQkJfj0/AAAILiERhmpqahQXF9ekPS4uTjU1NX79WXl5eXI6nZ6tqqrKr+cHAADBJaBhaOHChbLZbGfcSkpKJEk2m63J8ZZlNdt+Lux2u6Kjo702AADQfgV0zdDMmTM1ceLEM/ZJSkrSjh07tH///ib7vvnmG8XHx7dWeQAAwAABDUOxsbGKjY39wX4ZGRlyOp364IMPNHToUEnStm3b5HQ6lZmZ2dplAgCAdiwk1gwlJyfr5z//uaZNm6bi4mIVFxdr2rRpGj16tNeVZP3799e6des87w8ePKjy8nLt3LlTklRRUaHy8nK/rzMCAAChKyTCkCStWrVKAwYMUFZWlrKysjRw4EC98sorXn0qKirkdDo97998800NHjxY1113nSRp4sSJGjx4sJ577rk2rR0AAAQvm2VZVqCLCGb19fVyOBxyOp0spgbakaNHjyo7O1uSVFBQoKioqABXBMCfzub7O2RGhgAAAFoDYQgAABiNMAQAAIxGGAIAAEYjDAEAAKMRhgAAgNEIQwAAwGiEIQAAYDTCEAAAMBphCAAAGI0wBAAAjEYYAgAARiMMAQAAoxGGAACA0QhDAADAaIQhAABgNMIQAAAwGmEIAAAYjTAEAACMRhgCAABGIwwBAACjEYYAAIDRCEMAAMBohCEAAGA0whAAADAaYQgAABiNMAQAAIxGGAIAAEYjDAEAAKMRhgAAgNEIQwAAwGiEIQAAYDTCEAAAMBphCAAAGI0wBAAAjEYYAgAARiMMAQAAoxGGAACA0QhDAADAaIQhAABgtJAJQ99++61ycnLkcDjkcDiUk5OjQ4cOnbb/8ePHNXfuXA0YMECdO3dWr169NHnyZH399ddtVzQAAAh6IROGJk2apPLycm3YsEEbNmxQeXm5cnJyTtv/u+++0/bt2zV//nxt375dr7/+unbv3q3rr7++DasGAADBLjzQBbTErl27tGHDBhUXF2vYsGGSpOeff14ZGRmqqKhQv379mhzjcDhUWFjo1fa73/1OQ4cOVWVlpXr37t0mtQMAgOAWEiNDW7dulcPh8AQhSbr88svlcDhUVFTU4vM4nU7ZbDadd955p+3T0NCg+vp6rw0AALRfIRGGampqFBcX16Q9Li5ONTU1LTrHsWPHdO+992rSpEmKjo4+bb/8/HzPuiSHw6GEhASf6wYAAMEvoGFo4cKFstlsZ9xKSkokSTabrcnxlmU12/59x48f18SJE+V2u7V06dIz9s3Ly5PT6fRsVVVVvn04AAAQEgK6ZmjmzJmaOHHiGfskJSVpx44d2r9/f5N933zzjeLj4894/PHjxzV+/Hjt3btX77777hlHhSTJbrfLbrf/cPEAAKBdCGgYio2NVWxs7A/2y8jIkNPp1AcffKChQ4dKkrZt2yan06nMzMzTHncqCO3Zs0cbN25UTEyM32oHAADtQ0isGUpOTtbPf/5zTZs2TcXFxSouLta0adM0evRoryvJ+vfvr3Xr1kmSTpw4oX//939XSUmJVq1aJZfLpZqaGtXU1KixsTFQHwUAAASZkAhDkrRq1SoNGDBAWVlZysrK0sCBA/XKK6949amoqJDT6ZQk7du3T2+++ab27dun1NRU9ezZ07OdzRVoAACgfQuJ+wxJUvfu3fVf//VfZ+xjWZbndVJSktd7AACA5oTMyBAAAEBrIAwBAACjEYYAAIDRCEMAAMBohCEAAGA0whAAADBayFxaD7QHlmXp2LFjgS4Dktffgb9J8IiMjGzRMycBfyIMAW3o2LFjys7ODnQZ+J5x48YFugT8fwUFBYqKigp0GTAM02QAAMBojAwBbSgyMlIFBQWBLgM6OWXZ0NAgSbLb7UzNBInIyMhAlwADEYaANmSz2ZgCCCKdOnUKdAkAggDTZAAAwGiEIQAAYDTCEAAAMBphCAAAGI0wBAAAjEYYAgAARiMMAQAAoxGGAACA0QhDAADAaIQhAABgNMIQAAAwGmEIAAAYjTAEAACMxlPrf4BlWZKk+vr6AFcCAABa6tT39qnv8TMhDP2Aw4cPS5ISEhICXAkAADhbhw8flsPhOGMfm9WSyGQwt9utr7/+Wl27dpXNZgt0OQD8qL6+XgkJCaqqqlJ0dHSgywHgR5Zl6fDhw+rVq5c6dDjzqiDCEABj1dfXy+FwyOl0EoYAg7GAGgAAGI0wBAAAjEYYAmAsu92u+++/X3a7PdClAAgg1gwBAACjMTIEAACMRhgCAABGIwwBAACjEYYAAIDRCEMA0AJffPGFbDabysvLA10KAD8jDAHwu8bGxjb/mS6XS263OyhqARBaCEMAztnIkSM1c+ZM5ebmKjY2Vtdcc4127typa6+9Vl26dFF8fLxycnJUW1vrOcbtdmvx4sW66KKLZLfb1bt3bz388MOSpPfee082m02HDh3y9C8vL5fNZtMXX3whSfrjH/+o8847T//7v/+rSy+9VHa7XV9++aWSkpL00EMPacqUKXI4HJo2bZokqaioSD/96U8VFRWlhIQEzZo1S0eOHPGcPykpSY888ohuueUWde3aVb1799aKFSs8+/v06SNJGjx4sGw2m0aOHPmDv5cpU6Zo7NixeuCBBxQXF6fo6GjdfvvtXgHt1O9u5syZOu+88xQTE6P77rvP60nb3377rSZPnqxu3bqpU6dOys7O1p49e1r+BwJwRoQhAH7x8ssvKzw8XFu2bNGjjz6qESNGKDU1VSUlJdqwYYP279+v8ePHe/rn5eVp8eLFmj9/vnbu3KnVq1crPj7+rH7md999p/z8fL3wwgv6+9//rri4OEnS448/rpSUFJWWlmr+/Pn6+OOPNWrUKN14443asWOH1q5dq82bN2vmzJle53vyySeVnp6usrIy/epXv9Idd9yhf/zjH5KkDz74QJL017/+VdXV1Xr99ddbVOM777yjXbt2aePGjVqzZo3WrVunBx54oNnf3bZt2/TMM8/ot7/9rV544QXP/ilTpqikpERvvvmmtm7dKsuydO211+r48eNn9fsCcBoWAJyjESNGWKmpqZ738+fPt7Kysrz6VFVVWZKsiooKq76+3rLb7dbzzz/f7Pk2btxoSbK+/fZbT1tZWZklydq7d69lWZb10ksvWZKs8vJyr2MTExOtsWPHerXl5ORYt912m1fbpk2brA4dOlhHjx71HPeLX/zCs9/tdltxcXHWsmXLLMuyrL1791qSrLKysh/+hfx/N998s9W9e3fryJEjnrZly5ZZXbp0sVwul2VZJ393ycnJltvt9vSZO3eulZycbFmWZe3evduSZG3ZssWzv7a21oqKirL+/Oc/t7gWAKcXHsggBqD9SE9P97wuLS3Vxo0b1aVLlyb9PvvsMx06dEgNDQ26+uqrz+lnRkREaODAgWes5VQ9n376qVatWuVpsyxLbrdbe/fuVXJysiR5nctms+n888/XgQMHzqnGQYMGqVOnTp73GRkZ+uc//6mqqiolJiZKki6//HLZbDavPk8++aRcLpd27dql8PBwDRs2zLM/JiZG/fr1065du86pNgAnEYYA+EXnzp09r91ut8aMGaPFixc36dezZ099/vnnZzxXhw4nZ/Ctf1k309yUUFRUlFeIaK6WU/XcfvvtmjVrVpO+vXv39rzu2LGj1z6bzdbsomx/aK7u5lineWKSZVktPgeAMyMMAfC7IUOG6LXXXlNSUpLCw5v+N3PxxRcrKipK77zzjqZOndpkf48ePSRJ1dXV6tatmySd0yXtQ4YM0d///ndddNFFPp8jIiJC0smr1s7GRx99pKNHjyoqKkqSVFxcrC5duujCCy/09CkuLvY6pri4WBdffLHCwsJ06aWX6sSJE9q2bZsyMzMlSXV1ddq9e7dnRAvAuWEBNQC/mzFjhg4ePKibbrpJH3zwgT7//HO9/fbbuuWWW+RyuRQZGam5c+fqnnvu0cqVK/XZZ5+puLhYL774oiTpoosuUkJCghYuXKjdu3fr//7v//Tkk0/6XM/cuXO1detWzZgxQ+Xl5dqzZ4/efPNN3XnnnS0+R1xcnKKiojyLwZ1OZ4uOa2xs1K233qqdO3eqoKBA999/v2bOnOkZ/ZKkqqoq5ebmqqKiQmvWrNHvfvc73XXXXZJOBscbbrhB06ZN0+bNm/XRRx/pF7/4hS644ALdcMMNZ/eLANAswhAAv+vVq5e2bNkil8ulUaNGKSUlRXfddZccDocnBMyfP1933323FixYoOTkZE2YMMGzPqdjx45as2aN/vGPf2jQoEFavHixHnroIZ/rGThwoN5//33t2bNHw4cP1+DBgzV//nz17NmzxecIDw/XM888o+XLl6tXr14tDiJXX321Lr74Yv30pz/V+PHjNWbMGC1cuNCrz+TJk3X06FENHTpUM2bM0J133qnbbrvNs/+ll15SWlqaRo8erYyMDFmWpfXr1zeZ1gPgG5t1uglpAMA5mTJlig4dOqQ33njjtH1Gjhyp1NRULVmypM3qAuCNkSEAAGA0FlADgI+au3XAKQUFBW1YCYBzwTQZAPjo008/Pe2+Cy64wHMFGYDgRhgCAABGY80QAAAwGmEIAAAYjTAEAACMRhgCAABGIwwBAACjEYYA4BzYbLYz3mEaQPAjDAEAAKMRhgCEpA0bNugnP/mJzjvvPMXExGj06NH67LPPPPuLioqUmpqqyMhIpaen64033pDNZlN5ebmnz86dO3XttdeqS5cuio+PV05Ojmpraz37R44cqVmzZumee+5R9+7ddf7553s9ZDUpKUmSNG7cONlsNs97AKGFMAQgJB05ckS5ubn68MMP9c4776hDhw4aN26c3G63Dh8+rDFjxmjAgAHavn27HnzwQc2dO9fr+Orqao0YMUKpqakqKSnRhg0btH//fo0fP96r38svv6zOnTtr27Zteuyxx7Ro0SIVFhZKkj788ENJJ58qX11d7XkPILRwB2oA7cI333yjuLg4ffzxx9q8ebPuu+8+7du3T5GRkZKkF154QdOmTVNZWZlSU1O1YMECbdu2TW+99ZbnHPv27VNCQoIqKip0ySWXaOTIkXK5XNq0aZOnz9ChQ3XVVVfp0UcflXRyzdC6des0duzYNv28APyHkSEAIemzzz7TpEmT1LdvX0VHR6tPnz6SpMrKSlVUVGjgwIGeICSdDDH/qrS0VBs3blSXLl08W//+/T3nPmXgwIFex/Xs2VMHDhxorY8FIAB4aj2AkDRmzBglJCTo+eefV69eveR2u5WSkqLGxkZZliWbzebV//uD4G63W2PGjNHixYubnLtnz56e1x07dvTaZ7PZ5Ha7/fhJAAQaYQhAyKmrq9OuXbu0fPlyDR8+XJK0efNmz/7+/ftr1apVamhokN1ulySVlJR4nWPIkCF67bXXlJSUpPBw3/8r7Nixo1wul8/HAwg8pskAhJxu3bopJiZGK1as0Keffqp3331Xubm5nv2TJk2S2+3Wbbfdpl27dumtt97SE088IUmeEaMZM2bo4MGDuummm/TBBx/o888/19tvv61bbrnlrMJNUlKS3nnnHdXU1Ojbb7/17wcF0CYIQwBCTocOHfSnP/1JpaWlSklJ0Zw5c/T444979kdHR+svf/mLysvLlZqaqnnz5mnBggWS5FlH1KtXL23ZskUul0ujRo1SSkqK7rrrLjkcDnXo0PL/Gp988kkVFhYqISFBgwcP9u8HBdAmuJoMgBFWrVqlX/7yl3I6nYqKigp0OQCCCGuGALRLK1euVN++fXXBBRfoo48+0ty5czV+/HiCEIAmCEMA2qWamhotWLBANTU16tmzp/7jP/5DDz/8cKDLAhCEmCYDAABGYwE1AAAwGmEIAAAYjTAEAACMRhgCAABGIwwBAACjEYYAAIDRCEMAAMBohCEAAGC0/wckBiKHAhsrzgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ppo_agent_df['alpha_ratio'] = ppo_agent_df['alpha'] / np.abs(ppo_agent_df['market_wealth'] + 1e-8)\n",
    "sns.boxplot(data=ppo_agent_df, x='agent', y='alpha_ratio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b12cc700",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGENT > RANDOM value counts agent>random\n",
      "True     13\n",
      "False     9\n",
      "Name: count, dtype: int64\n",
      "AGENT > MARKET value counts agent>market\n",
      "False    12\n",
      "True     10\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agent_wallet</th>\n",
       "      <th>random_wallet</th>\n",
       "      <th>market_wallet</th>\n",
       "      <th>agent&gt;random</th>\n",
       "      <th>agent&gt;market</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.065841</td>\n",
       "      <td>1.034780</td>\n",
       "      <td>1.125752</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.019390</td>\n",
       "      <td>1.057422</td>\n",
       "      <td>1.034882</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.228413</td>\n",
       "      <td>1.252413</td>\n",
       "      <td>1.287680</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.030380</td>\n",
       "      <td>1.034864</td>\n",
       "      <td>1.069142</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.034362</td>\n",
       "      <td>1.058359</td>\n",
       "      <td>1.105384</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.791616</td>\n",
       "      <td>0.937270</td>\n",
       "      <td>0.796494</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.081266</td>\n",
       "      <td>1.029813</td>\n",
       "      <td>1.094549</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.295419</td>\n",
       "      <td>1.265498</td>\n",
       "      <td>1.270158</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.092628</td>\n",
       "      <td>1.178819</td>\n",
       "      <td>1.126862</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.148415</td>\n",
       "      <td>0.984193</td>\n",
       "      <td>1.034525</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.109442</td>\n",
       "      <td>1.047526</td>\n",
       "      <td>1.103266</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.010357</td>\n",
       "      <td>0.848545</td>\n",
       "      <td>0.961874</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.105697</td>\n",
       "      <td>1.043057</td>\n",
       "      <td>1.077780</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.262132</td>\n",
       "      <td>0.841714</td>\n",
       "      <td>1.005905</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.999623</td>\n",
       "      <td>1.104021</td>\n",
       "      <td>1.138085</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.236890</td>\n",
       "      <td>1.030872</td>\n",
       "      <td>1.068939</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.105886</td>\n",
       "      <td>1.032703</td>\n",
       "      <td>1.036516</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.943757</td>\n",
       "      <td>0.850246</td>\n",
       "      <td>0.915823</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.924051</td>\n",
       "      <td>1.061035</td>\n",
       "      <td>0.959747</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.989043</td>\n",
       "      <td>0.957231</td>\n",
       "      <td>1.009738</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.055964</td>\n",
       "      <td>1.057269</td>\n",
       "      <td>1.069336</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.099192</td>\n",
       "      <td>1.065155</td>\n",
       "      <td>0.990159</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    agent_wallet  random_wallet  market_wallet  agent>random  agent>market\n",
       "0       1.065841       1.034780       1.125752          True         False\n",
       "1       1.019390       1.057422       1.034882         False         False\n",
       "2       1.228413       1.252413       1.287680         False         False\n",
       "3       1.030380       1.034864       1.069142         False         False\n",
       "4       1.034362       1.058359       1.105384         False         False\n",
       "5       0.791616       0.937270       0.796494         False         False\n",
       "6       1.081266       1.029813       1.094549          True         False\n",
       "7       1.295419       1.265498       1.270158          True          True\n",
       "8       1.092628       1.178819       1.126862         False         False\n",
       "9       1.148415       0.984193       1.034525          True          True\n",
       "10      1.109442       1.047526       1.103266          True          True\n",
       "11      1.010357       0.848545       0.961874          True          True\n",
       "12      1.105697       1.043057       1.077780          True          True\n",
       "13      1.262132       0.841714       1.005905          True          True\n",
       "14      0.999623       1.104021       1.138085         False         False\n",
       "15      1.236890       1.030872       1.068939          True          True\n",
       "16      1.105886       1.032703       1.036516          True          True\n",
       "17      0.943757       0.850246       0.915823          True          True\n",
       "18      0.924051       1.061035       0.959747         False         False\n",
       "19      0.989043       0.957231       1.009738          True         False\n",
       "20      1.055964       1.057269       1.069336         False         False\n",
       "21      1.099192       1.065155       0.990159          True          True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "episode_complete_results = []\n",
    "for i in range(len(ppo_agent_infos)):# or select based on alpha, reward, etc.\n",
    "#for i in range(5):# or select based on alpha, reward, etc.\n",
    "    info = ppo_agent_infos[i]\n",
    "    info_ = random_agent_infos[i]\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(info['market_history'], label='Market')\n",
    "    plt.plot(info['wallet_history'], label='Wallet (Agent)')\n",
    "    plt.plot(info_['wallet_history'], label='Wallet (Random)')\n",
    "    plt.title(f\"Episode {info.get('episode_id')} - {info.get('ticker')}\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \"\"\"\n",
    "    episode_complete_results.append({\n",
    "        \"agent_wallet\":info['wallet_history'][-1],\n",
    "        \"random_wallet\":info_['wallet_history'][-1],\n",
    "        \"market_wallet\":info_['market_history'][-1],\n",
    "                                   })\n",
    "episode_complete_results_df = pd.DataFrame(episode_complete_results)\n",
    "episode_complete_results_df['agent>random']=episode_complete_results_df['agent_wallet']>episode_complete_results_df['random_wallet']\n",
    "episode_complete_results_df['agent>market']=episode_complete_results_df['agent_wallet']>episode_complete_results_df['market_wallet']\n",
    "print(\"AGENT > RANDOM value counts\",episode_complete_results_df['agent>random'].value_counts())\n",
    "print(\"AGENT > MARKET value counts\",episode_complete_results_df['agent>market'].value_counts())\n",
    "episode_complete_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f3e75250",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPO wins over Random: 13/22, binomial p-value = 0.2617\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import binom_test\n",
    "\n",
    "n_wins = episode_complete_results_df['agent>random'].sum()\n",
    "n_trials = len(episode_complete_results_df)\n",
    "\n",
    "p_val = binom_test(n_wins, n_trials, p=0.5, alternative='greater')\n",
    "print(f\"PPO wins over Random: {n_wins}/{n_trials}, binomial p-value = {p_val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e6298c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'i': 0, 'wallet': 1.0, 'price': 367.55, 'performed_action': 0.0}\n",
      "{'i': 1, 'wallet': 1.0, 'price': 367.55, 'performed_action': 0.0}\n",
      "{'i': 2, 'wallet': 1.0, 'price': 366.84, 'performed_action': 0.0}\n",
      "{'i': 3, 'wallet': 1.0, 'price': 374.6, 'performed_action': 0.0}\n",
      "{'i': 4, 'wallet': 1.0, 'price': 377.14, 'performed_action': 0.0}\n",
      "{'i': 5, 'wallet': 1.0, 'price': 378.58, 'performed_action': 0.0}\n",
      "{'i': 6, 'wallet': 1.0, 'price': 382.11, 'performed_action': 0.0}\n",
      "{'i': 7, 'wallet': 1.0, 'price': 384.27, 'performed_action': 0.0}\n",
      "{'i': 8, 'wallet': 1.0, 'price': 374.71, 'performed_action': 0.0}\n",
      "{'i': 9, 'wallet': 1.0, 'price': 381.6, 'performed_action': 0.0}\n",
      "{'i': 10, 'wallet': 1.0, 'price': 384.54, 'performed_action': 0.0}\n",
      "{'i': 11, 'wallet': 1.0, 'price': 384.69, 'performed_action': 0.0}\n",
      "{'i': 12, 'wallet': 1.0, 'price': 391.04, 'performed_action': 0.0}\n",
      "{'i': 13, 'wallet': 1.0, 'price': 388.21, 'performed_action': 1.0}\n",
      "{'i': 14, 'wallet': 0.9907781870637027, 'price': 384.63, 'performed_action': 0.0}\n",
      "{'i': 15, 'wallet': 1.0012879627006002, 'price': 388.71, 'performed_action': 0.0}\n",
      "{'i': 16, 'wallet': 1.006336776486953, 'price': 390.67, 'performed_action': 0.0}\n",
      "{'i': 17, 'wallet': 1.0011076479225163, 'price': 388.64, 'performed_action': 0.0}\n",
      "{'i': 18, 'wallet': 0.9885886504726824, 'price': 383.78, 'performed_action': 0.0}\n",
      "{'i': 19, 'wallet': 0.9807835965070453, 'price': 380.75, 'performed_action': 0.0}\n",
      "{'i': 20, 'wallet': 0.9732361350815281, 'price': 377.82, 'performed_action': 0.0}\n",
      "{'i': 21, 'wallet': 0.9916540017001109, 'price': 384.97, 'performed_action': 0.0}\n",
      "{'i': 22, 'wallet': 0.9834367996702815, 'price': 381.78, 'performed_action': 0.0}\n",
      "{'i': 23, 'wallet': 0.9777182452796167, 'price': 379.56, 'performed_action': 0.0}\n",
      "{'i': 24, 'wallet': 0.9848277993869298, 'price': 382.32, 'performed_action': 0.0}\n",
      "{'i': 25, 'wallet': 0.9835398366863295, 'price': 381.82, 'performed_action': 0.0}\n",
      "{'i': 26, 'wallet': 0.9844414105767497, 'price': 382.17, 'performed_action': 0.0}\n",
      "{'i': 27, 'wallet': 0.9772545787074005, 'price': 379.38, 'performed_action': 0.0}\n",
      "{'i': 28, 'wallet': 0.973184616573504, 'price': 377.8, 'performed_action': 0.0}\n",
      "{'i': 29, 'wallet': 0.9694752839957754, 'price': 376.36, 'performed_action': 0.0}\n",
      "{'i': 30, 'wallet': 0.966229617990263, 'price': 375.1, 'performed_action': 0.0}\n",
      "{'i': 31, 'wallet': 0.9723860796991318, 'price': 377.49, 'performed_action': 0.0}\n",
      "{'i': 32, 'wallet': 0.9726436722392517, 'price': 377.59, 'performed_action': 0.0}\n",
      "{'i': 33, 'wallet': 0.9746013755441643, 'price': 378.35, 'performed_action': 0.0}\n",
      "{'i': 34, 'wallet': 0.9735452461296721, 'price': 377.94, 'performed_action': 0.0}\n",
      "{'i': 35, 'wallet': 0.9829473738440535, 'price': 381.59, 'performed_action': 0.0}\n",
      "{'i': 36, 'wallet': 0.9841838180366297, 'price': 382.07, 'performed_action': 0.0}\n",
      "{'i': 37, 'wallet': 0.9964967414543675, 'price': 386.85, 'performed_action': 0.0}\n",
      "{'i': 38, 'wallet': 0.9971149635506554, 'price': 387.09, 'performed_action': 0.0}\n",
      "{'i': 39, 'wallet': 0.9969861672805955, 'price': 387.04, 'performed_action': 0.0}\n",
      "{'i': 40, 'wallet': 1.0018031477808402, 'price': 388.91, 'performed_action': 0.0}\n",
      "{'i': 41, 'wallet': 0.9829731330980654, 'price': 381.6, 'performed_action': 0.0}\n",
      "{'i': 42, 'wallet': 0.9873264470260941, 'price': 383.29, 'performed_action': 0.0}\n",
      "{'i': 43, 'wallet': 0.9959042786120913, 'price': 386.62, 'performed_action': 0.0}\n",
      "{'i': 44, 'wallet': 0.9963937044383193, 'price': 386.81, 'performed_action': 0.0}\n",
      "{'i': 45, 'wallet': 1.0029365549573683, 'price': 389.35, 'performed_action': 0.0}\n",
      "{'i': 46, 'wallet': 0.9992529816336517, 'price': 387.92, 'performed_action': 0.0}\n",
      "{'i': 47, 'wallet': 0.9921176682723266, 'price': 385.15, 'performed_action': 0.0}\n",
      "{'i': 48, 'wallet': 1.0040957213879085, 'price': 389.8, 'performed_action': 0.0}\n",
      "{'i': 49, 'wallet': 0.9994332964117357, 'price': 387.99, 'performed_action': 0.0}\n",
      "{'i': 50, 'wallet': 0.9982483707271834, 'price': 387.53, 'performed_action': 0.0}\n",
      "{'i': 51, 'wallet': 1.0040442028798842, 'price': 389.78, 'performed_action': 0.0}\n",
      "{'i': 52, 'wallet': 0.9758120604827281, 'price': 378.82, 'performed_action': 0.0}\n",
      "{'i': 53, 'wallet': 0.9593776564230697, 'price': 372.44, 'performed_action': 0.0}\n",
      "{'i': 54, 'wallet': 0.9606913783776819, 'price': 372.95, 'performed_action': 0.0}\n",
      "{'i': 55, 'wallet': 0.9700162283300273, 'price': 376.57, 'performed_action': 0.0}\n",
      "{'i': 56, 'wallet': 0.9561835089255813, 'price': 371.2, 'performed_action': 0.0}\n",
      "{'i': 57, 'wallet': 0.9582700085005537, 'price': 372.01, 'performed_action': 0.0}\n",
      "{'i': 58, 'wallet': 0.9620823780943303, 'price': 373.49, 'performed_action': 0.0}\n",
      "{'i': 59, 'wallet': 0.959145823136962, 'price': 372.35, 'performed_action': 0.0}\n",
      "{'i': 60, 'wallet': 0.9536333427783931, 'price': 370.21, 'performed_action': 0.0}\n",
      "{'i': 61, 'wallet': 0.9603822673295381, 'price': 372.83, 'performed_action': 0.0}\n",
      "{'i': 62, 'wallet': 0.9752711161484764, 'price': 378.61, 'performed_action': 0.0}\n",
      "{'i': 63, 'wallet': 0.9527317688879731, 'price': 369.86, 'performed_action': 0.0}\n",
      "{'i': 64, 'wallet': 0.9622111743643904, 'price': 373.54, 'performed_action': 0.0}\n",
      "{'i': 65, 'wallet': 0.9627006001906185, 'price': 373.73, 'performed_action': 0.0}\n",
      "{'i': 66, 'wallet': 0.9761726900388964, 'price': 378.96, 'performed_action': 0.0}\n",
      "{'i': 67, 'wallet': 0.9754256716725483, 'price': 378.67, 'performed_action': 0.0}\n",
      "{'i': 68, 'wallet': 0.9729527832873959, 'price': 377.71, 'performed_action': 0.0}\n",
      "{'i': 69, 'wallet': 0.973416449859612, 'price': 377.89, 'performed_action': 0.0}\n",
      "{'i': 70, 'wallet': 0.9768939491512325, 'price': 379.24, 'performed_action': 0.0}\n",
      "{'i': 71, 'wallet': 0.9816594111434532, 'price': 381.09, 'performed_action': 0.0}\n",
      "{'i': 72, 'wallet': 0.9566986940058215, 'price': 371.4, 'performed_action': 0.0}\n",
      "{'i': 73, 'wallet': 0.9534530280003091, 'price': 370.14, 'performed_action': 0.0}\n",
      "{'i': 74, 'wallet': 0.9437160299837717, 'price': 366.36, 'performed_action': 0.0}\n",
      "{'i': 75, 'wallet': 0.9413204193606554, 'price': 365.43, 'performed_action': 0.0}\n",
      "{'i': 76, 'wallet': 0.9460343628448521, 'price': 367.26, 'performed_action': 0.0}\n",
      "{'i': 77, 'wallet': 0.938615697689395, 'price': 364.38, 'performed_action': 0.0}\n",
      "{'i': 78, 'wallet': 0.9539166945725251, 'price': 370.32, 'performed_action': 0.0}\n",
      "{'i': 79, 'wallet': 0.9544576389067772, 'price': 370.53, 'performed_action': 0.0}\n",
      "{'i': 80, 'wallet': 0.9759408567527884, 'price': 378.87, 'performed_action': 0.0}\n",
      "{'i': 81, 'wallet': 0.9844156513227377, 'price': 382.16, 'performed_action': 0.0}\n",
      "{'i': 82, 'wallet': 0.9971407228046675, 'price': 387.1, 'performed_action': 0.0}\n",
      "{'i': 83, 'wallet': 1.0037350918317405, 'price': 389.66, 'performed_action': 0.0}\n",
      "{'i': 84, 'wallet': 1.0110764792251614, 'price': 392.51, 'performed_action': 0.0}\n",
      "{'i': 85, 'wallet': 1.0123386826717498, 'price': 393.0, 'performed_action': 0.0}\n",
      "{'i': 86, 'wallet': 1.0028077586873083, 'price': 389.3, 'performed_action': 0.0}\n",
      "{'i': 87, 'wallet': 1.0104324978748616, 'price': 392.26, 'performed_action': 0.0}\n",
      "{'i': 88, 'wallet': 1.007135313361325, 'price': 390.98, 'performed_action': 0.0}\n",
      "{'i': 89, 'wallet': 1.0299580124159602, 'price': 399.84, 'performed_action': 0.0}\n",
      "{'i': 90, 'wallet': 1.0297261791298522, 'price': 399.75, 'performed_action': 0.0}\n",
      "{'i': 91, 'wallet': 1.0400556399886656, 'price': 403.76, 'performed_action': 0.0}\n",
      "{'i': 92, 'wallet': 1.0374539553334532, 'price': 402.75, 'performed_action': 0.0}\n",
      "{'i': 93, 'wallet': 1.0519821745962235, 'price': 408.39, 'performed_action': 0.0}\n",
      "{'i': 94, 'wallet': 1.0506684526416112, 'price': 407.88, 'performed_action': 0.0}\n",
      "{'i': 95, 'wallet': 1.0516730635480793, 'price': 408.27, 'performed_action': 0.0}\n",
      "{'i': 96, 'wallet': 1.061049432008449, 'price': 411.91, 'performed_action': 0.0}\n",
      "{'i': 97, 'wallet': 1.0603024136421006, 'price': 411.62, 'performed_action': 0.0}\n",
      "{'i': 98, 'wallet': 1.0669998196852217, 'price': 414.22, 'performed_action': 0.0}\n",
      "{'i': 99, 'wallet': 1.0633420056155172, 'price': 412.8, 'performed_action': 0.0}\n",
      "{'i': 100, 'wallet': 1.0580098400350324, 'price': 410.73, 'performed_action': 0.0}\n",
      "{'i': 101, 'wallet': 1.0597099507998244, 'price': 411.39, 'performed_action': 0.0}\n",
      "{'i': 102, 'wallet': 1.0658406532546814, 'price': 413.77, 'performed_action': 0.0}\n"
     ]
    }
   ],
   "source": [
    "w_p_df = pd.DataFrame({\"wallet\":ppo_agent_infos[0][\"wallet_history\"],\"price\":ppo_agent_infos[0][\"market_price_history\"],\"performed_action\":ppo_agent_infos[0][\"performed_action_history\"]})\n",
    "for i in range(len(w_p_df)):\n",
    "    print({\"i\":i,\"wallet\":w_p_df.iloc[i][\"wallet\"], \"price\":w_p_df.iloc[i][\"price\"], \"performed_action\":w_p_df.iloc[i][\"performed_action\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "df898e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103, 103, 102)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ppo_agent_infos[0][\"performed_action_history\"]),len(ppo_agent_infos[0][\"market_price_history\"]),len(info[\"returns\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6c03b16f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'regime': 0,\n",
       " 'episode_sharpe': 0.037526619175614985,\n",
       " 'episode_sortino': 0.054199542864414293,\n",
       " 'episode_total_reward': 0.006974334617493513,\n",
       " 'cumulative_return': 0.002091166731928329,\n",
       " 'calmar': 0.01821618181918696,\n",
       " 'max_drawdown': 0.11479720353503058,\n",
       " 'win_rate': 0.0,\n",
       " 'alpha': -0.03380154745756636,\n",
       " 'returns': array([ 0.00193171, -0.02115364, -0.00678057, -0.00381821, -0.00932432,\n",
       "        -0.00565282,  0.02487834, -0.01838755, -0.0077044 , -0.00039008,\n",
       "        -0.0165068 ,  0.00723711, -0.00922181,  0.0106076 ,  0.00504232,\n",
       "        -0.0051962 , -0.01250515, -0.00789515, -0.00769534,  0.01892436,\n",
       "        -0.00828636, -0.00581487,  0.00727158, -0.0013078 ,  0.00091666,\n",
       "        -0.00730042, -0.00416469, -0.00381154, -0.00334786,  0.00637163,\n",
       "         0.00026491,  0.00201277, -0.00108365,  0.00965762,  0.00125789,\n",
       "         0.0125108 ,  0.0006204 , -0.00012917,  0.00483154, -0.01879612,\n",
       "         0.00442872,  0.00868794,  0.00049144,  0.00656653, -0.00367279,\n",
       "        -0.00714065,  0.01207322, -0.00464341, -0.0011856 ,  0.005806  ,\n",
       "        -0.02811843, -0.01684177,  0.00136935,  0.00970639, -0.0142603 ,\n",
       "         0.00218211,  0.00397839, -0.00305229, -0.00574728,  0.00707706,\n",
       "         0.01550304, -0.02311085,  0.00994971,  0.00050865,  0.01399406,\n",
       "        -0.00076525, -0.00253519,  0.00047656,  0.00357247,  0.00487818,\n",
       "        -0.02542706, -0.00339257, -0.01021235, -0.00253849,  0.0050078 ,\n",
       "        -0.00784186,  0.01630166,  0.00056708,  0.0225083 ,  0.00868372,\n",
       "         0.01292652,  0.00661328,  0.00731407,  0.00124838, -0.00941476,\n",
       "         0.00760339, -0.00326314,  0.02266101, -0.00022509,  0.01003127,\n",
       "        -0.00250149,  0.01400372, -0.00124881,  0.00095616,  0.00891567,\n",
       "        -0.00070404,  0.00631651, -0.00342813, -0.00501453,  0.0016069 ,\n",
       "         0.00578526, -0.00500278]),\n",
       " 'market_returns': array([ 6.74221516e-03,  7.41114510e-03,  8.47017996e-03, -1.02438116e-03,\n",
       "         3.85535644e-03,  7.11728822e-03,  2.35785887e-03, -6.75687515e-03,\n",
       "         3.24154827e-04,  4.03408916e-03,  2.81471203e-03, -1.55447448e-04,\n",
       "        -6.42470028e-03,  9.87788188e-03,  1.46871720e-03, -2.66509187e-03,\n",
       "        -1.38395754e-02, -2.54797392e-03, -5.29999622e-03,  9.02405745e-03,\n",
       "        -4.21827002e-03, -7.03874756e-03,  2.50687712e-04, -1.06963120e-03,\n",
       "         5.75038362e-03, -1.15508317e-02, -7.55544339e-03, -7.71286439e-03,\n",
       "        -1.48729166e-04,  6.87917505e-03, -2.77741791e-03,  1.10448884e-02,\n",
       "        -1.34580400e-02,  6.71798844e-03,  6.26459753e-03,  1.45083470e-02,\n",
       "         3.83312989e-03, -1.59694521e-03,  1.79915965e-03, -4.19419058e-03,\n",
       "        -6.97157776e-03, -3.21130091e-03,  1.42660083e-03,  6.72351480e-03,\n",
       "        -5.69587250e-03,  1.24162352e-03,  8.42988378e-03, -1.21595525e-02,\n",
       "         7.21296446e-04, -2.15110261e-03, -9.39479517e-03, -1.64008905e-02,\n",
       "        -2.29561201e-03,  4.02309227e-03, -1.47344978e-02,  2.29318620e-04,\n",
       "         5.89307312e-03, -2.70949136e-03,  7.92901202e-05, -1.37440858e-02,\n",
       "         8.10980151e-03, -1.30401642e-03,  1.18148791e-02,  6.30381803e-03,\n",
       "         5.20797295e-03,  4.29301736e-03, -6.24635877e-03, -5.01884077e-03,\n",
       "         1.05943463e-02, -9.83165014e-05, -1.33997988e-02, -8.48282575e-03,\n",
       "        -1.25853202e-02, -1.68554221e-03,  7.26575987e-03, -1.43395924e-02,\n",
       "        -1.18325105e-02, -4.80031325e-03,  1.20100938e-02,  6.47496172e-03,\n",
       "         1.05059850e-02,  1.88585748e-02,  9.39371622e-03,  1.75296099e-03,\n",
       "         2.84014127e-03,  1.00493790e-03, -8.08391021e-03,  1.56164100e-02,\n",
       "        -8.35741658e-04,  1.90749283e-02,  1.59708166e-03,  1.19034929e-03,\n",
       "         1.28209678e-03,  7.39030842e-03, -2.02094393e-03,  4.06109043e-03,\n",
       "         5.96933692e-04, -1.95423022e-03,  9.80127153e-04, -9.46235804e-04,\n",
       "         3.78413301e-03]),\n",
       " 'downside': array([-0.02115364, -0.00678057, -0.00381821, -0.00932432, -0.00565282,\n",
       "        -0.01838755, -0.0077044 , -0.00039008, -0.0165068 , -0.00922181,\n",
       "        -0.0051962 , -0.01250515, -0.00789515, -0.00769534, -0.00828636,\n",
       "        -0.00581487, -0.0013078 , -0.00730042, -0.00416469, -0.00381154,\n",
       "        -0.00334786, -0.00108365, -0.00012917, -0.01879612, -0.00367279,\n",
       "        -0.00714065, -0.00464341, -0.0011856 , -0.02811843, -0.01684177,\n",
       "        -0.0142603 , -0.00305229, -0.00574728, -0.02311085, -0.00076525,\n",
       "        -0.00253519, -0.02542706, -0.00339257, -0.01021235, -0.00253849,\n",
       "        -0.00784186, -0.00941476, -0.00326314, -0.00022509, -0.00250149,\n",
       "        -0.00124881, -0.00070404, -0.00342813, -0.00501453, -0.00500278]),\n",
       " 'final_wealth': 1.0020911667319283,\n",
       " 'action_hold_count': 0,\n",
       " 'action_buy_count': 90,\n",
       " 'action_sell_count': 12,\n",
       " 'ticker': 'LIN',\n",
       " 'wallet_history': [1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9907781870637027,\n",
       "  1.0012879627006002,\n",
       "  1.006336776486953,\n",
       "  1.0011076479225163,\n",
       "  0.9885886504726824,\n",
       "  0.9807835965070453,\n",
       "  0.9732361350815281,\n",
       "  0.9916540017001109,\n",
       "  0.9834367996702815,\n",
       "  0.9777182452796167,\n",
       "  0.9848277993869298,\n",
       "  0.9835398366863295,\n",
       "  0.9844414105767497,\n",
       "  0.9772545787074005,\n",
       "  0.973184616573504,\n",
       "  0.9694752839957754,\n",
       "  0.966229617990263,\n",
       "  0.9723860796991318,\n",
       "  0.9726436722392517,\n",
       "  0.9746013755441643,\n",
       "  0.9735452461296721,\n",
       "  0.9829473738440535,\n",
       "  0.9841838180366297,\n",
       "  0.9964967414543675,\n",
       "  0.9971149635506554,\n",
       "  0.9969861672805955,\n",
       "  1.0018031477808402,\n",
       "  0.9829731330980654,\n",
       "  0.9873264470260941,\n",
       "  0.9959042786120913,\n",
       "  0.9963937044383193,\n",
       "  1.0029365549573683,\n",
       "  0.9992529816336517,\n",
       "  0.9921176682723266,\n",
       "  1.0040957213879085,\n",
       "  0.9994332964117357,\n",
       "  0.9982483707271834,\n",
       "  1.0040442028798842,\n",
       "  0.9758120604827281,\n",
       "  0.9593776564230697,\n",
       "  0.9606913783776819,\n",
       "  0.9700162283300273,\n",
       "  0.9561835089255813,\n",
       "  0.9582700085005537,\n",
       "  0.9620823780943303,\n",
       "  0.959145823136962,\n",
       "  0.9536333427783931,\n",
       "  0.9603822673295381,\n",
       "  0.9752711161484764,\n",
       "  0.9527317688879731,\n",
       "  0.9622111743643904,\n",
       "  0.9627006001906185,\n",
       "  0.9761726900388964,\n",
       "  0.9754256716725483,\n",
       "  0.9729527832873959,\n",
       "  0.973416449859612,\n",
       "  0.9768939491512325,\n",
       "  0.9816594111434532,\n",
       "  0.9566986940058215,\n",
       "  0.9534530280003091,\n",
       "  0.9437160299837717,\n",
       "  0.9413204193606554,\n",
       "  0.9460343628448521,\n",
       "  0.938615697689395,\n",
       "  0.9539166945725251,\n",
       "  0.9544576389067772,\n",
       "  0.9759408567527884,\n",
       "  0.9844156513227377,\n",
       "  0.9971407228046675,\n",
       "  1.0037350918317405,\n",
       "  1.0110764792251614,\n",
       "  1.0123386826717498,\n",
       "  1.0028077586873083,\n",
       "  1.0104324978748616,\n",
       "  1.007135313361325,\n",
       "  1.0299580124159602,\n",
       "  1.0297261791298522,\n",
       "  1.0400556399886656,\n",
       "  1.0374539553334532,\n",
       "  1.0519821745962235,\n",
       "  1.0506684526416112,\n",
       "  1.0516730635480793,\n",
       "  1.061049432008449,\n",
       "  1.0603024136421006,\n",
       "  1.0669998196852217,\n",
       "  1.0633420056155172,\n",
       "  1.0580098400350324,\n",
       "  1.0597099507998244,\n",
       "  1.0658406532546814],\n",
       " 'market_history': [1.0,\n",
       "  1.0,\n",
       "  0.9980682900285675,\n",
       "  1.0191810638008434,\n",
       "  1.0260916882056863,\n",
       "  1.0300095225139436,\n",
       "  1.0396136580057136,\n",
       "  1.0454904094680995,\n",
       "  1.019480342810502,\n",
       "  1.0382260916882058,\n",
       "  1.046225003400898,\n",
       "  1.0466331111413412,\n",
       "  1.0639096721534484,\n",
       "  1.0562100394504148,\n",
       "  1.0464698680451638,\n",
       "  1.0575703985852265,\n",
       "  1.062903006393688,\n",
       "  1.0573799483063528,\n",
       "  1.044157257515984,\n",
       "  1.035913481159026,\n",
       "  1.02794177662903,\n",
       "  1.0473949122568358,\n",
       "  1.0387158209767378,\n",
       "  1.0326758264181743,\n",
       "  1.0401850088423343,\n",
       "  1.0388246497075226,\n",
       "  1.039776901101891,\n",
       "  1.0321860971296422,\n",
       "  1.0278873622636375,\n",
       "  1.0239695279553802,\n",
       "  1.020541422935655,\n",
       "  1.0270439396000544,\n",
       "  1.0273160114270166,\n",
       "  1.0293837573119304,\n",
       "  1.0282682628213848,\n",
       "  1.0381988845055095,\n",
       "  1.0395048292749285,\n",
       "  1.0525098626037275,\n",
       "  1.0531628349884368,\n",
       "  1.0530267990749558,\n",
       "  1.0581145422391511,\n",
       "  1.0382260916882058,\n",
       "  1.042824105563869,\n",
       "  1.051884097401714,\n",
       "  1.0524010338729424,\n",
       "  1.0593116582777853,\n",
       "  1.0554210311522243,\n",
       "  1.047884641545368,\n",
       "  1.0605359814991158,\n",
       "  1.0556114814310977,\n",
       "  1.0543599510270711,\n",
       "  1.060481567133723,\n",
       "  1.0306624948986531,\n",
       "  1.0133043123384573,\n",
       "  1.014691878655965,\n",
       "  1.024540878792001,\n",
       "  1.0099306216841246,\n",
       "  1.0121344034825193,\n",
       "  1.0161610665215617,\n",
       "  1.0130594476941912,\n",
       "  1.0072371105971976,\n",
       "  1.0143653924636102,\n",
       "  1.0300911440620324,\n",
       "  1.0062848592028295,\n",
       "  1.016297102435043,\n",
       "  1.0168140389062712,\n",
       "  1.0310433954564004,\n",
       "  1.0302543871582097,\n",
       "  1.0276424976193714,\n",
       "  1.0281322269079036,\n",
       "  1.031805196571895,\n",
       "  1.0368385253706978,\n",
       "  1.0104747653380493,\n",
       "  1.007046660318324,\n",
       "  0.9967623452591484,\n",
       "  0.9942320772683988,\n",
       "  0.9992109917018093,\n",
       "  0.9913753230852945,\n",
       "  1.007536389606856,\n",
       "  1.008107740443477,\n",
       "  1.0307985308121344,\n",
       "  1.0397496939191948,\n",
       "  1.053190042171133,\n",
       "  1.0601550809413685,\n",
       "  1.0679091280097945,\n",
       "  1.06924227996191,\n",
       "  1.059175622364304,\n",
       "  1.0672289484423887,\n",
       "  1.0637464290572711,\n",
       "  1.0878519929261323,\n",
       "  1.0876071282818665,\n",
       "  1.0985172085430552,\n",
       "  1.095769283090736,\n",
       "  1.1111141341314106,\n",
       "  1.1097265678139028,\n",
       "  1.110787647939056,\n",
       "  1.1206910624404842,\n",
       "  1.1199020541422935,\n",
       "  1.126975921643314,\n",
       "  1.1231125017004489,\n",
       "  1.1174806148823289,\n",
       "  1.11927628894028,\n",
       "  1.1257515984219832],\n",
       " 'market_price_history': [367.55,\n",
       "  367.55,\n",
       "  366.84,\n",
       "  374.6,\n",
       "  377.14,\n",
       "  378.58,\n",
       "  382.11,\n",
       "  384.27,\n",
       "  374.71,\n",
       "  381.6,\n",
       "  384.54,\n",
       "  384.69,\n",
       "  391.04,\n",
       "  388.21,\n",
       "  384.63,\n",
       "  388.71,\n",
       "  390.67,\n",
       "  388.64,\n",
       "  383.78,\n",
       "  380.75,\n",
       "  377.82,\n",
       "  384.97,\n",
       "  381.78,\n",
       "  379.56,\n",
       "  382.32,\n",
       "  381.82,\n",
       "  382.17,\n",
       "  379.38,\n",
       "  377.8,\n",
       "  376.36,\n",
       "  375.1,\n",
       "  377.49,\n",
       "  377.59,\n",
       "  378.35,\n",
       "  377.94,\n",
       "  381.59,\n",
       "  382.07,\n",
       "  386.85,\n",
       "  387.09,\n",
       "  387.04,\n",
       "  388.91,\n",
       "  381.6,\n",
       "  383.29,\n",
       "  386.62,\n",
       "  386.81,\n",
       "  389.35,\n",
       "  387.92,\n",
       "  385.15,\n",
       "  389.8,\n",
       "  387.99,\n",
       "  387.53,\n",
       "  389.78,\n",
       "  378.82,\n",
       "  372.44,\n",
       "  372.95,\n",
       "  376.57,\n",
       "  371.2,\n",
       "  372.01,\n",
       "  373.49,\n",
       "  372.35,\n",
       "  370.21,\n",
       "  372.83,\n",
       "  378.61,\n",
       "  369.86,\n",
       "  373.54,\n",
       "  373.73,\n",
       "  378.96,\n",
       "  378.67,\n",
       "  377.71,\n",
       "  377.89,\n",
       "  379.24,\n",
       "  381.09,\n",
       "  371.4,\n",
       "  370.14,\n",
       "  366.36,\n",
       "  365.43,\n",
       "  367.26,\n",
       "  364.38,\n",
       "  370.32,\n",
       "  370.53,\n",
       "  378.87,\n",
       "  382.16,\n",
       "  387.1,\n",
       "  389.66,\n",
       "  392.51,\n",
       "  393.0,\n",
       "  389.3,\n",
       "  392.26,\n",
       "  390.98,\n",
       "  399.84,\n",
       "  399.75,\n",
       "  403.76,\n",
       "  402.75,\n",
       "  408.39,\n",
       "  407.88,\n",
       "  408.27,\n",
       "  411.91,\n",
       "  411.62,\n",
       "  414.22,\n",
       "  412.8,\n",
       "  410.73,\n",
       "  411.39,\n",
       "  413.77],\n",
       " 'performed_action_history': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0]}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1325d73d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'reward_history'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 20\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m#plt.figure(figsize=(14, 5))\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m#plt.subplot(1, 2, 1)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m#plt.plot(cum_returns, label=\"Cumulative Return\")\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m#plt.plot(np.cumsum(info[\"reward_history\"]), label=\"Cumulative Reward\")\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m#plt.title(\"Cumulative Return vs Reward\")\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m#plt.legend(); plt.grid(True)\u001b[39;00m\n\u001b[0;32m     19\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m plt\u001b[38;5;241m.\u001b[39mscatter(np\u001b[38;5;241m.\u001b[39mcumsum(info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreward_history\u001b[39m\u001b[38;5;124m\"\u001b[39m]), cum_returns)\n\u001b[0;32m     21\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCumulative Reward\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     22\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCumulative Return\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'reward_history'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# REWARD ANALYSIS\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Pick one episode\n",
    "info = ppo_agent_infos[0]  # or any i\n",
    "rewards = info[\"episode_total_reward\"]\n",
    "returns = np.array([1]+info[\"returns\"].tolist())\n",
    "cum_rewards = np.cumsum(returns* info[\"performed_action_history\"])  # or info['reward_history'] if saved\n",
    "cum_returns = np.cumprod(1 + np.array(returns)) - 1\n",
    "\n",
    "#plt.figure(figsize=(14, 5))\n",
    "#plt.subplot(1, 2, 1)\n",
    "#plt.plot(cum_returns, label=\"Cumulative Return\")\n",
    "#plt.plot(np.cumsum(info[\"reward_history\"]), label=\"Cumulative Reward\")\n",
    "#plt.title(\"Cumulative Return vs Reward\")\n",
    "#plt.legend(); plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(np.cumsum(info[\"reward_history\"]), cum_returns)\n",
    "plt.xlabel(\"Cumulative Reward\")\n",
    "plt.ylabel(\"Cumulative Return\")\n",
    "plt.title(\"Reward vs Return Correlation\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40caf421",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "corr(reward, return) ≥ 0.7 ⇒ strong alignment\n",
    "\n",
    "corr(reward, alpha) ≥ 0.6 ⇒ good relative performance\n",
    "\n",
    "If < 0.3 → your agent may be overfitting to reward noise or not capturing actual alpha\n",
    "\"\"\"\n",
    "reward_list = []\n",
    "return_list = []\n",
    "alpha_list = []\n",
    "\n",
    "for info in ppo_agent_infos:\n",
    "    reward_list.append(np.sum(info[\"reward_history\"]))\n",
    "    return_list.append(info[\"final_wealth\"] - 1)\n",
    "    alpha_list.append(info[\"alpha\"])\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({\n",
    "    \"reward\": reward_list,\n",
    "    \"return\": return_list,\n",
    "    \"alpha\": alpha_list\n",
    "})\n",
    "\n",
    "print(df.corr())\n",
    "sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af5ccc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba61c0be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
