{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7470753f",
   "metadata": {},
   "source": [
    "\n",
    "## ‚úÖ Summary of the Task\n",
    "\n",
    "**Goal**: Given a sequence of discrete 6D word vectors (representing an unknown language), predict whether the **next word will increase or decrease the sentiment** of the sentence.\n",
    "\n",
    "---\n",
    "\n",
    "## üß± Step-by-Step Plan\n",
    "\n",
    "### 1. **Synthetic Dataset Creation**\n",
    "\n",
    "* Build a vocabulary of discrete 6D word vectors.\n",
    "* Define a simple but meaningful **sentiment function** over sequences (e.g., a non-linear function of vector mean or weighted sum).\n",
    "* For each sequence, compute sentiment before and after adding the next word ‚Üí label: `‚Üë` or `‚Üì`.\n",
    "\n",
    "### 2. **Input Preprocessing**\n",
    "\n",
    "Since vectors are discrete:\n",
    "\n",
    "* Normalize: ‚úÖ (to remove scale issues).\n",
    "* Quantize: ‚ùå probably not needed unless you're feeding integer tokens. Transformers work better with continuous embeddings.\n",
    "\n",
    "So: **normalize the vectors (e.g., MinMax or z-score)**, but don‚Äôt quantize yet ‚Äî we‚Äôre not tokenizing.\n",
    "\n",
    "### 3. **Model Architecture**\n",
    "\n",
    "* Transformer encoder for the **sequence** of vectors.\n",
    "* Final vector (to be predicted) can be:\n",
    "\n",
    "  * Appended (and let the model learn the delta)\n",
    "  * OR input separately and compared with sentence encoding\n",
    "\n",
    "**Output**: Binary classification (‚Üë or ‚Üì in sentiment)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17607d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francisco S√°\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\arrays\\masked.py:61: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7501cac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from src.utils.system import boot\n",
    "from src.defaults import RANDOM_SEEDS, TOP2_STOCK_BY_SECTOR\n",
    "from tracker import OHLCV_DF, EpisodeTracker, EnvironmentTracker, AgentTracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "debe26a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>trade_count</th>\n",
       "      <th>sp500</th>\n",
       "      <th>vix</th>\n",
       "      <th>return_1d</th>\n",
       "      <th>candle_size</th>\n",
       "      <th>candle_relative_size</th>\n",
       "      <th>candle_upper</th>\n",
       "      <th>candle_body</th>\n",
       "      <th>candle_lower</th>\n",
       "      <th>candle_direction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-04</th>\n",
       "      <td>182.640</td>\n",
       "      <td>182.94</td>\n",
       "      <td>179.120</td>\n",
       "      <td>179.70</td>\n",
       "      <td>106090378.0</td>\n",
       "      <td>831898.0</td>\n",
       "      <td>47.9354</td>\n",
       "      <td>0.1691</td>\n",
       "      <td>-0.026600</td>\n",
       "      <td>3.820</td>\n",
       "      <td>0.020915</td>\n",
       "      <td>0.078534</td>\n",
       "      <td>0.769634</td>\n",
       "      <td>0.151832</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-05</th>\n",
       "      <td>179.610</td>\n",
       "      <td>180.17</td>\n",
       "      <td>174.640</td>\n",
       "      <td>174.92</td>\n",
       "      <td>95142198.0</td>\n",
       "      <td>848518.0</td>\n",
       "      <td>47.0058</td>\n",
       "      <td>0.1973</td>\n",
       "      <td>-0.026600</td>\n",
       "      <td>5.530</td>\n",
       "      <td>0.030789</td>\n",
       "      <td>0.101266</td>\n",
       "      <td>0.848101</td>\n",
       "      <td>0.050633</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-06</th>\n",
       "      <td>172.700</td>\n",
       "      <td>175.30</td>\n",
       "      <td>171.640</td>\n",
       "      <td>172.00</td>\n",
       "      <td>103899632.0</td>\n",
       "      <td>960344.0</td>\n",
       "      <td>46.9605</td>\n",
       "      <td>0.1961</td>\n",
       "      <td>-0.016693</td>\n",
       "      <td>3.660</td>\n",
       "      <td>0.021193</td>\n",
       "      <td>0.710383</td>\n",
       "      <td>0.191257</td>\n",
       "      <td>0.098361</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-07</th>\n",
       "      <td>172.890</td>\n",
       "      <td>174.14</td>\n",
       "      <td>171.030</td>\n",
       "      <td>172.17</td>\n",
       "      <td>94554334.0</td>\n",
       "      <td>715419.0</td>\n",
       "      <td>46.7703</td>\n",
       "      <td>0.1876</td>\n",
       "      <td>0.000988</td>\n",
       "      <td>3.110</td>\n",
       "      <td>0.017988</td>\n",
       "      <td>0.401929</td>\n",
       "      <td>0.231511</td>\n",
       "      <td>0.366559</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-10</th>\n",
       "      <td>169.080</td>\n",
       "      <td>172.50</td>\n",
       "      <td>168.170</td>\n",
       "      <td>172.19</td>\n",
       "      <td>117005143.0</td>\n",
       "      <td>956342.0</td>\n",
       "      <td>46.7029</td>\n",
       "      <td>0.1940</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>4.330</td>\n",
       "      <td>0.025609</td>\n",
       "      <td>0.071594</td>\n",
       "      <td>0.718245</td>\n",
       "      <td>0.210162</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-29</th>\n",
       "      <td>203.575</td>\n",
       "      <td>203.81</td>\n",
       "      <td>198.510</td>\n",
       "      <td>199.95</td>\n",
       "      <td>51477938.0</td>\n",
       "      <td>652509.0</td>\n",
       "      <td>59.1217</td>\n",
       "      <td>0.1918</td>\n",
       "      <td>-0.002345</td>\n",
       "      <td>5.300</td>\n",
       "      <td>0.026035</td>\n",
       "      <td>0.044340</td>\n",
       "      <td>0.683962</td>\n",
       "      <td>0.271698</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-30</th>\n",
       "      <td>199.370</td>\n",
       "      <td>201.96</td>\n",
       "      <td>196.780</td>\n",
       "      <td>200.85</td>\n",
       "      <td>70819942.0</td>\n",
       "      <td>605924.0</td>\n",
       "      <td>59.1169</td>\n",
       "      <td>0.1857</td>\n",
       "      <td>0.004501</td>\n",
       "      <td>5.180</td>\n",
       "      <td>0.025982</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-02</th>\n",
       "      <td>200.280</td>\n",
       "      <td>202.13</td>\n",
       "      <td>200.120</td>\n",
       "      <td>201.70</td>\n",
       "      <td>35423294.0</td>\n",
       "      <td>501431.0</td>\n",
       "      <td>59.3594</td>\n",
       "      <td>0.1836</td>\n",
       "      <td>0.004232</td>\n",
       "      <td>2.010</td>\n",
       "      <td>0.010036</td>\n",
       "      <td>0.213930</td>\n",
       "      <td>0.706468</td>\n",
       "      <td>0.079602</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-03</th>\n",
       "      <td>201.350</td>\n",
       "      <td>203.77</td>\n",
       "      <td>200.955</td>\n",
       "      <td>203.27</td>\n",
       "      <td>46381567.0</td>\n",
       "      <td>519820.0</td>\n",
       "      <td>59.7037</td>\n",
       "      <td>0.1769</td>\n",
       "      <td>0.007784</td>\n",
       "      <td>2.815</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>0.177620</td>\n",
       "      <td>0.682060</td>\n",
       "      <td>0.140320</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-04</th>\n",
       "      <td>202.910</td>\n",
       "      <td>206.24</td>\n",
       "      <td>202.100</td>\n",
       "      <td>202.82</td>\n",
       "      <td>43603985.0</td>\n",
       "      <td>568214.0</td>\n",
       "      <td>59.7081</td>\n",
       "      <td>0.1761</td>\n",
       "      <td>-0.002214</td>\n",
       "      <td>4.140</td>\n",
       "      <td>0.020403</td>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>857 rows √ó 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               open    high      low   close       volume  trade_count  \\\n",
       "date                                                                     \n",
       "2022-01-04  182.640  182.94  179.120  179.70  106090378.0     831898.0   \n",
       "2022-01-05  179.610  180.17  174.640  174.92   95142198.0     848518.0   \n",
       "2022-01-06  172.700  175.30  171.640  172.00  103899632.0     960344.0   \n",
       "2022-01-07  172.890  174.14  171.030  172.17   94554334.0     715419.0   \n",
       "2022-01-10  169.080  172.50  168.170  172.19  117005143.0     956342.0   \n",
       "...             ...     ...      ...     ...          ...          ...   \n",
       "2025-05-29  203.575  203.81  198.510  199.95   51477938.0     652509.0   \n",
       "2025-05-30  199.370  201.96  196.780  200.85   70819942.0     605924.0   \n",
       "2025-06-02  200.280  202.13  200.120  201.70   35423294.0     501431.0   \n",
       "2025-06-03  201.350  203.77  200.955  203.27   46381567.0     519820.0   \n",
       "2025-06-04  202.910  206.24  202.100  202.82   43603985.0     568214.0   \n",
       "\n",
       "              sp500     vix  return_1d  candle_size  candle_relative_size  \\\n",
       "date                                                                        \n",
       "2022-01-04  47.9354  0.1691  -0.026600        3.820              0.020915   \n",
       "2022-01-05  47.0058  0.1973  -0.026600        5.530              0.030789   \n",
       "2022-01-06  46.9605  0.1961  -0.016693        3.660              0.021193   \n",
       "2022-01-07  46.7703  0.1876   0.000988        3.110              0.017988   \n",
       "2022-01-10  46.7029  0.1940   0.000116        4.330              0.025609   \n",
       "...             ...     ...        ...          ...                   ...   \n",
       "2025-05-29  59.1217  0.1918  -0.002345        5.300              0.026035   \n",
       "2025-05-30  59.1169  0.1857   0.004501        5.180              0.025982   \n",
       "2025-06-02  59.3594  0.1836   0.004232        2.010              0.010036   \n",
       "2025-06-03  59.7037  0.1769   0.007784        2.815              0.013981   \n",
       "2025-06-04  59.7081  0.1761  -0.002214        4.140              0.020403   \n",
       "\n",
       "            candle_upper  candle_body  candle_lower  candle_direction  \n",
       "date                                                                   \n",
       "2022-01-04      0.078534     0.769634      0.151832              -1.0  \n",
       "2022-01-05      0.101266     0.848101      0.050633              -1.0  \n",
       "2022-01-06      0.710383     0.191257      0.098361              -1.0  \n",
       "2022-01-07      0.401929     0.231511      0.366559              -1.0  \n",
       "2022-01-10      0.071594     0.718245      0.210162               1.0  \n",
       "...                  ...          ...           ...               ...  \n",
       "2025-05-29      0.044340     0.683962      0.271698              -1.0  \n",
       "2025-05-30      0.214286     0.285714      0.500000               1.0  \n",
       "2025-06-02      0.213930     0.706468      0.079602               1.0  \n",
       "2025-06-03      0.177620     0.682060      0.140320               1.0  \n",
       "2025-06-04      0.804348     0.021739      0.173913              -1.0  \n",
       "\n",
       "[857 rows x 15 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = OHLCV_DF[OHLCV_DF['symbol']==\"AAPL\"].copy()\n",
    "df = df.set_index('date')[['open','high','low','close','volume','trade_count','sp500','vix', 'return_1d',]]\n",
    "\n",
    "df['candle_size'] = df['high'] - df['low']\n",
    "df['candle_relative_size'] = df['candle_size'] / df['open']\n",
    "\n",
    "df['candle_upper'] = (df['high'] - np.maximum(df['open'], df['close'])) / df['candle_size']\n",
    "df['candle_body'] = np.abs(df['close'] - df['open']) / df['candle_size']\n",
    "df['candle_lower'] = (np.minimum(df['open'], df['close']) - df['low']) / df['candle_size']\n",
    "\n",
    "df['candle_direction'] = np.sign(df['close'] - df['open'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0c3e637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Candle Vector Dataset\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<!--| quarto-html-table-processing: none -->\n",
       "<table id=\"itables_5c17c6bd_9153_4af9_9570_65979d6c636f\"><tbody><tr>\n",
       "    <td style=\"vertical-align:middle; text-align:left\">\n",
       "    <a href=https://mwouts.github.io/itables/><svg class=\"main-svg\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n",
       "width=\"64\" viewBox=\"0 0 500 400\" style=\"font-family: 'Droid Sans', sans-serif;\">\n",
       "    <g style=\"fill:#d9d7fc\">\n",
       "        <path d=\"M100,400H500V357H100Z\" />\n",
       "        <path d=\"M100,300H400V257H100Z\" />\n",
       "        <path d=\"M0,200H400V157H0Z\" />\n",
       "        <path d=\"M100,100H500V57H100Z\" />\n",
       "        <path d=\"M100,350H500V307H100Z\" />\n",
       "        <path d=\"M100,250H400V207H100Z\" />\n",
       "        <path d=\"M0,150H400V107H0Z\" />\n",
       "        <path d=\"M100,50H500V7H100Z\" />\n",
       "    </g>\n",
       "    <g style=\"fill:#1a1366;stroke:#1a1366;\">\n",
       "   <rect x=\"100\" y=\"7\" width=\"400\" height=\"43\">\n",
       "    <animate\n",
       "      attributeName=\"width\"\n",
       "      values=\"0;400;0\"\n",
       "      dur=\"5s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "      <animate\n",
       "      attributeName=\"x\"\n",
       "      values=\"100;100;500\"\n",
       "      dur=\"5s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "  </rect>\n",
       "        <rect x=\"0\" y=\"107\" width=\"400\" height=\"43\">\n",
       "    <animate\n",
       "      attributeName=\"width\"\n",
       "      values=\"0;400;0\"\n",
       "      dur=\"3.5s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "    <animate\n",
       "      attributeName=\"x\"\n",
       "      values=\"0;0;400\"\n",
       "      dur=\"3.5s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "  </rect>\n",
       "        <rect x=\"100\" y=\"207\" width=\"300\" height=\"43\">\n",
       "    <animate\n",
       "      attributeName=\"width\"\n",
       "      values=\"0;300;0\"\n",
       "      dur=\"3s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "    <animate\n",
       "      attributeName=\"x\"\n",
       "      values=\"100;100;400\"\n",
       "      dur=\"3s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "  </rect>\n",
       "        <rect x=\"100\" y=\"307\" width=\"400\" height=\"43\">\n",
       "    <animate\n",
       "      attributeName=\"width\"\n",
       "      values=\"0;400;0\"\n",
       "      dur=\"4s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "      <animate\n",
       "      attributeName=\"x\"\n",
       "      values=\"100;100;500\"\n",
       "      dur=\"4s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "  </rect>\n",
       "        <g style=\"fill:transparent;stroke-width:8; stroke-linejoin:round\" rx=\"5\">\n",
       "            <g transform=\"translate(45 50) rotate(-45)\">\n",
       "                <circle r=\"33\" cx=\"0\" cy=\"0\" />\n",
       "                <rect x=\"-8\" y=\"32\" width=\"16\" height=\"30\" />\n",
       "            </g>\n",
       "\n",
       "            <g transform=\"translate(450 152)\">\n",
       "                <polyline points=\"-15,-20 -35,-20 -35,40 25,40 25,20\" />\n",
       "                <rect x=\"-15\" y=\"-40\" width=\"60\" height=\"60\" />\n",
       "            </g>\n",
       "\n",
       "            <g transform=\"translate(50 352)\">\n",
       "                <polygon points=\"-35,-5 0,-40 35,-5\" />\n",
       "                <polygon points=\"-35,10 0,45 35,10\" />\n",
       "            </g>\n",
       "\n",
       "            <g transform=\"translate(75 250)\">\n",
       "                <polyline points=\"-30,30 -60,0 -30,-30\" />\n",
       "                <polyline points=\"0,30 -30,0 0,-30\" />\n",
       "            </g>\n",
       "\n",
       "            <g transform=\"translate(425 250) rotate(180)\">\n",
       "                <polyline points=\"-30,30 -60,0 -30,-30\" />\n",
       "                <polyline points=\"0,30 -30,0 0,-30\" />\n",
       "            </g>\n",
       "        </g>\n",
       "    </g>\n",
       "</svg>\n",
       "</a>\n",
       "    Loading ITables v2.4.0 from the internet...\n",
       "    (need <a href=https://mwouts.github.io/itables/troubleshooting.html>help</a>?)</td>\n",
       "    </tr></tbody></table>\n",
       "<link href=\"https://www.unpkg.com/dt_for_itables@2.3.2/dt_bundle.css\" rel=\"stylesheet\">\n",
       "<script type=\"module\">\n",
       "    import { ITable, jQuery as $ } from 'https://www.unpkg.com/dt_for_itables@2.3.2/dt_bundle.js';\n",
       "\n",
       "    document.querySelectorAll(\"#itables_5c17c6bd_9153_4af9_9570_65979d6c636f:not(.dataTable)\").forEach(table => {\n",
       "        if (!(table instanceof HTMLTableElement))\n",
       "            return;\n",
       "\n",
       "        let dt_args = {\"layout\": {\"topStart\": \"pageLength\", \"topEnd\": \"search\", \"bottomStart\": \"info\", \"bottomEnd\": \"paging\"}, \"style\": {\"table-layout\": \"auto\", \"width\": \"auto\", \"margin\": \"auto\", \"caption-side\": \"bottom\"}, \"text_in_header_can_be_selected\": true, \"order\": [], \"classes\": [\"display\", \"nowrap\"], \"table_html\": \"<table><thead>\\n    <tr style=\\\"text-align: right;\\\">\\n      <th></th>\\n      <th>candle_relative_size</th>\\n      <th>candle_upper</th>\\n      <th>candle_body</th>\\n      <th>candle_lower</th>\\n      <th>candle_direction</th>\\n      <th>return_1d</th>\\n    </tr>\\n    <tr>\\n      <th>date</th>\\n      <th></th>\\n      <th></th>\\n      <th></th>\\n      <th></th>\\n      <th></th>\\n      <th></th>\\n    </tr>\\n  </thead></table>\", \"data_json\": \"[[\\\"2022-01-04\\\", -0.064016, -0.909524, 1.129761, -0.57876, -1.10333, -1.442646], [\\\"2022-01-05\\\", 0.716582, -0.796797, 1.420436, -1.060544, -1.10333, -1.442646], [\\\"2022-01-06\\\", -0.042088, 2.22379, -1.012766, -0.833325, -1.10333, -0.911009], [\\\"2022-01-07\\\", -0.295437, 0.694182, -0.863648, 0.443496, -1.10333, 0.037884], [\\\"2022-01-10\\\", 0.30707, -0.943941, 0.939398, -0.301071, 0.908487, -0.008923], [\\\"2022-01-11\\\", 0.282765, -1.185233, 0.623721, 0.336271, 0.908487, 0.885549], [\\\"2022-01-12\\\", -0.658193, 0.92836, -0.795159, 0.130659, -1.10333, 0.122776], [\\\"2022-01-13\\\", 0.454658, -0.44681, 1.039775, -0.90733, -1.10333, -1.036303], [\\\"2022-01-14\\\", -0.476369, 0.009901, 0.661117, -0.859146, 0.908487, 0.259106], [\\\"2022-01-18\\\", -0.27247, 0.33029, 0.299317, -0.701757, -1.10333, -1.029112], [\\\"2022-01-19\\\", 0.672811, -0.25701, 0.995772, -1.032992, -1.10333, -1.143454], [\\\"2022-01-20\\\", 0.886493, 1.13543, -0.05765, -1.01595, -1.10333, -0.570437], [\\\"2022-01-21\\\", 0.220259, 1.05746, 0.121744, -1.171648, -1.10333, -0.700203], [\\\"2022-01-24\\\", 2.037291, -0.855274, -0.941384, 2.030914, 0.908487, -0.276197], [\\\"2022-01-25\\\", 1.136884, 1.275543, -1.204964, 0.32402, 0.908487, -0.626121], [\\\"2022-01-26\\\", 1.459026, -0.6276, 0.427145, 0.053562, -1.10333, -0.045385], [\\\"2022-01-27\\\", 0.98831, -0.05923, 0.430751, -0.496722, -1.10333, -0.173104], [\\\"2022-01-28\\\", 1.884504, -1.285835, 0.545532, 0.533335, 0.908487, 3.729477], [\\\"2022-01-31\\\", 0.833181, -1.100251, 1.396093, -0.737937, 0.908487, 1.386888], [\\\"2022-02-01\\\", -0.568109, -0.848156, -0.842745, 1.897313, 0.908487, -0.067354]]\"};\n",
       "        new ITable(table, dt_args);\n",
       "    });\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Simulated OHLCV-like dataframe (for demonstration)\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "# Feature engineering\n",
    "df['candle_size'] = df['high'] - df['low']\n",
    "df['candle_relative_size'] = df['candle_size'] / df['open']\n",
    "df['candle_upper'] = (df['high'] - np.maximum(df['open'], df['close'])) / df['candle_size']\n",
    "df['candle_body'] = np.abs(df['close'] - df['open']) / df['candle_size']\n",
    "df['candle_lower'] = (np.minimum(df['open'], df['close']) - df['low']) / df['candle_size']\n",
    "df['candle_direction'] = np.sign(df['close'] - df['open'])\n",
    "\n",
    "# Drop rows with NaN\n",
    "df = df.dropna()\n",
    "\n",
    "# Select 6D word vector features\n",
    "vector_cols = [\n",
    "    'candle_relative_size',\n",
    "    'candle_upper',\n",
    "    'candle_body',\n",
    "    'candle_lower',\n",
    "    'candle_direction',\n",
    "    'return_1d'\n",
    "]\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "df[vector_cols] = scaler.fit_transform(df[vector_cols])\n",
    "\n",
    "# Preview the normalized vector-based dataset\n",
    "import ace_tools_open as tools; tools.display_dataframe_to_user(name=\"Normalized Candle Vector Dataset\", dataframe=df[vector_cols].head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0019c064",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SentimentShiftDataset(Dataset):\n",
    "    def __init__(self, df, sequence_length=10):\n",
    "        self.sequence_length = sequence_length\n",
    "        self.vector_cols = [\n",
    "            'candle_relative_size',\n",
    "            'candle_upper',\n",
    "            'candle_body',\n",
    "            'candle_lower',\n",
    "            'candle_direction',\n",
    "            'return_1d'\n",
    "        ]\n",
    "        self.data = df[self.vector_cols].values\n",
    "        self.labels = (df['return_1d'].shift(-1) > 0).astype(int).values  # 1 if next return is positive\n",
    "        self.valid_indices = range(len(df) - sequence_length - 1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.valid_indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start_idx = self.valid_indices[idx]\n",
    "        end_idx = start_idx + self.sequence_length\n",
    "        sequence = self.data[start_idx:end_idx]\n",
    "        label = self.labels[end_idx]  # Label is based on return of the day after the sequence\n",
    "        return torch.tensor(sequence, dtype=torch.float32), torch.tensor(label, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b774de4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([10, 6])\n",
      "Label: 0\n"
     ]
    }
   ],
   "source": [
    "dataset = SentimentShiftDataset(df, sequence_length=10)\n",
    "\n",
    "# Get one sample\n",
    "x, y = dataset[0]\n",
    "print(\"Input shape:\", x.shape)   # (10, 6)\n",
    "print(\"Label:\", y.item())        # 0 or 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1f5b8d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TransformerSentimentClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=6, model_dim=32, num_heads=4, num_layers=2, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.model_dim = model_dim\n",
    "\n",
    "        # Input projection to model_dim\n",
    "        self.input_proj = nn.Linear(input_dim, model_dim)\n",
    "\n",
    "        # Learnable positional encoding\n",
    "        self.pos_encoding = nn.Parameter(torch.randn(1, 100, model_dim))  # max_len=100\n",
    "\n",
    "        # Transformer encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=model_dim, nhead=num_heads, dropout=dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        # Classification head\n",
    "        self.cls_head = nn.Sequential(\n",
    "            nn.Linear(model_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 2)  # Binary classification (‚Üë / ‚Üì)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (batch_size, seq_len, input_dim)\n",
    "        \"\"\"\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "\n",
    "        # Project input to model_dim\n",
    "        x = self.input_proj(x)\n",
    "\n",
    "        # Add positional encoding\n",
    "        x = x + self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        # Transformer expects (seq_len, batch_size, model_dim)\n",
    "        x = x.permute(1, 0, 2)\n",
    "\n",
    "        # Transformer Encoder\n",
    "        x = self.transformer_encoder(x)\n",
    "\n",
    "        # Use the last token (or mean pooling)\n",
    "        x = x[-1, :, :]  # (batch_size, model_dim)\n",
    "\n",
    "        # Classify\n",
    "        out = self.cls_head(x)  # (batch_size, 2)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f14b321",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerSentimentClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=6, model_dim=32, num_heads=4, num_layers=2, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.model_dim = model_dim\n",
    "        self.input_proj = nn.Linear(input_dim, model_dim)\n",
    "        self.pos_encoding = nn.Parameter(torch.randn(1, 100, model_dim))  # max_len=100\n",
    "\n",
    "        # Define the encoder layer\n",
    "        self.encoder_layers = nn.ModuleList([\n",
    "            nn.TransformerEncoderLayer(d_model=model_dim, nhead=num_heads, dropout=dropout, batch_first=True)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        self.encoder = nn.Sequential(*self.encoder_layers)\n",
    "\n",
    "        self.cls_head = nn.Sequential(\n",
    "            nn.Linear(model_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, return_attention=False):\n",
    "        x = self.input_proj(x)  # (B, T, D)\n",
    "        x = x + self.pos_encoding[:, :x.size(1), :]\n",
    "\n",
    "        attentions = []\n",
    "\n",
    "        for layer in self.encoder_layers:\n",
    "            # Hook into attention weights via forward pre-hook\n",
    "            def hook(module, input, output):\n",
    "                attn = module.self_attn(input[0], input[0], input[0])[1]\n",
    "                attentions.append(attn.detach().cpu())\n",
    "\n",
    "            handle = layer.register_forward_hook(hook)\n",
    "            x = layer(x)\n",
    "            handle.remove()\n",
    "\n",
    "        cls_out = x[:, -1, :]  # use the last token\n",
    "        logits = self.cls_head(cls_out)\n",
    "\n",
    "        if return_attention:\n",
    "            return logits, attentions\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a9a3d0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch\n",
    "\n",
    "# Instantiate dataset\n",
    "dataset = SentimentShiftDataset(df, sequence_length=10)\n",
    "\n",
    "# Split dataset\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "\n",
    "# Initialize model\n",
    "model = TransformerSentimentClassifier()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Optimizer and loss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "def train(model, train_loader, val_loader, optimizer, criterion, epochs=10):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(batch_x)\n",
    "            loss = criterion(output, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        correct = total = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_x, batch_y in val_loader:\n",
    "                batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "                output = model(batch_x)\n",
    "                preds = output.argmax(dim=1)\n",
    "                correct += (preds == batch_y).sum().item()\n",
    "                total += batch_y.size(0)\n",
    "        accuracy = correct / total\n",
    "        print(f\"Epoch {epoch+1} | Loss: {avg_loss:.4f} | Val Acc: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c49129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 0.6543 | Val Acc: 0.5000\n",
      "Epoch 2 | Loss: 0.6593 | Val Acc: 0.5176\n",
      "Epoch 3 | Loss: 0.6443 | Val Acc: 0.4824\n",
      "Epoch 4 | Loss: 0.6464 | Val Acc: 0.5059\n",
      "Epoch 5 | Loss: 0.6351 | Val Acc: 0.5235\n"
     ]
    }
   ],
   "source": [
    "train(model,train_loader,val_loader,optimizer,criterion,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "25e03b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in dataloader:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            logits = model(batch_x)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            correct += (preds == batch_y).sum().item()\n",
    "            total += batch_y.size(0)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(batch_y.cpu().numpy())\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f\"[‚úì] Held-Out Accuracy: {accuracy:.4f}\")\n",
    "    return all_preds, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "67f4ac27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[‚úì] Held-Out Accuracy: 0.5059\n"
     ]
    }
   ],
   "source": [
    "preds,labels=evaluate_model(model,val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "07741bec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhIAAAHFCAYAAACn7hC1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA4QElEQVR4nO3deXhU9b3H8c+EhEkISYAIhLCFxQABA4gaQ1EQgiwREfUKQik7slUQRAxcBSs6wO217CDIjhptEQouuVEhsVbAsClSCi6sSoigLAlkCMm5f/gwdUyCmWEOE47vV5/zPM3v/OZ3vidPKV++3985YzMMwxAAAIAXAvwdAAAAuHGRSAAAAK+RSAAAAK+RSAAAAK+RSAAAAK+RSAAAAK+RSAAAAK+RSAAAAK+RSAAAAK+RSMDSPv/8cw0aNEgNGjRQcHCwKleurFtvvVWzZs3SDz/8YOq1d+/erfbt2ysiIkI2m02zZ8/2+TVsNpumTZvm83V/zcqVK2Wz2WSz2ZSRkVHsvGEYaty4sWw2mzp06ODVNRYuXKiVK1d69JmMjIxSYwJgjkB/BwCYZenSpRo1apSaNGmiiRMnKi4uTgUFBdqxY4cWL16srVu3av369aZdf/DgwcrLy1NqaqqqVq2qmJgYn19j69atqlOnjs/XLauwsDAtW7asWLKQmZmpr7/+WmFhYV6vvXDhQt10000aOHBgmT9z6623auvWrYqLi/P6ugA8QyIBS9q6datGjhypzp07a8OGDbLb7a5znTt31oQJE5SWlmZqDF988YWGDRumbt26mXaNO++807S1y6J379569dVXtWDBAoWHh7vGly1bpsTERJ07d+66xFFQUCCbzabw8HC//06A3xpaG7CkF198UTabTUuWLHFLIq6oWLGi7r//ftfPRUVFmjVrlpo2bSq73a4aNWroD3/4g44fP+72uQ4dOqhFixbKysrSXXfdpUqVKqlhw4aaMWOGioqKJP2n7H/58mUtWrTI1QKQpGnTprn++89d+czhw4ddY5s3b1aHDh0UGRmpkJAQ1atXTw899JAuXLjgmlNSa+OLL75Qz549VbVqVQUHB6tVq1ZatWqV25wrLYDXX39dU6ZMUXR0tMLDw5WUlKQDBw6U7Zcs6dFHH5Ukvf76666xs2fPat26dRo8eHCJn3nuueeUkJCgatWqKTw8XLfeequWLVumn39/YExMjPbt26fMzEzX7+9KRedK7GvWrNGECRNUu3Zt2e12ffXVV8VaG6dOnVLdunXVtm1bFRQUuNb/17/+pdDQUPXv37/M9wqgZCQSsJzCwkJt3rxZbdq0Ud26dcv0mZEjR2rSpEnq3LmzNm7cqOeff15paWlq27atTp065TY3Oztb/fr10+9//3tt3LhR3bp1U0pKitauXStJSk5O1tatWyVJDz/8sLZu3er6uawOHz6s5ORkVaxYUcuXL1daWppmzJih0NBQXbp0qdTPHThwQG3bttW+ffs0d+5cvfXWW4qLi9PAgQM1a9asYvMnT56sI0eO6JVXXtGSJUv05ZdfqkePHiosLCxTnOHh4Xr44Ye1fPly19jrr7+ugIAA9e7du9R7e+yxx/Tmm2/qrbfe0oMPPqg//vGPev75511z1q9fr4YNG6p169au398v21ApKSk6evSoFi9erE2bNqlGjRrFrnXTTTcpNTVVWVlZmjRpkiTpwoUL+q//+i/Vq1dPixcvLtN9ArgKA7CY7OxsQ5LRp0+fMs3fv3+/IckYNWqU2/j27dsNScbkyZNdY+3btzckGdu3b3ebGxcXZ3Tp0sVtTJIxevRot7GpU6caJf2xW7FihSHJOHTokGEYhvG3v/3NkGTs2bPnqrFLMqZOner6uU+fPobdbjeOHj3qNq9bt25GpUqVjDNnzhiGYRhbtmwxJBndu3d3m/fmm28akoytW7de9bpX4s3KynKt9cUXXxiGYRi33367MXDgQMMwDKN58+ZG+/btS12nsLDQKCgoMP70pz8ZkZGRRlFRketcaZ+9cr2777671HNbtmxxG585c6YhyVi/fr0xYMAAIyQkxPj888+veo8AyoaKBH7ztmzZIknFNvXdcccdatasmT788EO38aioKN1xxx1uY/Hx8Tpy5IjPYmrVqpUqVqyo4cOHa9WqVfrmm2/K9LnNmzerU6dOxSoxAwcO1IULF4pVRn7e3pF+ug9JHt1L+/bt1ahRIy1fvlx79+5VVlZWqW2NKzEmJSUpIiJCFSpUUFBQkJ599lmdPn1aOTk5Zb7uQw89VOa5EydOVHJysh599FGtWrVK8+bN0y233FLmzwMoHYkELOemm25SpUqVdOjQoTLNP336tCSpVq1axc5FR0e7zl8RGRlZbJ7dbtfFixe9iLZkjRo10gcffKAaNWpo9OjRatSokRo1aqQ5c+Zc9XOnT58u9T6unP+5X97Llf0kntyLzWbToEGDtHbtWi1evFixsbG66667Spz76aef6t5775X001M1//znP5WVlaUpU6Z4fN2S7vNqMQ4cOFD5+fmKiopibwTgQyQSsJwKFSqoU6dO2rlzZ7HNkiW58pfpiRMnip377rvvdNNNN/kstuDgYEmS0+l0G//lPgxJuuuuu7Rp0yadPXtW27ZtU2JiosaNG6fU1NRS14+MjCz1PiT59F5+buDAgTp16pQWL16sQYMGlTovNTVVQUFBevvtt/XII4+obdu2uu2227y6ZkmbVktz4sQJjR49Wq1atdLp06f15JNPenVNAMWRSMCSUlJSZBiGhg0bVuLmxIKCAm3atEmS1LFjR0lybZa8IisrS/v371enTp18FteVJw8+//xzt/ErsZSkQoUKSkhI0IIFCyRJu3btKnVup06dtHnzZlficMXq1atVqVIl0x6NrF27tiZOnKgePXpowIABpc6z2WwKDAxUhQoVXGMXL17UmjVris31VZWnsLBQjz76qGw2m9577z05HA7NmzdPb7311jWvDYD3SMCiEhMTtWjRIo0aNUpt2rTRyJEj1bx5cxUUFGj37t1asmSJWrRooR49eqhJkyYaPny45s2bp4CAAHXr1k2HDx/WM888o7p16+qJJ57wWVzdu3dXtWrVNGTIEP3pT39SYGCgVq5cqWPHjrnNW7x4sTZv3qzk5GTVq1dP+fn5ricjkpKSSl1/6tSpevvtt3XPPffo2WefVbVq1fTqq6/qnXfe0axZsxQREeGze/mlGTNm/Oqc5ORkvfTSS+rbt6+GDx+u06dP689//nOJj+jecsstSk1N1RtvvKGGDRsqODjYq30NU6dO1T/+8Q+lp6crKipKEyZMUGZmpoYMGaLWrVurQYMGHq8J4D9IJGBZw4YN0x133KG//OUvmjlzprKzsxUUFKTY2Fj17dtXY8aMcc1dtGiRGjVqpGXLlmnBggWKiIhQ165d5XA4StwT4a3w8HClpaVp3Lhx+v3vf68qVapo6NCh6tatm4YOHeqa16pVK6Wnp2vq1KnKzs5W5cqV1aJFC23cuNG1x6AkTZo00SeffKLJkydr9OjRunjxopo1a6YVK1Z49IZIs3Ts2FHLly/XzJkz1aNHD9WuXVvDhg1TjRo1NGTIELe5zz33nE6cOKFhw4bp/Pnzql+/vtt7Nsri/fffl8Ph0DPPPONWWVq5cqVat26t3r176+OPP1bFihV9cXvAb5LNMH72FhgAAAAPsEcCAAB4jUQCAAB4jUQCAAB4jUQCAAB4jUQCAAB4jUQCAAB4jUQCAAB4zZIvpOqycLu/QwDKpb8PT/B3CEC5E3wd/iYMaT3m1yeVwcXd832yji9RkQAAAF6zZEUCAIByxWbdf7eTSAAAYDYPvvb+RkMiAQCA2SxckbDunQEAANNRkQAAwGy0NgAAgNdobQAAABRHRQIAALPR2gAAAF6jtQEAAFAcFQkAAMxGawMAAHiN1gYAAEBxVCQAADCbhVsbVCQAADCbLcA3hwemTZsmm83mdkRFRbnOG4ahadOmKTo6WiEhIerQoYP27dvn8a2RSAAAYDabzTeHh5o3b64TJ064jr1797rOzZo1Sy+99JLmz5+vrKwsRUVFqXPnzjp//rxH1yCRAADAogIDAxUVFeU6qlevLumnasTs2bM1ZcoUPfjgg2rRooVWrVqlCxcu6LXXXvPoGiQSAACYzQ+tDUn68ssvFR0drQYNGqhPnz765ptvJEmHDh1Sdna27r33Xtdcu92u9u3b65NPPvHoGmy2BADAbD56/NPpdMrpdLqN2e122e32YnMTEhK0evVqxcbG6uTJk5o+fbratm2rffv2KTs7W5JUs2ZNt8/UrFlTR44c8SgmKhIAANwgHA6HIiIi3A6Hw1Hi3G7duumhhx7SLbfcoqSkJL3zzjuSpFWrVrnm2H6x78IwjGJjv4ZEAgAAswXYfHKkpKTo7NmzbkdKSkqZQggNDdUtt9yiL7/80vX0xpXKxBU5OTnFqhS/emsezQYAAJ7z0R4Ju92u8PBwt6OktkZJnE6n9u/fr1q1aqlBgwaKiorS+++/7zp/6dIlZWZmqm3bth7dGnskAACwoCeffFI9evRQvXr1lJOTo+nTp+vcuXMaMGCAbDabxo0bpxdffFE333yzbr75Zr344ouqVKmS+vbt69F1SCQAADCbH95sefz4cT366KM6deqUqlevrjvvvFPbtm1T/fr1JUlPPfWULl68qFGjRunHH39UQkKC0tPTFRYW5tF1bIZhGGbcgD91Wbjd3yEA5dLfhyf4OwSg3Am+Dv+kDkma4ZN1Ln7wtE/W8SX2SAAAAK/R2gAAwGwW/tIuEgkAAMzmoxdSlUckEgAAmM3CFQnrpkgAAMB0VCQAADAbrQ0AAOA1WhsAAADFUZEAAMBstDYAAIDXaG0AAAAUR0UCAACz0doAAABes3AiYd07AwAApqMiAQCA2Sy82ZJEAgAAs1m4tUEiAQCA2SxckbBuigQAAExHRQIAALPR2gAAAF6jtQEAAFAcFQkAAExms3BFgkQCAACTWTmRoLUBAAC8RkUCAACzWbcgQSIBAIDZaG0AAACUgIoEAAAms3JFgkQCAACTkUgAAACvWTmRYI8EAAC/AQ6HQzabTePGjXON5ebmasyYMapTp45CQkLUrFkzLVq0yKN1qUgAAGA2PxcksrKytGTJEsXHx7uNP/HEE9qyZYvWrl2rmJgYpaena9SoUYqOjlbPnj3LtDYVCQAATGaz2XxyeCM3N1f9+vXT0qVLVbVqVbdzW7du1YABA9ShQwfFxMRo+PDhatmypXbs2FHm9UkkAACwsNGjRys5OVlJSUnFzrVr104bN27Ut99+K8MwtGXLFh08eFBdunQp8/q0NgAAMJmvNls6nU45nU63MbvdLrvdXuL81NRU7dq1S1lZWSWenzt3roYNG6Y6deooMDBQAQEBeuWVV9SuXbsyx0RFAgAAk/mqteFwOBQREeF2OByOEq957NgxjR07VmvXrlVwcHCJc+bOnatt27Zp48aN2rlzp/73f/9Xo0aN0gcffFD2ezMMw/Dqt1KOdVm43d8hAOXS34cn+DsEoNwJvg61+Wr9X/PJOideeajMFYkNGzaoV69eqlChgmussLBQNptNAQEBOnv2rKpWrar169crOTnZNWfo0KE6fvy40tLSyhQTrQ0AAEzmq9bG1doYv9SpUyft3bvXbWzQoEFq2rSpJk2apMLCQhUUFCggwL05UaFCBRUVFZU5JhIJAADM5ofHP8PCwtSiRQu3sdDQUEVGRrrG27dvr4kTJyokJET169dXZmamVq9erZdeeqnM1yGRAADgNyo1NVUpKSnq16+ffvjhB9WvX18vvPCCRowYUeY1SCQAADBZeXlFdkZGhtvPUVFRWrFixTWtSSIBAIDJyksiYQYSCQAATGblRIL3SAAAAK9RkQAAwGzWLUiQSAAAYDZaGwAAACWgIgEAgMmsXJEgkQAAwGRWTiRobQAAAK9RkQAAwGRWrkiQSAAAYDbr5hG0NgAAgPeoSAAAYDJaGwAAwGskEgAAwGtWTiTYIwEAALxGRQIAALNZtyBBIgEAgNlobQAAAJSARAI+1fvWaP3fqASN+F29Es8/3j5G/zcqQb3io65zZMD19Wbqa3q4Vw+1veNWtb3jVvXv21sf/yPTdX7RgnnqeV9XJdzWSu0Sb9fwIQP1+eef+TFimMlms/nkKI9obcBnYmuEqntcdX1zKq/E84kNqqppzco6lXvpOkcGXH81akZp7BNPqm69n5LqTX/foLFjRuuNdevVuPHNql8/RilTnlWdOnWV78zX2tUrNXLYYG16731Vq1bNz9HD18prEuALVCTgE8GBAZqU1EizMw7pvLOw2PnI0CCNvitGM9//WpeLDD9ECFxfHe7pqLvubq+YmAaKiWmgP459QpUqVdLnn+2RJHW/r4fuTGyrOnXrqnHjm/XkUynKzc3VlwcP+DdwwEMkEvCJMXfH6NMjZ7T7+Lli52ySnurUSH/b852O/Hjx+gcH+FlhYaHee/cdXbx4QS1bti52vuDSJa376xsKCwtTbJMmfogQZqO1AVxF+8bV1Lh6qP74ty9KPP/IrdEqNKQNn5+8zpEB/vXlwQPq37ePLl1yqlKlSvrL3AVq1Lix63xmxhZNenK88vMv6qbq1bV46XJVrUpbw5LKZw7gEzd8RcLpdOrcuXNuR1EBPfjrpXrlihrZLkazPvhaBYXFWxaNq1fSA/E19ecPv/ZDdIB/xcQ00JvrNmjNa2/ov3o/qmcmT9LXX33lOn/7HQl6c90GrX41Vb9rd5cmThin06dP+zFiwHM2wzDKZcP69OnTmjt3rqZNm3bVcs60adP03HPPuY017D5EjZOHmR0i9NMGymndYlX4s30PFQJsKjIMGYa0bOtRDW1bTz//X1mFAJsKiwx9n3tJA9buuf5B/4b9fXiCv0P4TRs+ZKDq1K2nZ6f9qcTzPbrdqwcefEhDhj12nSP7bQu+DrX5huPf9ck637zU3Sfr+FK5bW3k5+fr9ddf1zfffKPVq1eXmkykpKRo/PjxbmMPreARqutlz/GzGp76udvYhI4NdezHfL25+zv9kFegHcfOup1/8b6m+vDgKaX/+/vrGSrgd4ZhqOBS6RVTwzB06SrnceMqr/sbfMGviUReXp7eeOONUs/369dPzz//vAzD0Nq1a0ucY7fbZbfb3cYCgir6NE6U7mJBkY784L6BMr+gSOfzC1zj552X3c5fLjL044UCHT+Tf93iBK63ubNfUru77lbNqChdyMtT2nvvakfWp1r48iu6cOGCXlmyWB3u6aibqlfX2TNn9Ebqazp5Mludu3T1d+gwgYXzCP8mErm5uVqzZk2p5690XT766CNdvnxZgYHltoACAG5Onz6lKU8/pe+/z1HlsDDFxjbRwpdfUWLb38npdOrQoW+08e/rdebHH1WlShU1b3GLVqx+VY0b3+zv0AGPlNs9EpI0cuRIvf3228rIyFCjRo3K/LkuC7ebGBVw42KPBFDc9dgjcfPENJ+s8+X/lL+KVbl9auOzzz5Tenq6MjMzPUoiAAAob2w23xzXwuFwyGazady4cW7j+/fv1/3336+IiAiFhYXpzjvv1NGjR8u8brntFbRs2VL//ve/FRQU5O9QAAC4oWVlZWnJkiWKj493G//666/Vrl07DRkyRM8995wiIiK0f/9+BQcHl3ntcptISCKJAABYgj+f2sjNzVW/fv20dOlSTZ8+3e3clClT1L17d82aNcs11rBhQ4/WL7etDQAArMKfrY3Ro0crOTlZSUlJbuNFRUV65513FBsbqy5duqhGjRpKSEjQhg0bPFqfRAIAgBtESW9zdjqdpc5PTU3Vrl275HA4ip3LyclRbm6uZsyYoa5duyo9PV29evXSgw8+qMzMzBJWKxmJBAAAJgsIsPnkcDgcioiIcDtKShIk6dixYxo7dqzWrl1b4p6HoqIiSVLPnj31xBNPqFWrVnr66ad13333afHixWW+t3K9RwIAACvw1RaJkt7m/MuXMl6xc+dO5eTkqE2bNq6xwsJCffTRR5o/f77y8vIUGBiouLg4t881a9ZMH3/8cZljIpEAAOAGUdLbnEvTqVMn7d27121s0KBBatq0qSZNmiS73a7bb79dBw4ccJtz8OBB1a9fv8wxkUgAAGAyfzy1ERYWphYtWriNhYaGKjIy0jU+ceJE9e7dW3fffbfuuecepaWladOmTcrIyCjzdUgkAAAwWXn9ro1evXpp8eLFcjgcevzxx9WkSROtW7dO7dq1K/MaJBIAAJisvHz7Z0mVhsGDB2vw4MFer8lTGwAAwGtUJAAAMFl5qUiYgUQCAACTWTiPoLUBAAC8R0UCAACT0doAAABes3AeQWsDAAB4j4oEAAAmo7UBAAC8ZuE8gtYGAADwHhUJAABMRmsDAAB4zcJ5BIkEAABms3JFgj0SAADAa1QkAAAwmYULEiQSAACYjdYGAABACahIAABgMgsXJEgkAAAwG60NAACAElCRAADAZBYuSJBIAABgNlobAAAAJaAiAQCAyaxckSCRAADAZBbOI0gkAAAwm5UrEuyRAAAAXqMiAQCAySxckCCRAADAbLQ2AAAASkBFAgAAk1m4IEFFAgAAswXYbD45roXD4ZDNZtO4ceNKPP/YY4/JZrNp9uzZnt3bNUUFAADKvaysLC1ZskTx8fElnt+wYYO2b9+u6Ohoj9cmkQAAwGQ2m28Ob+Tm5qpfv35aunSpqlatWuz8t99+qzFjxujVV19VUFCQx+uTSAAAYDKbzeaTw+l06ty5c26H0+m86rVHjx6t5ORkJSUlFTtXVFSk/v37a+LEiWrevLlX90YiAQCAyQJsvjkcDociIiLcDofDUep1U1NTtWvXrlLnzJw5U4GBgXr88ce9vjee2gAA4AaRkpKi8ePHu43Z7fYS5x47dkxjx45Venq6goODi53fuXOn5syZo127dl3Tey6oSAAAYDJftTbsdrvCw8PdjtISiZ07dyonJ0dt2rRRYGCgAgMDlZmZqblz5yowMFAZGRnKyclRvXr1XOePHDmiCRMmKCYmpsz3RkUCAACT+eM9Ep06ddLevXvdxgYNGqSmTZtq0qRJqlWrlrp06eJ2vkuXLurfv78GDRpU5uuQSAAAYEFhYWFq0aKF21hoaKgiIyNd45GRkW7ng4KCFBUVpSZNmpT5OiQSAACYzCbrvtqSRAIAAJMFlJM8IiMj46rnDx8+7PGabLYEAABeoyIBAIDJrPw14iQSAACYzMJ5BK0NAADgPSoSAACY7Fq/Arw8I5EAAMBkFs4jSCQAADCblTdbskcCAAB4jYoEAAAms3BBgkQCAACzWXmzJa0NAADgNSoSAACYzLr1CBIJAABMx1MbAAAAJaAiAQCAycrL14ibgUQCAACT0doAAAAoARUJAABMZuGCBIkEAABms3Jrg0QCAACTWXmzJXskAACA17xKJNasWaPf/e53io6O1pEjRyRJs2fP1t///nefBgcAgBXYbDafHOWRx4nEokWLNH78eHXv3l1nzpxRYWGhJKlKlSqaPXu2r+MDAOCGZ/PRUR55nEjMmzdPS5cu1ZQpU1ShQgXX+G233aa9e/f6NDgAAFC+ebzZ8tChQ2rdunWxcbvdrry8PJ8EBQCAlfA14j/ToEED7dmzp9j4e++9p7i4OF/EBACApdhsvjnKI48rEhMnTtTo0aOVn58vwzD06aef6vXXX5fD4dArr7xiRowAAKCc8jiRGDRokC5fvqynnnpKFy5cUN++fVW7dm3NmTNHffr0MSNGAABuaOX1iQtf8OqFVMOGDdOwYcN06tQpFRUVqUaNGr6OCwAAy7BwHnFtb7a86aabfBUHAAC4AXm12bJhw4alHgAAwF2AzeaT41o4HA7ZbDaNGzdOklRQUKBJkybplltuUWhoqKKjo/WHP/xB3333nUfrelyRuBLAFQUFBdq9e7fS0tI0ceJET5cDAMDy/N3ayMrK0pIlSxQfH+8au3Dhgnbt2qVnnnlGLVu21I8//qhx48bp/vvv144dO8q8tseJxNixY0scX7BggUcXBgDgt8Kfmy1zc3PVr18/LV26VNOnT3eNR0RE6P3333ebO2/ePN1xxx06evSo6tWrV6b1ffalXd26ddO6det8tRwAAPgFp9Opc+fOuR1Op/Oqnxk9erSSk5OVlJT0q+ufPXtWNptNVapUKXNMPvsa8b/97W+qVq2ar5a7Jh8tXePvEIByaUKtcH+HAJQ7C3o1M/0avvpXu8Ph0HPPPec2NnXqVE2bNq3E+ampqdq1a5eysrJ+de38/Hw9/fTT6tu3r8LDy/7/FR4nEq1bt3Yr0RiGoezsbH3//fdauHChp8sBAGB5vmptpKSkaPz48W5jdru9xLnHjh3T2LFjlZ6eruDg4KuuW1BQoD59+qioqMjjv8s9TiQeeOABt58DAgJUvXp1dejQQU2bNvV0OQAAUEZ2u73UxOGXdu7cqZycHLVp08Y1VlhYqI8++kjz58+X0+lUhQoVVFBQoEceeUSHDh3S5s2bPapGSB4mEpcvX1ZMTIy6dOmiqKgojy4EAMBvVYAf9lp26tSp2LdyDxo0SE2bNtWkSZPckogvv/xSW7ZsUWRkpMfX8SiRCAwM1MiRI7V//36PLwQAwG+VPxKJsLAwtWjRwm0sNDRUkZGRatGihS5fvqyHH35Yu3bt0ttvv63CwkJlZ2dLkqpVq6aKFSuW6ToetzYSEhK0e/du1a9f39OPAgCAcuL48ePauHGjJKlVq1Zu57Zs2aIOHTqUaR2PE4lRo0ZpwoQJOn78uNq0aaPQ0FC38z9/2QUAACg/X9qVkZHh+u8xMTEyDOOa1yxzIjF48GDNnj1bvXv3liQ9/vjjrnM2m02GYchms6mwsPCagwIAwEr80dq4XsqcSKxatUozZszQoUOHzIwHAADcQMqcSFwpf7A3AgAAz5STzoYpPNojUV56PAAA3Eiu9Zs7yzOPEonY2NhfTSZ++OGHawoIAACr8dkXW5VDHiUSzz33nCIiIsyKBQAA3GA8SiT69OmjGjVqmBULAACWZOHORtkTCfZHAADgHSvvkShz28YXL60AAADWUuaKRFFRkZlxAABgWRYuSHj+imwAAOAZK7/Z0spPpAAAAJNRkQAAwGRW3mxJIgEAgMksnEfQ2gAAAN6jIgEAgMmsvNmSRAIAAJPZZN1MgkQCAACTWbkiwR4JAADgNSoSAACYzMoVCRIJAABMZuUvvqS1AQAAvEZFAgAAk9HaAAAAXrNwZ4PWBgAA8B4VCQAATMaXdgEAAK9ZeY8ErQ0AAOA1KhIAAJjMwp0NEgkAAMwWYOEv7aK1AQCAyWw23xzXwuFwyGazady4ca4xwzA0bdo0RUdHKyQkRB06dNC+ffs8WpdEAgAAi8vKytKSJUsUHx/vNj5r1iy99NJLmj9/vrKyshQVFaXOnTvr/PnzZV6bRAIAAJMF2HxzeCM3N1f9+vXT0qVLVbVqVde4YRiaPXu2pkyZogcffFAtWrTQqlWrdOHCBb322mtlvzfvwgIAAGUVYLP55HA6nTp37pzb4XQ6r3rt0aNHKzk5WUlJSW7jhw4dUnZ2tu69917XmN1uV/v27fXJJ5+U/d48+1UAAAB/cTgcioiIcDscDkep81NTU7Vr164S52RnZ0uSatas6TZes2ZN17my4KkNAABM5qvHP1NSUjR+/Hi3MbvdXuLcY8eOaezYsUpPT1dwcPBVYnMPzjAMj772nEQCAACT+eoV2Xa7vdTE4Zd27typnJwctWnTxjVWWFiojz76SPPnz9eBAwck/VSZqFWrlmtOTk5OsSrF1dDaAADAgjp16qS9e/dqz549ruO2225Tv379tGfPHjVs2FBRUVF6//33XZ+5dOmSMjMz1bZt2zJfh4oEAAAm88ebLcPCwtSiRQu3sdDQUEVGRrrGx40bpxdffFE333yzbr75Zr344ouqVKmS+vbtW+brkEgAAGCy8lr+f+qpp3Tx4kWNGjVKP/74oxISEpSenq6wsLAyr0EiAQDAb0RGRobbzzabTdOmTdO0adO8XpNEAgAAk3nyFMSNhkQCAACTWTeNIJEAAMB0vnr8szwqr/s/AADADYCKBAAAJrNuPYJEAgAA01m4s0FrAwAAeI+KBAAAJuPxTwAA4DUrl/+tfG8AAMBkVCQAADAZrQ0AAOA166YRtDYAAMA1oCIBAIDJaG0AAACvWbn8TyIBAIDJrFyRsHKSBAAATEZFAgAAk1m3HkEiAQCA6Szc2aC1AQAAvEdFAgAAkwVYuLlBIgEAgMlobQAAAJSAigQAACaz0doAAADeorUBAABQAioSAACYjKc2AACA16zc2iCRAADAZFZOJNgjAQAAvEYiAQCAyWw++o8nFi1apPj4eIWHhys8PFyJiYl67733XOdzc3M1ZswY1alTRyEhIWrWrJkWLVrk8b3R2gAAwGQBfmht1KlTRzNmzFDjxo0lSatWrVLPnj21e/duNW/eXE888YS2bNmitWvXKiYmRunp6Ro1apSio6PVs2fPMl+HigQAABbUo0cPde/eXbGxsYqNjdULL7ygypUra9u2bZKkrVu3asCAAerQoYNiYmI0fPhwtWzZUjt27PDoOiQSAACYzFetDafTqXPnzrkdTqfzV69fWFio1NRU5eXlKTExUZLUrl07bdy4Ud9++60Mw9CWLVt08OBBdenSxaN7I5EAAMBkNptvDofDoYiICLfD4XCUet29e/eqcuXKstvtGjFihNavX6+4uDhJ0ty5cxUXF6c6deqoYsWK6tq1qxYuXKh27dp5dG/skQAA4AaRkpKi8ePHu43Z7fZS5zdp0kR79uzRmTNntG7dOg0YMECZmZmKi4vT3LlztW3bNm3cuFH169fXRx99pFGjRqlWrVpKSkoqc0w2wzAMr++onAppPcbfIQDl0uBnR/s7BKDcWdCrmenXyDjwg0/W6dCk2jV9PikpSY0aNdLs2bMVERGh9evXKzk52XV+6NChOn78uNLS0sq8JhUJAABM5o+nNkpiGIacTqcKCgpUUFCggAD3HQ4VKlRQUVGRR2uSSAAAYEGTJ09Wt27dVLduXZ0/f16pqanKyMhQWlqawsPD1b59e02cOFEhISGqX7++MjMztXr1ar300kseXYdEAtdsymPd9d8juruNZZ86pwadJ0uSenZsqSEPtVPrZnV1U9XKSujt0OcHv/VHqIDf3BsbqZ7Na2jzVz9o3d6TCrBJPeKqq3nNyroptKIuFhTqwPd5+vu+73U2/7K/w4WPefoyKV84efKk+vfvrxMnTigiIkLx8fFKS0tT586dJUmpqalKSUlRv3799MMPP6h+/fp64YUXNGLECI+uQyIBn9j31XdKHjHP9XNh0X+23lQKqaitn32ttz7YpUXP9vNHeIBf1asSrN/FVNHxs/musYoVAlS3SrDSDpzS8bNOVQoK0MPxUXrszjqalXHYf8HCFP74ro1ly5Zd9XxUVJRWrFhxzdchkYBPXC4s0snT50s89/o7WZKkerWubZMQcCOyV7Bp4O3Rem33CXVtcpNrPP9ykeb/85jb3Dc/y9akexqoakigfrxIVcJKyskWCVPwHgn4RON61fVN+gva//Y0rZ4xSDG1I/0dElAuPNIqSvuyc3Xg+wu/OjckKEBFhqGLBZ5tdgP86YavSDidzmJv9TKKCmULqOCniH57sr44rKHPrNGXR3JUIzJMTw/tqi0rJ6jNwy/oh7N5/g4P8Js2tcNVNyK4TK2KwACbejavoR3Hzin/MomE1QRY+HvEy0VFIj8/X1OmTFF+fv6vT/6Fkt7ydfnkThOiRGnS//kvbfhwj/Z99Z22bD+gXn/86dvjft8jwc+RAf5TJSRQD8fX1Kod3+ly0dVf1xNgkwbfXls2m01vfJZ9nSLE9WTz0VEe+T2RuHjxou677z5t3rxZBQUFHn8+JSVFZ8+edTsCa7YxIVKU1YX8S9r31XdqVK+6v0MB/KZelWCFBwdq0j0NNLdnU83t2VSx1UPVoVFVze3Z1PWXQoBNGnJHHUWGBmn+P49SjcANx6+tjfz8fCUnJ2v79u2aPn26/vrXv5Y6d/DgwSWO2+32Yq8Hpa3hXxWDAtW0QU39c/dX/g4F8JsD31/Q9A++cRvr36aWTp6/pPSDp2XoP0lEjcpBmvOPo8q7VOifYGG+8lpO8AG/JhJnzpzR7t27JUmbNm1SaW/rttlspSYS8D/HE730zkd7dezEj6pRrbImDe2qsNBgvbppuySpangl1Y2qqlo1IiRJsTE1JUknT58r9UkP4EbnvFykE+edxcZyLxXqxHmnAmzSsIQ6qhsRrEVbjynAJoXbf/pHUN6lQhVa7ssLftv88R6J68WviURUVJTS0tLUtWtX3XvvvXr66af9GQ68VLtmFa12DFJklVCd+jFXn+49rPYD/ldHT/woSUpuf4uW/qm/a/6amT8lhdMXv6sXXn7XLzED/lYlJEjxtcIkSZM7NXQ7N/sfR/TlqV9/ygMoD8rFl3Zt375dvXv31vbt21WzZs1rXo8v7QJKxpd2AcVdjy/t+vSbsz5Z546GET5Zx5fKxeOfCQkJ+vLLLxUUFOTvUAAA8DnrNjbKwVMbV5BEAABw4ykXFQkAACzNwiUJEgkAAEzGUxsAAMBrFn5DdvnZIwEAAG48VCQAADCZhQsSJBIAAJjOwpkErQ0AAOA1KhIAAJiMpzYAAIDXeGoDAACgBFQkAAAwmYULEiQSAACYzsKZBK0NAADgNSoSAACYjKc2AACA16z81AaJBAAAJrNwHsEeCQAA4D0qEgAAmM3CJQkSCQAATGblzZa0NgAAsKBFixYpPj5e4eHhCg8PV2Jiot577z23Ofv379f999+viIgIhYWF6c4779TRo0c9ug6JBAAAJrPZfHN4ok6dOpoxY4Z27NihHTt2qGPHjurZs6f27dsnSfr666/Vrl07NW3aVBkZGfrss8/0zDPPKDg42LN7MwzD8Cy08i+k9Rh/hwCUS4OfHe3vEIByZ0GvZqZfY/93eT5Zp1l06DV9vlq1avqf//kfDRkyRH369FFQUJDWrFlzTWtSkQAA4AbhdDp17tw5t8PpdP7q5woLC5Wamqq8vDwlJiaqqKhI77zzjmJjY9WlSxfVqFFDCQkJ2rBhg8cxkUgAAGA2m28Oh8OhiIgIt8PhcJR62b1796py5cqy2+0aMWKE1q9fr7i4OOXk5Cg3N1czZsxQ165dlZ6erl69eunBBx9UZmamZ7dGawP47aC1ARR3PVob/z5xwSfrNKhWoVgFwm63y263lzj/0qVLOnr0qM6cOaN169bplVdeUWZmpqpUqaLatWvr0Ucf1Wuvveaaf//99ys0NFSvv/56mWPi8U8AAG4QV0saSlKxYkU1btxYknTbbbcpKytLc+bM0bx58xQYGKi4uDi3+c2aNdPHH3/sUUwkEgAAmKy8fNeGYRhyOp2qWLGibr/9dh04cMDt/MGDB1W/fn2P1iSRAADAZP7IIyZPnqxu3bqpbt26On/+vFJTU5WRkaG0tDRJ0sSJE9W7d2/dfffduueee5SWlqZNmzYpIyPDo+uQSAAAYDY/ZBInT55U//79deLECUVERCg+Pl5paWnq3LmzJKlXr15avHixHA6HHn/8cTVp0kTr1q1Tu3btPLoOmy2B3xA2WwLFXY/NlgdP+mazZWzNSj5Zx5eoSAAAYDIrf9cGiQQAACYrL5stzcALqQAAgNeoSAAAYDILFyRIJAAAMJ2FMwlaGwAAwGtUJAAAMBlPbQAAAK/x1AYAAEAJqEgAAGAyCxckSCQAADCdhTMJEgkAAExm5c2W7JEAAABeoyIBAIDJrPzUBokEAAAms3AeQWsDAAB4j4oEAAAmo7UBAACugXUzCVobAADAa1QkAAAwGa0NAADgNQvnEbQ2AACA96hIAABgMlobAADAa1b+rg0SCQAAzGbdPII9EgAAwHtUJAAAMJmFCxIkEgAAmM3Kmy1pbQAAAK9RkQAAwGRWfmqDigQAAGaz+ejwwKJFixQfH6/w8HCFh4crMTFR7733XolzH3vsMdlsNs2ePdvjWyORAADAgurUqaMZM2Zox44d2rFjhzp27KiePXtq3759bvM2bNig7du3Kzo62qvrkEgAAGAyPxQk1KNHD3Xv3l2xsbGKjY3VCy+8oMqVK2vbtm2uOd9++63GjBmjV199VUFBQV7dG3skAAAwma+e2nA6nXI6nW5jdrtddrv9qp8rLCzUX//6V+Xl5SkxMVGSVFRUpP79+2vixIlq3ry51zFRkQAA4AbhcDgUERHhdjgcjlLn7927V5UrV5bdbteIESO0fv16xcXFSZJmzpypwMBAPf7449cUExUJAABM5qunNlJSUjR+/Hi3satVI5o0aaI9e/bozJkzWrdunQYMGKDMzExdvHhRc+bM0a5du2S7xnKJzTAM45pWKIdCWo/xdwhAuTT42dH+DgEodxb0amb6NX68UOiTdapWqnBNn09KSlKjRo3UrFkzjR8/XgEB/2lMFBYWKiAgQHXr1tXhw4fLvCYVCQAAfiMMw5DT6VT//v2VlJTkdq5Lly7q37+/Bg0a5NGaJBIAAFjQ5MmT1a1bN9WtW1fnz59XamqqMjIylJaWpsjISEVGRrrNDwoKUlRUlJo0aeLRdUgkAAAwmT++a+PkyZPq37+/Tpw4oYiICMXHxystLU2dO3f26XVIJAAAMJk/XpG9bNkyj+Z7si/i53j8EwAAeI2KBAAAJrPy14iTSAAAYDIL5xG0NgAAgPeoSAAAYDYLlyRIJAAAMJk/ntq4XmhtAAAAr1GRAADAZDy1AQAAvGbhPIJEAgAA01k4k2CPBAAA8BoVCQAATGblpzZIJAAAMJmVN1vS2gAAAF6zGYZh+DsIWJPT6ZTD4VBKSorsdru/wwHKDf5swEpIJGCac+fOKSIiQmfPnlV4eLi/wwHKDf5swEpobQAAAK+RSAAAAK+RSAAAAK+RSMA0drtdU6dOZTMZ8Av82YCVsNkSAAB4jYoEAADwGokEAADwGokEAADwGokETJedna3c3Fx/hwGUKydOnNDFixf9HQZwzUgkYLo+ffooNTXV32EA5cb27dvVrFkzde/eXRcuXPB3OMA1IZEAgOto+/bt6tKli5xOp7Zt26b77ruPZAI3NBIJALhOLl26pEceeURPPfWUEhISNH36dOXl5en555/3d2iA1wL9HQAA/FZUrFhR27ZtU61atZSenq6IiAilp6crKCjI36EBXiORAIDrqFatWm4/R0RE+CkSwDdobQAAAK+RSMA0e/bs0c/fwH78+HGdOnXKjxEBAHyNRAKmuHTpkh588EGNHDlShmHo+PHjuueeezRnzhx/hwYA8CH2SMAUFStWVHp6ujp06KATJ07o448/Vu/evTVt2jR/hwYA8CEqEjBN48aNlZGRoVq1aumRRx7RmjVrVKFCBX+HBQDwIb5GHKa7dOmSgoKCZLPZ/B0KAMDHSCQAAIDXaG0AAACvkUgAAACvkUgAAACvkUgAAACvkUgAAACvkUgAAACvkUgAFjRt2jS1atXK9fPAgQP1wAMPXPc4Dh8+LJvNpj179lz3awO4PkgkgOto4MCBstlsstlsCgoKUsOGDfXkk08qLy/P1OvOmTNHK1euLNNc/vIH4Am+awO4zrp27aoVK1aooKBA//jHPzR06FDl5eVp0aJFbvMKCgoUFBTkk2tGRET4ZB0A+CUqEsB1ZrfbFRUVpbp166pv377q16+fNmzY4GpHLF++XA0bNpTdbpdhGDp79qyGDx+uGjVqKDw8XB07dtRnn33mtuaMGTNUs2ZNhYWFaciQIcrPz3c7/8vWRlFRkWbOnKnGjRvLbrerXr16euGFFyRJDRo0kCS1bt1aNptNHTp0cH1uxYoVatasmYKDg9W0aVMtXLjQ7TqffvqpWrdureDgYN12223avXu3D39zAMojKhKAn4WEhKigoECS9NVXX+nNN9/UunXrXF9wlpycrGrVqundd99VRESEXn75ZXXq1EkHDx5UtWrV9Oabb2rq1KlasGCB7rrrLq1Zs0Zz585Vw4YNS71mSkqKli5dqr/85S9q166dTpw4oX//+9+SfkoG7rjjDn3wwQdq3ry5KlasKElaunSppk6dqvnz56t169bavXu3hg0bptDQUA0YMEB5eXm677771LFjR61du1aHDh3S2LFjTf7tAfA7A8B1M2DAAKNnz56un7dv325ERkYajzzyiDF16lQjKCjIyMnJcZ3/8MMPjfDwcCM/P99tnUaNGhkvv/yyYRiGkZiYaIwYMcLtfEJCgtGyZcsSr3vu3DnDbrcbS5cuLTHGQ4cOGZKM3bt3u43XrVvXeO2119zGnn/+eSMxMdEwDMN4+eWXjWrVqhl5eXmu84sWLSpxLQDWQWsDuM7efvttVa5cWcHBwUpMTNTdd9+tefPmSZLq16+v6tWru+bu3LlTubm5ioyMVOXKlV3HoUOH9PXXX0uS9u/fr8TERLdr/PLnn9u/f7+cTqc6depU5pi///57HTt2TEOGDHGLY/r06W5xtGzZUpUqVSpTHACsgdYGcJ3dc889WrRokYKCghQdHe22oTI0NNRtblFRkWrVqqWMjIxi61SpUsWr64eEhHj8maKiIkk/tTcSEhLczl1pwRh8kTDwm0QiAVxnoaGhaty4cZnm3nrrrcrOzlZgYKBiYmJKnNOsWTNt27ZNf/jDH1xj27ZtK3XNm2++WSEhIfrwww81dOjQYuev7IkoLCx0jdWsWVO1a9fWN998o379+pW4blxcnNasWaOLFy+6kpWrxQHAGmhtAOVYUlKSEhMT9cADD+j//u//dPjwYX3yySf67//+b+3YsUOSNHbsWC1fvlzLly/XwYMHNXXqVO3bt6/UNYODgzVp0iQ99dRTWr16tb7++mtt27ZNy5YtkyTVqFFDISEhSktL08mTJ3X27FlJP73kyuFwaM6cOTp48KD27t2rFStW6KWXXpIk9e3bVwEBARoyZIj+9a9/6d1339Wf//xnk39DAPyNRAIox2w2m959913dfffdGjx4sGJjY9WnTx8dPnxYNWvWlCT17t1bzz77rCZNmqQ2bdroyJEjGjly5FXXfeaZZzRhwgQ9++yzatasmXr37q2cnBxJUmBgoObOnauXX35Z0dHR6tmzpyRp6NCheuWVV7Ry5Urdcsstat++vVauXOl6XLRy5cratGmT/vWvf6l169aaMmWKZs6caeJvB0B5YDNobAIAAC9RkQAAAF4jkQAAAF4jkQAAAF4jkQAAAF4jkQAAAF4jkQAAAF4jkQAAAF4jkQAAAF4jkQAAAF4jkQAAAF4jkQAAAF4jkQAAAF77f0/DXAMccpCSAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           ‚Üì       0.46      0.57      0.51        77\n",
      "           ‚Üë       0.56      0.45      0.50        93\n",
      "\n",
      "    accuracy                           0.51       170\n",
      "   macro avg       0.51      0.51      0.51       170\n",
      "weighted avg       0.52      0.51      0.51       170\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(labels, preds)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"‚Üì\", \"‚Üë\"], yticklabels=[\"‚Üì\", \"‚Üë\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(labels, preds, target_names=[\"‚Üì\", \"‚Üë\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2eeb7d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a7da21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
