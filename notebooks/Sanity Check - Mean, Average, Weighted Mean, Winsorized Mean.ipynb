{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e062bcb7",
   "metadata": {},
   "source": [
    "# Sanity check - Rolling method efficiency\n",
    "Will test how well the agent preforms using different rolling methods to understand if exists any superior method.\n",
    "\n",
    "## Final Report \n",
    "\n",
    "* The highest rewards are consistently when testing on rolling_median (column 2), regardless of training regime (all around -1036).\n",
    "\n",
    "* When testing on rolling_weighted_mean or rolling_winsorized_mean, rewards are much lower (more negative), suggesting those regimes are harder or the agent doesnâ€™t generalize as well to them.\n",
    "\n",
    "* Training regime has less effect than testing regimeâ€”all training regimes seem to generalize similarly to testing on rolling_median.\n",
    "\n",
    "\n",
    "* rolling_median is the easiest regime for the agent to perform on (highest rewards across all rows in that column).\n",
    "\n",
    "* rolling_weighted_mean and rolling_winsorized_mean are harder regimes or less well captured by your agent (much lower rewards).\n",
    "\n",
    "* Agents trained on any regime do about equally well when tested on the rolling_median regime."
   ]
  },
  {
   "cell_type": "raw",
   "id": "9498bf96",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(er=0\n",
    "    df,\n",
    "    annot=True, fmt=\".1f\", cmap=\"RdYlGn\", cent,\n",
    "    linewidths=0.5, linecolor='black'\n",
    ")\n",
    "plt.title(\"Train/Test Regime Mean Total Reward\\n(rows=train, cols=test)\")\n",
    "plt.xlabel(\"Test Regime\")\n",
    "plt.ylabel(\"Train Regime\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "41843731",
   "metadata": {},
   "source": [
    "df[\"Train avg\"] = df.mean(axis=1)\n",
    "df.loc[\"Test avg\"] = df.mean(axis=0)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70ec8c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWhat to Look For\\nGreener cells = better agent performance\\n\\nDiagonal: Generalization to same regime\\n\\nOff-diagonal: Generalization across regimes\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "What to Look For\n",
    "Greener cells = better agent performance\n",
    "\n",
    "Diagonal: Generalization to same regime\n",
    "\n",
    "Off-diagonal: Generalization across regimes\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a54dfc58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francisco SÃ¡\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\arrays\\masked.py:61: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "# Store Sales Forecasting - Real Dataset with RMSLE Optimization\n",
    "import jupyter\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "from scipy.stats import mstats\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from src.utils.system import boot,notify\n",
    "from src.experiments.experiment_tracker import ExperimentTracker\n",
    "\n",
    "boot()\n",
    "\n",
    "experience_name = \"sanity-check__evaluate_efficiency_of_averaging_policies\"\n",
    "target_date = \"2025-06-01\"\n",
    "experiment_tracker = ExperimentTracker(experience_name)\n",
    "config={\n",
    "    \"dataset\":\"kaggle-sales-prediction\",\n",
    "    \"model\": \"xgb.XGBRegressor\"\n",
    "}\n",
    "\n",
    "features = [\n",
    "        'store_nbr', 'family', 'dayofweek', 'month', 'day', 'week', 'is_holiday',\n",
    "        'transactions', 'lag_7', 'lag_14', 'trans_lag_7', 'trans_lag_14',\n",
    "        'rolling_mean_7', 'rolling_std_7', 'rolling_mean_14', 'rolling_std_14',\n",
    "        'trans_roll_mean_7', 'trans_roll_mean_14',\n",
    "        'onpromo_lag_7', 'onpromo_mean_14'\n",
    "]\n",
    "\n",
    "run_settings={\n",
    "    \"n_estimators\":750, \n",
    "    \"learning_rate\":0.05, \n",
    "    \"max_depth\":6, \n",
    "    \"random_state\":42,\n",
    "    \"regime\": \"rolling_mean\",\n",
    "    \"features\": features.copy()\n",
    "}\n",
    "run_settings[\"features\"].sort()\n",
    "\n",
    "\n",
    "#def save_run(\n",
    "#        self,\n",
    "#        config: Dict,\n",
    "#        results: Dict,\n",
    "#        target_date: str,\n",
    "#        run_settings: Dict,\n",
    "#        files: Optional[Dict] = None\n",
    "#    ) -> None:\n",
    "#        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712a6ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ExecutionTimeTracker]::preprocess_dataset - Start.\n",
      "[ExecutionTimeTracker]::preprocess_dataset - Complete. Took 5s to complete.\n",
      "\n",
      "rolling_mean\n",
      "Preprocessing features\n",
      "[ExecutionTimeTracker]::preprocess_feature_dataset - Start.\n",
      "Loaded cached features from data/experiments/kaggle-sales-prediction/rolling_mean__train.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francisco SÃ¡\\AppData\\Local\\Temp\\ipykernel_13616\\283564385.py:182: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[features].dropna(inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ExecutionTimeTracker]::preprocess_feature_dataset - Complete. Took 13s to complete.\n",
      "\n",
      "[ExecutionTimeTracker]::xgb_train__1000 - Start.\n",
      "[0]\tvalidation_0-rmse:2.94891\n",
      "[25]\tvalidation_0-rmse:0.96020\n",
      "[50]\tvalidation_0-rmse:0.53333\n",
      "[75]\tvalidation_0-rmse:0.47142\n",
      "[100]\tvalidation_0-rmse:0.45699\n",
      "[125]\tvalidation_0-rmse:0.44896\n",
      "[150]\tvalidation_0-rmse:0.44246\n",
      "[175]\tvalidation_0-rmse:0.43695\n",
      "[200]\tvalidation_0-rmse:0.43176\n",
      "[225]\tvalidation_0-rmse:0.42857\n",
      "[250]\tvalidation_0-rmse:0.42601\n",
      "[275]\tvalidation_0-rmse:0.42276\n",
      "[300]\tvalidation_0-rmse:0.42005\n",
      "[325]\tvalidation_0-rmse:0.41717\n",
      "[350]\tvalidation_0-rmse:0.41539\n",
      "[375]\tvalidation_0-rmse:0.41239\n",
      "[400]\tvalidation_0-rmse:0.41055\n",
      "[425]\tvalidation_0-rmse:0.40869\n",
      "[450]\tvalidation_0-rmse:0.40693\n",
      "[475]\tvalidation_0-rmse:0.40552\n",
      "[500]\tvalidation_0-rmse:0.40401\n",
      "[525]\tvalidation_0-rmse:0.40276\n",
      "[550]\tvalidation_0-rmse:0.40186\n",
      "[575]\tvalidation_0-rmse:0.40095\n",
      "[600]\tvalidation_0-rmse:0.40049\n",
      "[625]\tvalidation_0-rmse:0.39984\n",
      "[650]\tvalidation_0-rmse:0.39931\n",
      "[675]\tvalidation_0-rmse:0.39886\n",
      "[700]\tvalidation_0-rmse:0.39796\n",
      "[725]\tvalidation_0-rmse:0.39738\n",
      "[749]\tvalidation_0-rmse:0.39667\n",
      "[ExecutionTimeTracker]::xgb_train__1000 - Complete. Took 213s to complete.\n",
      "\n",
      "RMSLE:0.3917, 0.3967,0.3825\n",
      "rolling_median\n",
      "Preprocessing features\n",
      "[ExecutionTimeTracker]::preprocess_feature_dataset - Start.\n",
      "Loaded cached features from data/experiments/kaggle-sales-prediction/rolling_median__train.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francisco SÃ¡\\AppData\\Local\\Temp\\ipykernel_13616\\283564385.py:182: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[features].dropna(inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ExecutionTimeTracker]::preprocess_feature_dataset - Complete. Took 14s to complete.\n",
      "\n",
      "[ExecutionTimeTracker]::xgb_train__1000 - Start.\n",
      "[0]\tvalidation_0-rmse:2.94880\n",
      "[25]\tvalidation_0-rmse:0.95748\n",
      "[50]\tvalidation_0-rmse:0.52200\n",
      "[75]\tvalidation_0-rmse:0.46010\n",
      "[100]\tvalidation_0-rmse:0.44767\n",
      "[125]\tvalidation_0-rmse:0.44123\n",
      "[150]\tvalidation_0-rmse:0.43642\n",
      "[175]\tvalidation_0-rmse:0.43209\n",
      "[200]\tvalidation_0-rmse:0.42813\n",
      "[225]\tvalidation_0-rmse:0.42440\n",
      "[250]\tvalidation_0-rmse:0.42149\n",
      "[275]\tvalidation_0-rmse:0.41924\n",
      "[300]\tvalidation_0-rmse:0.41721\n",
      "[325]\tvalidation_0-rmse:0.41485\n",
      "[350]\tvalidation_0-rmse:0.41463\n",
      "[375]\tvalidation_0-rmse:0.41274\n",
      "[400]\tvalidation_0-rmse:0.41045\n",
      "[425]\tvalidation_0-rmse:0.40945\n",
      "[450]\tvalidation_0-rmse:0.40896\n",
      "[475]\tvalidation_0-rmse:0.40843\n",
      "[500]\tvalidation_0-rmse:0.40759\n",
      "[525]\tvalidation_0-rmse:0.40671\n",
      "[550]\tvalidation_0-rmse:0.40678\n",
      "[575]\tvalidation_0-rmse:0.40693\n",
      "[600]\tvalidation_0-rmse:0.40632\n",
      "[625]\tvalidation_0-rmse:0.40648\n",
      "[650]\tvalidation_0-rmse:0.40583\n",
      "[675]\tvalidation_0-rmse:0.40574\n",
      "[700]\tvalidation_0-rmse:0.40528\n",
      "[725]\tvalidation_0-rmse:0.40524\n",
      "[749]\tvalidation_0-rmse:0.40460\n",
      "[ExecutionTimeTracker]::xgb_train__1000 - Complete. Took 208s to complete.\n",
      "\n",
      "RMSLE:0.3974, 0.4046,0.3850\n",
      "rolling_weighted_mean\n",
      "Preprocessing features\n",
      "[ExecutionTimeTracker]::preprocess_feature_dataset - Start.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francisco SÃ¡\\AppData\\Local\\Temp\\ipykernel_13616\\283564385.py:182: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[features].dropna(inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ExecutionTimeTracker]::preprocess_feature_dataset - Complete. Took 611s to complete.\n",
      "\n",
      "[ExecutionTimeTracker]::xgb_train__1000 - Start.\n",
      "[0]\tvalidation_0-rmse:2.94881\n",
      "[25]\tvalidation_0-rmse:0.95645\n",
      "[50]\tvalidation_0-rmse:0.52083\n",
      "[75]\tvalidation_0-rmse:0.45934\n",
      "[100]\tvalidation_0-rmse:0.44571\n",
      "[125]\tvalidation_0-rmse:0.43731\n",
      "[150]\tvalidation_0-rmse:0.43127\n",
      "[175]\tvalidation_0-rmse:0.42606\n",
      "[200]\tvalidation_0-rmse:0.42172\n",
      "[225]\tvalidation_0-rmse:0.41874\n",
      "[250]\tvalidation_0-rmse:0.41564\n",
      "[275]\tvalidation_0-rmse:0.41280\n",
      "[300]\tvalidation_0-rmse:0.41015\n",
      "[325]\tvalidation_0-rmse:0.40822\n",
      "[350]\tvalidation_0-rmse:0.40573\n",
      "[375]\tvalidation_0-rmse:0.40391\n",
      "[400]\tvalidation_0-rmse:0.40260\n",
      "[425]\tvalidation_0-rmse:0.40098\n",
      "[450]\tvalidation_0-rmse:0.39997\n",
      "[475]\tvalidation_0-rmse:0.39882\n",
      "[500]\tvalidation_0-rmse:0.39736\n",
      "[525]\tvalidation_0-rmse:0.39657\n",
      "[550]\tvalidation_0-rmse:0.39571\n",
      "[575]\tvalidation_0-rmse:0.39463\n",
      "[600]\tvalidation_0-rmse:0.39372\n",
      "[625]\tvalidation_0-rmse:0.39260\n",
      "[650]\tvalidation_0-rmse:0.39174\n",
      "[675]\tvalidation_0-rmse:0.39094\n",
      "[700]\tvalidation_0-rmse:0.39030\n",
      "[725]\tvalidation_0-rmse:0.38971\n",
      "[749]\tvalidation_0-rmse:0.38921\n",
      "[ExecutionTimeTracker]::xgb_train__1000 - Complete. Took 175s to complete.\n",
      "\n",
      "RMSLE:0.3876, 0.3892,0.3896\n",
      "rolling_winsorized_mean\n",
      "Preprocessing features\n",
      "[ExecutionTimeTracker]::preprocess_feature_dataset - Start.\n"
     ]
    }
   ],
   "source": [
    "# Store Sales Forecasting - Real Dataset with RMSLE Optimization\n",
    "import jupyter\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from scipy.stats import mstats\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from src.utils.system import boot,notify\n",
    "\n",
    "\n",
    "boot()\n",
    "\n",
    "\n",
    "class ExecutionTimeTracker:\n",
    "    def __init__(self,name):\n",
    "        self.name = name\n",
    "        self.start = time.time()\n",
    "        self.end = None\n",
    "        self.signature = f\"[ExecutionTimeTracker]::{self.name} -\"\n",
    "        print(f\"{self.signature} Start.\")\n",
    "\n",
    "    def done(self):\n",
    "        if self.end == None:\n",
    "            self.end =time.time()\n",
    "            self.duration = self.end -self.start\n",
    "            \n",
    "        print(f\"{self.signature} Complete. Took {int(self.end-self.start)}s to complete.\")\n",
    "        print('')\n",
    "        \n",
    "# REGIME FUNCTIONS =================================================\n",
    "def rolling_mean(x):\n",
    "    if len(x) == 0 or np.all(np.isnan(x)):\n",
    "        return np.nan\n",
    "    return np.nanmean(x)\n",
    "\n",
    "def rolling_median(x):\n",
    "    if len(x) == 0 or np.all(np.isnan(x)):\n",
    "        return np.nan\n",
    "    return np.nanmedian(x)\n",
    "\n",
    "def rolling_weighted_mean(x): \n",
    "    if len(x) == 0 or np.all(np.isnan(x)):\n",
    "        return np.nan\n",
    "    weights = np.arange(1, len(x)+1)\n",
    "    valid = ~np.isnan(x)\n",
    "    if np.sum(valid) == 0:\n",
    "        return np.nan\n",
    "    return np.average(x[valid], weights=weights[valid])\n",
    "\n",
    "def rolling_winsorized_mean(x):\n",
    "    if len(x) < 2 or np.all(np.isnan(x)):\n",
    "        return np.nan\n",
    "    x_clean = x[~np.isnan(x)]\n",
    "    if len(x_clean) < 2:\n",
    "        return np.nan\n",
    "    return mstats.winsorize(x_clean, limits=(0.1, 0.1)).mean()\n",
    "\n",
    "# REGIME FUNCTIONS REGISTRY =======================================\n",
    "regimes = {\n",
    "    'rolling_mean': rolling_mean,\n",
    "    'rolling_median': rolling_median,\n",
    "    'rolling_weighted_mean': rolling_weighted_mean,\n",
    "    'rolling_winsorized_mean': rolling_winsorized_mean,\n",
    "}\n",
    "\n",
    "# Feature engineering pipeline with regime-based rolling =========\n",
    "def add_lag_rolling(df, train_func, train_name, lag_days=[7, 14], rolling_windows=[7, 14],mode=\"train\"):\n",
    "    FOLDER = 'data/experiments/kaggle-sales-prediction/'\n",
    "    file_path = os.path.join(FOLDER, train_name+'__'+mode+'.csv')\n",
    "    exists = os.path.exists(file_path)\n",
    "    \n",
    "    if exists:\n",
    "        cached_df = pd.read_csv(file_path, parse_dates=['date'])\n",
    "        if not cached_df.empty:\n",
    "            print(f\"Loaded cached features from {file_path}\")\n",
    "            return cached_df\n",
    "    \n",
    "    df = df.sort_values(['store_nbr', 'family', 'date'])\n",
    "\n",
    "    for lag in [7, 14]:\n",
    "        df[f'lag_{lag}'] = df.groupby(['store_nbr', 'family'])['sales'].shift(lag)\n",
    "        df[f'trans_lag_{lag}'] = df.groupby(['store_nbr'])['transactions'].shift(lag)\n",
    "\n",
    "    for window in [7, 14]:\n",
    "        df[f'rolling_mean_{window}'] = df.groupby(['store_nbr', 'family'])['sales'].transform(lambda x: x.shift(1).rolling(window, min_periods=1).apply(train_func, raw=True))#.shift(1)#.rolling(window, min_periods=1).mean()\n",
    "        df[f'rolling_std_{window}'] = df.groupby(['store_nbr', 'family'])['sales'].shift(1).rolling(window, min_periods=1).std()\n",
    "        df[f'trans_roll_mean_{window}'] = df.groupby(['store_nbr'])['transactions'].transform(lambda x: x.shift(1).rolling(window, min_periods=1).apply(train_func, raw=True))#.shift(1)#.rolling(window, min_periods=1).mean()\n",
    "\n",
    "    df['onpromo_lag_7'] = df.groupby(['store_nbr', 'family'])['onpromotion'].shift(7)\n",
    "    df['onpromo_mean_14'] = df.groupby(['store_nbr', 'family'])['onpromotion'].transform(lambda x: x.shift(1).rolling(14, min_periods=1).apply(train_func, raw=True))#.shift(1)#.rolling(14, min_periods=1).mean()\n",
    "\n",
    "    df.to_csv(file_path, index=False)\n",
    "    return df\n",
    "\n",
    "# GENERATE BASE TRAIN/TEST DATASET ======================================\n",
    "\n",
    "\n",
    "def preprocess_dataset():\n",
    "    FOLDER = 'data/experiments/kaggle-sales-prediction/'\n",
    "    _train = pd.read_csv(FOLDER+'train.csv', parse_dates=['date'])\n",
    "    _test = pd.read_csv(FOLDER+'test.csv', parse_dates=['date'])\n",
    "    _stores = pd.read_csv(FOLDER+'stores.csv')\n",
    "    _holidays = pd.read_csv(FOLDER+'holidays_events.csv', parse_dates=['date'])\n",
    "    _transactions = pd.read_csv(FOLDER+'transactions.csv', parse_dates=['date'])\n",
    "    _df = pd.concat([_train,_test]).sort_values(by=\"date\")\n",
    "    _separator = _test.iloc[0]['date']\n",
    "    def preprocess(df,stores,holidays,transactions):\n",
    "        train = df\n",
    "        \n",
    "        # 2. Merge External Features\n",
    "        train = train.merge(stores, on='store_nbr', how='left')\n",
    "        train = train.merge(transactions, on=['date', 'store_nbr'], how='left')\n",
    "\n",
    "        holidays = holidays[(holidays['locale'] == 'National') & (holidays['transferred'] == False)]\n",
    "        holidays = holidays[['date']].drop_duplicates()\n",
    "        holidays['is_holiday'] = 1\n",
    "        train = train.merge(holidays, on='date', how='left')\n",
    "        train['is_holiday'] = train['is_holiday'].fillna(0)\n",
    "\n",
    "        # Merge onpromotion before encoding 'family'\n",
    "        #train = train.merge(test[['date', 'store_nbr', 'family', 'onpromotion']],\n",
    "        #                    on=['date', 'store_nbr', 'family'], how='left')\n",
    "\n",
    "        # Clean up column names\n",
    "        if 'onpromotion_x' in train.columns:\n",
    "            train['onpromotion'] = train['onpromotion_x'].fillna(0).astype(int)\n",
    "            train.drop(columns=['onpromotion_x', 'onpromotion_'], errors='ignore', inplace=True)\n",
    "        else:\n",
    "            train['onpromotion'] = train['onpromotion'].fillna(0).astype(int)\n",
    "\n",
    "        # Now encode 'family'\n",
    "        train['family'] = train['family'].astype('category').cat.codes\n",
    "    \n",
    "        train['dayofweek'] = train['date'].dt.dayofweek\n",
    "        train['month'] = train['date'].dt.month\n",
    "        train['day'] = train['date'].dt.day\n",
    "        train['week'] = train['date'].dt.isocalendar().week.astype(int)\n",
    "        train['transactions'] = train['transactions'].fillna(0)\n",
    "\n",
    "        # 4. Lag and Rolling Features\n",
    "        train = train.sort_values(['store_nbr', 'family', 'date'])\n",
    "        return train\n",
    "    \n",
    "    processed =preprocess(_df.copy(),_stores.copy(),_holidays.copy(),_transactions.copy())\n",
    "    train = processed[processed['date'] < _separator]\n",
    "    test = processed[processed['date'] >= _separator]\n",
    "                      #test  =preprocess(_test.copy(),_stores.copy(),_holidays.copy(),_transactions.copy())\n",
    "    \n",
    "    return train,test\n",
    "\n",
    "def preprocess_feature_dataset(dataset,train_func,train_name,mode):\n",
    "   \n",
    "    df=add_lag_rolling(dataset.copy(),train_func,train_name,mode=mode)\n",
    "    for col in ['lag_7', 'lag_14', 'rolling_mean_7', 'rolling_std_7', 'rolling_mean_14', 'rolling_std_14']:\n",
    "        df[col] = np.log1p(df[col])\n",
    "    for col in ['trans_lag_7', 'trans_lag_14', 'trans_roll_mean_7', 'trans_roll_mean_14']:\n",
    "        df[col] = np.log1p(df[col] + 1e-5)\n",
    "    features = [\n",
    "        'store_nbr', 'family', 'dayofweek', 'month', 'day', 'week', 'is_holiday',\n",
    "        'transactions', 'lag_7', 'lag_14', 'trans_lag_7', 'trans_lag_14',\n",
    "        'rolling_mean_7', 'rolling_std_7', 'rolling_mean_14', 'rolling_std_14',\n",
    "        'trans_roll_mean_7', 'trans_roll_mean_14',\n",
    "\n",
    "        #'store_dow', \n",
    "        #'family_month', \n",
    "        'onpromo_lag_7', 'onpromo_mean_14'\n",
    "    ]\n",
    "                             \n",
    "    \n",
    "    df = df[df[features].notna().all(axis=1)].copy()     \n",
    "                             \n",
    " \n",
    "    df[features].dropna(inplace=True)\n",
    "                      \n",
    "    X = df[features]\n",
    "    y = np.log1p(df['sales'])\n",
    "    if mode ==\"train\":\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "        return X_train,X_val,y_train,y_val\n",
    "    else:\n",
    "        return X,X,y,y\n",
    "    \n",
    "# START EXPERIENCE =====================================================\n",
    "results = {}\n",
    "preprocess_execution_tracker = ExecutionTimeTracker('preprocess_dataset')\n",
    "train_df,test_df = preprocess_dataset()\n",
    "preprocess_execution_tracker.done()                         \n",
    "                             \n",
    "for train_name, train_func in regimes.items():\n",
    "    \n",
    "    run_settings['regime'] = train_name\n",
    "    if experiment_tracker.did_run(config,target_date,run_settings):\n",
    "        continue\n",
    "    else:\n",
    "   \n",
    "        print(train_name)\n",
    "        # 1. Load Dataset\n",
    "\n",
    "        print('Preprocessing features')\n",
    "        preprocess_features_execution_tracker = ExecutionTimeTracker('preprocess_feature_dataset')  \n",
    "\n",
    "        X_train,X_val,y_train,y_val= preprocess_feature_dataset(train_df.copy(),train_func,train_name,\"train\")\n",
    "\n",
    "        _test_val_separator = int(len(X_val)/2)\n",
    "\n",
    "        X_val_full = X_val.copy()\n",
    "        y_val_full = y_val.copy()\n",
    "\n",
    "        X_val = X_val_full.iloc[:_test_val_separator]\n",
    "        X_test = X_val_full.iloc[_test_val_separator:]\n",
    "    \n",
    "        y_val = y_val_full.iloc[:_test_val_separator]\n",
    "        y_test = y_val_full.iloc[_test_val_separator:]\n",
    "\n",
    "\n",
    "        preprocess_features_execution_tracker.done()\n",
    "\n",
    "        xgb_train_execution_tracker = ExecutionTimeTracker('xgb_train__1000')   \n",
    "\n",
    "        model = xgb.XGBRegressor(\n",
    "            n_estimators=run_settings[\"n_estimators\"], \n",
    "            learning_rate=run_settings[\"learning_rate\"], \n",
    "            max_depth=run_settings[\"max_depth\"], \n",
    "            random_state=run_settings[\"random_state\"])\n",
    "\n",
    "        model.fit(X_train, y_train,\n",
    "                  eval_set=[(X_val, y_val)],\n",
    "\n",
    "                  verbose=25)\n",
    "\n",
    "        xgb_train_execution_tracker.done()\n",
    "        y_pred = np.expm1(model.predict(X_train))\n",
    "        y_real = np.expm1(y_train)\n",
    "        rmsle_train = np.sqrt(mean_squared_log_error(y_real, y_pred))\n",
    "\n",
    "        # 6. Evaluation\n",
    "        y_pred = np.expm1(model.predict(X_val))\n",
    "        y_real = np.expm1(y_val)\n",
    "\n",
    "        rmsle_val = np.sqrt(mean_squared_log_error(y_real, y_pred))\n",
    "\n",
    "        y_pred = np.expm1(model.predict(X_test))\n",
    "        y_real = np.expm1(y_test)\n",
    "\n",
    "        rmsle_test = np.sqrt(mean_squared_log_error(y_real, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "        #results[train_name]=[rmsle]\n",
    "        results[train_name]=[rmsle_train,rmsle_val,rmsle_test]\n",
    "\n",
    " \n",
    "        experiment_tracker.save_run(\n",
    "            config,\n",
    "            {\"train\":rmsle_train,\"val\":rmsle_val,\"test\":rmsle_test},\n",
    "            target_date,\n",
    "            run_settings\n",
    "        )\n",
    "        print(f\"RMSLE:{rmsle_train:.4f}, {rmsle_val:.4f},{rmsle_test:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1284e575",
   "metadata": {},
   "source": [
    "### Whatâ€™s a Good Score?\n",
    "For Store Sales (Kaggle):\n",
    "\n",
    "ðŸ¥‰ RMSLE > 0.60 â†’ Baseline or simple model\n",
    "\n",
    "ðŸ¥ˆ RMSLE â‰ˆ 0.45 â†’ Reasonable with lags + rolling + calendar features\n",
    "\n",
    "ðŸ¥‡ RMSLE < 0.40 â†’ Competitive (youâ€™re doing very well)\n",
    "\n",
    "ðŸ† RMSLE < 0.38 â†’ Likely leaderboard top 10%\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44852939",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb1a2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "sns.heatmap(\n",
    "    pd.DataFrame(results),\n",
    "    #er=0,\n",
    "    \n",
    "    annot=True, fmt=\".1f\", cmap=\"RdYlGn\", \n",
    "    linewidths=0.5, linecolor='black'\n",
    "           )\n",
    "#plt.title(\"Train/Test Regime Mean Total Reward\\n(rows=train, cols=test)\")\n",
    "plt.xlabel(\"Test Regime\")\n",
    "plt.ylabel(\"Train Regime\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9eb897",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a01c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dabff3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
